{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d68a359a",
   "metadata": {},
   "source": [
    "## Epoch in Machine Learning\n",
    "Each time a dataset passes through an algorithm, it is said to have completed an epoch. Therefore, Epoch, in machine learning, refers to the one entire passing of training data through the algorithm. It's a hyperparameter that determines the process of training the machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19532806",
   "metadata": {},
   "source": [
    "## What is gradient descent?\n",
    "Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks.  Training data helps these models learn over time, and the cost function within gradient descent specifically acts as a barometer, gauging its accuracy with each iteration of parameter updates. Until the function is close to or equal to zero, the model will continue to adjust its parameters to yield the smallest possible error. Once machine learning models are optimized for accuracy, they can be powerful tools for artificial intelligence (AI) and computer science applications.<br>\n",
    "The goal of gradient descent is to minimize the cost function, or the error between predicted and actual y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41733644",
   "metadata": {},
   "source": [
    "## Learning Rate \n",
    "Learning rate (also referred to as step size or the alpha) is the size of the steps that are taken to reach the minimum. This is typically a small value, and it is evaluated and updated based on the behavior of the cost function. High learning rates result in larger steps but risks overshooting the minimum. Conversely, a low learning rate has small step sizes. While it has the advantage of more precision, the number of iterations compromises overall efficiency as this takes more time and computations to reach the minimum."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "d00de931",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb158bc",
   "metadata": {},
   "source": [
    "## Types of gradient descent\n",
    "### 1. Batch gradient descent \n",
    "Batch gradient descent sums the error for each point in a training set, updating the model only after all training examples have been evaluated. This process referred to as a training epoch.<br>\n",
    "While this batching provides computation efficiency, it can still have a long processing time for large training datasets as it still needs to store all of the data into memory. Batch gradient descent also usually produces a stable error gradient and convergence, but sometimes that convergence point isn’t the most ideal, finding the local minimum versus the global one.\n",
    "### 2. Stochastic gradient descent\n",
    "Stochastic gradient descent (SGD) runs a training epoch for each example within the dataset and it updates each training example's parameters one at a time. Since you only need to hold one training example, they are easier to store in memory. While these frequent updates can offer more detail and speed, it can result in losses in computational efficiency when compared to batch gradient descent. Its frequent updates can result in noisy gradients, but this can also be helpful in escaping the local minimum and finding the global one.\n",
    "### 3. Mini-batch gradient descent \n",
    "Mini-batch gradient descent combines concepts from both batch gradient descent and stochastic gradient descent. It splits the training dataset into small batch sizes and performs updates on each of those batches. This approach strikes a balance between the computational efficiency of batch gradient descent and the speed of stochastic gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b925f7b",
   "metadata": {},
   "source": [
    "## Code for cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec3e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa021d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y_true, y_predicted):\n",
    "    epsilon = 1e-15\n",
    "    y_predicted_new = [max(i,epsilon) for i in y_predicted]\n",
    "    y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]\n",
    "    y_predicted_new = np.array(y_predicted_new)\n",
    "    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6835c59",
   "metadata": {},
   "source": [
    "## Code for activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2da3f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aec744",
   "metadata": {},
   "source": [
    "#### since sigmoid gives continuous value we need to set a thresold above thresold its 1 and below thresold its 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f38e0a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_output(prediction):\n",
    "    return [1 if i>0.5 else 0 for i in prediciton]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f838af02",
   "metadata": {},
   "source": [
    "## Code for gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea9d3a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x1, x2, y_true, alpha = 0.5, epochs = 1000):\n",
    "    \n",
    "    bias = 0\n",
    "    w1 = w2 = 1\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        y_hat = w1*x1 + w2*x2 + bias\n",
    "        # uncomment the line below if you use activation function on output layer. \n",
    "        y_hat = sigmoid(y_hat) # don't forget to define activation function\n",
    "        error = log_loss(y_true,y_hat)\n",
    "\n",
    "        n = len(x1)\n",
    "        df_dw1 = (1/n)*np.dot(np.transpose(x1),(y_hat-y_true))\n",
    "        df_dw2 = (1/n)*np.dot(np.transpose(x2),(y_hat-y_true))\n",
    "        df_db = np.mean((y_hat-y_true))\n",
    "\n",
    "        w1 = w1 - (alpha * df_dw1)\n",
    "        w2 = w2 - (alpha * df_dw2)\n",
    "        bias = bias - (alpha * df_db)\n",
    "        \n",
    "        print('W1:',w1,'W2:',w2,'b',bias,'Loss:',error)\n",
    "    cofficients = (w1,w2,bias)\n",
    "    return cofficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be37551c",
   "metadata": {},
   "source": [
    "## Code for prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8474b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_fun(cofficients,x1,x2):\n",
    "    w1,w2,bias = cofficients\n",
    "    prediction = (w1*x1) + (w2*x2) + bias\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ffad1f",
   "metadata": {},
   "source": [
    "## Implementing our code with simple dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0535196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9517847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  affordibility  bought_insurance\n",
       "0   22              1                 0\n",
       "1   25              0                 0\n",
       "2   47              1                 1\n",
       "3   52              0                 0\n",
       "4   46              1                 1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('insurance_data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39fbaf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling x1 between [0,1] because x2 is ranging [0,1]\n",
    "df['age'] = df['age']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a15c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['age','affordibility']],df.bought_insurance,test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "530ff176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  affordibility\n",
       "0   0.22              1\n",
       "13  0.29              0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed5ab41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 6, 22, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(X_test),len(y_train),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0711aebd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 0.974907633470177 W2: 0.948348125394529 b -0.11341867736368583 Loss: 0.7113403233723417\n",
      "W1: 0.9556229728273669 W2: 0.9058873696677865 b -0.2122349122718517 Loss: 0.681264778737757\n",
      "W1: 0.9416488476693794 W2: 0.8719790823960313 b -0.2977578997796538 Loss: 0.6591474252715025\n",
      "W1: 0.9323916996249162 W2: 0.8457541517722915 b -0.3715094724003511 Loss: 0.6431523291301917\n",
      "W1: 0.9272267472726993 W2: 0.8262362885332687 b -0.43506643026891584 Loss: 0.6316873063379158\n",
      "W1: 0.9255469396815343 W2: 0.8124402814952774 b -0.48994490058938817 Loss: 0.623471707997592\n",
      "W1: 0.9267936114129968 W2: 0.8034375029757677 b -0.5375299543522853 Loss: 0.6175321183044205\n",
      "W1: 0.93047170420295 W2: 0.7983920007454487 b -0.5790424270894963 Loss: 0.6131591858705934\n",
      "W1: 0.9361540784567942 W2: 0.7965748796787705 b -0.6155315088627655 Loss: 0.6098518179750948\n",
      "W1: 0.9434791243557357 W2: 0.7973647616854131 b -0.6478828179413606 Loss: 0.6072639970231438\n",
      "W1: 0.9521448361628082 W2: 0.8002404280558159 b -0.6768343869109611 Loss: 0.6051606942838051\n",
      "W1: 0.9619014360798376 W2: 0.8047697991276092 b -0.7029956527236098 Loss: 0.6033841405177724\n",
      "W1: 0.9725437902239876 W2: 0.8105978078160995 b -0.7268665798879941 Loss: 0.6018292976282692\n",
      "W1: 0.9839042828641819 W2: 0.8174345999952901 b -0.7488554155033402 Loss: 0.6004266142491015\n",
      "W1: 0.9958464546516588 W2: 0.8250447751055391 b -0.769294418817745 Loss: 0.5991301804031037\n",
      "W1: 1.0082595007242081 W2: 0.8332379503132499 b -0.7884533918133878 Loss: 0.5979097221992564\n",
      "W1: 1.0210536111133566 W2: 0.8418606908070436 b -0.8065510935633605 Loss: 0.5967452540340851\n",
      "W1: 1.034156080666481 W2: 0.8507897246509063 b -0.8237647415878959 Loss: 0.5956235357679642\n",
      "W1: 1.0475080939682688 W2: 0.8599263049589658 b -0.8402378469114854 Loss: 0.5945357398126384\n",
      "W1: 1.0610620872868053 W2: 0.8691915649552581 b -0.8560866317233403 Loss: 0.5934759216594547\n",
      "W1: 1.0747795953648005 W2: 0.8785227146485403 b -0.8714052604012273 Loss: 0.5924400203169505\n",
      "W1: 1.0886295007650375 W2: 0.8878699408379153 b -0.8862700880092956 Loss: 0.5914252065214394\n",
      "W1: 1.1025866146156011 W2: 0.8971938890119441 b -0.9007431016492755 Loss: 0.5904294583596238\n",
      "W1: 1.1166305284975315 W2: 0.9064636231844676 b -0.9148747025148294 Loss: 0.5894512852039241\n",
      "W1: 1.130744687166233 W2: 0.9156549761872753 b -0.9287059516737735 Loss: 0.5884895481881011\n",
      "W1: 1.1449156405234902 W2: 0.9247492176815199 b -0.9422703810055986 Loss: 0.5875433434377384\n",
      "W1: 1.1591324407175467 W2: 0.9337319799254573 b -0.9555954523596437 Loss: 0.5866119260562087\n",
      "W1: 1.1733861565198167 W2: 0.9425923921787205 b -0.9687037326284236 Loss: 0.5856946605640079\n",
      "W1: 1.1876694823356402 W2: 0.9513223836938425 b -0.9816138397030203 Loss: 0.5847909885040025\n",
      "W1: 1.2019764234961199 W2: 0.9599161227563919 b -0.994341203820797 Loss: 0.5839004071862915\n",
      "W1: 1.2163020429886013 W2: 0.9683695654077998 b -1.006898680274023 Loss: 0.5830224556644095\n",
      "W1: 1.2306422576428844 W2: 0.9766800925300213 b -1.0192970425003876 Loss: 0.5821567054089575\n",
      "W1: 1.244993674111329 W2: 0.9848462180774323 b -1.0315453789434794 Loss: 0.5813027540359855\n",
      "W1: 1.2593534568600255 W2: 0.9928673545729692 b -1.0436514125153917 Loss: 0.5804602210251408\n",
      "W1: 1.2737192219062514 W2: 1.0007436246821175 b -1.0556217578155669 Loss: 0.5796287447370064\n",
      "W1: 1.2880889512619975 W2: 1.0084757098569885 b -1.067462128294764 Loss: 0.57880798028165\n",
      "W1: 1.3024609240300042 W2: 1.0160647288004139 b -1.079177503164993 Loss: 0.5779975979476322\n",
      "W1: 1.3168336608930384 W2: 1.0235121399165894 b -1.0907722619345364 Loss: 0.5771972820026156\n",
      "W1: 1.331205879376151 W2: 1.0308196630555955 b -1.1022502929016078 Loss: 0.5764067297427645\n",
      "W1: 1.345576457775507 W2: 1.03798921677727 b -1.1136150806976406 Loss: 0.5756256507109632\n",
      "W1: 1.3599444060604626 W2: 1.0450228680985851 b -1.124869776972519 Loss: 0.5748537660316542\n",
      "W1: 1.3743088423875547 W2: 1.0519227922827652 b -1.1360172575115421 Loss: 0.5740908078281305\n",
      "W1: 1.3886689741318718 W2: 1.0586912407061275 b -1.1470601684290498 Loss: 0.5733365186998217\n",
      "W1: 1.403024082555677 W2: 1.065330515222758 b -1.1580009635655026 Loss: 0.5725906512447178\n",
      "W1: 1.4173735104064384 W2: 1.0718429477560005 b -1.1688419347984433 Loss: 0.5718529676170188\n",
      "W1: 1.431716651874893 W2: 1.0782308840940895 b -1.1795852366431911 Loss: 0.5711232391133308\n",
      "W1: 1.446052944455051 W2: 1.0844966710669584 b -1.1902329062502135 Loss: 0.5704012457828124\n",
      "W1: 1.4603818623375084 W2: 1.0906426464418717 b -1.2007868796899672 Loss: 0.5696867760580652\n",
      "W1: 1.474702911039356 W2: 1.0966711310047097 b -1.2112490052422353 Loss: 0.5689796264044564\n",
      "W1: 1.4890156230318012 W2: 1.1025844223976542 b -1.2216210542672539 Loss: 0.5682796009861607\n",
      "W1: 1.503319554173139 W2: 1.108384790367645 b -1.2319047301235464 Loss: 0.5675865113475955\n",
      "W1: 1.5176142807921111 W2: 1.1140744731472638 b -1.2421016755069894 Loss: 0.5669001761092021\n",
      "W1: 1.5318993972968091 W2: 1.1196556747438646 b -1.2522134785128962 Loss: 0.566220420676692\n",
      "W1: 1.546174514208496 W2: 1.1251305629563741 b -1.2622416776643735 Loss: 0.5655470769630154\n",
      "W1: 1.5604392565392238 W2: 1.1305012679742994 b -1.2721877661030871 Loss: 0.5648799831223866\n",
      "W1: 1.5746932624478314 W2: 1.1357698814417572 b -1.2820531951006382 Loss: 0.5642189832957764\n",
      "W1: 1.5889361821215457 W2: 1.1409384558921223 b -1.2918393770181935 Loss: 0.5635639273673236\n",
      "W1: 1.6031676768405996 W2: 1.1460090044772484 b -1.3015476878174077 Loss: 0.562914670731162\n",
      "W1: 1.6173874181914885 W2: 1.150983500930006 b -1.3111794692058374 Loss: 0.5622710740681858\n",
      "W1: 1.6315950874010996 W2: 1.155863879710811 b -1.320736030484068 Loss: 0.5616330031323111\n",
      "W1: 1.6457903747692835 W2: 1.1606520362984267 b -1.3302186501488862 Loss: 0.5610003285458062\n",
      "W1: 1.6599729791817353 W2: 1.1653498275930778 b -1.3396285772964385 Loss: 0.5603729256032908\n",
      "W1: 1.6741426076885264 W2: 1.1699590724061661 b -1.348967032860937 Loss: 0.5597506740840237\n",
      "W1: 1.6882989751364197 W2: 1.1744815520159209 b -1.3582352107177078 Loss: 0.5591334580721091\n",
      "W1: 1.7024418038453646 W2: 1.1789190107723873 b -1.3674342786739169 Loss: 0.5585211657842806\n",
      "W1: 1.7165708233213919 W2: 1.1832731567384374 b -1.3765653793659074 Loss: 0.5579136894049259\n",
      "W1: 1.7306857699995972 W2: 1.1875456623561378 b -1.385629631078514 Loss: 0.5573109249280388\n",
      "W1: 1.744786387012096 W2: 1.1917381651299463 b -1.3946281284988502 Loss: 0.556712772005794\n",
      "W1: 1.7588724239767908 W2: 1.1958522683199346 b -1.4035619434147377 Loss: 0.5561191338034575\n",
      "W1: 1.7729436368035707 W2: 1.199889541639625 b -1.412432125366066 Loss: 0.5555299168603557\n",
      "W1: 1.786999787515191 W2: 1.2038515219541523 b -1.4212397022558536 Loss: 0.55494503095664\n",
      "W1: 1.8010406440805895 W2: 1.207739713975371 b -1.4299856809265468 Loss: 0.5543643889855958\n",
      "W1: 1.8150659802588058 W2: 1.2115555909512503 b -1.4386710477060998 Loss: 0.5537879068312537\n",
      "W1: 1.8290755754520083 W2: 1.2153005953475016 b -1.4472967689275704 Loss: 0.5532155032510755\n",
      "W1: 1.843069214566395 W2: 1.2189761395198409 b -1.4558637914253105 Loss: 0.5526470997634941\n",
      "W1: 1.8570466878799647 W2: 1.2225836063756856 b -1.4643730430103006 Loss: 0.5520826205400979\n",
      "W1: 1.8710077909163216 W2: 1.226124350024384 b -1.472825432926746 Loss: 0.5515219923022593\n",
      "W1: 1.8849523243238273 W2: 1.2295996964153226 b -1.4812218522917016 Loss: 0.5509651442220168\n",
      "W1: 1.8988800937595307 W2: 1.2330109439634604 b -1.4895631745192046 Loss: 0.5504120078270269\n",
      "W1: 1.9127909097773985 W2: 1.2363593641619888 b -1.4978502557301687 Loss: 0.5498625169094129\n",
      "W1: 1.9266845877204515 W2: 1.239646202181951 b -1.5060839351490927 Loss: 0.5493166074383391\n",
      "W1: 1.940560947616469 W2: 1.2428726774587497 b -1.5142650354884937 Loss: 0.5487742174761587\n",
      "W1: 1.954419814076982 W2: 1.2460399842655547 b -1.5223943633218389 Loss: 0.5482352870979753\n",
      "W1: 1.9682610161993137 W2: 1.2491492922736827 b -1.5304727094456483 Loss: 0.5476997583144769\n",
      "W1: 1.9820843874714604 W2: 1.2522017471000741 b -1.538500849231359 Loss: 0.547167574997903\n",
      "W1: 1.9958897656796377 W2: 1.2551984708420287 b -1.5464795429674643 Loss: 0.5466386828110088\n",
      "W1: 2.0096769928183362 W2: 1.258140562599388 b -1.554409536192387 Loss: 0.5461130291389041\n",
      "W1: 2.0234459150027546 W2: 1.2610290989843818 b -1.5622915600184968 Loss: 0.545590563023641\n",
      "W1: 2.0371963823834887 W2: 1.2638651346193674 b -1.5701263314476384 Loss: 0.5450712351014358\n",
      "W1: 2.050928249063373 W2: 1.266649702622703 b -1.577914553678509 Loss: 0.5445549975424178\n",
      "W1: 2.064641373016381 W2: 1.2693838150830057 b -1.585656916406187 Loss: 0.5440418039927909\n",
      "W1: 2.078335616008497 W2: 1.2720684635220505 b -1.5933540961140944 Loss: 0.5435316095193146\n",
      "W1: 2.0920108435204865 W2: 1.2747046193465694 b -1.6010067563586592 Loss: 0.5430243705560023\n",
      "W1: 2.105666924672487 W2: 1.2772932342892065 b -1.6086155480469115 Loss: 0.5425200448529465\n",
      "W1: 2.119303732150364 W2: 1.279835240838892 b -1.6161811097072503 Loss: 0.5420185914271817\n",
      "W1: 2.132921142133765 W2: 1.2823315526608892 b -1.62370406775359 Loss: 0.5415199705154982\n",
      "W1: 2.1465190342258182 W2: 1.2847830650067704 b -1.6311850367430925 Loss: 0.5410241435291299\n",
      "W1: 2.160097291384423 W2: 1.287190655114571 b -1.638624619627673 Loss: 0.5405310730102341\n",
      "W1: 2.1736557998550836 W2: 1.28955518259937 b -1.6460234079994696 Loss: 0.5400407225900913\n",
      "W1: 2.187194449105236 W2: 1.291877489834538 b -1.6533819823304428 Loss: 0.5395530569489538\n",
      "W1: 2.2007131317600317 W2: 1.2941584023238906 b -1.6607009122062801 Loss: 0.5390680417774752\n",
      "W1: 2.2142117435395283 W2: 1.2963987290649805 b -1.667980756554761 Loss: 0.5385856437396539\n",
      "W1: 2.2276901831972507 W2: 1.2985992629037542 b -1.675222063868738 Loss: 0.5381058304372314\n",
      "W1: 2.2411483524600855 W2: 1.3007607808807962 b -1.6824253724238831 Loss: 0.5376285703754836\n",
      "W1: 2.25458615596947 W2: 1.3028840445693781 b -1.68959121049134 Loss: 0.5371538329303491\n",
      "W1: 2.2680035012238426 W2: 1.3049698004055228 b -1.696720096545423 Loss: 0.5366815883168389\n",
      "W1: 2.2814002985223207 W2: 1.3070187800102901 b -1.7038125394664934 Loss: 0.5362118075586769\n",
      "W1: 2.2947764609095707 W2: 1.3090317005044874 b -1.7108690387391425 Loss: 0.5357444624591193\n",
      "W1: 2.3081319041218444 W2: 1.3110092648159954 b -1.717890084645807 Loss: 0.5352795255729065\n",
      "W1: 2.321466546534148 W2: 1.312952161979907 b -1.7248761584559342 Loss: 0.5348169701793003\n",
      "W1: 2.3347803091085155 W2: 1.3148610674316568 b -1.7318277326108187 Loss: 0.5343567702561652\n",
      "W1: 2.348073115343355 W2: 1.3167366432933294 b -1.7387452709042173 Loss: 0.5338989004550466\n",
      "W1: 2.3613448912238524 W2: 1.3185795386533172 b -1.7456292286588566 Loss: 0.533443336077212\n",
      "W1: 2.3745955651733883 W2: 1.3203903898394995 b -1.752480052898938 Loss: 0.5329900530506113\n",
      "W1: 2.3878250680059607 W2: 1.3221698206861114 b -1.759298182518741 Loss: 0.532539027907722\n",
      "W1: 2.4010333328795763 W2: 1.3239184427944624 b -1.7660840484474298 Loss: 0.5320902377642434\n",
      "W1: 2.4142202952505922 W2: 1.3256368557876619 b -1.772838073810153 Loss: 0.5316436602986057\n",
      "W1: 2.4273858928289846 W2: 1.3273256475595068 b -1.7795606740855376 Loss: 0.5311992737322607\n",
      "W1: 2.4405300655345203 W2: 1.3289853945176773 b -1.7862522572596642 Loss: 0.5307570568107249\n",
      "W1: 2.453652755453811 W2: 1.330616661821388 b -1.7929132239766132 Loss: 0.5303169887853427\n",
      "W1: 2.4667539067982296 W2: 1.3322200036136331 b -1.7995439676856702 Loss: 0.5298790493957434\n",
      "W1: 2.4798334658626655 W2: 1.3337959632481657 b -1.8061448747852695 Loss: 0.5294432188529622\n",
      "W1: 2.492891380985102 W2: 1.33534507351134 b -1.8127163247637639 Loss: 0.5290094778232024\n",
      "W1: 2.5059276025069956 W2: 1.3368678568389492 b -1.8192586903370926 Loss: 0.5285778074122077\n",
      "W1: 2.5189420827344384 W2: 1.338364825528185 b -1.82577233758343 Loss: 0.5281481891502279\n",
      "W1: 2.531934775900084 W2: 1.339836481944839 b -1.832257626074885 Loss: 0.5277206049775486\n",
      "W1: 2.5449056381258224 W2: 1.3412833187258661 b -1.8387149090063277 Loss: 0.5272950372305655\n",
      "W1: 2.557854627386186 W2: 1.342705818977428 b -1.8451445333214114 Loss: 0.5268714686283815\n",
      "W1: 2.570781703472465 W2: 1.3441044564685247 b -1.851546839835858 Loss: 0.5264498822599072\n",
      "W1: 2.583686827957525 W2: 1.3454796958203283 b -1.857922163358077 Loss: 0.5260302615714416\n",
      "W1: 2.596569964161303 W2: 1.3468319926913224 b -1.8642708328071762 Loss: 0.5256125903547197\n",
      "W1: 2.6094310771169718 W2: 1.3481617939583526 b -1.8705931713284367 Loss: 0.5251968527354037\n",
      "W1: 2.6222701335377545 W2: 1.349469537893688 b -1.8768894964063034 Loss: 0.5247830331620029\n",
      "W1: 2.6350871017843773 W2: 1.3507556543381918 b -1.8831601199749577 Loss: 0.5243711163952075\n",
      "W1: 2.6478819518331442 W2: 1.3520205648706969 b -1.8894053485265268 Loss: 0.5239610874976152\n",
      "W1: 2.6606546552446213 W2: 1.3532646829736785 b -1.8956254832169885 Loss: 0.5235529318238407\n",
      "W1: 2.673405185132917 W2: 1.3544884141953153 b -1.901820819969824 Loss: 0.5231466350109902\n",
      "W1: 2.686133516135546 W2: 1.3556921563080246 b -1.9079916495774736 Loss: 0.5227421829694883\n",
      "W1: 2.6988396243838646 W2: 1.3568762994635606 b -1.9141382578006458 Loss: 0.5223395618742417\n",
      "W1: 2.7115234874740586 W2: 1.358041226344755 b -1.920260925465534 Loss: 0.5219387581561296\n",
      "W1: 2.7241850844386852 W2: 1.3591873123139833 b -1.9263599285589843 Loss: 0.5215397584938061\n",
      "W1: 2.736824395718744 W2: 1.3603149255584353 b -1.9324355383216678 Loss: 0.5211425498058038\n",
      "W1: 2.7494414031362724 W2: 1.361424427232265 b -1.9384880213393003 Loss: 0.5207471192429269\n",
      "W1: 2.7620360898674545 W2: 1.3625161715956968 b -1.9445176396319575 Loss: 0.5203534541809204\n",
      "W1: 2.7746084404162286 W2: 1.3635905061511575 b -1.9505246507415273 Loss: 0.5199615422134104\n",
      "W1: 2.7871584405883882 W2: 1.3646477717765084 b -1.9565093078173448 Loss: 0.5195713711450982\n",
      "W1: 2.7996860774661627 W2: 1.3656883028554427 b -1.9624718597000501 Loss: 0.5191829289852048\n",
      "W1: 2.812191339383267 W2: 1.3667124274051177 b -1.9684125510037105 Loss: 0.5187962039411522\n",
      "W1: 2.8246742159004152 W2: 1.367720467201086 b -1.974331622196247 Loss: 0.5184111844124737\n",
      "W1: 2.8371346977812815 W2: 1.3687127378995891 b -1.9802293096782038 Loss: 0.5180278589849453\n",
      "W1: 2.8495727769689077 W2: 1.369689549157275 b -1.986105845859897 Loss: 0.5176462164249294\n",
      "W1: 2.861988446562541 W2: 1.3706512047484005 b -1.9919614592369834 Loss: 0.517266245673921\n",
      "W1: 2.8743817007948964 W2: 1.3715980026795773 b -1.9977963744644796 Loss: 0.5168879358432925\n",
      "W1: 2.886752535009836 W2: 1.3725302353021167 b -2.003610812429271 Loss: 0.5165112762092271\n",
      "W1: 2.899100945640454 W2: 1.3734481894220314 b -2.009404990321143 Loss: 0.5161362562078318\n",
      "W1: 2.9114269301875635 W2: 1.374352146407746 b -2.015179121702366 Loss: 0.5157628654304282\n",
      "W1: 2.92373048719857 W2: 1.3752423822955713 b -2.0209334165758692 Loss: 0.5153910936190104\n",
      "W1: 2.9360116162467333 W2: 1.3761191678929914 b -2.0266680814520357 Loss: 0.515020930661866\n",
      "W1: 2.948270317910804 W2: 1.3769827688798153 b -2.032383319414142 Loss: 0.5146523665893518\n",
      "W1: 2.960506593755024 W2: 1.3778334459072412 b -2.038079330182483 Loss: 0.5142853915698211\n",
      "W1: 2.9727204463094954 W2: 1.3786714546948808 b -2.0437563101772027 Loss: 0.5139199959056944\n",
      "W1: 2.9849118790508973 W2: 1.3794970461257907 b -2.0494144525798648 Loss: 0.5135561700296716\n",
      "W1: 2.9970808963835536 W2: 1.3803104663395547 b -2.0550539473937857 Loss: 0.5131939045010747\n",
      "W1: 3.0092275036208394 W2: 1.3811119568234622 b -2.0606749815031633 Loss: 0.5128331900023233\n",
      "W1: 3.0213517069669216 W2: 1.381901754501825 b -2.0662777387310216 Loss: 0.5124740173355311\n",
      "W1: 3.0334535134988267 W2: 1.3826800918234745 b -2.0718623998960024 Loss: 0.5121163774192251\n",
      "W1: 3.045532931148831 W2: 1.3834471968474793 b -2.0774291428680245 Loss: 0.5117602612851784\n",
      "W1: 3.0575899686871644 W2: 1.3842032933271244 b -2.08297814262284 Loss: 0.5114056600753523\n",
      "W1: 3.069624635705022 W2: 1.3849486007921894 b -2.0885095712955057 Loss: 0.5110525650389492\n",
      "W1: 3.081636942597883 W2: 1.3856833346295634 b -2.094023598232799 Loss: 0.5107009675295656\n",
      "W1: 3.093626900549121 W2: 1.3864077061622344 b -2.0995203900445953 Loss: 0.5103508590024443\n",
      "W1: 3.105594521513912 W2: 1.3871219227266884 b -2.1050001106542355 Loss: 0.5100022310118232\n",
      "W1: 3.117539818203423 W2: 1.3878261877487534 b -2.110462921347898 Loss: 0.5096550752083747\n",
      "W1: 3.1294628040692865 W2: 1.3885207008179226 b -2.1159089808230034 Loss: 0.5093093833367357\n",
      "W1: 3.1413634932883454 W2: 1.3892056577601888 b -2.121338445235668 Loss: 0.5089651472331199\n",
      "W1: 3.153241900747673 W2: 1.3898812507094254 b -2.1267514682472277 Loss: 0.5086223588230153\n",
      "W1: 3.1650980420298556 W2: 1.3905476681773425 b -2.132148201069852 Loss: 0.5082810101189588\n",
      "W1: 3.1769319333985364 W2: 1.3912050951220507 b -2.1375287925112674 Loss: 0.5079410932183875\n",
      "W1: 3.1887435917842146 W2: 1.3918537130152626 b -2.1428933890186115 Loss: 0.5076026003015645\n",
      "W1: 3.2005330347702956 W2: 1.3924936999081616 b -2.1482421347214276 Loss: 0.5072655236295737\n",
      "W1: 3.2123002805793877 W2: 1.3931252304959658 b -2.1535751714738307 Loss: 0.5069298555423846\n",
      "W1: 3.22404534805984 W2: 1.393748476181216 b -2.158892638895851 Loss: 0.5065955884569808\n",
      "W1: 3.2357682566725186 W2: 1.3943636051358153 b -2.1641946744139777 Loss: 0.5062627148655543\n",
      "W1: 3.247469026477815 W2: 1.3949707823618454 b -2.1694814133009186 Loss: 0.505931227333758\n",
      "W1: 3.259147678122883 W2: 1.3955701697511882 b -2.1747529887145927 Loss: 0.5056011184990193\n",
      "W1: 3.2708042328291014 W2: 1.3961619261439757 b -2.1800095317363692 Loss: 0.505272381068909\n",
      "W1: 3.282438712379755 W2: 1.3967462073858947 b -2.185251171408572 Loss: 0.5049450078195657\n",
      "W1: 3.2940511391079363 W2: 1.3973231663843702 b -2.1904780347712607 Loss: 0.5046189915941713\n",
      "W1: 3.305641535884654 W2: 1.3978929531636497 b -2.1956902468983084 Loss: 0.5042943253014793\n",
      "W1: 3.3172099261071564 W2: 1.3984557149188146 b -2.2008879309327845 Loss: 0.5039710019143896\n",
      "W1: 3.3287563336874553 W2: 1.3990115960687386 b -2.2060712081216627 Loss: 0.5036490144685731\n",
      "W1: 3.3402807830410537 W2: 1.399560738308016 b -2.211240197849864 Loss: 0.503328356061139\n",
      "W1: 3.3517832990758705 W2: 1.4001032806578815 b -2.21639501767365 Loss: 0.5030090198493474\n",
      "W1: 3.363263907181359 W2: 1.4006393595161433 b -2.221535783353378 Loss: 0.502690999049364\n",
      "W1: 3.374722633217818 W2: 1.4011691087061484 b -2.2266626088856363 Loss: 0.502374286935055\n",
      "W1: 3.386159503505889 W2: 1.4016926595248016 b -2.231775606534763 Loss: 0.5020588768368215\n",
      "W1: 3.397574544816238 W2: 1.4022101407896579 b -2.236874886863771 Loss: 0.5017447621404708\n",
      "W1: 3.4089677843594157 W2: 1.4027216788851058 b -2.2419605587646827 Loss: 0.5014319362861261\n",
      "W1: 3.4203392497759015 W2: 1.4032273978076626 b -2.247032729488292 Loss: 0.5011203927671692\n",
      "W1: 3.4316889691263146 W2: 1.4037274192103975 b -2.252091504673362 Loss: 0.5008101251292184\n",
      "W1: 3.443016970881803 W2: 1.4042218624465033 b -2.2571369883752723 Loss: 0.5005011269691375\n",
      "W1: 3.4543232839145968 W2: 1.4047108446120309 b -2.2621692830941247 Loss: 0.5001933919340792\n",
      "W1: 3.4656079374887283 W2: 1.4051944805878065 b -2.2671884898023182 Loss: 0.4998869137205552\n",
      "W1: 3.4768709612509157 W2: 1.4056728830805474 b -2.2721947079716065 Loss: 0.499581686073539\n",
      "W1: 3.4881123852216054 W2: 1.4061461626631908 b -2.2771880355996448 Loss: 0.4992777027855931\n",
      "W1: 3.4993322397861726 W2: 1.406614427814455 b -2.282168569236039 Loss: 0.4989749576960279\n",
      "W1: 3.510530555686274 W2: 1.407077784957646 b -2.287136404007907 Loss: 0.4986734446900829\n",
      "W1: 3.5217073640113545 W2: 1.407536338498725 b -2.2920916336449575 Loss: 0.49837315769813556\n",
      "W1: 3.5328626961903016 W2: 1.4079901908636536 b -2.2970343505041027 Loss: 0.49807409069493364\n",
      "W1: 3.5439965839832466 W2: 1.4084394425350295 b -2.30196464559361 Loss: 0.49777623769885115\n",
      "W1: 3.5551090594735104 W2: 1.4088841920880264 b -2.3068826085968004 Loss: 0.49747959277116743\n",
      "W1: 3.5662001550596885 W2: 1.4093245362256548 b -2.3117883278953073 Loss: 0.4971841500153676\n",
      "W1: 3.577269903447877 W2: 1.4097605698133546 b -2.3166818905919 Loss: 0.4968899035764641\n",
      "W1: 3.5883183376440364 W2: 1.4101923859129344 b -2.321563382532884 Loss: 0.49659684764033973\n",
      "W1: 3.5993454909464844 W2: 1.4106200758158696 b -2.32643288833008 Loss: 0.49630497643310856\n",
      "W1: 3.610351396938527 W2: 1.4110437290759732 b -2.331290491382403 Loss: 0.49601428422049737\n",
      "W1: 3.6213360894812157 W2: 1.4114634335414504 b -2.3361362738970306 Loss: 0.4957247653072439\n",
      "W1: 3.6322996027062318 W2: 1.4118792753863514 b -2.3409703169101865 Loss: 0.49543641403651506\n",
      "W1: 3.6432419710088983 W2: 1.4122913391414305 b -2.345792700307536 Loss: 0.49514922478933926\n",
      "W1: 3.6541632290413135 W2: 1.4126997077244283 b -2.350603502844203 Loss: 0.4948631919840572\n",
      "W1: 3.6650634117056042 W2: 1.4131044624697842 b -2.3554028021644196 Loss: 0.49457831007578845\n",
      "W1: 3.6759425541473023 W2: 1.4135056831577921 b -2.360190674820809 Loss: 0.4942945735559119\n",
      "W1: 3.6868006917488327 W2: 1.4139034480432113 b -2.3649671962933168 Loss: 0.49401197695156235\n",
      "W1: 3.6976378601231215 W2: 1.4142978338833405 b -2.3697324410077902 Loss: 0.49373051482514135\n",
      "W1: 3.7084540951073124 W2: 1.4146889159655687 b -2.3744864823542158 Loss: 0.49345018177384004\n",
      "W1: 3.719249432756598 W2: 1.4150767681344103 b -2.379229392704622 Loss: 0.49317097242917785\n",
      "W1: 3.7300239093381586 W2: 1.4154614628180373 b -2.383961243430653 Loss: 0.4928928814565522\n",
      "W1: 3.740777561325208 W2: 1.4158430710543157 b -2.388682104920817 Loss: 0.4926159035548014\n",
      "W1: 3.751510425391147 W2: 1.4162216625163582 b -2.393392046597421 Loss: 0.4923400334557782\n",
      "W1: 3.7622225384038157 W2: 1.4165973055376 b -2.398091136933194 Loss: 0.4920652659239369\n",
      "W1: 3.772913937419856 W2: 1.4169700671364103 b -2.4027794434676064 Loss: 0.4917915957559304\n",
      "W1: 3.783584659679165 W2: 1.417340013040245 b -2.407457032822888 Loss: 0.49151901778021734\n",
      "W1: 3.7942347425994543 W2: 1.4177072077093518 b -2.412123970719756 Loss: 0.4912475268566808\n",
      "W1: 3.804864223770903 W2: 1.4180717143600363 b -2.4167803219928548 Loss: 0.4909771178762567\n",
      "W1: 3.8154731409509055 W2: 1.418433594987496 b -2.4214261506059125 Loss: 0.4907077857605718\n",
      "W1: 3.8260615320589157 W2: 1.4187929103882317 b -2.426061519666623 Loss: 0.49043952546159064\n",
      "W1: 3.83662943517138 W2: 1.4191497201820455 b -2.4306864914412545 Loss: 0.4901723319612717\n",
      "W1: 3.8471768885167634 W2: 1.41950408283363 b -2.4353011273689953 Loss: 0.4899062002712329\n",
      "W1: 3.857703930470663 W2: 1.4198560556737607 b -2.4399054880760342 Loss: 0.48964112543242444\n",
      "W1: 3.8682105995510105 W2: 1.4202056949200956 b -2.444499633389389 Loss: 0.48937710251481087\n",
      "W1: 3.8786969344133597 W2: 1.4205530556975927 b -2.4490836223504795 Loss: 0.48911412661705983\n",
      "W1: 3.8891629738462594 W2: 1.4208981920585493 b -2.45365751322846 Loss: 0.48885219286623943\n",
      "W1: 3.8996087567667086 W2: 1.4212411570022738 b -2.4582213635333026 Loss: 0.48859129641752214\n",
      "W1: 3.910034322215694 W2: 1.4215820024943946 b -2.4627752300286496 Loss: 0.48833143245389626\n",
      "W1: 3.920439709353808 W2: 1.4219207794858135 b -2.4673191687444302 Loss: 0.48807259618588394\n",
      "W1: 3.930824957456947 W2: 1.4222575379313118 b -2.471853234989249 Loss: 0.48781478285126634\n",
      "W1: 3.9411901059120837 W2: 1.422592326807813 b -2.4763774833625503 Loss: 0.4875579877148143\n",
      "W1: 3.9515351942131214 W2: 1.422925194132311 b -2.4808919677665644 Loss: 0.4873022060680255\n",
      "W1: 3.9618602619568177 W2: 1.4232561869794709 b -2.485396741418036 Loss: 0.487047433228868\n",
      "W1: 3.972165348838788 W2: 1.4235853514989025 b -2.489891856859742 Loss: 0.4867936645415293\n",
      "W1: 3.982450494649576 W2: 1.4239127329321233 b -2.494377365971801 Loss: 0.48654089537617085\n",
      "W1: 3.9927157392707997 W2: 1.4242383756292052 b -2.49885331998278 Loss: 0.48628912112868766\n",
      "W1: 4.002961122671366 W2: 1.42456232306512 b -2.503319769480601 Loss: 0.48603833722047357\n",
      "W1: 4.013186684903756 W2: 1.4248846178557855 b -2.50777676442325 Loss: 0.48578853909819186\n",
      "W1: 4.023392466100375 W2: 1.4252053017738153 b -2.512224354149295 Loss: 0.4855397222335499\n",
      "W1: 4.033578506469971 W2: 1.425524415763985 b -2.516662587388215 Loss: 0.4852918821230787\n",
      "W1: 4.043744846294124 W2: 1.4258419999584127 b -2.5210915122705426 Loss: 0.4850450142879177\n",
      "W1: 4.053891525923789 W2: 1.4261580936914633 b -2.525511176337824 Loss: 0.48479911427360317\n",
      "W1: 4.064018585775913 W2: 1.4264727355143816 b -2.529921626552404 Loss: 0.48455417764986114\n",
      "W1: 4.074126066330109 W2: 1.4267859632096573 b -2.534322909307031 Loss: 0.48431020001040465\n",
      "W1: 4.084214008125393 W2: 1.4270978138051291 b -2.5387150704342933 Loss: 0.48406717697273477\n",
      "W1: 4.094282451756979 W2: 1.427408323587831 b -2.5430981552158864 Loss: 0.4838251041779449\n",
      "W1: 4.104331437873139 W2: 1.4277175281175867 b -2.5474722083917123 Loss: 0.48358397729053065\n",
      "W1: 4.114361007172114 W2: 1.4280254622403572 b -2.5518372741688182 Loss: 0.4833437919982009\n",
      "W1: 4.124371200399091 W2: 1.4283321601013443 b -2.5561933962301766 Loss: 0.4831045440116944\n",
      "W1: 4.134362058343228 W2: 1.4286376551578575 b -2.560540617743305 Loss: 0.48286622906459864\n",
      "W1: 4.144333621834739 W2: 1.428941980191944 b -2.5648789813687354 Loss: 0.48262884291317165\n",
      "W1: 4.1542859317420335 W2: 1.4292451673227933 b -2.5692085292683324 Loss: 0.4823923813361684\n",
      "W1: 4.164219028968911 W2: 1.4295472480189124 b -2.5735293031134616 Loss: 0.4821568401346694\n",
      "W1: 4.174132954451802 W2: 1.429848253110083 b -2.5778413440930135 Loss: 0.481922215131912\n",
      "W1: 4.184027749157071 W2: 1.4301482127990992 b -2.5821446929212857 Loss: 0.4816885021731252\n",
      "W1: 4.1939034540783595 W2: 1.430447156673295 b -2.586439389845723 Loss: 0.4814556971253665\n",
      "W1: 4.203760110233989 W2: 1.4307451137158598 b -2.5907254746545227 Loss: 0.48122379587736286\n",
      "W1: 4.213597758664405 W2: 1.4310421123169508 b -2.5950029866841016 Loss: 0.48099279433935194\n",
      "W1: 4.223416440429678 W2: 1.431338180284603 b -2.5992719648264337 Loss: 0.48076268844292946\n",
      "W1: 4.233216196607044 W2: 1.4316333448554424 b -2.6035324475362565 Loss: 0.48053347414089403\n",
      "W1: 4.242997068288498 W2: 1.4319276327052035 b -2.607784472838149 Loss: 0.4803051474071001\n",
      "W1: 4.252759096578431 W2: 1.4322210699590587 b -2.612028078333486 Loss: 0.4800777042363081\n",
      "W1: 4.262502322591309 W2: 1.4325136822017586 b -2.616263301207267 Loss: 0.4798511406440404\n",
      "W1: 4.272226787449408 W2: 1.43280549448759 b -2.620490178234828 Loss: 0.47962545266643775\n",
      "W1: 4.281932532280578 W2: 1.4330965313501542 b -2.6247087457884315 Loss: 0.4794006363601184\n",
      "W1: 4.291619598216061 W2: 1.4333868168119663 b -2.628919039843741 Loss: 0.4791766878020384\n",
      "W1: 4.301288026388348 W2: 1.4336763743938836 b -2.633121095986182 Loss: 0.4789536030893553\n",
      "W1: 4.3109378579290745 W2: 1.433965227124362 b -2.637314949417191 Loss: 0.47873137833929297\n",
      "W1: 4.320569133966964 W2: 1.4342533975485452 b -2.6415006349603525 Loss: 0.47851000968900853\n",
      "W1: 4.330181895625803 W2: 1.4345409077371913 b -2.6456781870674306 Loss: 0.4782894932954603\n",
      "W1: 4.339776184022467 W2: 1.4348277792954356 b -2.6498476398242916 Loss: 0.47806982533527886\n",
      "W1: 4.349352040264972 W2: 1.435114033371397 b -2.6540090269567256 Loss: 0.47785100200463954\n",
      "W1: 4.358909505450577 W2: 1.4353996906646287 b -2.658162381836163 Loss: 0.4776330195191349\n",
      "W1: 4.368448620663914 W2: 1.4356847714344168 b -2.6623077374852917 Loss: 0.47741587411365194\n",
      "W1: 4.377969426975163 W2: 1.4359692955079275 b -2.666445126583577 Loss: 0.4771995620422475\n",
      "W1: 4.387471965438257 W2: 1.43625328228821 b -2.6705745814726813 Loss: 0.47698407957802763\n",
      "W1: 4.396956277089129 W2: 1.436536750762052 b -2.674696134161793 Loss: 0.476769423013028\n",
      "W1: 4.406422402943988 W2: 1.4368197195076962 b -2.6788098163328593 Loss: 0.47655558865809444\n",
      "W1: 4.415870383997634 W2: 1.4371022067024166 b -2.682915659345727 Loss: 0.4763425728427668\n",
      "W1: 4.425300261221806 W2: 1.437384230129958 b -2.6870136942431952 Loss: 0.476130371915163\n",
      "W1: 4.434712075563564 W2: 1.4376658071878416 b -2.69110395175598 Loss: 0.47591898224186396\n",
      "W1: 4.4441058679436996 W2: 1.4379469548945394 b -2.6951864623075887 Loss: 0.4757084002078021\n",
      "W1: 4.453481679255187 W2: 1.4382276898965187 b -2.6992612560191143 Loss: 0.47549862221614797\n",
      "W1: 4.462839550361659 W2: 1.4385080284751603 b -2.703328362713941 Loss: 0.4752896446882009\n",
      "W1: 4.472179522095915 W2: 1.438787986553552 b -2.707387811922373 Loss: 0.4750814640632793\n",
      "W1: 4.4815016352584625 W2: 1.439067579703159 b -2.711439632886177 Loss: 0.47487407679861204\n",
      "W1: 4.49080593061609 W2: 1.4393468231503754 b -2.7154838545630504 Loss: 0.47466747936923254\n",
      "W1: 4.500092448900464 W2: 1.4396257317829577 b -2.7195205056310083 Loss: 0.47446166826787173\n",
      "W1: 4.5093612308067605 W2: 1.4399043201563404 b -2.723549614492697 Loss: 0.4742566400048545\n",
      "W1: 4.518612316992322 W2: 1.440182602499841 b -2.72757120927963 Loss: 0.4740523911079949\n",
      "W1: 4.527845748075346 W2: 1.4404605927227512 b -2.731585317856352 Loss: 0.4738489181224942\n",
      "W1: 4.537061564633595 W2: 1.440738304420319 b -2.7355919678245306 Loss: 0.47364621761083875\n",
      "W1: 4.546259807203141 W2: 1.441015750879624 b -2.7395911865269764 Loss: 0.47344428615270023\n",
      "W1: 4.555440516277136 W2: 1.4412929450853456 b -2.7435830010515936 Loss: 0.4732431203448344\n",
      "W1: 4.564603732304602 W2: 1.4415698997254285 b -2.747567438235262 Loss: 0.473042716800984\n",
      "W1: 4.573749495689255 W2: 1.441846627196646 b -2.7515445246676515 Loss: 0.4728430721517801\n",
      "W1: 4.58287784678835 W2: 1.4421231396100629 b -2.7555142866949733 Loss: 0.4726441830446452\n",
      "W1: 4.591988825911552 W2: 1.4423994487964005 b -2.759476750423661 Loss: 0.4724460461436974\n",
      "W1: 4.601082473319831 W2: 1.4426755663113053 b -2.763431941723993 Loss: 0.47224865812965516\n",
      "W1: 4.610158829224385 W2: 1.4429515034405223 b -2.7673798862336514 Loss: 0.47205201569974303\n",
      "W1: 4.619217933785582 W2: 1.4432272712049754 b -2.7713206093612155 Loss: 0.47185611556759816\n",
      "W1: 4.628259827111926 W2: 1.4435028803657577 b -2.7752541362896017 Loss: 0.4716609544631776\n",
      "W1: 4.63728454925905 W2: 1.44377834142903 b -2.7791804919794383 Loss: 0.47146652913266657\n",
      "W1: 4.646292140228726 W2: 1.4440536646508326 b -2.7830997011723855 Loss: 0.4712728363383867\n",
      "W1: 4.655282639967903 W2: 1.4443288600418103 b -2.787011788394397 Loss: 0.4710798728587066\n",
      "W1: 4.664256088367763 W2: 1.4446039373718518 b -2.7909167779589263 Loss: 0.4708876354879519\n",
      "W1: 4.673212525262796 W2: 1.4448789061746472 b -2.7948146939700766 Loss: 0.470696121036316\n",
      "W1: 4.682151990429907 W2: 1.445153775752162 b -2.7987055603256983 Loss: 0.4705053263297723\n",
      "W1: 4.691074523587528 W2: 1.445428555179031 b -2.8025894007204317 Loss: 0.4703152482099871\n",
      "W1: 4.6999801643947645 W2: 1.4457032533068734 b -2.8064662386487 Loss: 0.47012588353423135\n",
      "W1: 4.708868952450553 W2: 1.445977878768531 b -2.8103360974076472 Loss: 0.4699372291752969\n",
      "W1: 4.7177409272928434 W2: 1.4462524399822285 b -2.81419900010003 Loss: 0.46974928202140903\n",
      "W1: 4.726596128397797 W2: 1.4465269451556608 b -2.818054969637057 Loss: 0.4695620389761421\n",
      "W1: 4.735434595179007 W2: 1.446801402290005 b -2.82190402874118 Loss: 0.4693754969583367\n",
      "W1: 4.744256366986734 W2: 1.4470758191838622 b -2.82574619994884 Loss: 0.46918965290201436\n",
      "W1: 4.753061483107164 W2: 1.4473502034371264 b -2.8295815056131626 Loss: 0.469004503756296\n",
      "W1: 4.76184998276168 W2: 1.4476245624547852 b -2.833409967906611 Loss: 0.46882004648531833\n",
      "W1: 4.770621905106156 W2: 1.4478989034506518 b -2.8372316088235907 Loss: 0.46863627806815394\n",
      "W1: 4.779377289230264 W2: 1.448173233451029 b -2.841046450183012 Loss: 0.4684531954987285\n",
      "W1: 4.7881161741568015 W2: 1.4484475592983093 b -2.8448545136308083 Loss: 0.46827079578574116\n",
      "W1: 4.796838598841035 W2: 1.448721887654507 b -2.848655820642411 Loss: 0.46808907595258414\n",
      "W1: 4.805544602170057 W2: 1.4489962250047304 b -2.852450392525183 Loss: 0.467908033037264\n",
      "W1: 4.814234222962166 W2: 1.4492705776605888 b -2.8562382504208115 Loss: 0.4677276640923221\n",
      "W1: 4.822907499966253 W2: 1.4495449517635393 b -2.860019415307658 Loss: 0.4675479661847561\n",
      "W1: 4.831564471861215 W2: 1.4498193532881727 b -2.8637939080030708 Loss: 0.46736893639594346\n",
      "W1: 4.840205177255373 W2: 1.4500937880454414 b -2.8675617491656573 Loss: 0.4671905718215625\n",
      "W1: 4.848829654685914 W2: 1.4503682616858278 b -2.8713229592975185 Loss: 0.46701286957151705\n",
      "W1: 4.85743794261834 W2: 1.4506427797024561 b -2.875077558746444 Loss: 0.46683582676985935\n",
      "W1: 4.866030079445939 W2: 1.450917347434149 b -2.8788255677080725 Loss: 0.4666594405547149\n",
      "W1: 4.874606103489267 W2: 1.4511919700684275 b -2.882567006228014 Loss: 0.46648370807820677\n",
      "W1: 4.883166052995643 W2: 1.4514666526444582 b -2.8863018942039362 Loss: 0.4663086265063812\n",
      "W1: 4.891709966138657 W2: 1.4517414000559465 b -2.8900302513876173 Loss: 0.466134193019133\n",
      "W1: 4.900237881017698 W2: 1.4520162170539788 b -2.893752097386962 Loss: 0.4659604048101324\n",
      "W1: 4.9087498356574875 W2: 1.4522911082498116 b -2.8974674516679864 Loss: 0.4657872590867513\n",
      "W1: 4.917245868007634 W2: 1.4525660781176122 b -2.901176333556766 Loss: 0.46561475306999006\n",
      "W1: 4.925726015942192 W2: 1.4528411309971487 b -2.9048787622413546 Loss: 0.4654428839944057\n",
      "W1: 4.9341903172592385 W2: 1.453116271096432 b -2.9085747567736684 Loss: 0.4652716491080398\n",
      "W1: 4.942638809680464 W2: 1.45339150249431 b -2.91226433607134 Loss: 0.46510104567234706\n",
      "W1: 4.95107153085077 W2: 1.453666829143015 b -2.9159475189195407 Loss: 0.4649310709621242\n",
      "W1: 4.959488518337886 W2: 1.453942254870665 b -2.919624323972772 Loss: 0.46476172226543927\n",
      "W1: 4.967889809631988 W2: 1.4542177833837202 b -2.9232947697566276 Loss: 0.4645929968835612\n",
      "W1: 4.976275442145338 W2: 1.4544934182693938 b -2.9269588746695274 Loss: 0.46442489213089116\n",
      "W1: 4.984645453211936 W2: 1.4547691629980217 b -2.93061665698442 Loss: 0.464257405334892\n",
      "W1: 4.9929998800871696 W2: 1.4550450209253871 b -2.934268134850457 Loss: 0.46409053383601956\n",
      "W1: 5.001338759947489 W2: 1.4553209952950035 b -2.9379133262946424 Loss: 0.46392427498765465\n",
      "W1: 5.00966212989009 W2: 1.4555970892403576 b -2.9415522492234514 Loss: 0.46375862615603475\n",
      "W1: 5.0179700269326 W2: 1.45587330578711 b -2.9451849214244237 Loss: 0.46359358472018636\n",
      "W1: 5.026262488012782 W2: 1.456149647855258 b -2.94881136056773 Loss: 0.4634291480718573\n",
      "W1: 5.0345395499882475 W2: 1.456426118261257 b -2.952431584207713 Loss: 0.46326531361545026\n",
      "W1: 5.042801249636176 W2: 1.4567027197201048 b -2.956045609784402 Loss: 0.46310207876795667\n",
      "W1: 5.051047623653049 W2: 1.4569794548473887 b -2.9596534546250037 Loss: 0.46293944095888917\n",
      "W1: 5.059278708654391 W2: 1.4572563261612936 b -2.963255135945366 Loss: 0.4627773976302174\n",
      "W1: 5.067494541174521 W2: 1.457533336084576 b -2.9668506708514206 Loss: 0.46261594623630214\n",
      "W1: 5.075695157666312 W2: 1.4578104869465 b -2.9704400763406005 Loss: 0.46245508424383\n",
      "W1: 5.083880594500959 W2: 1.4580877809847403 b -2.9740233693032323 Loss: 0.462294809131749\n",
      "W1: 5.092050887967763 W2: 1.4583652203472484 b -2.97760056652391 Loss: 0.46213511839120436\n",
      "W1: 5.1002060742739115 W2: 1.4586428070940867 b -2.9811716846828404 Loss: 0.46197600952547513\n",
      "W1: 5.108346189544282 W2: 1.4589205431992291 b -2.9847367403571723 Loss: 0.4618174800499098\n",
      "W1: 5.11647126982124 W2: 1.4591984305523278 b -2.9882957500222984 Loss: 0.4616595274918638\n",
      "W1: 5.124581351064456 W2: 1.4594764709604489 b -2.991848730053141 Loss: 0.46150214939063616\n",
      "W1: 5.132676469150726 W2: 1.459754666149776 b -2.995395696725413 Loss: 0.46134534329740795\n",
      "W1: 5.140756659873802 W2: 1.4600330177672833 b -2.998936666216859 Loss: 0.4611891067751793\n",
      "W1: 5.148821958944227 W2: 1.4603115273823781 b -3.002471654608477 Loss: 0.46103343739870833\n",
      "W1: 5.1568724019891805 W2: 1.4605901964885124 b -3.00600067788572 Loss: 0.46087833275444917\n",
      "W1: 5.164908024552334 W2: 1.460869026504767 b -3.0095237519396765 Loss: 0.46072379044049144\n",
      "W1: 5.172928862093707 W2: 1.4611480187774049 b -3.013040892568235 Loss: 0.46056980806649916\n",
      "W1: 5.18093494998954 W2: 1.4614271745813974 b -3.0165521154772263 Loss: 0.4604163832536507\n",
      "W1: 5.188926323532163 W2: 1.4617064951219225 b -3.0200574362815478 Loss: 0.4602635136345788\n",
      "W1: 5.196903017929883 W2: 1.4619859815358351 b -3.0235568705062716 Loss: 0.46011119685331026\n",
      "W1: 5.20486506830687 W2: 1.4622656348931111 b -3.027050433587733 Loss: 0.4599594305652072\n",
      "W1: 5.212812509703053 W2: 1.4625454561982645 b -3.0305381408746 Loss: 0.459808212436908\n",
      "W1: 5.220745377074022 W2: 1.4628254463917392 b -3.0340200076289303 Loss: 0.45965754014626775\n",
      "W1: 5.2286637052909395 W2: 1.4631056063512748 b -3.0374960490272054 Loss: 0.45950741138230133\n",
      "W1: 5.236567529140453 W2: 1.4633859368932485 b -3.040966280161352 Loss: 0.45935782384512386\n",
      "W1: 5.244456883324618 W2: 1.46366643877399 b -3.044430716039745 Loss: 0.45920877524589404\n",
      "W1: 5.2523318024608265 W2: 1.4639471126910755 b -3.047889371588196 Loss: 0.4590602633067558\n",
      "W1: 5.26019232108174 W2: 1.4642279592845953 b -3.051342261650923 Loss: 0.45891228576078197\n",
      "W1: 5.2680384736352295 W2: 1.4645089791383998 b -3.0547894009915098 Loss: 0.45876484035191684\n",
      "W1: 5.2758702944843225 W2: 1.464790172781322 b -3.0582308042938426 Loss: 0.4586179248349204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 5.283687817907154 W2: 1.4650715406883765 b -3.0616664861630394 Loss: 0.4584715369753113\n",
      "W1: 5.291491078096924 W2: 1.4653530832819395 b -3.065096461126359 Loss: 0.4583256745493111\n",
      "W1: 5.29928010916186 W2: 1.465634800932903 b -3.0685207436340973 Loss: 0.45818033534378916\n",
      "W1: 5.307054945125187 W2: 1.4659166939618118 b -3.0719393480604706 Loss: 0.45803551715620744\n",
      "W1: 5.314815619925096 W2: 1.4661987626399762 b -3.0753522887044826 Loss: 0.45789121779456465\n",
      "W1: 5.3225621674147305 W2: 1.4664810071905663 b -3.0787595797907787 Loss: 0.4577474350773423\n",
      "W1: 5.330294621362164 W2: 1.4667634277896855 b -3.0821612354704873 Loss: 0.45760416683345007\n",
      "W1: 5.338013015450391 W2: 1.4670460245674237 b -3.085557269822047 Loss: 0.45746141090217146\n",
      "W1: 5.345717383277323 W2: 1.4673287976088918 b -3.08894769685202 Loss: 0.4573191651331106\n",
      "W1: 5.353407758355784 W2: 1.4676117469552366 b -3.0923325304958955 Loss: 0.4571774273861379\n",
      "W1: 5.361084174113516 W2: 1.4678948726046375 b -3.095711784618876 Loss: 0.45703619553133773\n",
      "W1: 5.368746663893185 W2: 1.4681781745132836 b -3.099085473016656 Loss: 0.4568954674489547\n",
      "W1: 5.376395260952396 W2: 1.4684616525963339 b -3.1024536094161848 Loss: 0.45675524102934145\n",
      "W1: 5.384029998463711 W2: 1.4687453067288592 b -3.105816207476418 Loss: 0.4566155141729059\n",
      "W1: 5.391650909514665 W2: 1.4690291367467667 b -3.1091732807890606 Loss: 0.45647628479005964\n",
      "W1: 5.399258027107797 W2: 1.4693131424477066 b -3.112524842879292 Loss: 0.45633755080116567\n",
      "W1: 5.406851384160677 W2: 1.4695973235919633 b -3.115870907206487 Loss: 0.45619931013648696\n",
      "W1: 5.414431013505944 W2: 1.4698816799033285 b -3.119211487164919 Loss: 0.4560615607361354\n",
      "W1: 5.421996947891339 W2: 1.4701662110699598 b -3.122546596084457 Loss: 0.4559243005500205\n",
      "W1: 5.429549219979749 W2: 1.4704509167452209 b -3.1258762472312505 Loss: 0.4557875275377991\n",
      "W1: 5.437087862349255 W2: 1.4707357965485086 b -3.1292004538084 Loss: 0.45565123966882415\n",
      "W1: 5.444612907493179 W2: 1.4710208500660629 b -3.132519228956625 Loss: 0.4555154349220958\n",
      "W1: 5.452124387820137 W2: 1.4713060768517623 b -3.1358325857549123 Loss: 0.4553801112862097\n",
      "W1: 5.4596223356541005 W2: 1.471591476427904 b -3.1391405372211625 Loss: 0.45524526675930943\n",
      "W1: 5.467106783234451 W2: 1.4718770482859704 b -3.1424430963128214 Loss: 0.45511089934903537\n",
      "W1: 5.474577762716048 W2: 1.4721627918873796 b -3.1457402759275035 Loss: 0.4549770070724764\n",
      "W1: 5.482035306169296 W2: 1.4724487066642238 b -3.1490320889036054 Loss: 0.45484358795612145\n",
      "W1: 5.489479445580214 W2: 1.472734792019992 b -3.152318548020911 Loss: 0.45471064003580947\n",
      "W1: 5.496910212850512 W2: 1.4730210473302805 b -3.155599666001186 Loss: 0.4545781613566829\n",
      "W1: 5.5043276397976655 W2: 1.4733074719434889 b -3.158875455508763 Loss: 0.4544461499731387\n",
      "W1: 5.511731758154998 W2: 1.473594065181504 b -3.1621459291511194 Loss: 0.45431460394877965\n",
      "W1: 5.519122599571763 W2: 1.4738808263403704 b -3.165411099479446 Loss: 0.45418352135636886\n",
      "W1: 5.526500195613234 W2: 1.4741677546909477 b -3.1686709789892062 Loss: 0.45405290027778056\n",
      "W1: 5.533864577760789 W2: 1.4744548494795566 b -3.171925580120686 Loss: 0.45392273880395406\n",
      "W1: 5.541215777412006 W2: 1.4747421099286122 b -3.175174915259538 Loss: 0.4537930350348469\n",
      "W1: 5.548553825880759 W2: 1.4750295352372447 b -3.178418996737316 Loss: 0.4536637870793873\n",
      "W1: 5.555878754397314 W2: 1.475317124581909 b -3.1816578368319997 Loss: 0.45353499305543016\n",
      "W1: 5.56319059410843 W2: 1.4756048771169827 b -3.1848914477685155 Loss: 0.4534066510897079\n",
      "W1: 5.570489376077461 W2: 1.475892791975353 b -3.1881198417192462 Loss: 0.45327875931778683\n",
      "W1: 5.577775131284468 W2: 1.4761808682689912 b -3.1913430308045334 Loss: 0.45315131588402174\n",
      "W1: 5.585047890626319 W2: 1.4764691050895176 b -3.194561027093174 Loss: 0.45302431894150863\n",
      "W1: 5.592307684916806 W2: 1.4767575015087548 b -3.1977738426029085 Loss: 0.4528977666520415\n",
      "W1: 5.5995545448867565 W2: 1.4770460565792713 b -3.2009814893009008 Loss: 0.45277165718606693\n",
      "W1: 5.606788501184148 W2: 1.4773347693349135 b -3.2041839791042124 Loss: 0.4526459887226389\n",
      "W1: 5.614009584374228 W2: 1.4776236387913277 b -3.20738132388027 Loss: 0.45252075944937553\n",
      "W1: 5.621217824939633 W2: 1.4779126639464741 b -3.2105735354473235 Loss: 0.4523959675624138\n",
      "W1: 5.62841325328051 W2: 1.4782018437811277 b -3.2137606255749005 Loss: 0.4522716112663669\n",
      "W1: 5.635595899714644 W2: 1.478491177259372 b -3.2169426059842516 Loss: 0.45214768877427897\n",
      "W1: 5.642765794477582 W2: 1.478780663329082 b -3.2201194883487907 Loss: 0.4520241983075832\n",
      "W1: 5.649922967722765 W2: 1.4790703009223984 b -3.223291284294528 Loss: 0.451901138096058\n",
      "W1: 5.657067449521655 W2: 1.4793600889561926 b -3.2264580054004974 Loss: 0.4517785063777841\n",
      "W1: 5.664199269863869 W2: 1.4796500263325223 b -3.229619663199176 Loss: 0.45165630139910157\n",
      "W1: 5.671318458657316 W2: 1.479940111939079 b -3.2327762691769 Loss: 0.45153452141456757\n",
      "W1: 5.678425045728331 W2: 1.4802303446496252 b -3.235927834774272 Loss: 0.4514131646869144\n",
      "W1: 5.685519060821814 W2: 1.480520723324426 b -3.239074371386565 Loss: 0.4512922294870064\n",
      "W1: 5.69260053360137 W2: 1.4808112468106691 b -3.2422158903641174 Loss: 0.45117171409379964\n",
      "W1: 5.699669493649452 W2: 1.4811019139428783 b -3.245352403012725 Loss: 0.4510516167942988\n",
      "W1: 5.706725970467503 W2: 1.4813927235433193 b -3.2484839205940266 Loss: 0.4509319358835171\n",
      "W1: 5.713769993476104 W2: 1.481683674422396 b -3.251610454325884 Loss: 0.45081266966443406\n",
      "W1: 5.720801592015117 W2: 1.4819747653790407 b -3.254732015382755 Loss: 0.4506938164479553\n",
      "W1: 5.727820795343835 W2: 1.4822659952010955 b -3.257848614896063 Loss: 0.45057537455287144\n",
      "W1: 5.734827632641134 W2: 1.4825573626656863 b -3.2609602639545625 Loss: 0.45045734230581774\n",
      "W1: 5.741822133005624 W2: 1.4828488665395902 b -3.264066973604695 Loss: 0.4503397180412337\n",
      "W1: 5.748804325455798 W2: 1.483140505579595 b -3.2671687548509447 Loss: 0.4502225001013233\n",
      "W1: 5.75577423893019 W2: 1.483432278532851 b -3.270265618656185 Loss: 0.45010568683601504\n",
      "W1: 5.762731902287531 W2: 1.483724184137218 b -3.2733575759420237 Loss: 0.4499892766029216\n",
      "W1: 5.769677344306905 W2: 1.484016221121602 b -3.2764446375891407 Loss: 0.4498732677673018\n",
      "W1: 5.7766105936879075 W2: 1.4843083882062886 b -3.279526814437623 Loss: 0.44975765870201984\n",
      "W1: 5.783531679050804 W2: 1.4846006841032682 b -3.282604117287292 Loss: 0.44964244778750756\n",
      "W1: 5.790440628936692 W2: 1.4848931075165537 b -3.285676556898031 Loss: 0.4495276334117247\n",
      "W1: 5.797337471807666 W2: 1.485185657142494 b -3.2887441439901024 Loss: 0.44941321397012096\n",
      "W1: 5.804222236046974 W2: 1.4854783316700793 b -3.291806889244466 Loss: 0.4492991878655977\n",
      "W1: 5.81109494995919 W2: 1.4857711297812415 b -3.294864803303088 Loss: 0.4491855535084689\n",
      "W1: 5.817955641770373 W2: 1.4860640501511484 b -3.29791789676925 Loss: 0.4490723093164238\n",
      "W1: 5.824804339628237 W2: 1.4863570914484907 b -3.3009661802078503 Loss: 0.44895945371448925\n",
      "W1: 5.831641071602318 W2: 1.4866502523357652 b -3.3040096641457035 Loss: 0.4488469851349922\n",
      "W1: 5.838465865684142 W2: 1.4869435314695505 b -3.307048359071834 Loss: 0.44873490201752125\n",
      "W1: 5.845278749787397 W2: 1.4872369275007782 b -3.310082275437768 Loss: 0.44862320280889134\n",
      "W1: 5.852079751748099 W2: 1.4875304390749975 b -3.3131114236578183 Loss: 0.44851188596310493\n",
      "W1: 5.85886889932477 W2: 1.487824064832636 b -3.3161358141093675 Loss: 0.4484009499413165\n",
      "W1: 5.865646220198606 W2: 1.4881178034092533 b -3.319155457133148 Loss: 0.4482903932117955\n",
      "W1: 5.872411741973649 W2: 1.4884116534357907 b -3.322170363033516 Loss: 0.44818021424988963\n",
      "W1: 5.879165492176968 W2: 1.4887056135388155 b -3.325180542078722 Loss: 0.4480704115379898\n",
      "W1: 5.885907498258827 W2: 1.4889996823407596 b -3.3281860045011795 Loss: 0.44796098356549247\n",
      "W1: 5.892637787592863 W2: 1.4892938584601543 b -3.3311867604977303 Loss: 0.4478519288287654\n",
      "W1: 5.8993563874762645 W2: 1.4895881405118587 b -3.334182820229903 Loss: 0.44774324583111125\n",
      "W1: 5.906063325129948 W2: 1.489882527107285 b -3.33717419382417 Loss: 0.44763493308273233\n",
      "W1: 5.912758627698735 W2: 1.490177016854618 b -3.340160891372204 Loss: 0.4475269891006954\n",
      "W1: 5.91944232225153 W2: 1.4904716083590301 b -3.3431429229311247 Loss: 0.4474194124088964\n",
      "W1: 5.926114435781505 W2: 1.4907663002228924 b -3.3461202985237484 Loss: 0.44731220153802637\n",
      "W1: 5.932774995206271 W2: 1.4910610910459803 b -3.349093028138831 Loss: 0.4472053550255353\n",
      "W1: 5.939424027368068 W2: 1.4913559794256765 b -3.352061121731309 Loss: 0.44709887141560006\n",
      "W1: 5.946061559033938 W2: 1.4916509639571676 b -3.355024589222536 Loss: 0.44699274925908733\n",
      "W1: 5.952687616895912 W2: 1.4919460432336376 b -3.357983440500518 Loss: 0.4468869871135214\n",
      "W1: 5.959302227571194 W2: 1.4922412158464577 b -3.3609376854201436 Loss: 0.44678158354304964\n",
      "W1: 5.965905417602337 W2: 1.4925364803853716 b -3.3638873338034143 Loss: 0.446676537118409\n",
      "W1: 5.972497213457433 W2: 1.4928318354386756 b -3.3668323954396686 Loss: 0.44657184641689207\n",
      "W1: 5.979077641530294 W2: 1.4931272795933974 b -3.3697728800858044 Loss: 0.44646751002231383\n",
      "W1: 5.985646728140637 W2: 1.493422811435469 b -3.372708797466499 Loss: 0.4463635265249787\n",
      "W1: 5.992204499534268 W2: 1.493718429549896 b -3.375640157274426 Loss: 0.4462598945216474\n",
      "W1: 5.998750981883271 W2: 1.4940141325209244 b -3.37856696917047 Loss: 0.446156612615504\n",
      "W1: 6.005286201286188 W2: 1.4943099189322027 b -3.3814892427839363 Loss: 0.44605367941612317\n",
      "W1: 6.011810183768208 W2: 1.4946057873669407 b -3.384406987712762 Loss: 0.44595109353943824\n",
      "W1: 6.018322955281357 W2: 1.4949017364080652 b -3.3873202135237204 Loss: 0.4458488536077084\n",
      "W1: 6.024824541704677 W2: 1.4951977646383716 b -3.3902289297526247 Loss: 0.44574695824948607\n",
      "W1: 6.031314968844422 W2: 1.4954938706406726 b -3.39313314590453 Loss: 0.4456454060995865\n",
      "W1: 6.037794262434237 W2: 1.4957900529979435 b -3.3960328714539307 Loss: 0.4455441957990543\n",
      "W1: 6.0442624481353535 W2: 1.4960863102934643 b -3.398928115844957 Loss: 0.445443325995133\n",
      "W1: 6.050719551536772 W2: 1.4963826411109582 b -3.4018188884915688 Loss: 0.4453427953412328\n",
      "W1: 6.0571655981554535 W2: 1.4966790440347275 b -3.404705198777747 Loss: 0.4452426024968999\n",
      "W1: 6.063600613436507 W2: 1.4969755176497868 b -3.407587056057682 Loss: 0.44514274612778487\n",
      "W1: 6.070024622753379 W2: 1.4972720605419914 b -3.41046446965596 Loss: 0.44504322490561193\n",
      "W1: 6.076437651408041 W2: 1.4975686712981648 b -3.413337448867748 Loss: 0.44494403750814837\n",
      "W1: 6.08283972463118 W2: 1.4978653485062225 b -3.4162060029589765 Loss: 0.4448451826191738\n",
      "W1: 6.089230867582389 W2: 1.4981620907552928 b -3.419070141166517 Loss: 0.4447466589284494\n",
      "W1: 6.095611105350355 W2: 1.4984588966358343 b -3.4219298726983634 Loss: 0.444648465131688\n",
      "W1: 6.10198046295305 W2: 1.4987557647397522 b -3.4247852067338043 Loss: 0.44455059993052404\n",
      "W1: 6.1083389653379205 W2: 1.4990526936605104 b -3.427636152423598 Loss: 0.44445306203248297\n",
      "W1: 6.114686637382076 W2: 1.4993496819932415 b -3.430482718890144 Loss: 0.44435585015095247\n",
      "W1: 6.121023503892482 W2: 1.4996467283348542 b -3.4333249152276526 Loss: 0.4442589630051517\n",
      "W1: 6.1273495896061485 W2: 1.4999438312841387 b -3.4361627505023122 Loss: 0.44416239932010265\n",
      "W1: 6.133664919190323 W2: 1.500240989441868 b -3.4389962337524542 Loss: 0.4440661578266006\n",
      "W1: 6.139969517242678 W2: 1.5005382014108992 b -3.4418253739887175 Loss: 0.4439702372611849\n",
      "W1: 6.1462634082915 W2: 1.50083546579627 b -3.444650180194209 Loss: 0.4438746363661096\n",
      "W1: 6.152546616795888 W2: 1.501132781205294 b -3.4474706613246653 Loss: 0.4437793538893154\n",
      "W1: 6.158819167145936 W2: 1.5014301462476534 b -3.4502868263086084 Loss: 0.4436843885844002\n",
      "W1: 6.165081083662925 W2: 1.50172755953549 b -3.4530986840475033 Loss: 0.4435897392105908\n",
      "W1: 6.171332390599519 W2: 1.5020250196834932 b -3.4559062434159125 Loss: 0.44349540453271546\n",
      "W1: 6.177573112139951 W2: 1.502322525308986 b -3.458709513261647 Loss: 0.44340138332117357\n",
      "W1: 6.183803272400215 W2: 1.5026200750320093 b -3.4615085024059202 Loss: 0.4433076743519095\n",
      "W1: 6.190022895428256 W2: 1.5029176674754032 b -3.464303219643493 Loss: 0.4432142764063839\n",
      "W1: 6.196232005204162 W2: 1.5032153012648874 b -3.4670936737428244 Loss: 0.4431211882715459\n",
      "W1: 6.202430625640353 W2: 1.5035129750291383 b -3.469879873446217 Loss: 0.44302840873980576\n",
      "W1: 6.208618780581776 W2: 1.5038106873998651 b -3.472661827469959 Loss: 0.44293593660900704\n",
      "W1: 6.214796493806087 W2: 1.5041084370118836 b -3.4754395445044706 Loss: 0.44284377068239933\n",
      "W1: 6.220963789023853 W2: 1.504406222503188 b -3.478213033214441 Loss: 0.4427519097686114\n",
      "W1: 6.22712068987873 W2: 1.5047040425150207 b -3.480982302238971 Loss: 0.44266035268162407\n",
      "W1: 6.233267219947664 W2: 1.5050018956919406 b -3.48374736019171 Loss: 0.44256909824074264\n",
      "W1: 6.2394034027410745 W2: 1.5052997806818895 b -3.4865082156609906 Loss: 0.4424781452705712\n",
      "W1: 6.245529261703047 W2: 1.5055976961362563 b -3.4892648772099673 Loss: 0.44238749260098537\n",
      "W1: 6.251644820211523 W2: 1.50589564070994 b -3.4920173533767467 Loss: 0.44229713906710566\n",
      "W1: 6.257750101578492 W2: 1.5061936130614109 b -3.494765652674521 Loss: 0.442207083509272\n",
      "W1: 6.263845129050175 W2: 1.5064916118527696 b -3.4975097835917004 Loss: 0.44211732477301685\n",
      "W1: 6.2699299258072205 W2: 1.506789635749805 b -3.500249754592038 Loss: 0.44202786170903907\n",
      "W1: 6.276004514964892 W2: 1.5070876834220504 b -3.502985574114762 Loss: 0.4419386931731786\n",
      "W1: 6.282068919573257 W2: 1.5073857535428379 b -3.505717250574701 Loss: 0.4418498180263903\n",
      "W1: 6.288123162617374 W2: 1.5076838447893517 b -3.508444792362408 Loss: 0.4417612351347186\n",
      "W1: 6.294167267017485 W2: 1.507981955842679 b -3.5111682078442854 Loss: 0.44167294336927176\n",
      "W1: 6.3002012556292035 W2: 1.5082800853878606 b -3.513887505362708 Loss: 0.44158494160619655\n",
      "W1: 6.306225151243701 W2: 1.5085782321139392 b -3.5166026932361443 Loss: 0.441497228726653\n",
      "W1: 6.3122389765878975 W2: 1.5088763947140056 b -3.5193137797592757 Loss: 0.44140980361679016\n",
      "W1: 6.3182427543246495 W2: 1.5091745718852456 b -3.522020773203116 Loss: 0.44132266516771956\n",
      "W1: 6.3242365070529365 W2: 1.5094727623289836 b -3.5247236818151304 Loss: 0.44123581227549186\n",
      "W1: 6.330220257308051 W2: 1.5097709647507258 b -3.5274225138193493 Loss: 0.44114924384107135\n",
      "W1: 6.336194027561785 W2: 1.510069177860201 b -3.5301172774164864 Loss: 0.441062958770312\n",
      "W1: 6.342157840222615 W2: 1.5103674003714014 b -3.5328079807840513 Loss: 0.4409769559739329\n",
      "W1: 6.348111717635895 W2: 1.510665631002622 b -3.5354946320764626 Loss: 0.4408912343674929\n",
      "W1: 6.354055682084037 W2: 1.5109638684764979 b -3.5381772394251607 Loss: 0.44080579287136834\n",
      "W1: 6.3599897557867004 W2: 1.5112621115200402 b -3.5408558109387176 Loss: 0.4407206304107282\n",
      "W1: 6.365913960900979 W2: 1.5115603588646722 b -3.5435303547029475 Loss: 0.44063574591550925\n",
      "W1: 6.371828319521587 W2: 1.511858609246263 b -3.546200878781015 Loss: 0.4405511383203939\n",
      "W1: 6.377732853681042 W2: 1.5121568614051601 b -3.5488673912135424 Loss: 0.44046680656478576\n",
      "W1: 6.383627585349855 W2: 1.5124551140862226 b -3.5515299000187177 Loss: 0.4403827495927864\n",
      "W1: 6.389512536436712 W2: 1.5127533660388497 b -3.5541884131923984 Loss: 0.4402989663531709\n",
      "W1: 6.395387728788659 W2: 1.5130516160170124 b -3.5568429387082166 Loss: 0.44021545579936655\n",
      "W1: 6.401253184191291 W2: 1.513349862779281 b -3.559493484517683 Loss: 0.44013221688942855\n",
      "W1: 6.4071089243689325 W2: 1.513648105088852 b -3.5621400585502894 Loss: 0.4400492485860166\n",
      "W1: 6.4129549709848215 W2: 1.5139463417135757 b -3.564782668713609 Loss: 0.4399665498563729\n",
      "W1: 6.418791345641294 W2: 1.5142445714259811 b -3.567421322893399 Loss: 0.43988411967229923\n",
      "W1: 6.42461806987997 W2: 1.5145427930033 b -3.570056028953699 Loss: 0.4398019570101342\n",
      "W1: 6.430435165181932 W2: 1.514841005227491 b -3.57268679473693 Loss: 0.4397200608507302\n",
      "W1: 6.436242652967913 W2: 1.5151392068852616 b -3.5753136280639923 Loss: 0.43963843017943205\n",
      "W1: 6.4420405545984725 W2: 1.5154373967680903 b -3.5779365367343625 Loss: 0.43955706398605426\n",
      "W1: 6.447828891374186 W2: 1.5157355736722466 b -3.58055552852619 Loss: 0.43947596126485844\n",
      "W1: 6.4536076845358235 W2: 1.5160337363988112 b -3.583170611196391 Loss: 0.43939512101453193\n",
      "W1: 6.4593769552645295 W2: 1.5163318837536948 b -3.585781792480744 Loss: 0.4393145422381654\n",
      "W1: 6.465136724682005 W2: 1.516630014547656 b -3.588389080093983 Loss: 0.43923422394323186\n",
      "W1: 6.4708870138506915 W2: 1.5169281275963187 b -3.5909924817298893 Loss: 0.4391541651415636\n",
      "W1: 6.476627843773947 W2: 1.5172262217201886 b -3.593592005061385 Loss: 0.43907436484933215\n",
      "W1: 6.48235923539623 W2: 1.5175242957446684 b -3.596187657740623 Loss: 0.4389948220870257\n",
      "W1: 6.488081209603276 W2: 1.5178223485000726 b -3.598779447399076 Loss: 0.43891553587942816\n",
      "W1: 6.4937937872222795 W2: 1.5181203788216417 b -3.601367381647628 Loss: 0.4388365052555984\n",
      "W1: 6.499496989022072 W2: 1.5184183855495557 b -3.6039514680766627 Loss: 0.4387577292488489\n",
      "W1: 6.5051908357133 W2: 1.5187163675289455 b -3.6065317142561497 Loss: 0.4386792068967235\n",
      "W1: 6.510875347948605 W2: 1.519014323609906 b -3.6091081277357335 Loss: 0.4386009372409789\n",
      "W1: 6.5165505463228 W2: 1.5193122526475067 b -3.611680716044819 Loss: 0.4385229193275618\n",
      "W1: 6.522216451373049 W2: 1.5196101535018016 b -3.6142494866926573 Loss: 0.43844515220658953\n",
      "W1: 6.527873083579043 W2: 1.5199080250378392 b -3.6168144471684296 Loss: 0.43836763493232866\n",
      "W1: 6.533520463363174 W2: 1.5202058661256717 b -3.6193756049413333 Loss: 0.43829036656317544\n",
      "W1: 6.539158611090717 W2: 1.5205036756403632 b -3.621932967460664 Loss: 0.4382133461616345\n",
      "W1: 6.544787547070004 W2: 1.520801452461997 b -3.6244865421559 Loss: 0.4381365727942996\n",
      "W1: 6.550407291552597 W2: 1.5210991954756836 b -3.6270363364367815 Loss: 0.4380600455318327\n",
      "W1: 6.556017864733468 W2: 1.5213969035715664 b -3.629582357693395 Loss: 0.43798376344894474\n",
      "W1: 6.561619286751167 W2: 1.5216945756448277 b -3.6321246132962526 Loss: 0.4379077256243747\n",
      "W1: 6.567211577688006 W2: 1.5219922105956942 b -3.6346631105963723 Loss: 0.437831931140871\n",
      "W1: 6.572794757570224 W2: 1.5222898073294415 b -3.6371978569253574 Loss: 0.4377563790851712\n",
      "W1: 6.578368846368167 W2: 1.522587364756398 b -3.6397288595954755 Loss: 0.43768106854798244\n",
      "W1: 6.583933863996457 W2: 1.5228848817919496 b -3.642256125899737 Loss: 0.4376059986239618\n",
      "W1: 6.589489830314168 W2: 1.523182357356541 b -3.6447796631119718 Loss: 0.4375311684116974\n",
      "W1: 6.595036765124998 W2: 1.5234797903756798 b -3.647299478486907 Loss: 0.43745657701368934\n",
      "W1: 6.600574688177439 W2: 1.5237771797799375 b -3.6498155792602427 Loss: 0.4373822235363292\n",
      "W1: 6.606103619164951 W2: 1.5240745245049516 b -3.652327972648729 Loss: 0.43730810708988277\n",
      "W1: 6.6116235777261325 W2: 1.524371823491426 b -3.65483666585024 Loss: 0.43723422678846935\n",
      "W1: 6.61713458344489 W2: 1.5246690756851322 b -3.6573416660438474 Loss: 0.43716058175004463\n",
      "W1: 6.62263665585061 W2: 1.5249662800369086 b -3.659842980389897 Loss: 0.4370871710963807\n",
      "W1: 6.62812981441833 W2: 1.5252634355026609 b -3.662340616030081 Loss: 0.43701399395304763\n",
      "W1: 6.633614078568904 W2: 1.5255605410433604 b -3.66483458008751 Loss: 0.4369410494493953\n",
      "W1: 6.639089467669177 W2: 1.5258575956250433 b -3.6673248796667863 Loss: 0.4368683367185348\n",
      "W1: 6.644556001032151 W2: 1.5261545982188087 b -3.6698115218540757 Loss: 0.43679585489731987\n",
      "W1: 6.65001369791715 W2: 1.5264515478008165 b -3.6722945137171785 Loss: 0.4367236031263286\n",
      "W1: 6.655462577529995 W2: 1.5267484433522847 b -3.6747738623056003 Loss: 0.43665158054984554\n",
      "W1: 6.660902659023166 W2: 1.5270452838594866 b -3.677249574650622 Loss: 0.43657978631584377\n",
      "W1: 6.66633396149597 W2: 1.5273420683137473 b -3.6797216577653695 Loss: 0.4365082195759664\n",
      "W1: 6.67175650399471 W2: 1.52763879571144 b -3.6821901186448835 Loss: 0.4364368794855091\n",
      "W1: 6.677170305512849 W2: 1.5279354650539811 b -3.684654964266188 Loss: 0.4363657652034023\n",
      "W1: 6.682575384991175 W2: 1.5282320753478278 b -3.6871162015883563 Loss: 0.4362948758921934\n",
      "W1: 6.687971761317968 W2: 1.5285286256044706 b -3.689573837552583 Loss: 0.43622421071802914\n",
      "W1: 6.6933594533291645 W2: 1.5288251148404295 b -3.692027879082247 Loss: 0.43615376885063806\n",
      "W1: 6.698738479808522 W2: 1.5291215420772488 b -3.694478333082981 Loss: 0.4360835494633134\n",
      "W1: 6.704108859487783 W2: 1.52941790634149 b -3.696925206442736 Loss: 0.43601355173289613\n",
      "W1: 6.709470611046836 W2: 1.5297142066647267 b -3.699368506031848 Loss: 0.4359437748397559\n",
      "W1: 6.714823753113883 W2: 1.530010442083537 b -3.7018082387031037 Loss: 0.43587421796777653\n",
      "W1: 6.7201683042655995 W2: 1.5303066116394977 b -3.7042444112918043 Loss: 0.43580488030433684\n",
      "W1: 6.725504283027296 W2: 1.5306027143791765 b -3.7066770306158303 Loss: 0.43573576104029504\n",
      "W1: 6.730831707873081 W2: 1.5308987493541246 b -3.7091061034757065 Loss: 0.4356668593699713\n",
      "W1: 6.736150597226024 W2: 1.5311947156208692 b -3.7115316366546636 Loss: 0.4355981744911309\n",
      "W1: 6.741460969458312 W2: 1.531490612240905 b -3.7139536369187027 Loss: 0.43552970560496784\n",
      "W1: 6.746762842891415 W2: 1.5317864382806867 b -3.716372111016658 Loss: 0.43546145191608826\n",
      "W1: 6.752056235796242 W2: 1.5320821928116193 b -3.7187870656802584 Loss: 0.4353934126324932\n",
      "W1: 6.757341166393301 W2: 1.5323778749100503 b -3.72119850762419 Loss: 0.43532558696556356\n",
      "W1: 6.762617652852862 W2: 1.5326734836572602 b -3.7236064435461573 Loss: 0.43525797413004313\n",
      "W1: 6.767885713295111 W2: 1.532969018139453 b -3.726010880126944 Loss: 0.4351905733440214\n",
      "W1: 6.773145365790309 W2: 1.533264477447747 b -3.7284118240304736 Loss: 0.43512338382891896\n",
      "W1: 6.778396628358951 W2: 1.5335598606781649 b -3.7308092819038703 Loss: 0.43505640480947033\n",
      "W1: 6.783639518971926 W2: 1.533855166931623 b -3.733203260377518 Loss: 0.43498963551370884\n",
      "W1: 6.788874055550666 W2: 1.5341503953139222 b -3.7355937660651204 Loss: 0.43492307517295\n",
      "W1: 6.794100255967311 W2: 1.5344455449357366 b -3.73798080556376 Loss: 0.43485672302177586\n",
      "W1: 6.799318138044858 W2: 1.534740614912603 b -3.7403643854539563 Loss: 0.43479057829801954\n",
      "W1: 6.804527719557322 W2: 1.5350356043649103 b -3.7427445122997245 Loss: 0.4347246402427496\n",
      "W1: 6.809729018229889 W2: 1.5353305124178878 b -3.745121192648634 Loss: 0.4346589081002541\n",
      "W1: 6.814922051739067 W2: 1.5356253382015943 b -3.7474944330318647 Loss: 0.4345933811180251\n",
      "W1: 6.820106837712848 W2: 1.535920080850907 b -3.7498642399642654 Loss: 0.4345280585467441\n",
      "W1: 6.825283393730854 W2: 1.536214739505509 b -3.7522306199444104 Loss: 0.4344629396402658\n",
      "W1: 6.830451737324493 W2: 1.5365093133098777 b -3.7545935794546557 Loss: 0.43439802365560304\n",
      "W1: 6.835611885977114 W2: 1.536803801413273 b -3.7569531249611954 Loss: 0.434333309852912\n",
      "W1: 6.8407638571241565 W2: 1.537098202969725 b -3.7593092629141176 Loss: 0.43426879749547687\n",
      "W1: 6.845907668153303 W2: 1.5373925171380218 b -3.76166199974746 Loss: 0.434204485849695\n",
      "W1: 6.851043336404632 W2: 1.5376867430816963 b -3.7640113418792644 Loss: 0.43414037418506174\n",
      "W1: 6.856170879170766 W2: 1.537980879969014 b -3.7663572957116327 Loss: 0.43407646177415554\n",
      "W1: 6.861290313697026 W2: 1.5382749269729605 b -3.7686998676307804 Loss: 0.4340127478926241\n",
      "W1: 6.866401657181577 W2: 1.5385688832712279 b -3.771039064007091 Loss: 0.4339492318191682\n",
      "W1: 6.871504926775582 W2: 1.538862748046202 b -3.773374891195171 Loss: 0.43388591283552835\n",
      "W1: 6.876600139583349 W2: 1.5391565204849489 b -3.775707355533901 Loss: 0.43382279022646963\n",
      "W1: 6.8816873126624785 W2: 1.5394501997792016 b -3.7780364633464916 Loss: 0.43375986327976734\n",
      "W1: 6.8867664630240135 W2: 1.5397437851253468 b -3.780362220940534 Loss: 0.43369713128619297\n",
      "W1: 6.8918376076325885 W2: 1.5400372757244105 b -3.782684634608055 Loss: 0.4336345935394995\n",
      "W1: 6.896900763406574 W2: 1.540330670782045 b -3.7850037106255674 Loss: 0.43357224933640687\n",
      "W1: 6.901955947218226 W2: 1.5406239695085144 b -3.7873194552541225 Loss: 0.4335100979765892\n",
      "W1: 6.90700317589383 W2: 1.5409171711186813 b -3.7896318747393627 Loss: 0.4334481387626586\n",
      "W1: 6.912042466213848 W2: 1.541210274831992 b -3.7919409753115714 Loss: 0.43338637100015337\n",
      "W1: 6.917073834913068 W2: 1.5415032798724624 b -3.7942467631857255 Loss: 0.4333247939975223\n",
      "W1: 6.9220972986807405 W2: 1.5417961854686641 b -3.7965492445615454 Loss: 0.433263407066112\n",
      "W1: 6.9271128741607315 W2: 1.5420889908537097 b -3.7988484256235466 Loss: 0.4332022095201527\n",
      "W1: 6.932120577951663 W2: 1.5423816952652378 b -3.8011443125410884 Loss: 0.43314120067674416\n",
      "W1: 6.9371204266070565 W2: 1.5426742979453993 b -3.8034369114684257 Loss: 0.43308037985584275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 6.942112436635479 W2: 1.5429667981408421 b -3.805726228544757 Loss: 0.43301974638024715\n",
      "W1: 6.947096624500681 W2: 1.5432591951026964 b -3.8080122698942747 Loss: 0.4329592995755856\n",
      "W1: 6.9520730066217435 W2: 1.5435514880865597 b -3.810295041626215 Loss: 0.43289903877030206\n",
      "W1: 6.95704159937322 W2: 1.5438436763524825 b -3.8125745498349053 Loss: 0.4328389632956426\n",
      "W1: 6.962002419085274 W2: 1.5441357591649523 b -3.8148508005998147 Loss: 0.43277907248564274\n",
      "W1: 6.966955482043824 W2: 1.5444277357928793 b -3.817123799985601 Loss: 0.43271936567711383\n",
      "W1: 6.971900804490683 W2: 1.5447196055095807 b -3.819393554042158 Loss: 0.43265984220962994\n",
      "W1: 6.976838402623697 W2: 1.545011367592766 b -3.821660068804667 Loss: 0.4326005014255148\n",
      "W1: 6.981768292596888 W2: 1.545303021324521 b -3.82392335029364 Loss: 0.43254134266982885\n",
      "W1: 6.9866904905205915 W2: 1.5455945659912929 b -3.8261834045149703 Loss: 0.4324823652903563\n",
      "W1: 6.991605012461594 W2: 1.545886000883875 b -3.828440237459978 Loss: 0.43242356863759235\n",
      "W1: 6.996511874443276 W2: 1.5461773252973912 b -3.8306938551054572 Loss: 0.43236495206473025\n",
      "W1: 7.0014110924457436 W2: 1.5464685385312795 b -3.8329442634137236 Loss: 0.43230651492764793\n",
      "W1: 7.0063026824059715 W2: 1.5467596398892778 b -3.83519146833266 Loss: 0.43224825658489724\n",
      "W1: 7.011186660217938 W2: 1.5470506286794075 b -3.8374354757957616 Loss: 0.43219017639768914\n",
      "W1: 7.01606304173276 W2: 1.547341504213958 b -3.839676291722185 Loss: 0.43213227372988217\n",
      "W1: 7.020931842758835 W2: 1.547632265809471 b -3.84191392201679 Loss: 0.4320745479479701\n",
      "W1: 7.0257930790619705 W2: 1.5479229127867247 b -3.8441483725701877 Loss: 0.43201699842106966\n",
      "W1: 7.030646766365521 W2: 1.5482134444707176 b -3.846379649258785 Loss: 0.4319596245209069\n",
      "W1: 7.035492920350526 W2: 1.5485038601906536 b -3.8486077579448303 Loss: 0.4319024256218071\n",
      "W1: 7.0403315566558415 W2: 1.5487941592799253 b -3.8508327044764563 Loss: 0.4318454011006802\n",
      "W1: 7.045162690878274 W2: 1.5490843410760982 b -3.853054494687727 Loss: 0.43178855033701063\n",
      "W1: 7.049986338572717 W2: 1.5493744049208953 b -3.8552731343986806 Loss: 0.43173187271284413\n",
      "W1: 7.054802515252281 W2: 1.5496643501601808 b -3.857488629415374 Loss: 0.4316753676127755\n",
      "W1: 7.059611236388429 W2: 1.5499541761439435 b -3.859700985529927 Loss: 0.43161903442393756\n",
      "W1: 7.064412517411107 W2: 1.550243882226282 b -3.8619102085205657 Loss: 0.43156287253598863\n",
      "W1: 7.069206373708874 W2: 1.5505334677653877 b -3.8641163041516653 Loss: 0.4315068813411012\n",
      "W1: 7.07399282062904 W2: 1.550822932123529 b -3.866319278173795 Loss: 0.431451060233949\n",
      "W1: 7.078771873477789 W2: 1.5511122746670354 b -3.8685191363237603 Loss: 0.43139540861169684\n",
      "W1: 7.083543547520318 W2: 1.5514014947662815 b -3.870715884324645 Loss: 0.43133992587398784\n",
      "W1: 7.088307857980958 W2: 1.5516905917956705 b -3.8729095278858554 Loss: 0.4312846114229322\n",
      "W1: 7.0930648200433115 W2: 1.551979565133618 b -3.8751000727031615 Loss: 0.43122946466309586\n",
      "W1: 7.09781444885038 W2: 1.5522684141625365 b -3.8772875244587404 Loss: 0.4311744850014881\n",
      "W1: 7.1025567595046875 W2: 1.552557138268819 b -3.879471888821217 Loss: 0.4311196718475518\n",
      "W1: 7.107291767068419 W2: 1.5528457368428226 b -3.881653171445708 Loss: 0.43106502461315055\n",
      "W1: 7.112019486563538 W2: 1.5531342092788523 b -3.88383137797386 Loss: 0.4310105427125581\n",
      "W1: 7.116739932971923 W2: 1.5534225549751453 b -3.8860065140338955 Loss: 0.4309562255624469\n",
      "W1: 7.121453121235488 W2: 1.5537107733338544 b -3.8881785852406505 Loss: 0.43090207258187657\n",
      "W1: 7.126159066256315 W2: 1.5539988637610325 b -3.890347597195617 Loss: 0.4308480831922838\n",
      "W1: 7.130857782896774 W2: 1.5542868256666154 b -3.892513555486985 Loss: 0.4307942568174704\n",
      "W1: 7.135549285979656 W2: 1.5545746584644065 b -3.894676465689681 Loss: 0.43074059288359234\n",
      "W1: 7.140233590288294 W2: 1.55486236157206 b -3.8968363333654104 Loss: 0.43068709081914913\n",
      "W1: 7.1449107105666885 W2: 1.5551499344110657 b -3.8989931640626967 Loss: 0.4306337500549725\n",
      "W1: 7.149580661519635 W2: 1.555437376406732 b -3.901146963316922 Loss: 0.4305805700242166\n",
      "W1: 7.154243457812844 W2: 1.5557246869881696 b -3.903297736650368 Loss: 0.4305275501623456\n",
      "W1: 7.158899114073068 W2: 1.556011865588276 b -3.905445489572254 Loss: 0.43047468990712434\n",
      "W1: 7.163547644888227 W2: 1.5562989116437196 b -3.907590227578778 Loss: 0.4304219886986068\n",
      "W1: 7.168189064807525 W2: 1.5565858245949225 b -3.909731956153155 Loss: 0.43036944597912596\n",
      "W1: 7.172823388341578 W2: 1.5568726038860452 b -3.9118706807656585 Loss: 0.43031706119328333\n",
      "W1: 7.177450629962536 W2: 1.5571592489649708 b -3.9140064068736558 Loss: 0.43026483378793773\n",
      "W1: 7.182070804104202 W2: 1.557445759283288 b -3.916139139921651 Loss: 0.43021276321219565\n",
      "W1: 7.186683925162157 W2: 1.5577321342962753 b -3.9182688853413215 Loss: 0.4301608489174003\n",
      "W1: 7.191290007493877 W2: 1.5580183734628859 b -3.9203956485515565 Loss: 0.4301090903571218\n",
      "W1: 7.195889065418856 W2: 1.5583044762457303 b -3.9225194349584966 Loss: 0.4300574869871459\n",
      "W1: 7.2004811132187285 W2: 1.5585904421110615 b -3.924640249955572 Loss: 0.4300060382654652\n",
      "W1: 7.205066165137385 W2: 1.558876270528758 b -3.9267580989235387 Loss: 0.4299547436522673\n",
      "W1: 7.209644235381093 W2: 1.5591619609723084 b -3.9288729872305193 Loss: 0.42990360260992655\n",
      "W1: 7.214215338118617 W2: 1.5594475129187955 b -3.930984920232038 Loss: 0.42985261460299157\n",
      "W1: 7.218779487481337 W2: 1.5597329258488801 b -3.9330939032710615 Loss: 0.42980177909817807\n",
      "W1: 7.223336697563364 W2: 1.5600181992467854 b -3.9351999416780323 Loss: 0.42975109556435614\n",
      "W1: 7.227886982421663 W2: 1.5603033326002806 b -3.93730304077091 Loss: 0.429700563472542\n",
      "W1: 7.232430356076165 W2: 1.5605883254006658 b -3.939403205855206 Loss: 0.42965018229588803\n",
      "W1: 7.236966832509887 W2: 1.5608731771427558 b -3.9415004422240214 Loss: 0.4295999515096721\n",
      "W1: 7.241496425669048 W2: 1.5611578873248637 b -3.9435947551580828 Loss: 0.4295498705912885\n",
      "W1: 7.246019149463187 W2: 1.5614424554487867 b -3.945686149925781 Loss: 0.42949993902023764\n",
      "W1: 7.250535017765276 W2: 1.5617268810197884 b -3.9477746317832056 Loss: 0.42945015627811717\n",
      "W1: 7.255044044411836 W2: 1.5620111635465848 b -3.949860205974183 Loss: 0.42940052184861166\n",
      "W1: 7.259546243203053 W2: 1.5622953025413275 b -3.951942877730311 Loss: 0.42935103521748325\n",
      "W1: 7.264041627902892 W2: 1.5625792975195887 b -3.9540226522709956 Loss: 0.4293016958725623\n",
      "W1: 7.268530212239214 W2: 1.5628631480003452 b -3.9560995348034877 Loss: 0.42925250330373754\n",
      "W1: 7.273012009903885 W2: 1.5631468535059632 b -3.9581735305229175 Loss: 0.42920345700294665\n",
      "W1: 7.277487034552894 W2: 1.563430413562182 b -3.9602446446123314 Loss: 0.42915455646416745\n",
      "W1: 7.2819552998064605 W2: 1.5637138276980993 b -3.9623128822427263 Loss: 0.429105801183408\n",
      "W1: 7.286416819249156 W2: 1.5639970954461557 b -3.964378248573086 Loss: 0.4290571906586974\n",
      "W1: 7.290871606430008 W2: 1.5642802163421183 b -3.9664407487504163 Loss: 0.4290087243900765\n",
      "W1: 7.295319674862616 W2: 1.5645631899250665 b -3.968500387909779 Loss: 0.4289604018795892\n",
      "W1: 7.299761038025262 W2: 1.5648460157373758 b -3.970557171174329 Loss: 0.4289122226312727\n",
      "W1: 7.304195709361024 W2: 1.5651286933247028 b -3.9726111036553458 Loss: 0.42886418615114824\n",
      "W1: 7.308623702277884 W2: 1.5654112222359697 b -3.9746621904522716 Loss: 0.42881629194721316\n",
      "W1: 7.313045030148837 W2: 1.5656936020233494 b -3.9767104366527435 Loss: 0.4287685395294305\n",
      "W1: 7.317459706312007 W2: 1.56597583224225 b -3.978755847332629 Loss: 0.4287209284097209\n",
      "W1: 7.32186774407075 W2: 1.566257912451299 b -3.9807984275560604 Loss: 0.42867345810195395\n",
      "W1: 7.32626915669377 W2: 1.5665398422123298 b -3.9828381823754673 Loss: 0.428626128121938\n",
      "W1: 7.330663957415221 W2: 1.5668216210903652 b -3.984875116831612 Loss: 0.4285789379874126\n",
      "W1: 7.335052159434822 W2: 1.5671032486536023 b -3.986909235953624 Loss: 0.42853188721803903\n",
      "W1: 7.33943377591796 W2: 1.5673847244733985 b -3.988940544759032 Loss: 0.4284849753353924\n",
      "W1: 7.343808819995801 W2: 1.5676660481242555 b -3.990969048253798 Loss: 0.4284382018629516\n",
      "W1: 7.348177304765397 W2: 1.5679472191838049 b -3.992994751432352 Loss: 0.428391566326092\n",
      "W1: 7.352539243289791 W2: 1.568228237232793 b -3.995017659277623 Loss: 0.42834506825207563\n",
      "W1: 7.356894648598128 W2: 1.5685091018550663 b -3.9970377767610743 Loss: 0.4282987071700441\n",
      "W1: 7.361243533685756 W2: 1.5687898126375566 b -3.999055108842736 Loss: 0.42825248261100834\n",
      "W1: 7.365585911514338 W2: 1.5690703691702659 b -4.001069660471237 Loss: 0.42820639410784145\n",
      "W1: 7.369921795011951 W2: 1.5693507710462518 b -4.003081436583839 Loss: 0.42816044119526975\n",
      "W1: 7.374251197073197 W2: 1.569631017861613 b -4.005090442106469 Loss: 0.4281146234098647\n",
      "W1: 7.378574130559305 W2: 1.5699111092154747 b -4.00709668195375 Loss: 0.4280689402900338\n",
      "W1: 7.3828906082982355 W2: 1.5701910447099734 b -4.009100161029038 Loss: 0.4280233913760128\n",
      "W1: 7.387200643084786 W2: 1.5704708239502432 b -4.011100884224449 Loss: 0.42797797620985806\n",
      "W1: 7.391504247680696 W2: 1.5707504465444009 b -4.0130988564208945 Loss: 0.42793269433543696\n",
      "W1: 7.395801434814745 W2: 1.5710299121035314 b -4.015094082488112 Loss: 0.42788754529842093\n",
      "W1: 7.400092217182861 W2: 1.5713092202416732 b -4.017086567284697 Loss: 0.42784252864627653\n",
      "W1: 7.404376607448223 W2: 1.5715883705758047 b -4.019076315658138 Loss: 0.4277976439282579\n",
      "W1: 7.408654618241361 W2: 1.571867362725829 b -4.021063332444843 Loss: 0.4277528906953982\n",
      "W1: 7.412926262160258 W2: 1.5721461963145602 b -4.023047622470175 Loss: 0.4277082685005018\n",
      "W1: 7.417191551770454 W2: 1.572424870967709 b -4.025029190548482 Loss: 0.4276637768981365\n",
      "W1: 7.421450499605147 W2: 1.5727033863138689 b -4.027008041483128 Loss: 0.42761941544462556\n",
      "W1: 7.425703118165291 W2: 1.572981741984501 b -4.0289841800665265 Loss: 0.42757518369803926\n",
      "W1: 7.429949419919701 W2: 1.573259937613921 b -4.030957611080168 Loss: 0.4275310812181878\n",
      "W1: 7.4341894173051495 W2: 1.5735379728392849 b -4.032928339294654 Loss: 0.4274871075666127\n",
      "W1: 7.438423122726469 W2: 1.5738158473005746 b -4.034896369469727 Loss: 0.42744326230658025\n",
      "W1: 7.44265054855665 W2: 1.5740935606405844 b -4.0368617063543 Loss: 0.4273995450030719\n",
      "W1: 7.446871707136943 W2: 1.5743711125049067 b -4.038824354686492 Loss: 0.42735595522277864\n",
      "W1: 7.451086610776953 W2: 1.5746485025419186 b -4.04078431919365 Loss: 0.4273124925340916\n",
      "W1: 7.455295271754741 W2: 1.574925730402768 b -4.042741604592386 Loss: 0.4272691565070955\n",
      "W1: 7.459497702316924 W2: 1.5752027957413595 b -4.044696215588609 Loss: 0.4272259467135606\n",
      "W1: 7.463693914678769 W2: 1.575479698214341 b -4.0466481568775485 Loss: 0.42718286272693545\n",
      "W1: 7.467883921024293 W2: 1.5757564374810904 b -4.048597433143788 Loss: 0.42713990412233876\n",
      "W1: 7.472067733506359 W2: 1.5760330132037008 b -4.050544049061298 Loss: 0.4270970704765526\n",
      "W1: 7.476245364246773 W2: 1.5763094250469682 b -4.05248800929346 Loss: 0.42705436136801483\n",
      "W1: 7.480416825336382 W2: 1.5765856726783776 b -4.0544293184931 Loss: 0.42701177637681165\n",
      "W1: 7.484582128835171 W2: 1.5768617557680893 b -4.05636798130252 Loss: 0.42696931508466973\n",
      "W1: 7.4887412867723535 W2: 1.5771376739889258 b -4.058304002353522 Loss: 0.4269269770749497\n",
      "W1: 7.492894311146474 W2: 1.5774134270163584 b -4.060237386267444 Loss: 0.4268847619326387\n",
      "W1: 7.497041213925498 W2: 1.5776890145284936 b -4.062168137655181 Loss: 0.4268426692443421\n",
      "W1: 7.50118200704691 W2: 1.57796443620606 b -4.064096261117225 Loss: 0.426800698598278\n",
      "W1: 7.505316702417806 W2: 1.5782396917323958 b -4.066021761243684 Loss: 0.4267588495842688\n",
      "W1: 7.509445311914991 W2: 1.578514780793434 b -4.067944642614319 Loss: 0.4267171217937342\n",
      "W1: 7.513567847385069 W2: 1.5787897030776914 b -4.069864909798566 Loss: 0.4266755148196848\n",
      "W1: 7.5176843206445385 W2: 1.5790644582762536 b -4.071782567355572 Loss: 0.42663402825671387\n",
      "W1: 7.5217947434798855 W2: 1.5793390460827632 b -4.073697619834218 Loss: 0.4265926617009916\n",
      "W1: 7.525899127647677 W2: 1.5796134661934067 b -4.075610071773149 Loss: 0.4265514147502568\n",
      "W1: 7.529997484874653 W2: 1.5798877183069011 b -4.077519927700806 Loss: 0.42651028700381155\n",
      "W1: 7.534089826857819 W2: 1.5801618021244812 b -4.079427192135449 Loss: 0.4264692780625124\n",
      "W1: 7.538176165264539 W2: 1.5804357173498875 b -4.08133186958519 Loss: 0.4264283875287648\n",
      "W1: 7.542256511732624 W2: 1.5807094636893526 b -4.08323396454802 Loss: 0.4263876150065156\n",
      "W1: 7.546330877870429 W2: 1.5809830408515886 b -4.085133481511835 Loss: 0.426346960101247\n",
      "W1: 7.550399275256937 W2: 1.581256448547775 b -4.087030424954466 Loss: 0.42630642241996825\n",
      "W1: 7.554461715441855 W2: 1.5815296864915456 b -4.088924799343707 Loss: 0.42626600157121075\n",
      "W1: 7.558518209945703 W2: 1.581802754398976 b -4.0908166091373435 Loss: 0.4262256971650198\n",
      "W1: 7.562568770259904 W2: 1.582075651988572 b -4.0927058587831775 Loss: 0.4261855088129487\n",
      "W1: 7.566613407846872 W2: 1.582348378981255 b -4.0945925527190585 Loss: 0.4261454361280519\n",
      "W1: 7.570652134140106 W2: 1.582620935100352 b -4.096476695372909 Loss: 0.42610547872487836\n",
      "W1: 7.574684960544274 W2: 1.5828933200715818 b -4.098358291162751 Loss: 0.42606563621946497\n",
      "W1: 7.578711898435304 W2: 1.5831655336230435 b -4.100237344496739 Loss: 0.42602590822932984\n",
      "W1: 7.582732959160475 W2: 1.5834375754852035 b -4.102113859773179 Loss: 0.4259862943734658\n",
      "W1: 7.586748154038499 W2: 1.583709445390884 b -4.103987841380563 Loss: 0.42594679427233434\n",
      "W1: 7.590757494359618 W2: 1.5839811430752504 b -4.105859293697591 Loss: 0.42590740754785883\n",
      "W1: 7.594760991385683 W2: 1.5842526682757994 b -4.107728221093202 Loss: 0.42586813382341704\n",
      "W1: 7.5987586563502445 W2: 1.5845240207323468 b -4.109594627926598 Loss: 0.4258289727238371\n",
      "W1: 7.602750500458643 W2: 1.584795200187016 b -4.111458518547272 Loss: 0.42578992387538916\n",
      "W1: 7.606736534888089 W2: 1.5850662063842256 b -4.1133198972950336 Loss: 0.4257509869057794\n",
      "W1: 7.610716770787755 W2: 1.5853370390706771 b -4.11517876850004 Loss: 0.42571216144414437\n",
      "W1: 7.6146912192788605 W2: 1.5856076979953442 b -4.117035136482816 Loss: 0.42567344712104416\n",
      "W1: 7.6186598914547545 W2: 1.58587818290946 b -4.118889005554284 Loss: 0.42563484356845627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 7.622622798381005 W2: 1.5861484935665058 b -4.120740380015794 Loss: 0.42559635041976945\n",
      "W1: 7.626579951095482 W2: 1.5864186297221994 b -4.12258926415914 Loss: 0.4255579673097776\n",
      "W1: 7.630531360608445 W2: 1.5866885911344828 b -4.124435662266599 Loss: 0.4255196938746733\n",
      "W1: 7.634477037902623 W2: 1.5869583775635119 b -4.126279578610944 Loss: 0.42548152975204195\n",
      "W1: 7.638416993933304 W2: 1.5872279887716434 b -4.128121017455482 Loss: 0.42544347458085563\n",
      "W1: 7.6423512396284154 W2: 1.5874974245234246 b -4.12995998305407 Loss: 0.42540552800146736\n",
      "W1: 7.646279785888609 W2: 1.5877666845855811 b -4.131796479651148 Loss: 0.4253676896556039\n",
      "W1: 7.650202643587346 W2: 1.5880357687270061 b -4.13363051148176 Loss: 0.42532995918636113\n",
      "W1: 7.654119823570977 W2: 1.5883046767187488 b -4.135462082771585 Loss: 0.4252923362381976\n",
      "W1: 7.658031336658827 W2: 1.5885734083340024 b -4.137291197736955 Loss: 0.4252548204569283\n",
      "W1: 7.661937193643278 W2: 1.5888419633480944 b -4.139117860584889 Loss: 0.42521741148971864\n",
      "W1: 7.665837405289851 W2: 1.5891103415384735 b -4.140942075513113 Loss: 0.42518010898507935\n",
      "W1: 7.6697319823372885 W2: 1.5893785426847005 b -4.142763846710085 Loss: 0.4251429125928594\n",
      "W1: 7.673620935497634 W2: 1.5896465665684354 b -4.144583178355022 Loss: 0.4251058219642419\n",
      "W1: 7.677504275456315 W2: 1.5899144129734273 b -4.146400074617929 Loss: 0.4250688367517364\n",
      "W1: 7.681382012872229 W2: 1.5901820816855032 b -4.148214539659615 Loss: 0.4250319566091742\n",
      "W1: 7.685254158377814 W2: 1.5904495724925576 b -4.150026577631728 Loss: 0.4249951811917027\n",
      "W1: 7.689120722579136 W2: 1.5907168851845404 b -4.151836192676772 Loss: 0.4249585101557789\n",
      "W1: 7.692981716055972 W2: 1.5909840195534468 b -4.153643388928135 Loss: 0.4249219431591644\n",
      "W1: 7.696837149361883 W2: 1.591250975393307 b -4.155448170510116 Loss: 0.4248854798609196\n",
      "W1: 7.700687033024297 W2: 1.5915177525001745 b -4.157250541537946 Loss: 0.42484911992139784\n",
      "W1: 7.7045313775445905 W2: 1.5917843506721154 b -4.159050506117816 Loss: 0.42481286300223986\n",
      "W1: 7.7083701933981645 W2: 1.592050769709199 b -4.160848068346896 Loss: 0.4247767087663687\n",
      "W1: 7.712203491034525 W2: 1.5923170094134855 b -4.162643232313365 Loss: 0.42474065687798285\n",
      "W1: 7.7160312808773615 W2: 1.5925830695890169 b -4.164436002096435 Loss: 0.42470470700255264\n",
      "W1: 7.719853573324626 W2: 1.5928489500418053 b -4.166226381766373 Loss: 0.42466885880681277\n",
      "W1: 7.72367037874861 W2: 1.5931146505798233 b -4.168014375384525 Loss: 0.4246331119587584\n",
      "W1: 7.727481707496023 W2: 1.5933801710129931 b -4.16979998700334 Loss: 0.42459746612763904\n",
      "W1: 7.73128756988807 W2: 1.5936455111531764 b -4.171583220666398 Loss: 0.4245619209839526\n",
      "W1: 7.735087976220529 W2: 1.5939106708141642 b -4.17336408040843 Loss: 0.4245264761994411\n",
      "W1: 7.7388829367638285 W2: 1.5941756498116657 b -4.1751425702553435 Loss: 0.4244911314470844\n",
      "W1: 7.742672461763122 W2: 1.5944404479632994 b -4.176918694224245 Loss: 0.4244558864010955\n",
      "W1: 7.746456561438367 W2: 1.5947050650885817 b -4.178692456323464 Loss: 0.4244207407369147\n",
      "W1: 7.750235245984403 W2: 1.5949695010089173 b -4.180463860552579 Loss: 0.42438569413120464\n",
      "W1: 7.754008525571021 W2: 1.5952337555475893 b -4.182232910902439 Loss: 0.424350746261845\n",
      "W1: 7.757776410343046 W2: 1.5954978285297488 b -4.183999611355186 Loss: 0.4243158968079269\n",
      "W1: 7.76153891042041 W2: 1.595761719782405 b -4.185763965884282 Loss: 0.42428114544974815\n",
      "W1: 7.765296035898225 W2: 1.5960254291344156 b -4.187525978454527 Loss: 0.42424649186880836\n",
      "W1: 7.769047796846861 W2: 1.5962889564164762 b -4.18928565302209 Loss: 0.42421193574780214\n",
      "W1: 7.77279420331202 W2: 1.596552301461111 b -4.1910429935345235 Loss: 0.42417747677061635\n",
      "W1: 7.77653526531481 W2: 1.5968154641026628 b -4.192798003930793 Loss: 0.4241431146223229\n",
      "W1: 7.780270992851819 W2: 1.5970784441772836 b -4.194550688141297 Loss: 0.424108848989175\n",
      "W1: 7.7840013958951895 W2: 1.597341241522924 b -4.196301050087893 Loss: 0.4240746795586017\n",
      "W1: 7.7877264843926906 W2: 1.5976038559793244 b -4.198049093683915 Loss: 0.42404060601920207\n",
      "W1: 7.791446268267795 W2: 1.597866287388005 b -4.1997948228342015 Loss: 0.4240066280607415\n",
      "W1: 7.795160757419748 W2: 1.5981285355922563 b -4.201538241435117 Loss: 0.4239727453741459\n",
      "W1: 7.798869961723644 W2: 1.5983906004371295 b -4.203279353374572 Loss: 0.423938957651497\n",
      "W1: 7.802573891030495 W2: 1.5986524817694274 b -4.20501816253205 Loss: 0.4239052645860271\n",
      "W1: 7.8062725551673084 W2: 1.598914179437694 b -4.206754672778627 Loss: 0.4238716658721144\n",
      "W1: 7.809965963937154 W2: 1.5991756932922059 b -4.208488887976994 Loss: 0.4238381612052784\n",
      "W1: 7.813654127119239 W2: 1.599437023184963 b -4.210220811981482 Loss: 0.42380475028217435\n",
      "W1: 7.817337054468979 W2: 1.599698168969679 b -4.21195044863808 Loss: 0.42377143280058854\n",
      "W1: 7.8210147557180685 W2: 1.5999591305017715 b -4.2136778017844625 Loss: 0.42373820845943444\n",
      "W1: 7.824687240574553 W2: 1.6002199076383536 b -4.215402875250008 Loss: 0.42370507695874626\n",
      "W1: 7.828354518722901 W2: 1.600480500238225 b -4.21712567285582 Loss: 0.42367203799967573\n",
      "W1: 7.832016599824072 W2: 1.6007409081618613 b -4.218846198414755 Loss: 0.42363909128448624\n",
      "W1: 7.835673493515587 W2: 1.601001131271407 b -4.220564455731438 Loss: 0.4236062365165484\n",
      "W1: 7.839325209411605 W2: 1.6012611694306644 b -4.222280448602287 Loss: 0.4235734734003361\n",
      "W1: 7.8429717571029824 W2: 1.6015210225050864 b -4.223994180815538 Loss: 0.4235408016414206\n",
      "W1: 7.846613146157351 W2: 1.6017806903617662 b -4.225705656151259 Loss: 0.4235082209464664\n",
      "W1: 7.850249386119184 W2: 1.602040172869429 b -4.2274148783813805 Loss: 0.4234757310232269\n",
      "W1: 7.853880486509868 W2: 1.602299469898423 b -4.229121851269711 Loss: 0.4234433315805394\n",
      "W1: 7.857506456827767 W2: 1.6025585813207106 b -4.230826578571961 Loss: 0.42341102232832045\n",
      "W1: 7.861127306548295 W2: 1.6028175070098598 b -4.232529064035766 Loss: 0.4233788029775617\n",
      "W1: 7.864743045123985 W2: 1.603076246841035 b -4.234229311400703 Loss: 0.4233466732403249\n",
      "W1: 7.868353681984556 W2: 1.6033348006909882 b -4.235927324398316 Loss: 0.4233146328297373\n",
      "W1: 7.871959226536979 W2: 1.6035931684380513 b -4.237623106752139 Loss: 0.4232826814599877\n",
      "W1: 7.875559688165548 W2: 1.6038513499621265 b -4.23931666217771 Loss: 0.42325081884632154\n",
      "W1: 7.879155076231946 W2: 1.604109345144678 b -4.241007994382599 Loss: 0.4232190447050366\n",
      "W1: 7.882745400075314 W2: 1.6043671538687234 b -4.242697107066428 Loss: 0.42318735875347785\n",
      "W1: 7.886330669012316 W2: 1.6046247760188257 b -4.24438400392089 Loss: 0.4231557607100344\n",
      "W1: 7.889910892337205 W2: 1.6048822114810843 b -4.246068688629769 Loss: 0.42312425029413403\n",
      "W1: 7.893486079321896 W2: 1.6051394601431266 b -4.247751164868966 Loss: 0.42309282722623887\n",
      "W1: 7.897056239216023 W2: 1.6053965218940998 b -4.249431436306512 Loss: 0.4230614912278416\n",
      "W1: 7.900621381247013 W2: 1.6056533966246624 b -4.251109506602599 Loss: 0.4230302420214606\n",
      "W1: 7.904181514620147 W2: 1.6059100842269765 b -4.252785379409589 Loss: 0.4229990793306358\n",
      "W1: 7.907736648518629 W2: 1.6061665845946984 b -4.2544590583720465 Loss: 0.4229680028799242\n",
      "W1: 7.91128679210365 W2: 1.6064228976229715 b -4.25613054712675 Loss: 0.42293701239489595\n",
      "W1: 7.9148319545144545 W2: 1.6066790232084176 b -4.257799849302716 Loss: 0.42290610760212993\n",
      "W1: 7.918372144868403 W2: 1.6069349612491286 b -4.259466968521219 Loss: 0.4228752882292092\n",
      "W1: 7.92190737226104 W2: 1.607190711644659 b -4.261131908395814 Loss: 0.42284455400471743\n",
      "W1: 7.925437645766155 W2: 1.6074462742960174 b -4.262794672532354 Loss: 0.422813904658234\n",
      "W1: 7.928962974435851 W2: 1.6077016491056584 b -4.26445526452901 Loss: 0.42278333992032985\n",
      "W1: 7.932483367300607 W2: 1.607956835977475 b -4.266113687976295 Loss: 0.4227528595225643\n",
      "W1: 7.93599883336934 W2: 1.6082118348167902 b -4.267769946457079 Loss: 0.4227224631974798\n",
      "W1: 7.939509381629472 W2: 1.6084666455303498 b -4.269424043546613 Loss: 0.42269215067859817\n",
      "W1: 7.943015021046991 W2: 1.6087212680263137 b -4.271075982812548 Loss: 0.4226619217004164\n",
      "W1: 7.946515760566514 W2: 1.6089757022142486 b -4.272725767814955 Loss: 0.4226317759984031\n",
      "W1: 7.950011609111355 W2: 1.6092299480051202 b -4.274373402106342 Loss: 0.4226017133089936\n",
      "W1: 7.953502575583581 W2: 1.6094840053112853 b -4.276018889231679 Loss: 0.4225717333695865\n",
      "W1: 7.956988668864079 W2: 1.6097378740464843 b -4.277662232728415 Loss: 0.4225418359185397\n",
      "W1: 7.960469897812617 W2: 1.609991554125833 b -4.279303436126495 Loss: 0.42251202069516586\n",
      "W1: 7.963946271267907 W2: 1.6102450454658157 b -4.280942502948387 Loss: 0.42248228743972854\n",
      "W1: 7.967417798047666 W2: 1.6104983479842772 b -4.282579436709094 Loss: 0.42245263589343884\n",
      "W1: 7.97088448694868 W2: 1.610751461600415 b -4.284214240916177 Loss: 0.4224230657984508\n",
      "W1: 7.974346346746863 W2: 1.6110043862347727 b -4.285846919069775 Loss: 0.42239357689785756\n",
      "W1: 7.977803386197318 W2: 1.6112571218092315 b -4.287477474662623 Loss: 0.4223641689356877\n",
      "W1: 7.981255614034402 W2: 1.6115096682470031 b -4.289105911180071 Loss: 0.4223348416569012\n",
      "W1: 7.984703038971783 W2: 1.6117620254726226 b -4.2907322321001065 Loss: 0.4223055948073856\n",
      "W1: 7.988145669702502 W2: 1.6120141934119407 b -4.292356440893369 Loss: 0.42227642813395183\n",
      "W1: 7.991583514899036 W2: 1.6122661719921167 b -4.293978541023171 Loss: 0.422247341384331\n",
      "W1: 7.995016583213354 W2: 1.6125179611416112 b -4.295598535945522 Loss: 0.4222183343071697\n",
      "W1: 7.99844488327698 W2: 1.6127695607901782 b -4.297216429109137 Loss: 0.4221894066520274\n",
      "W1: 8.001868423701053 W2: 1.6130209708688588 b -4.2988322239554675 Loss: 0.42216055816937137\n",
      "W1: 8.005287213076384 W2: 1.6132721913099735 b -4.300445923918711 Loss: 0.42213178861057377\n",
      "W1: 8.008701259973522 W2: 1.613523222047115 b -4.302057532425835 Loss: 0.4221030977279076\n",
      "W1: 8.012110572942804 W2: 1.6137740630151414 b -4.303667052896595 Loss: 0.42207448527454283\n",
      "W1: 8.015515160514422 W2: 1.6140247141501691 b -4.3052744887435495 Loss: 0.42204595100454334\n",
      "W1: 8.018915031198476 W2: 1.6142751753895652 b -4.306879843372085 Loss: 0.4220174946728619\n",
      "W1: 8.022310193485039 W2: 1.6145254466719412 b -4.308483120180431 Loss: 0.42198911603533806\n",
      "W1: 8.02570065584421 W2: 1.6147755279371456 b -4.3100843225596766 Loss: 0.4219608148486934\n",
      "W1: 8.029086426726176 W2: 1.615025419126257 b -4.311683453893795 Loss: 0.4219325908705281\n",
      "W1: 8.032467514561267 W2: 1.6152751201815774 b -4.313280517559656 Loss: 0.42190444385931786\n",
      "W1: 8.035843927760018 W2: 1.615524631046625 b -4.314875516927048 Loss: 0.4218763735744091\n",
      "W1: 8.039215674713223 W2: 1.6157739516661276 b -4.316468455358694 Loss: 0.42184837977601713\n",
      "W1: 8.04258276379199 W2: 1.616023081986016 b -4.318059336210274 Loss: 0.4218204622252205\n",
      "W1: 8.045945203347811 W2: 1.6162720219534168 b -4.319648162830437 Loss: 0.42179262068395906\n",
      "W1: 8.049303001712602 W2: 1.6165207715166459 b -4.321234938560825 Loss: 0.4217648549150299\n",
      "W1: 8.052656167198771 W2: 1.6167693306252018 b -4.322819666736088 Loss: 0.4217371646820833\n",
      "W1: 8.056004708099273 W2: 1.6170176992297587 b -4.3244023506839016 Loss: 0.4217095497496199\n",
      "W1: 8.059348632687666 W2: 1.6172658772821602 b -4.325982993724989 Loss: 0.4216820098829871\n",
      "W1: 8.062687949218166 W2: 1.6175138647354124 b -4.327561599173134 Loss: 0.4216545448483753\n",
      "W1: 8.066022665925702 W2: 1.6177616615436776 b -4.329138170335203 Loss: 0.42162715441281445\n",
      "W1: 8.06935279102598 W2: 1.6180092676622677 b -4.330712710511159 Loss: 0.4215998383441711\n",
      "W1: 8.072678332715526 W2: 1.6182566830476377 b -4.332285222994083 Loss: 0.42157259641114386\n",
      "W1: 8.075999299171754 W2: 1.618503907657379 b -4.33385571107019 Loss: 0.4215454283832614\n",
      "W1: 8.079315698553012 W2: 1.6187509414502133 b -4.3354241780188465 Loss: 0.421518334030878\n",
      "W1: 8.082627538998645 W2: 1.6189977843859855 b -4.3369906271125895 Loss: 0.4214913131251708\n",
      "W1: 8.085934828629044 W2: 1.6192444364256589 b -4.338555061617143 Loss: 0.421464365438136\n",
      "W1: 8.089237575545702 W2: 1.619490897531307 b -4.340117484791435 Loss: 0.4214374907425851\n",
      "W1: 8.092535787831274 W2: 1.619737167666108 b -4.341677899887616 Loss: 0.4214106888121428\n",
      "W1: 8.095829473549623 W2: 1.6199832467943396 b -4.3432363101510765 Loss: 0.42138395942124285\n",
      "W1: 8.099118640745882 W2: 1.6202291348813702 b -4.3447927188204645 Loss: 0.4213573023451247\n",
      "W1: 8.102403297446502 W2: 1.6204748318936553 b -4.346347129127702 Loss: 0.42133071735983046\n",
      "W1: 8.10568345165931 W2: 1.6207203377987296 b -4.347899544298003 Loss: 0.42130420424220144\n",
      "W1: 8.108959111373562 W2: 1.6209656525652019 b -4.349449967549891 Loss: 0.4212777627698749\n",
      "W1: 8.112230284559995 W2: 1.6212107761627481 b -4.350998402095214 Loss: 0.42125139272128126\n",
      "W1: 8.115496979170883 W2: 1.6214557085621062 b -4.352544851139164 Loss: 0.42122509387563983\n",
      "W1: 8.118759203140089 W2: 1.6217004497350689 b -4.354089317880294 Loss: 0.42119886601295703\n",
      "W1: 8.122016964383114 W2: 1.6219449996544786 b -4.3556318055105345 Loss: 0.42117270891402186\n",
      "W1: 8.125270270797158 W2: 1.622189358294221 b -4.35717231721521 Loss: 0.4211466223604029\n",
      "W1: 8.128519130261164 W2: 1.6224335256292195 b -4.358710856173055 Loss: 0.4211206061344466\n",
      "W1: 8.13176355063588 W2: 1.6226775016354287 b -4.360247425556235 Loss: 0.421094660019272\n",
      "W1: 8.1350035397639 W2: 1.6229212862898286 b -4.3617820285303575 Loss: 0.4210687837987688\n",
      "W1: 8.13823910546973 W2: 1.6231648795704192 b -4.363314668254494 Loss: 0.42104297725759426\n",
      "W1: 8.141470255559824 W2: 1.6234082814562145 b -4.364845347881194 Loss: 0.42101724018116965\n",
      "W1: 8.14469699782265 W2: 1.6236514919272362 b -4.366374070556501 Loss: 0.42099157235567725\n",
      "W1: 8.147919340028736 W2: 1.6238945109645084 b -4.367900839419971 Loss: 0.42096597356805776\n",
      "W1: 8.151137289930714 W2: 1.6241373385500517 b -4.36942565760469 Loss: 0.42094044360600597\n",
      "W1: 8.154350855263388 W2: 1.6243799746668774 b -4.370948528237287 Loss: 0.42091498225796936\n",
      "W1: 8.157560043743768 W2: 1.624622419298982 b -4.372469454437952 Loss: 0.42088958931314374\n",
      "W1: 8.160764863071133 W2: 1.6248646724313411 b -4.373988439320454 Loss: 0.42086426456147097\n",
      "W1: 8.163965320927074 W2: 1.6251067340499046 b -4.375505485992155 Loss: 0.42083900779363526\n",
      "W1: 8.167161424975552 W2: 1.62534860414159 b -4.377020597554031 Loss: 0.4208138188010613\n",
      "W1: 8.170353182862941 W2: 1.625590282694278 b -4.37853377710068 Loss: 0.4207886973759098\n",
      "W1: 8.173540602218083 W2: 1.6258317696968057 b -4.380045027720345 Loss: 0.4207636433110753\n",
      "W1: 8.176723690652334 W2: 1.6260730651389617 b -4.38155435249493 Loss: 0.4207386564001837\n",
      "W1: 8.179902455759622 W2: 1.626314169011481 b -4.383061754500011 Loss: 0.4207137364375885\n",
      "W1: 8.183076905116486 W2: 1.6265550813060392 b -4.384567236804857 Loss: 0.42068888321836795\n",
      "W1: 8.186247046282135 W2: 1.6267958020152464 b -4.386070802472447 Loss: 0.42066409653832254\n",
      "W1: 8.18941288679849 W2: 1.6270363311326428 b -4.3875724545594785 Loss: 0.42063937619397157\n",
      "W1: 8.192574434190238 W2: 1.6272766686526927 b -4.389072196116392 Loss: 0.42061472198255084\n",
      "W1: 8.19573169596488 W2: 1.6275168145707797 b -4.390570030187383 Loss: 0.4205901337020094\n",
      "W1: 8.198884679612782 W2: 1.6277567688832002 b -4.392065959810416 Loss: 0.42056561115100644\n",
      "W1: 8.202033392607216 W2: 1.6279965315871596 b -4.393559988017244 Loss: 0.4205411541289092\n",
      "W1: 8.205177842404419 W2: 1.6282361026807661 b -4.395052117833422 Loss: 0.4205167624357892\n",
      "W1: 8.208318036443632 W2: 1.6284754821630256 b -4.396542352278325 Loss: 0.4204924358724202\n",
      "W1: 8.211453982147157 W2: 1.6287146700338366 b -4.39803069436516 Loss: 0.42046817424027483\n",
      "W1: 8.2145856869204 W2: 1.6289536662939847 b -4.399517147100986 Loss: 0.4204439773415223\n",
      "W1: 8.217713158151916 W2: 1.629192470945138 b -4.401001713486725 Loss: 0.4204198449790246\n",
      "W1: 8.220836403213468 W2: 1.6294310839898412 b -4.40248439651718 Loss: 0.4203957769563353\n",
      "W1: 8.22395542946006 W2: 1.6296695054315113 b -4.4039651991810524 Loss: 0.42037177307769547\n",
      "W1: 8.227070244229996 W2: 1.6299077352744322 b -4.405444124460953 Loss: 0.42034783314803126\n",
      "W1: 8.230180854844921 W2: 1.630145773523749 b -4.406921175333419 Loss: 0.42032395697295133\n",
      "W1: 8.233287268609871 W2: 1.6303836201854638 b -4.408396354768934 Loss: 0.4203001443587439\n",
      "W1: 8.23638949281332 W2: 1.6306212752664304 b -4.409869665731935 Loss: 0.42027639511237475\n",
      "W1: 8.239487534727225 W2: 1.6308587387743494 b -4.411341111180834 Loss: 0.4202527090414831\n",
      "W1: 8.242581401607074 W2: 1.631096010717763 b -4.41281069406803 Loss: 0.4202290859543805\n",
      "W1: 8.245671100691933 W2: 1.6313330911060502 b -4.4142784173399265 Loss: 0.4202055256600468\n",
      "W1: 8.24875663920449 W2: 1.6315699799494219 b -4.415744283936945 Loss: 0.4201820279681284\n",
      "W1: 8.251838024351107 W2: 1.631806677258916 b -4.417208296793541 Loss: 0.42015859268893524\n",
      "W1: 8.254915263321859 W2: 1.6320431830463924 b -4.418670458838218 Loss: 0.42013521963343786\n",
      "W1: 8.257988363290583 W2: 1.6322794973245285 b -4.4201307729935415 Loss: 0.4201119086132657\n",
      "W1: 8.261057331414923 W2: 1.6325156201068143 b -4.421589242176158 Loss: 0.4200886594407033\n",
      "W1: 8.264122174836379 W2: 1.632751551407547 b -4.423045869296806 Loss: 0.4200654719286883\n",
      "W1: 8.267182900680348 W2: 1.6329872912418273 b -4.424500657260332 Loss: 0.42004234589080947\n",
      "W1: 8.270239516056172 W2: 1.6332228396255535 b -4.425953608965705 Loss: 0.42001928114130216\n",
      "W1: 8.273292028057181 W2: 1.633458196575418 b -4.427404727306034 Loss: 0.4199962774950483\n",
      "W1: 8.276340443760741 W2: 1.6336933621089016 b -4.428854015168578 Loss: 0.4199733347675719\n",
      "W1: 8.279384770228297 W2: 1.6339283362442694 b -4.430301475434764 Loss: 0.41995045277503684\n",
      "W1: 8.282425014505417 W2: 1.6341631190005659 b -4.4317471109802 Loss: 0.4199276313342454\n",
      "W1: 8.28546118362184 W2: 1.6343977103976104 b -4.433190924674692 Loss: 0.4199048702626344\n",
      "W1: 8.288493284591512 W2: 1.6346321104559927 b -4.434632919382255 Loss: 0.41988216937827344\n",
      "W1: 8.291521324412644 W2: 1.6348663191970678 b -4.436073097961132 Loss: 0.41985952849986236\n",
      "W1: 8.294545310067743 W2: 1.6351003366429524 b -4.437511463263802 Loss: 0.41983694744672806\n",
      "W1: 8.297565248523664 W2: 1.6353341628165194 b -4.438948018137002 Loss: 0.4198144260388229\n",
      "W1: 8.300581146731652 W2: 1.6355677977413943 b -4.4403827654217345 Loss: 0.41979196409672165\n",
      "W1: 8.303593011627381 W2: 1.6358012414419496 b -4.441815707953287 Loss: 0.4197695614416197\n",
      "W1: 8.306600850131003 W2: 1.6360344939433016 b -4.443246848561245 Loss: 0.4197472178953295\n",
      "W1: 8.309604669147193 W2: 1.636267555271305 b -4.444676190069502 Loss: 0.4197249332802793\n",
      "W1: 8.312604475565186 W2: 1.6365004254525493 b -4.44610373529628 Loss: 0.4197027074195098\n",
      "W1: 8.315600276258824 W2: 1.636733104514353 b -4.4475294870541395 Loss: 0.4196805401366721\n",
      "W1: 8.3185920780866 W2: 1.636965592484761 b -4.4489534481499975 Loss: 0.4196584312560258\n",
      "W1: 8.321579887891694 W2: 1.6371978893925394 b -4.4503756213851355 Loss: 0.4196363806024354\n",
      "W1: 8.324563712502028 W2: 1.6374299952671707 b -4.45179600955522 Loss: 0.419614388001369\n",
      "W1: 8.327543558730296 W2: 1.6376619101388508 b -4.453214615450311 Loss: 0.41959245327889577\n",
      "W1: 8.330519433374015 W2: 1.637893634038483 b -4.454631441854881 Loss: 0.4195705762616828\n",
      "W1: 8.33349134321556 W2: 1.638125166997676 b -4.456046491547824 Loss: 0.4195487567769937\n",
      "W1: 8.336459295022214 W2: 1.6383565090487369 b -4.457459767302476 Loss: 0.41952699465268567\n",
      "W1: 8.339423295546206 W2: 1.6385876602246696 b -4.458871271886619 Loss: 0.4195052897172075\n",
      "W1: 8.342383351524752 W2: 1.6388186205591688 b -4.4602810080625055 Loss: 0.41948364179959685\n",
      "W1: 8.345339469680098 W2: 1.639049390086617 b -4.4616889785868645 Loss: 0.4194620507294784\n",
      "W1: 8.348291656719562 W2: 1.6392799688420794 b -4.463095186210919 Loss: 0.4194405163370611\n",
      "W1: 8.351239919335573 W2: 1.6395103568613005 b -4.464499633680397 Loss: 0.41941903845313655\n",
      "W1: 8.354184264205715 W2: 1.6397405541807 b -4.465902323735549 Loss: 0.4193976169090757\n",
      "W1: 8.35712469799277 W2: 1.6399705608373678 b -4.4673032591111586 Loss: 0.41937625153682756\n",
      "W1: 8.360061227344753 W2: 1.640200376869061 b -4.468702442536556 Loss: 0.4193549421689164\n",
      "W1: 8.362993858894958 W2: 1.6404300023141993 b -4.470099876735634 Loss: 0.4193336886384394\n",
      "W1: 8.365922599261996 W2: 1.6406594372118612 b -4.471495564426856 Loss: 0.41931249077906524\n",
      "W1: 8.368847455049838 W2: 1.6408886816017803 b -4.472889508323279 Loss: 0.41929134842503024\n",
      "W1: 8.371768432847855 W2: 1.64111773552434 b -4.474281711132557 Loss: 0.4192702614111383\n",
      "W1: 8.374685539230855 W2: 1.6413465990205716 b -4.4756721755569595 Loss: 0.4192492295727567\n",
      "W1: 8.37759878075913 W2: 1.6415752721321484 b -4.477060904293386 Loss: 0.4192282527458149\n",
      "W1: 8.380508163978485 W2: 1.6418037549013833 b -4.478447900033373 Loss: 0.4192073307668025\n",
      "W1: 8.383413695420293 W2: 1.6420320473712238 b -4.479833165463116 Loss: 0.4191864634727666\n",
      "W1: 8.386315381601523 W2: 1.6422601495852487 b -4.481216703263476 Loss: 0.4191656507013097\n",
      "W1: 8.389213229024783 W2: 1.6424880615876642 b -4.482598516109993 Loss: 0.41914489229058716\n",
      "W1: 8.392107244178362 W2: 1.6427157834233 b -4.483978606672904 Loss: 0.41912418807930635\n",
      "W1: 8.394997433536266 W2: 1.642943315137605 b -4.485356977617153 Loss: 0.4191035379067229\n",
      "W1: 8.397883803558262 W2: 1.6431706567766446 b -4.486733631602401 Loss: 0.41908294161263987\n",
      "W1: 8.40076636068991 W2: 1.6433978083870961 b -4.488108571283045 Loss: 0.4190623990374045\n",
      "W1: 8.40364511136261 W2: 1.643624770016245 b -4.489481799308228 Loss: 0.41904191002190705\n",
      "W1: 8.406520061993636 W2: 1.6438515417119812 b -4.49085331832185 Loss: 0.41902147440757814\n",
      "W1: 8.409391218986173 W2: 1.644078123522796 b -4.492223130962585 Loss: 0.41900109203638675\n",
      "W1: 8.412258588729363 W2: 1.6443045154977773 b -4.493591239863891 Loss: 0.418980762750838\n",
      "W1: 8.41512217759834 W2: 1.644530717686607 b -4.494957647654023 Loss: 0.41896048639397176\n",
      "W1: 8.417981991954264 W2: 1.6447567301395565 b -4.496322356956047 Loss: 0.4189402628093598\n",
      "W1: 8.420838038144366 W2: 1.6449825529074833 b -4.4976853703878525 Loss: 0.4189200918411035\n",
      "W1: 8.423690322501983 W2: 1.645208186041828 b -4.499046690562165 Loss: 0.41889997333383316\n",
      "W1: 8.426538851346594 W2: 1.6454336295946093 b -4.500406320086557 Loss: 0.41887990713270434\n",
      "W1: 8.429383630983864 W2: 1.645658883618422 b -4.501764261563464 Loss: 0.41885989308339705\n",
      "W1: 8.432224667705675 W2: 1.6458839481664325 b -4.503120517590195 Loss: 0.4188399310321129\n",
      "W1: 8.43506196779017 W2: 1.6461088232923753 b -4.504475090758944 Loss: 0.4188200208255737\n",
      "W1: 8.437895537501786 W2: 1.6463335090505495 b -4.505827983656806 Loss: 0.41880016231101896\n",
      "W1: 8.440725383091292 W2: 1.646558005495816 b -4.507179198865785 Loss: 0.4187803553362043\n",
      "W1: 8.443551510795828 W2: 1.6467823126835925 b -4.508528738962811 Loss: 0.41876059974939905\n",
      "W1: 8.446373926838943 W2: 1.6470064306698518 b -4.50987660651975 Loss: 0.41874089539938436\n",
      "W1: 8.44919263743063 W2: 1.6472303595111168 b -4.511222804103416 Loss: 0.4187212421354518\n",
      "W1: 8.452007648767362 W2: 1.6474540992644582 b -4.512567334275583 Loss: 0.4187016398074006\n",
      "W1: 8.454818967032132 W2: 1.6476776499874901 b -4.513910199593001 Loss: 0.41868208826553577\n",
      "W1: 8.457626598394489 W2: 1.6479010117383677 b -4.5152514026074035 Loss: 0.4186625873606673\n",
      "W1: 8.460430549010573 W2: 1.6481241845757828 b -4.516590945865523 Loss: 0.4186431369441063\n",
      "W1: 8.463230825023151 W2: 1.6483471685589612 b -4.517928831909101 Loss: 0.4186237368676647\n",
      "W1: 8.466027432561658 W2: 1.6485699637476592 b -4.5192650632749025 Loss: 0.41860438698365265\n",
      "W1: 8.468820377742228 W2: 1.6487925702021595 b -4.520599642494727 Loss: 0.41858508714487647\n",
      "W1: 8.471609666667732 W2: 1.6490149879832692 b -4.521932572095419 Loss: 0.4185658372046372\n",
      "W1: 8.474395305427814 W2: 1.6492372171523155 b -4.523263854598882 Loss: 0.4185466370167281\n",
      "W1: 8.477177300098928 W2: 1.6494592577711429 b -4.524593492522093 Loss: 0.41852748643543336\n",
      "W1: 8.479955656744375 W2: 1.6496811099021096 b -4.525921488377107 Loss: 0.41850838531552625\n",
      "W1: 8.482730381414331 W2: 1.6499027736080842 b -4.527247844671077 Loss: 0.4184893335122663\n",
      "W1: 8.485501480145896 W2: 1.6501242489524433 b -4.528572563906262 Loss: 0.4184703308813986\n",
      "W1: 8.488268958963115 W2: 1.650345535999067 b -4.5298956485800375 Loss: 0.4184513772791515\n",
      "W1: 8.491032823877022 W2: 1.6505666348123371 b -4.531217101184912 Loss: 0.41843247256223415\n",
      "W1: 8.493793080885677 W2: 1.6507875454571324 b -4.532536924208534 Loss: 0.4184136165878357\n",
      "W1: 8.496549735974192 W2: 1.6510082679988267 b -4.533855120133708 Loss: 0.4183948092136229\n",
      "W1: 8.499302795114774 W2: 1.6512288025032853 b -4.535171691438403 Loss: 0.4183760502977382\n",
      "W1: 8.502052264266759 W2: 1.6514491490368617 b -4.536486640595764 Loss: 0.41835733969879824\n",
      "W1: 8.504798149376642 W2: 1.6516693076663944 b -4.537799970074127 Loss: 0.41833867727589175\n",
      "W1: 8.507540456378116 W2: 1.6518892784592043 b -4.53911168233703 Loss: 0.41832006288857787\n",
      "W1: 8.510279191192108 W2: 1.6521090614830911 b -4.54042177984322 Loss: 0.41830149639688446\n",
      "W1: 8.513014359726805 W2: 1.6523286568063307 b -4.54173026504667 Loss: 0.41828297766130657\n",
      "W1: 8.515745967877699 W2: 1.6525480644976716 b -4.5430371403965895 Loss: 0.4182645065428034\n",
      "W1: 8.518474021527615 W2: 1.6527672846263322 b -4.5443424083374335 Loss: 0.4182460829027983\n",
      "W1: 8.521198526546746 W2: 1.6529863172619979 b -4.545646071308917 Loss: 0.41822770660317554\n",
      "W1: 8.52391948879269 W2: 1.6532051624748174 b -4.5469481317460225 Loss: 0.4182093775062797\n",
      "W1: 8.526636914110476 W2: 1.653423820335401 b -4.548248592079017 Loss: 0.418191095474913\n",
      "W1: 8.529350808332609 W2: 1.653642290914816 b -4.549547454733459 Loss: 0.4181728603723341\n",
      "W1: 8.532061177279093 W2: 1.6538605742845853 b -4.550844722130212 Loss: 0.418154672062256\n",
      "W1: 8.534768026757476 W2: 1.6540786705166832 b -4.552140396685455 Loss: 0.41813653040884496\n",
      "W1: 8.537471362562869 W2: 1.6542965796835332 b -4.553434480810692 Loss: 0.4181184352767179\n",
      "W1: 8.540171190477993 W2: 1.6545143018580049 b -4.554726976912767 Loss: 0.41810038653094117\n",
      "W1: 8.542867516273205 W2: 1.654731837113411 b -4.556017887393875 Loss: 0.41808238403702913\n",
      "W1: 8.545560345706534 W2: 1.6549491855235046 b -4.5573072146515665 Loss: 0.4180644276609419\n",
      "W1: 8.548249684523709 W2: 1.6551663471624758 b -4.55859496107877 Loss: 0.41804651726908376\n",
      "W1: 8.5509355384582 W2: 1.6553833221049499 b -4.559881129063792 Loss: 0.418028652728302\n",
      "W1: 8.553617913231243 W2: 1.6556001104259834 b -4.561165720990338 Loss: 0.41801083390588434\n",
      "W1: 8.556296814551878 W2: 1.655816712201062 b -4.562448739237512 Loss: 0.41799306066955816\n",
      "W1: 8.558972248116982 W2: 1.6560331275060975 b -4.56373018617984 Loss: 0.4179753328874885\n",
      "W1: 8.561644219611296 W2: 1.6562493564174248 b -4.565010064187273 Loss: 0.41795765042827604\n",
      "W1: 8.564312734707462 W2: 1.6564653990117992 b -4.566288375625201 Loss: 0.41794001316095597\n",
      "W1: 8.566977799066057 W2: 1.656681255366394 b -4.567565122854462 Loss: 0.41792242095499604\n",
      "W1: 8.569639418335619 W2: 1.6568969255587975 b -4.568840308231353 Loss: 0.4179048736802953\n",
      "W1: 8.572297598152682 W2: 1.6571124096670098 b -4.5701139341076455 Loss: 0.4178873712071818\n",
      "W1: 8.574952344141812 W2: 1.6573277077694408 b -4.5713860028305895 Loss: 0.4178699134064118\n",
      "W1: 8.577603661915632 W2: 1.6575428199449072 b -4.57265651674293 Loss: 0.41785250014916764\n",
      "W1: 8.580251557074858 W2: 1.6577577462726296 b -4.573925478182913 Loss: 0.41783513130705574\n",
      "W1: 8.582896035208332 W2: 1.6579724868322305 b -4.575192889484302 Loss: 0.4178178067521065\n",
      "W1: 8.58553710189305 W2: 1.6581870417037305 b -4.576458752976382 Loss: 0.4178005263567705\n",
      "W1: 8.588174762694198 W2: 1.658401410967547 b -4.577723070983976 Loss: 0.41778328999391934\n",
      "W1: 8.590809023165175 W2: 1.6586155947044898 b -4.578985845827452 Loss: 0.417766097536842\n",
      "W1: 8.593439888847634 W2: 1.6588295929957606 b -4.580247079822736 Loss: 0.4177489488592443\n",
      "W1: 8.596067365271507 W2: 1.6590434059229486 b -4.581506775281322 Loss: 0.41773184383524725\n",
      "W1: 8.59869145795504 W2: 1.659257033568029 b -4.58276493451028 Loss: 0.41771478233938575\n",
      "W1: 8.60131217240482 W2: 1.6594704760133598 b -4.58402155981227 Loss: 0.41769776424660593\n",
      "W1: 8.603929514115809 W2: 1.6596837333416794 b -4.585276653485553 Loss: 0.4176807894322645\n",
      "W1: 8.606543488571374 W2: 1.659896805636104 b -4.586530217823997 Loss: 0.41766385777212794\n",
      "W1: 8.60915410124332 W2: 1.6601096929801253 b -4.587782255117091 Loss: 0.41764696914236904\n",
      "W1: 8.611761357591913 W2: 1.6603223954576078 b -4.589032767649956 Loss: 0.4176301234195669\n",
      "W1: 8.61436526306592 W2: 1.660534913152786 b -4.590281757703353 Loss: 0.417613320480705\n",
      "W1: 8.616965823102634 W2: 1.6607472461502624 b -4.591529227553694 Loss: 0.41759656020316954\n",
      "W1: 8.619563043127904 W2: 1.6609593945350045 b -4.592775179473054 Loss: 0.41757984246474816\n",
      "W1: 8.62215692855617 W2: 1.6611713583923429 b -4.594019615729179 Loss: 0.4175631671436277\n",
      "W1: 8.624747484790484 W2: 1.6613831378079684 b -4.595262538585499 Loss: 0.41754653411839426\n",
      "W1: 8.627334717222555 W2: 1.6615947328679295 b -4.596503950301135 Loss: 0.41752994326803\n",
      "W1: 8.62991863123276 W2: 1.66180614365863 b -4.597743853130912 Loss: 0.41751339447191305\n",
      "W1: 8.632499232190193 W2: 1.662017370266827 b -4.598982249325368 Loss: 0.4174968876098146\n",
      "W1: 8.635076525452678 W2: 1.662228412779628 b -4.600219141130763 Loss: 0.41748042256189916\n",
      "W1: 8.637650516366811 W2: 1.6624392712844887 b -4.601454530789093 Loss: 0.4174639992087216\n",
      "W1: 8.640221210267983 W2: 1.66264994586921 b -4.602688420538096 Loss: 0.41744761743122644\n",
      "W1: 8.64278861248041 W2: 1.6628604366219373 b -4.603920812611262 Loss: 0.4174312771107461\n",
      "W1: 8.645352728317167 W2: 1.6630707436311558 b -4.605151709237849 Loss: 0.4174149781289998\n",
      "W1: 8.64791356308021 W2: 1.66328086698569 b -4.606381112642885 Loss: 0.41739872036809195\n",
      "W1: 8.650471122060413 W2: 1.6634908067747005 b -4.607609025047183 Loss: 0.41738250371051056\n",
      "W1: 8.65302541053759 W2: 1.6637005630876818 b -4.6088354486673495 Loss: 0.41736632803912577\n",
      "W1: 8.65557643378053 W2: 1.6639101360144601 b -4.610060385715796 Loss: 0.41735019323718886\n",
      "W1: 8.658124197047021 W2: 1.664119525645191 b -4.611283838400746 Loss: 0.41733409918833053\n",
      "W1: 8.660668705583884 W2: 1.664328732070357 b -4.612505808926247 Loss: 0.4173180457765595\n",
      "W1: 8.663209964626995 W2: 1.6645377553807654 b -4.613726299492181 Loss: 0.41730203288626116\n",
      "W1: 8.66574797940132 W2: 1.664746595667546 b -4.614945312294272 Loss: 0.4172860604021963\n",
      "W1: 8.668282755120941 W2: 1.6649552530221485 b -4.6161628495240965 Loss: 0.4172701282094992\n",
      "W1: 8.670814296989086 W2: 1.6651637275363411 b -4.6173789133690955 Loss: 0.4172542361936769\n",
      "W1: 8.673342610198151 W2: 1.6653720193022075 b -4.618593506012581 Loss: 0.4172383842406076\n",
      "W1: 8.67586769992974 W2: 1.6655801284121445 b -4.619806629633748 Loss: 0.4172225722365393\n",
      "W1: 8.67838957135468 W2: 1.6657880549588606 b -4.6210182864076845 Loss: 0.41720680006808786\n",
      "W1: 8.680908229633062 W2: 1.6659957990353733 b -4.622228478505378 Loss: 0.41719106762223696\n",
      "W1: 8.683423679914258 W2: 1.666203360735007 b -4.62343720809373 Loss: 0.4171753747863351\n",
      "W1: 8.685935927336956 W2: 1.6664107401513908 b -4.6246444773355595 Loss: 0.4171597214480956\n",
      "W1: 8.688444977029185 W2: 1.6666179373784558 b -4.6258502883896195 Loss: 0.4171441074955947\n",
      "W1: 8.690950834108342 W2: 1.6668249525104342 b -4.6270546434106015 Loss: 0.4171285328172701\n",
      "W1: 8.693453503681223 W2: 1.6670317856418562 b -4.628257544549147 Loss: 0.41711299730192003\n",
      "W1: 8.695952990844047 W2: 1.667238436867548 b -4.629458993951856 Loss: 0.4170975008387012\n",
      "W1: 8.698449300682485 W2: 1.6674449062826295 b -4.630658993761297 Loss: 0.4170820433171286\n",
      "W1: 8.700942438271692 W2: 1.6676511939825132 b -4.631857546116018 Loss: 0.4170666246270729\n",
      "W1: 8.703432408676324 W2: 1.6678573000629004 b -4.6330546531505545 Loss: 0.4170512446587605\n",
      "W1: 8.705919216950575 W2: 1.6680632246197808 b -4.634250316995437 Loss: 0.4170359033027707\n",
      "W1: 8.708402868138197 W2: 1.6682689677494296 b -4.635444539777204 Loss: 0.41702060045003597\n",
      "W1: 8.710883367272535 W2: 1.668474529548405 b -4.63663732361841 Loss: 0.41700533599183937\n",
      "W1: 8.713360719376547 W2: 1.6686799101135468 b -4.637828670637632 Loss: 0.41699010981981394\n",
      "W1: 8.715834929462835 W2: 1.6688851095419746 b -4.639018582949485 Loss: 0.4169749218259413\n",
      "W1: 8.718306002533666 W2: 1.6690901279310848 b -4.640207062664625 Loss: 0.41695977190255035\n",
      "W1: 8.720773943581008 W2: 1.6692949653785496 b -4.6413941118897615 Loss: 0.4169446599423159\n",
      "W1: 8.72323875758655 W2: 1.6694996219823144 b -4.6425797327276666 Loss: 0.41692958583825757\n",
      "W1: 8.725700449521732 W2: 1.6697040978405957 b -4.643763927277183 Loss: 0.4169145494837384\n",
      "W1: 8.728159024347764 W2: 1.6699083930518794 b -4.644946697633234 Loss: 0.4168995507724633\n",
      "W1: 8.730614487015668 W2: 1.6701125077149186 b -4.646128045886833 Loss: 0.4168845895984789\n",
      "W1: 8.733066842466286 W2: 1.670316441928732 b -4.647307974125091 Loss: 0.41686966585617075\n",
      "W1: 8.735516095630318 W2: 1.6705201957926015 b -4.6484864844312295 Loss: 0.4168547794402633\n",
      "W1: 8.737962251428348 W2: 1.6707237694060704 b -4.649663578884583 Loss: 0.41683993024581806\n",
      "W1: 8.740405314770863 W2: 1.6709271628689417 b -4.650839259560615 Loss: 0.41682511816823276\n",
      "W1: 8.742845290558286 W2: 1.6711303762812757 b -4.652013528530923 Loss: 0.41681034310323956\n",
      "W1: 8.745282183680997 W2: 1.6713334097433885 b -4.653186387863249 Loss: 0.4167956049469041\n",
      "W1: 8.747715999019364 W2: 1.6715362633558497 b -4.654357839621486 Loss: 0.4167809035956248\n",
      "W1: 8.750146741443766 W2: 1.6717389372194809 b -4.655527885865691 Loss: 0.41676623894613096\n",
      "W1: 8.752574415814614 W2: 1.6719414314353533 b -4.656696528652092 Loss: 0.4167516108954818\n",
      "W1: 8.754999026982386 W2: 1.6721437461047866 b -4.657863770033095 Loss: 0.41673701934106494\n",
      "W1: 8.757420579787647 W2: 1.672345881329346 b -4.659029612057296 Loss: 0.4167224641805962\n",
      "W1: 8.759839079061074 W2: 1.6725478372108415 b -4.6601940567694875 Loss: 0.416707945312117\n",
      "W1: 8.762254529623482 W2: 1.6727496138513256 b -4.661357106210669 Loss: 0.4166934626339944\n",
      "W1: 8.764666936285852 W2: 1.6729512113530907 b -4.662518762418055 Loss: 0.4166790160449189\n",
      "W1: 8.767076303849356 W2: 1.6731526298186687 b -4.663679027425084 Loss: 0.41666460544390455\n",
      "W1: 8.769482637105376 W2: 1.673353869350828 b -4.664837903261425 Loss: 0.4166502307302862\n",
      "W1: 8.771885940835537 W2: 1.673554930052572 b -4.665995391952992 Loss: 0.41663589180371957\n",
      "W1: 8.774286219811726 W2: 1.6737558120271379 b -4.6671514955219475 Loss: 0.4166215885641795\n",
      "W1: 8.776683478796121 W2: 1.6739565153779936 b -4.6683062159867115 Loss: 0.4166073209119592\n",
      "W1: 8.779077722541214 W2: 1.6741570402088375 b -4.669459555361972 Loss: 0.4165930887476682\n",
      "W1: 8.781468955789837 W2: 1.6743573866235955 b -4.6706115156586945 Loss: 0.41657889197223275\n",
      "W1: 8.783857183275185 W2: 1.6745575547264195 b -4.671762098884127 Loss: 0.41656473048689285\n",
      "W1: 8.78624240972084 W2: 1.6747575446216862 b -4.672911307041812 Loss: 0.41655060419320283\n",
      "W1: 8.7886246398408 W2: 1.6749573564139946 b -4.6740591421315925 Loss: 0.41653651299302885\n",
      "W1: 8.791003878339497 W2: 1.6751569902081647 b -4.675205606149624 Loss: 0.4165224567885486\n",
      "W1: 8.79338012991183 W2: 1.6753564461092356 b -4.67635070108838 Loss: 0.4165084354822499\n",
      "W1: 8.795753399243178 W2: 1.6755557242224641 b -4.67749442893666 Loss: 0.4164944489769294\n",
      "W1: 8.798123691009437 W2: 1.6757548246533223 b -4.6786367916796 Loss: 0.41648049717569186\n",
      "W1: 8.800491009877032 W2: 1.6759537475074966 b -4.679777791298681 Loss: 0.41646657998194886\n",
      "W1: 8.802855360502951 W2: 1.6761524928908855 b -4.680917429771736 Loss: 0.4164526972994176\n",
      "W1: 8.805216747534763 W2: 1.6763510609095984 b -4.6820557090729595 Loss: 0.41643884903211953\n",
      "W1: 8.80757517561064 W2: 1.6765494516699535 b -4.683192631172914 Loss: 0.41642503508438006\n",
      "W1: 8.809930649359393 W2: 1.676747665278476 b -4.684328198038542 Loss: 0.4164112553608268\n",
      "W1: 8.81228317340048 W2: 1.6769457018418972 b -4.68546241163317 Loss: 0.4163975097663887\n",
      "W1: 8.814632752344043 W2: 1.6771435614671517 b -4.68659527391652 Loss: 0.41638379820629506\n",
      "W1: 8.81697939079092 W2: 1.677341244261377 b -4.687726786844718 Loss: 0.4163701205860739\n",
      "W1: 8.81932309333268 W2: 1.6775387503319115 b -4.688856952370298 Loss: 0.41635647681155175\n",
      "W1: 8.821663864551637 W2: 1.6777360797862915 b -4.689985772442214 Loss: 0.41634286678885196\n",
      "W1: 8.82400170902088 W2: 1.6779332327322516 b -4.69111324900585 Loss: 0.4163292904243938\n",
      "W1: 8.826336631304294 W2: 1.6781302092777222 b -4.692239384003024 Loss: 0.41631574762489126\n",
      "W1: 8.82866863595658 W2: 1.6783270095308274 b -4.693364179371996 Loss: 0.4163022382973523\n",
      "W1: 8.830997727523284 W2: 1.6785236335998845 b -4.694487637047481 Loss: 0.41628876234907786\n",
      "W1: 8.83332391054082 W2: 1.6787200815934014 b -4.695609758960652 Loss: 0.41627531968766\n",
      "W1: 8.835647189536484 W2: 1.6789163536200755 b -4.69673054703915 Loss: 0.416261910220982\n",
      "W1: 8.837967569028491 W2: 1.6791124497887924 b -4.697850003207093 Loss: 0.4162485338572164\n",
      "W1: 8.840285053525985 W2: 1.6793083702086236 b -4.698968129385084 Loss: 0.4162351905048245\n",
      "W1: 8.842599647529072 W2: 1.6795041149888255 b -4.700084927490217 Loss: 0.41622188007255506\n",
      "W1: 8.844911355528836 W2: 1.6796996842388376 b -4.701200399436087 Loss: 0.4162086024694433\n",
      "W1: 8.847220182007366 W2: 1.6798950780682813 b -4.702314547132798 Loss: 0.4161953576048102\n",
      "W1: 8.849526131437774 W2: 1.680090296586958 b -4.703427372486969 Loss: 0.4161821453882608\n",
      "W1: 8.85182920828422 W2: 1.6802853399048476 b -4.7045388774017445 Loss: 0.4161689657296838\n",
      "W1: 8.854129417001941 W2: 1.6804802081321075 b -4.7056490637768 Loss: 0.41615581853925065\n",
      "W1: 8.856426762037263 W2: 1.6806749013790703 b -4.706757933508352 Loss: 0.41614270372741374\n",
      "W1: 8.858721247827626 W2: 1.6808694197562428 b -4.707865488489165 Loss: 0.416129621204906\n",
      "W1: 8.861012878801613 W2: 1.6810637633743046 b -4.708971730608559 Loss: 0.4161165708827401\n",
      "W1: 8.863301659378966 W2: 1.6812579323441064 b -4.710076661752417 Loss: 0.4161035526722069\n",
      "W1: 8.865587593970607 W2: 1.681451926776668 b -4.711180283803196 Loss: 0.41609056648487464\n",
      "W1: 8.867870686978668 W2: 1.6816457467831785 b -4.712282598639929 Loss: 0.41607761223258816\n",
      "W1: 8.870150942796503 W2: 1.6818393924749926 b -4.713383608138239 Loss: 0.4160646898274675\n",
      "W1: 8.872428365808718 W2: 1.6820328639636308 b -4.714483314170342 Loss: 0.4160517991819079\n",
      "W1: 8.874702960391188 W2: 1.6822261613607774 b -4.715581718605057 Loss: 0.4160389402085772\n",
      "W1: 8.876974730911083 W2: 1.682419284778279 b -4.716678823307814 Loss: 0.4160261128204164\n",
      "W1: 8.879243681726887 W2: 1.6826122343281436 b -4.71777463014066 Loss: 0.4160133169306377\n",
      "W1: 8.88150981718842 W2: 1.682805010122538 b -4.718869140962269 Loss: 0.41600055245272444\n",
      "W1: 8.88377314163686 W2: 1.6829976122737877 b -4.719962357627948 Loss: 0.4159878193004291\n",
      "W1: 8.886033659404765 W2: 1.6831900408943747 b -4.721054281989645 Loss: 0.4159751173877729\n",
      "W1: 8.888291374816093 W2: 1.6833822960969365 b -4.722144915895954 Loss: 0.41596244662904525\n",
      "W1: 8.890546292186228 W2: 1.6835743779942642 b -4.723234261192129 Loss: 0.4159498069388016\n",
      "W1: 8.892798415821995 W2: 1.683766286699302 b -4.724322319720086 Loss: 0.41593719823186404\n",
      "W1: 8.895047750021684 W2: 1.6839580223251445 b -4.7254090933184125 Loss: 0.4159246204233192\n",
      "W1: 8.897294299075075 W2: 1.684149584985037 b -4.726494583822374 Loss: 0.4159120734285175\n",
      "W1: 8.899538067263453 W2: 1.6843409747923725 b -4.727578793063924 Loss: 0.41589955716307275\n",
      "W1: 8.901779058859637 W2: 1.6845321918606917 b -4.728661722871709 Loss: 0.41588707154286053\n",
      "W1: 8.90401727812799 W2: 1.6847232363036806 b -4.7297433750710764 Loss: 0.4158746164840179\n",
      "W1: 8.90625272932445 W2: 1.6849141082351695 b -4.730823751484083 Loss: 0.415862191902942\n",
      "W1: 8.908485416696548 W2: 1.6851048077691322 b -4.7319028539295 Loss: 0.4158497977162894\n",
      "W1: 8.910715344483426 W2: 1.685295335019684 b -4.732980684222826 Loss: 0.4158374338409749\n",
      "W1: 8.912942516915862 W2: 1.6854856901010806 b -4.734057244176287 Loss: 0.41582510019417107\n",
      "W1: 8.915166938216286 W2: 1.685675873127717 b -4.735132535598849 Loss: 0.4158127966933071\n",
      "W1: 8.917388612598808 W2: 1.6858658842141256 b -4.736206560296223 Loss: 0.4158005232560677\n",
      "W1: 8.919607544269232 W2: 1.6860557234749758 b -4.737279320070873 Loss: 0.4157882798003923\n",
      "W1: 8.921823737425077 W2: 1.6862453910250716 b -4.738350816722024 Loss: 0.4157760662444742\n",
      "W1: 8.924037196255604 W2: 1.6864348869793515 b -4.739421052045668 Loss: 0.4157638825067604\n",
      "W1: 8.926247924941826 W2: 1.6866242114528862 b -4.740490027834573 Loss: 0.4157517285059489\n",
      "W1: 8.928455927656541 W2: 1.686813364560878 b -4.741557745878288 Loss: 0.41573960416098993\n",
      "W1: 8.930661208564342 W2: 1.6870023464186594 b -4.742624207963152 Loss: 0.4157275093910833\n",
      "W1: 8.93286377182164 W2: 1.6871911571416915 b -4.743689415872299 Loss: 0.4157154441156791\n",
      "W1: 8.93506362157669 W2: 1.6873797968455633 b -4.744753371385669 Loss: 0.4157034082544752\n",
      "W1: 8.9372607619696 W2: 1.6875682656459894 b -4.745816076280012 Loss: 0.41569140172741753\n",
      "W1: 8.939455197132363 W2: 1.6877565636588103 b -4.746877532328896 Loss: 0.415679424454699\n",
      "W1: 8.941646931188869 W2: 1.6879446909999902 b -4.747937741302715 Loss: 0.4156674763567585\n",
      "W1: 8.943835968254927 W2: 1.6881326477856158 b -4.748996704968693 Loss: 0.4156555573542798\n",
      "W1: 8.946022312438288 W2: 1.6883204341318951 b -4.750054425090897 Loss: 0.4156436673681908\n",
      "W1: 8.948205967838662 W2: 1.6885080501551566 b -4.751110903430238 Loss: 0.41563180631966345\n",
      "W1: 8.950386938547737 W2: 1.6886954959718476 b -4.752166141744481 Loss: 0.41561997413011187\n",
      "W1: 8.9525652286492 W2: 1.6888827716985333 b -4.753220141788252 Loss: 0.41560817072119177\n",
      "W1: 8.95474084221876 W2: 1.6890698774518955 b -4.754272905313045 Loss: 0.4155963960147998\n",
      "W1: 8.956913783324158 W2: 1.6892568133487313 b -4.755324434067228 Loss: 0.4155846499330727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 8.9590840560252 W2: 1.6894435795059521 b -4.756374729796051 Loss: 0.4155729323983865\n",
      "W1: 8.961251664373764 W2: 1.6896301760405825 b -4.757423794241653 Loss: 0.41556124333335537\n",
      "W1: 8.963416612413829 W2: 1.6898166030697588 b -4.758471629143067 Loss: 0.41554958266083103\n",
      "W1: 8.96557890418149 W2: 1.690002860710728 b -4.75951823623623 Loss: 0.415537950303902\n",
      "W1: 8.967738543704975 W2: 1.690188949080847 b -4.760563617253987 Loss: 0.41552634618589257\n",
      "W1: 8.96989553500467 W2: 1.690374868297581 b -4.761607773926101 Loss: 0.4155147702303621\n",
      "W1: 8.972049882093133 W2: 1.690560618478502 b -4.762650707979256 Loss: 0.4155032223611041\n",
      "W1: 8.974201588975118 W2: 1.6907461997412887 b -4.76369242113707 Loss: 0.41549170250214557\n",
      "W1: 8.97635065964759 W2: 1.6909316122037246 b -4.764732915120092 Loss: 0.41548021057774615\n",
      "W1: 8.978497098099746 W2: 1.691116855983697 b -4.765772191645819 Loss: 0.41546874651239707\n",
      "W1: 8.980640908313035 W2: 1.6913019311991964 b -4.766810252428698 Loss: 0.4154573102308207\n",
      "W1: 8.982782094261173 W2: 1.6914868379683141 b -4.767847099180131 Loss: 0.4154459016579697\n",
      "W1: 8.984920659910168 W2: 1.691671576409243 b -4.7688827336084865 Loss: 0.4154345207190257\n",
      "W1: 8.987056609218333 W2: 1.6918561466402744 b -4.769917157419101 Loss: 0.41542316733939927\n",
      "W1: 8.98918994613631 W2: 1.6920405487797985 b -4.770950372314292 Loss: 0.4154118414447286\n",
      "W1: 8.991320674607083 W2: 1.6922247829463026 b -4.771982379993358 Loss: 0.41540054296087897\n",
      "W1: 8.993448798566002 W2: 1.6924088492583702 b -4.77301318215259 Loss: 0.41538927181394175\n",
      "W1: 8.995574321940795 W2: 1.6925927478346796 b -4.774042780485275 Loss: 0.4153780279302339\n",
      "W1: 8.997697248651598 W2: 1.6927764787940036 b -4.775071176681707 Loss: 0.41536681123629665\n",
      "W1: 8.99981758261096 W2: 1.6929600422552078 b -4.776098372429188 Loss: 0.41535562165889567\n",
      "W1: 9.001935327723874 W2: 1.6931434383372495 b -4.777124369412039 Loss: 0.4153444591250191\n",
      "W1: 9.004050487887785 W2: 1.6933266671591767 b -4.778149169311605 Loss: 0.41533332356187797\n",
      "W1: 9.006163066992611 W2: 1.6935097288401273 b -4.77917277380626 Loss: 0.41532221489690446\n",
      "W1: 9.00827306892077 W2: 1.6936926234993281 b -4.780195184571417 Loss: 0.41531113305775164\n",
      "W1: 9.010380497547185 W2: 1.6938753512560933 b -4.781216403279532 Loss: 0.4153000779722926\n",
      "W1: 9.01248535673931 W2: 1.694057912229824 b -4.782236431600112 Loss: 0.4152890495686197\n",
      "W1: 9.014587650357148 W2: 1.6942403065400067 b -4.78325527119972 Loss: 0.41527804777504385\n",
      "W1: 9.016687382253268 W2: 1.6944225343062123 b -4.784272923741982 Loss: 0.41526707252009365\n",
      "W1: 9.018784556272822 W2: 1.6946045956480957 b -4.785289390887595 Loss: 0.4152561237325145\n",
      "W1: 9.02087917625356 W2: 1.6947864906853942 b -4.786304674294331 Loss: 0.41524520134126847\n",
      "W1: 9.02297124602586 W2: 1.6949682195379265 b -4.787318775617045 Loss: 0.4152343052755329\n",
      "W1: 9.025060769412727 W2: 1.695149782325592 b -4.788331696507682 Loss: 0.4152234354646998\n",
      "W1: 9.027147750229833 W2: 1.6953311791683698 b -4.789343438615282 Loss: 0.4152125918383751\n",
      "W1: 9.029232192285514 W2: 1.6955124101863173 b -4.790354003585985 Loss: 0.41520177432637867\n",
      "W1: 9.0313140993808 W2: 1.6956934754995692 b -4.791363393063042 Loss: 0.41519098285874206\n",
      "W1: 9.033393475309433 W2: 1.6958743752283374 b -4.792371608686818 Loss: 0.4151802173657091\n",
      "W1: 9.035470323857876 W2: 1.6960551094929088 b -4.793378652094799 Loss: 0.4151694777777348\n",
      "W1: 9.037544648805337 W2: 1.6962356784136456 b -4.794384524921598 Loss: 0.41515876402548424\n",
      "W1: 9.039616453923786 W2: 1.6964160821109833 b -4.79538922879896 Loss: 0.41514807603983234\n",
      "W1: 9.041685742977974 W2: 1.69659632070543 b -4.796392765355773 Loss: 0.41513741375186297\n",
      "W1: 9.043752519725444 W2: 1.6967763943175658 b -4.7973951362180705 Loss: 0.415126777092868\n",
      "W1: 9.045816787916557 W2: 1.6969563030680415 b -4.798396343009036 Loss: 0.41511616599434703\n",
      "W1: 9.047878551294502 W2: 1.6971360470775778 b -4.799396387349014 Loss: 0.41510558038800593\n",
      "W1: 9.049937813595317 W2: 1.6973156264669642 b -4.800395270855514 Loss: 0.41509502020575756\n",
      "W1: 9.051994578547905 W2: 1.6974950413570584 b -4.801392995143216 Loss: 0.41508448537971937\n",
      "W1: 9.05404884987405 W2: 1.697674291868785 b -4.8023895618239765 Loss: 0.4150739758422137\n",
      "W1: 9.05610063128844 W2: 1.6978533781231349 b -4.803384972506838 Loss: 0.41506349152576694\n",
      "W1: 9.058149926498675 W2: 1.698032300241164 b -4.80437922879803 Loss: 0.4150530323631086\n",
      "W1: 9.060196739205294 W2: 1.6982110583439927 b -4.80537233230098 Loss: 0.4150425982871708\n",
      "W1: 9.06224107310178 W2: 1.6983896525528046 b -4.806364284616316 Loss: 0.4150321892310877\n",
      "W1: 9.06428293187459 W2: 1.6985680829888459 b -4.807355087341874 Loss: 0.4150218051281945\n",
      "W1: 9.066322319203163 W2: 1.6987463497734243 b -4.808344742072705 Loss: 0.4150114459120269\n",
      "W1: 9.068359238759937 W2: 1.6989244530279084 b -4.80933325040108 Loss: 0.41500111151632024\n",
      "W1: 9.070393694210372 W2: 1.6991023928737263 b -4.810320613916497 Loss: 0.41499080187500953\n",
      "W1: 9.072425689212961 W2: 1.6992801694323652 b -4.811306834205686 Loss: 0.41498051692222765\n",
      "W1: 9.07445522741925 W2: 1.6994577828253703 b -4.812291912852614 Loss: 0.4149702565923057\n",
      "W1: 9.07648231247385 W2: 1.6996352331743438 b -4.813275851438495 Loss: 0.4149600208197713\n",
      "W1: 9.07850694801446 W2: 1.6998125206009447 b -4.814258651541791 Loss: 0.4149498095393494\n",
      "W1: 9.08052913767188 W2: 1.6999896452268866 b -4.8152403147382214 Loss: 0.4149396226859599\n",
      "W1: 9.082548885070024 W2: 1.700166607173938 b -4.816220842600769 Loss: 0.41492946019471816\n",
      "W1: 9.084566193825944 W2: 1.7003434065639218 b -4.817200236699684 Loss: 0.4149193220009339\n",
      "W1: 9.086581067549844 W2: 1.7005200435187127 b -4.81817849860249 Loss: 0.4149092080401107\n",
      "W1: 9.088593509845092 W2: 1.7006965181602376 b -4.819155629873992 Loss: 0.41489911824794506\n",
      "W1: 9.09060352430824 W2: 1.700872830610475 b -4.820131632076283 Loss: 0.4148890525603264\n",
      "W1: 9.092611114529037 W2: 1.7010489809914535 b -4.821106506768744 Loss: 0.4148790109133352\n",
      "W1: 9.094616284090451 W2: 1.701224969425251 b -4.822080255508056 Loss: 0.41486899324324367\n",
      "W1: 9.096619036568683 W2: 1.7014007960339943 b -4.823052879848205 Loss: 0.41485899948651456\n",
      "W1: 9.098619375533179 W2: 1.7015764609398576 b -4.824024381340483 Loss: 0.4148490295798\n",
      "W1: 9.10061730454665 W2: 1.7017519642650627 b -4.824994761533501 Loss: 0.41483908345994197\n",
      "W1: 9.102612827165089 W2: 1.7019273061318771 b -4.82596402197319 Loss: 0.4148291610639702\n",
      "W1: 9.104605946937781 W2: 1.7021024866626138 b -4.826932164202809 Loss: 0.4148192623291033\n",
      "W1: 9.106596667407326 W2: 1.7022775059796302 b -4.827899189762947 Loss: 0.4148093871927468\n",
      "W1: 9.10858499210965 W2: 1.702452364205328 b -4.8288651001915355 Loss: 0.41479953559249233\n",
      "W1: 9.110570924574025 W2: 1.7026270614621513 b -4.829829897023847 Loss: 0.41478970746611843\n",
      "W1: 9.112554468323083 W2: 1.7028015978725866 b -4.8307935817925065 Loss: 0.41477990275158844\n",
      "W1: 9.114535626872827 W2: 1.7029759735591616 b -4.8317561560274935 Loss: 0.414770121387051\n",
      "W1: 9.116514403732657 W2: 1.7031501886444447 b -4.83271762125615 Loss: 0.4147603633108384\n",
      "W1: 9.118490802405372 W2: 1.703324243251044 b -4.833677979003185 Loss: 0.41475062846146693\n",
      "W1: 9.120464826387199 W2: 1.7034981375016067 b -4.83463723079068 Loss: 0.41474091677763525\n",
      "W1: 9.122436479167801 W2: 1.7036718715188184 b -4.835595378138095 Loss: 0.4147312281982249\n",
      "W1: 9.124405764230296 W2: 1.703845445425402 b -4.836552422562274 Loss: 0.41472156266229876\n",
      "W1: 9.126372685051269 W2: 1.704018859344117 b -4.837508365577453 Loss: 0.41471192010910085\n",
      "W1: 9.128337245100788 W2: 1.704192113397759 b -4.838463208695263 Loss: 0.4147023004780555\n",
      "W1: 9.130299447842424 W2: 1.7043652077091587 b -4.839416953424733 Loss: 0.41469270370876726\n",
      "W1: 9.13225929673326 W2: 1.7045381424011814 b -4.840369601272302 Loss: 0.4146831297410198\n",
      "W1: 9.13421679522391 W2: 1.7047109175967259 b -4.841321153741821 Loss: 0.4146735785147752\n",
      "W1: 9.136171946758534 W2: 1.704883533418724 b -4.842271612334557 Loss: 0.41466404997017386\n",
      "W1: 9.138124754774854 W2: 1.7050559899901399 b -4.843220978549202 Loss: 0.4146545440475336\n",
      "W1: 9.140075222704166 W2: 1.7052282874339688 b -4.844169253881877 Loss: 0.41464506068734885\n",
      "W1: 9.142023353971357 W2: 1.705400425873237 b -4.845116439826138 Loss: 0.41463559983029036\n",
      "W1: 9.143969151994922 W2: 1.7055724054310006 b -4.846062537872979 Loss: 0.41462616141720515\n",
      "W1: 9.145912620186975 W2: 1.7057442262303455 b -4.847007549510841 Loss: 0.41461674538911436\n",
      "W1: 9.147853761953266 W2: 1.7059158883943855 b -4.8479514762256155 Loss: 0.4146073516872143\n",
      "W1: 9.1497925806932 W2: 1.7060873920462625 b -4.84889431950065 Loss: 0.4145979802528749\n",
      "W1: 9.151729079799843 W2: 1.7062587373091456 b -4.849836080816757 Loss: 0.4145886310276397\n",
      "W1: 9.153663262659945 W2: 1.7064299243062302 b -4.85077676165221 Loss: 0.4145793039532244\n",
      "W1: 9.155595132653952 W2: 1.7066009531607373 b -4.851716363482763 Loss: 0.4145699989715173\n",
      "W1: 9.157524693156018 W2: 1.7067718239959133 b -4.852654887781641 Loss: 0.4145607160245785\n",
      "W1: 9.159451947534027 W2: 1.7069425369350286 b -4.853592336019559 Loss: 0.41455145505463875\n",
      "W1: 9.161376899149596 W2: 1.7071130921013773 b -4.854528709664716 Loss: 0.4145422160040992\n",
      "W1: 9.163299551358104 W2: 1.7072834896182765 b -4.855464010182806 Loss: 0.414532998815531\n",
      "W1: 9.165219907508694 W2: 1.707453729609065 b -4.856398239037026 Loss: 0.4145238034316747\n",
      "W1: 9.167137970944296 W2: 1.7076238121971041 b -4.857331397688076 Loss: 0.41451462979543957\n",
      "W1: 9.169053745001637 W2: 1.7077937375057755 b -4.858263487594164 Loss: 0.4145054778499029\n",
      "W1: 9.170967233011256 W2: 1.7079635056584808 b -4.859194510211018 Loss: 0.41449634753830955\n",
      "W1: 9.172878438297522 W2: 1.7081331167786415 b -4.860124466991883 Loss: 0.41448723880407173\n",
      "W1: 9.174787364178643 W2: 1.7083025709896982 b -4.861053359387533 Loss: 0.4144781515907678\n",
      "W1: 9.176694013966687 W2: 1.7084718684151092 b -4.861981188846272 Loss: 0.4144690858421427\n",
      "W1: 9.178598390967588 W2: 1.7086410091783506 b -4.862907956813942 Loss: 0.41446004150210586\n",
      "W1: 9.180500498481168 W2: 1.7088099934029153 b -4.863833664733925 Loss: 0.4144510185147323\n",
      "W1: 9.182400339801145 W2: 1.7089788212123125 b -4.864758314047154 Loss: 0.4144420168242608\n",
      "W1: 9.184297918215155 W2: 1.7091474927300667 b -4.865681906192109 Loss: 0.41443303637509427\n",
      "W1: 9.186193237004757 W2: 1.709316008079718 b -4.866604442604833 Loss: 0.4144240771117985\n",
      "W1: 9.188086299445452 W2: 1.7094843673848201 b -4.8675259247189295 Loss: 0.4144151389791025\n",
      "W1: 9.189977108806701 W2: 1.709652570768941 b -4.8684463539655685 Loss: 0.4144062219218968\n",
      "W1: 9.19186566835193 W2: 1.709820618355661 b -4.869365731773495 Loss: 0.4143973258852336\n",
      "W1: 9.193751981338552 W2: 1.7099885102685732 b -4.870284059569034 Loss: 0.41438845081432657\n",
      "W1: 9.195636051017976 W2: 1.7101562466312825 b -4.87120133877609 Loss: 0.41437959665454954\n",
      "W1: 9.19751788063562 W2: 1.7103238275674049 b -4.872117570816159 Loss: 0.414370763351436\n",
      "W1: 9.199397473430935 W2: 1.7104912532005667 b -4.87303275710833 Loss: 0.41436195085067973\n",
      "W1: 9.201274832637404 W2: 1.7106585236544045 b -4.873946899069291 Loss: 0.41435315909813286\n",
      "W1: 9.203149961482568 W2: 1.7108256390525638 b -4.874859998113334 Loss: 0.4143443880398058\n",
      "W1: 9.205022863188033 W2: 1.710992599518699 b -4.87577205565236 Loss: 0.41433563762186726\n",
      "W1: 9.206893540969485 W2: 1.7111594051764722 b -4.876683073095882 Loss: 0.41432690779064313\n",
      "W1: 9.208761998036708 W2: 1.7113260561495538 b -4.8775930518510355 Loss: 0.4143181984926157\n",
      "W1: 9.21062823759359 W2: 1.71149255256162 b -4.878501993322578 Loss: 0.41430950967442465\n",
      "W1: 9.212492262838145 W2: 1.711658894536354 b -4.879409898912896 Loss: 0.4143008412828642\n",
      "W1: 9.214354076962518 W2: 1.7118250821974443 b -4.880316770022012 Loss: 0.4142921932648845\n",
      "W1: 9.216213683153006 W2: 1.7119911156685845 b -4.881222608047586 Loss: 0.41428356556759033\n",
      "W1: 9.218071084590067 W2: 1.712156995073473 b -4.8821274143849225 Loss: 0.41427495813824095\n",
      "W1: 9.219926284448334 W2: 1.7123227205358118 b -4.8830311904269745 Loss: 0.4142663709242491\n",
      "W1: 9.221779285896634 W2: 1.7124882921793065 b -4.883933937564351 Loss: 0.4142578038731806\n",
      "W1: 9.223630092097991 W2: 1.712653710127665 b -4.884835657185318 Loss: 0.4142492569327546\n",
      "W1: 9.22547870620965 W2: 1.7128189745045979 b -4.885736350675807 Loss: 0.4142407300508419\n",
      "W1: 9.22732513138308 W2: 1.712984085433817 b -4.8866360194194165 Loss: 0.41423222317546515\n",
      "W1: 9.229169370764001 W2: 1.7131490430390353 b -4.887534664797421 Loss: 0.41422373625479864\n",
      "W1: 9.231011427492382 W2: 1.713313847443966 b -4.888432288188772 Loss: 0.4142152692371667\n",
      "W1: 9.232851304702463 W2: 1.7134784987723226 b -4.889328890970106 Loss: 0.41420682207104453\n",
      "W1: 9.234689005522766 W2: 1.713642997147818 b -4.890224474515745 Loss: 0.4141983947050567\n",
      "W1: 9.23652453307611 W2: 1.7138073426941633 b -4.891119040197707 Loss: 0.414189987087977\n",
      "W1: 9.238357890479623 W2: 1.7139715355350684 b -4.8920125893857085 Loss: 0.41418159916872826\n",
      "W1: 9.240189080844752 W2: 1.7141355757942407 b -4.892905123447167 Loss: 0.4141732308963814\n",
      "W1: 9.242018107277284 W2: 1.7142994635953848 b -4.893796643747209 Loss: 0.4141648822201552\n",
      "W1: 9.243844972877348 W2: 1.7144631990622017 b -4.894687151648673 Loss: 0.4141565530894155\n",
      "W1: 9.245669680739436 W2: 1.7146267823183885 b -4.895576648512116 Loss: 0.41414824345367535\n",
      "W1: 9.247492233952414 W2: 1.714790213487638 b -4.8964651356958155 Loss: 0.4141399532625936\n",
      "W1: 9.249312635599535 W2: 1.714953492693638 b -4.897352614555777 Loss: 0.4141316824659757\n",
      "W1: 9.251130888758452 W2: 1.7151166200600707 b -4.898239086445737 Loss: 0.41412343101377186\n",
      "W1: 9.252946996501226 W2: 1.715279595710612 b -4.899124552717169 Loss: 0.4141151988560775\n",
      "W1: 9.254760961894348 W2: 1.7154424197689315 b -4.900009014719289 Loss: 0.4141069859431321\n",
      "W1: 9.256572787998746 W2: 1.7156050923586916 b -4.900892473799055 Loss: 0.41409879222531937\n",
      "W1: 9.258382477869796 W2: 1.715767613603547 b -4.90177493130118 Loss: 0.41409061765316674\n",
      "W1: 9.26019003455734 W2: 1.715929983627144 b -4.902656388568129 Loss: 0.41408246217734407\n",
      "W1: 9.261995461105693 W2: 1.716092202553121 b -4.90353684694013 Loss: 0.4140743257486644\n",
      "W1: 9.26379876055366 W2: 1.7162542705051063 b -4.904416307755174 Loss: 0.41406620831808216\n",
      "W1: 9.265599935934548 W2: 1.716416187606719 b -4.90529477234902 Loss: 0.41405810983669417\n",
      "W1: 9.267398990276174 W2: 1.716577953981568 b -4.906172242055204 Loss: 0.4140500302557377\n",
      "W1: 9.269195926600887 W2: 1.7167395697532515 b -4.907048718205038 Loss: 0.41404196952659117\n",
      "W1: 9.270990747925568 W2: 1.7169010350453564 b -4.90792420212762 Loss: 0.41403392760077296\n",
      "W1: 9.272783457261653 W2: 1.7170623499814581 b -4.908798695149833 Loss: 0.4140259044299416\n",
      "W1: 9.27457405761514 W2: 1.7172235146851196 b -4.909672198596354 Loss: 0.41401789996589433\n",
      "W1: 9.276362551986603 W2: 1.7173845292798913 b -4.910544713789657 Loss: 0.4140099141605679\n",
      "W1: 9.278148943371203 W2: 1.7175453938893104 b -4.911416242050018 Loss: 0.4140019469660372\n",
      "W1: 9.279933234758705 W2: 1.7177061086369008 b -4.912286784695519 Loss: 0.41399399833451495\n",
      "W1: 9.281715429133483 W2: 1.7178666736461716 b -4.913156343042052 Loss: 0.4139860682183516\n",
      "W1: 9.283495529474536 W2: 1.718027089040618 b -4.914024918403326 Loss: 0.4139781565700346\n",
      "W1: 9.2852735387555 W2: 1.7181873549437197 b -4.914892512090868 Loss: 0.41397026334218806\n",
      "W1: 9.287049459944663 W2: 1.7183474714789408 b -4.915759125414032 Loss: 0.41396238848757216\n",
      "W1: 9.288823296004972 W2: 1.71850743876973 b -4.916624759679997 Loss: 0.413954531959083\n",
      "W1: 9.290595049894048 W2: 1.7186672569395185 b -4.917489416193779 Loss: 0.4139466937097516\n",
      "W1: 9.292364724564196 W2: 1.7188269261117213 b -4.91835309625823 Loss: 0.4139388736927444\n",
      "W1: 9.29413232296242 W2: 1.7189864464097355 b -4.919215801174046 Loss: 0.41393107186136185\n",
      "W1: 9.295897848030437 W2: 1.719145817956941 b -4.920077532239768 Loss: 0.4139232881690386\n",
      "W1: 9.297661302704679 W2: 1.7193050408766986 b -4.92093829075179 Loss: 0.4139155225693428\n",
      "W1: 9.299422689916314 W2: 1.7194641152923504 b -4.921798078004362 Loss: 0.4139077750159755\n",
      "W1: 9.301182012591257 W2: 1.71962304132722 b -4.922656895289593 Loss: 0.4139000454627707\n",
      "W1: 9.302939273650177 W2: 1.7197818191046104 b -4.923514743897456 Loss: 0.4138923338636947\n",
      "W1: 9.304694476008516 W2: 1.719940448747805 b -4.924371625115794 Loss: 0.41388464017284526\n",
      "W1: 9.306447622576494 W2: 1.7200989303800662 b -4.925227540230324 Loss: 0.4138769643444522\n",
      "W1: 9.308198716259124 W2: 1.7202572641246359 b -4.926082490524641 Loss: 0.4138693063328755\n",
      "W1: 9.309947759956225 W2: 1.720415450104734 b -4.926936477280222 Loss: 0.41386166609260633\n",
      "W1: 9.311694756562432 W2: 1.7205734884435588 b -4.927789501776429 Loss: 0.4138540435782657\n",
      "W1: 9.313439708967204 W2: 1.7207313792642862 b -4.928641565290517 Loss: 0.41384643874460464\n",
      "W1: 9.315182620054843 W2: 1.720889122690069 b -4.929492669097637 Loss: 0.413838851546503\n",
      "W1: 9.3169234927045 W2: 1.7210467188440375 b -4.930342814470835 Loss: 0.41383128193897006\n",
      "W1: 9.318662329790191 W2: 1.7212041678492978 b -4.931192002681067 Loss: 0.4138237298771429\n",
      "W1: 9.320399134180803 W2: 1.721361469828932 b -4.932040234997193 Loss: 0.4138161953162874\n",
      "W1: 9.322133908740113 W2: 1.7215186249059977 b -4.932887512685988 Loss: 0.4138086782117964\n",
      "W1: 9.323866656326791 W2: 1.721675633203528 b -4.933733837012142 Loss: 0.41380117851919035\n",
      "W1: 9.325597379794415 W2: 1.72183249484453 b -4.934579209238269 Loss: 0.4137936961941166\n",
      "W1: 9.327326081991487 W2: 1.721989209951986 b -4.935423630624905 Loss: 0.4137862311923486\n",
      "W1: 9.329052765761439 W2: 1.7221457786488512 b -4.936267102430518 Loss: 0.41377878346978586\n",
      "W1: 9.330777433942643 W2: 1.7223022010580549 b -4.93710962591151 Loss: 0.4137713529824538\n",
      "W1: 9.332500089368429 W2: 1.722458477302499 b -4.937951202322219 Loss: 0.41376393968650277\n",
      "W1: 9.33422073486709 W2: 1.7226146075050581 b -4.938791832914929 Loss: 0.41375654353820795\n",
      "W1: 9.335939373261896 W2: 1.7227705917885796 b -4.939631518939867 Loss: 0.4137491644939688\n",
      "W1: 9.337656007371105 W2: 1.722926430275882 b -4.940470261645214 Loss: 0.41374180251030895\n",
      "W1: 9.339370640007976 W2: 1.7230821230897555 b -4.941308062277105 Loss: 0.4137344575438755\n",
      "W1: 9.341083273980775 W2: 1.7232376703529615 b -4.942144922079631 Loss: 0.41372712955143887\n",
      "W1: 9.342793912092791 W2: 1.723393072188232 b -4.942980842294852 Loss: 0.4137198184898923\n",
      "W1: 9.344502557142345 W2: 1.723548328718269 b -4.943815824162792 Loss: 0.41371252431625133\n",
      "W1: 9.346209211922803 W2: 1.7237034400657443 b -4.944649868921449 Loss: 0.4137052469876535\n",
      "W1: 9.347913879222585 W2: 1.7238584063532998 b -4.945482977806794 Loss: 0.41369798646135797\n",
      "W1: 9.349616561825176 W2: 1.724013227703546 b -4.94631515205278 Loss: 0.41369074269474543\n",
      "W1: 9.351317262509138 W2: 1.724167904239062 b -4.947146392891345 Loss: 0.41368351564531686\n",
      "W1: 9.35301598404812 W2: 1.7243224360823959 b -4.947976701552413 Loss: 0.41367630527069427\n",
      "W1: 9.354712729210872 W2: 1.7244768233560628 b -4.948806079263902 Loss: 0.4136691115286194\n",
      "W1: 9.356407500761252 W2: 1.7246310661825461 b -4.949634527251726 Loss: 0.4136619343769538\n",
      "W1: 9.358100301458238 W2: 1.7247851646842962 b -4.9504620467398 Loss: 0.4136547737736784\n",
      "W1: 9.359791134055941 W2: 1.7249391189837302 b -4.951288638950043 Loss: 0.4136476296768927\n",
      "W1: 9.36148000130361 W2: 1.725092929203232 b -4.952114305102383 Loss: 0.41364050204481545\n",
      "W1: 9.36316690594565 W2: 1.7252465954651512 b -4.952939046414762 Loss: 0.413633390835783\n",
      "W1: 9.364851850721633 W2: 1.7254001178918035 b -4.953762864103135 Loss: 0.4136262960082494\n",
      "W1: 9.366534838366299 W2: 1.7255534966054695 b -4.954585759381483 Loss: 0.41361921752078684\n",
      "W1: 9.368215871609575 W2: 1.7257067317283954 b -4.955407733461809 Loss: 0.41361215533208356\n",
      "W1: 9.369894953176585 W2: 1.7258598233827918 b -4.956228787554144 Loss: 0.4136051094009454\n",
      "W1: 9.371572085787658 W2: 1.7260127716908333 b -4.957048922866555 Loss: 0.41359807968629414\n",
      "W1: 9.373247272158343 W2: 1.726165576774659 b -4.957868140605143 Loss: 0.4135910661471671\n",
      "W1: 9.374920514999413 W2: 1.7263182387563714 b -4.958686441974051 Loss: 0.4135840687427177\n",
      "W1: 9.37659181701688 W2: 1.7264707577580358 b -4.959503828175468 Loss: 0.4135770874322145\n",
      "W1: 9.378261180912007 W2: 1.7266231339016813 b -4.96032030040963 Loss: 0.4135701221750407\n",
      "W1: 9.379928609381313 W2: 1.7267753673092987 b -4.961135859874827 Loss: 0.413563172930694\n",
      "W1: 9.381594105116589 W2: 1.7269274581028415 b -4.961950507767405 Loss: 0.4135562396587862\n",
      "W1: 9.383257670804905 W2: 1.727079406404225 b -4.962764245281771 Loss: 0.41354932231904284\n",
      "W1: 9.384919309128623 W2: 1.7272312123353257 b -4.963577073610397 Loss: 0.41354242087130316\n",
      "W1: 9.386579022765403 W2: 1.7273828760179817 b -4.964388993943822 Loss: 0.41353553527551873\n",
      "W1: 9.38823681438822 W2: 1.7275343975739919 b -4.96520000747066 Loss: 0.4135286654917545\n",
      "W1: 9.389892686665366 W2: 1.7276857771251155 b -4.9660101153776 Loss: 0.41352181148018713\n",
      "W1: 9.39154664226047 W2: 1.7278370147930724 b -4.96681931884941 Loss: 0.4135149732011057\n",
      "W1: 9.3931986838325 W2: 1.7279881106995418 b -4.967627619068944 Loss: 0.41350815061491064\n",
      "W1: 9.394848814035777 W2: 1.728139064966163 b -4.968435017217144 Loss: 0.41350134368211366\n",
      "W1: 9.396497035519987 W2: 1.728289877714534 b -4.969241514473041 Loss: 0.4134945523633374\n",
      "W1: 9.398143350930185 W2: 1.7284405490662118 b -4.970047112013766 Loss: 0.4134877766193149\n",
      "W1: 9.399787762906813 W2: 1.7285910791427122 b -4.970851811014548 Loss: 0.4134810164108896\n",
      "W1: 9.401430274085703 W2: 1.728741468065509 b -4.971655612648716 Loss: 0.4134742716990145\n",
      "W1: 9.403070887098092 W2: 1.7288917159560346 b -4.97245851808771 Loss: 0.4134675424447524\n",
      "W1: 9.40470960457063 W2: 1.7290418229356783 b -4.973260528501081 Loss: 0.4134608286092752\n",
      "W1: 9.406346429125392 W2: 1.7291917891257869 b -4.9740616450564925 Loss: 0.4134541301538633\n",
      "W1: 9.407981363379884 W2: 1.7293416146476641 b -4.974861868919729 Loss: 0.41344744703990577\n",
      "W1: 9.409614409947057 W2: 1.7294912996225706 b -4.975661201254695 Loss: 0.4134407792288999\n",
      "W1: 9.411245571435316 W2: 1.7296408441717235 b -4.976459643223424 Loss: 0.4134341266824505\n",
      "W1: 9.412874850448528 W2: 1.7297902484162957 b -4.977257195986077 Loss: 0.4134274893622703\n",
      "W1: 9.414502249586034 W2: 1.7299395124774162 b -4.97805386070095 Loss: 0.4134208672301783\n",
      "W1: 9.41612777144266 W2: 1.7300886364761692 b -4.9788496385244745 Loss: 0.41341426024810113\n",
      "W1: 9.417751418608724 W2: 1.730237620533594 b -4.9796445306112265 Loss: 0.41340766837807136\n",
      "W1: 9.419373193670046 W2: 1.7303864647706853 b -4.9804385381139245 Loss: 0.4134010915822273\n",
      "W1: 9.42099309920796 W2: 1.7305351693083917 b -4.981231662183437 Loss: 0.4133945298228143\n",
      "W1: 9.422611137799324 W2: 1.7306837342676167 b -4.982023903968784 Loss: 0.41338798306218166\n",
      "W1: 9.424227312016525 W2: 1.7308321597692176 b -4.982815264617141 Loss: 0.41338145126278464\n",
      "W1: 9.425841624427495 W2: 1.7309804459340052 b -4.983605745273844 Loss: 0.4133749343871831\n",
      "W1: 9.427454077595717 W2: 1.7311285928827442 b -4.984395347082394 Loss: 0.41336843239804105\n",
      "W1: 9.429064674080237 W2: 1.731276600736152 b -4.985184071184456 Loss: 0.413361945258127\n",
      "W1: 9.43067341643567 W2: 1.7314244696148988 b -4.985971918719868 Loss: 0.41335547293031283\n",
      "W1: 9.432280307212215 W2: 1.7315721996396076 b -4.986758890826643 Loss: 0.4133490153775743\n",
      "W1: 9.433885348955659 W2: 1.7317197909308537 b -4.987544988640969 Loss: 0.41334257256299\n",
      "W1: 9.43548854420739 W2: 1.7318672436091644 b -4.9883302132972185 Loss: 0.4133361444497414\n",
      "W1: 9.437089895504405 W2: 1.7320145577950188 b -4.989114565927949 Loss: 0.41332973100111253\n",
      "W1: 9.438689405379321 W2: 1.732161733608847 b -4.989898047663905 Loss: 0.4133233321804895\n",
      "W1: 9.440287076360386 W2: 1.732308771171031 b -4.990680659634027 Loss: 0.41331694795136026\n",
      "W1: 9.441882910971481 W2: 1.7324556706019032 b -4.991462402965449 Loss: 0.41331057827731427\n",
      "W1: 9.44347691173214 W2: 1.7326024320217466 b -4.992243278783507 Loss: 0.4133042231220424\n",
      "W1: 9.445069081157554 W2: 1.732749055550795 b -4.993023288211738 Loss: 0.41329788244933585\n",
      "W1: 9.446659421758575 W2: 1.7328955413092317 b -4.993802432371887 Loss: 0.41329155622308705\n",
      "W1: 9.448247936041737 W2: 1.7330418894171906 b -4.994580712383911 Loss: 0.41328524440728837\n",
      "W1: 9.449834626509256 W2: 1.7331880999947544 b -4.995358129365979 Loss: 0.41327894696603235\n",
      "W1: 9.451419495659046 W2: 1.7333341731619556 b -4.9961346844344785 Loss: 0.4132726638635106\n",
      "W1: 9.453002545984722 W2: 1.7334801090387757 b -4.996910378704018 Loss: 0.4132663950640147\n",
      "W1: 9.454583779975614 W2: 1.7336259077451448 b -4.997685213287432 Loss: 0.41326014053193477\n",
      "W1: 9.456163200116775 W2: 1.7337715694009415 b -4.998459189295782 Loss: 0.4132539002317602\n",
      "W1: 9.457740808888987 W2: 1.733917094125993 b -4.999232307838362 Loss: 0.41324767412807817\n",
      "W1: 9.459316608768777 W2: 1.7340624820400743 b -5.0000045700227 Loss: 0.4132414621855742\n",
      "W1: 9.460890602228421 W2: 1.734207733262908 b -5.000775976954564 Loss: 0.41323526436903163\n",
      "W1: 9.462462791735952 W2: 1.7343528479141646 b -5.001546529737966 Loss: 0.41322908064333136\n",
      "W1: 9.464033179755175 W2: 1.7344978261134616 b -5.002316229475159 Loss: 0.41322291097345104\n",
      "W1: 9.465601768745671 W2: 1.7346426679803637 b -5.003085077266651 Loss: 0.41321675532446567\n",
      "W1: 9.46716856116281 W2: 1.7347873736343824 b -5.003853074211199 Loss: 0.4132106136615468\n",
      "W1: 9.468733559457755 W2: 1.7349319431949755 b -5.004620221405817 Loss: 0.413204485949962\n",
      "W1: 9.470296766077475 W2: 1.7350763767815471 b -5.005386519945779 Loss: 0.4131983721550748\n",
      "W1: 9.471858183464754 W2: 1.7352206745134477 b -5.006151970924623 Loss: 0.4131922722423447\n",
      "W1: 9.473417814058198 W2: 1.7353648365099732 b -5.006916575434152 Loss: 0.41318618617732633\n",
      "W1: 9.474975660292246 W2: 1.7355088628903652 b -5.00768033456444 Loss: 0.4131801139256696\n",
      "W1: 9.476531724597178 W2: 1.735652753773811 b -5.008443249403833 Loss: 0.41317405545311875\n",
      "W1: 9.478086009399123 W2: 1.735796509279442 b -5.009205321038957 Loss: 0.41316801072551324\n",
      "W1: 9.479638517120069 W2: 1.735940129526336 b -5.009966550554714 Loss: 0.413161979708786\n",
      "W1: 9.481189250177872 W2: 1.736083614633514 b -5.010726939034293 Loss: 0.4131559623689645\n",
      "W1: 9.482738210986264 W2: 1.7362269647199422 b -5.011486487559168 Loss: 0.41314995867216936\n",
      "W1: 9.484285401954866 W2: 1.7363701799045308 b -5.012245197209104 Loss: 0.41314396858461466\n",
      "W1: 9.485830825489186 W2: 1.7365132603061337 b -5.013003069062162 Loss: 0.4131379920726076\n",
      "W1: 9.487374483990644 W2: 1.736656206043549 b -5.013760104194695 Loss: 0.4131320291025482\n",
      "W1: 9.488916379856564 W2: 1.736799017235518 b -5.014516303681361 Loss: 0.4131260796409287\n",
      "W1: 9.490456515480195 W2: 1.7369416940007252 b -5.015271668595121 Loss: 0.4131201436543337\n",
      "W1: 9.491994893250716 W2: 1.7370842364577983 b -5.016026200007242 Loss: 0.41311422110943974\n",
      "W1: 9.49353151555324 W2: 1.7372266447253077 b -5.016779898987301 Loss: 0.4131083119730146\n",
      "W1: 9.49506638476883 W2: 1.737368918921767 b -5.017532766603192 Loss: 0.413102416211918\n",
      "W1: 9.496599503274503 W2: 1.737511059165631 b -5.018284803921122 Loss: 0.4130965337931\n",
      "W1: 9.498130873443241 W2: 1.737653065575298 b -5.019036012005621 Loss: 0.41309066468360206\n",
      "W1: 9.499660497644 W2: 1.7377949382691074 b -5.019786391919543 Loss: 0.4130848088505559\n",
      "W1: 9.501188378241713 W2: 1.7379366773653406 b -5.020535944724067 Loss: 0.413078966261183\n",
      "W1: 9.502714517597306 W2: 1.7380782829822208 b -5.021284671478704 Loss: 0.4130731368827956\n",
      "W1: 9.504238918067703 W2: 1.7382197552379122 b -5.022032573241299 Loss: 0.4130673206827949\n",
      "W1: 9.505761582005833 W2: 1.7383610942505203 b -5.022779651068032 Loss: 0.4130615176286717\n",
      "W1: 9.507282511760645 W2: 1.7385023001380915 b -5.0235259060134245 Loss: 0.41305572768800614\n",
      "W1: 9.508801709677106 W2: 1.7386433730186128 b -5.02427133913034 Loss: 0.4130499508284667\n",
      "W1: 9.510319178096221 W2: 1.7387843130100118 b -5.0250159514699915 Loss: 0.41304418701781087\n",
      "W1: 9.511834919355032 W2: 1.7389251202301563 b -5.025759744081939 Loss: 0.4130384362238841\n",
      "W1: 9.51334893578663 W2: 1.7390657947968544 b -5.026502718014097 Loss: 0.41303269841462\n",
      "W1: 9.514861229720164 W2: 1.739206336827854 b -5.027244874312736 Loss: 0.41302697355803986\n",
      "W1: 9.516371803480855 W2: 1.7393467464408432 b -5.0279862140224845 Loss: 0.41302126162225244\n",
      "W1: 9.517880659389988 W2: 1.7394870237534485 b -5.028726738186337 Loss: 0.41301556257545396\n",
      "W1: 9.519387799764939 W2: 1.7396271688832368 b -5.029466447845651 Loss: 0.41300987638592696\n",
      "W1: 9.520893226919169 W2: 1.7397671819477134 b -5.030205344040154 Loss: 0.41300420302204127\n",
      "W1: 9.522396943162244 W2: 1.739907063064323 b -5.030943427807947 Loss: 0.4129985424522528\n",
      "W1: 9.523898950799834 W2: 1.740046812350449 b -5.031680700185506 Loss: 0.41299289464510364\n",
      "W1: 9.525399252133726 W2: 1.7401864299234129 b -5.032417162207683 Loss: 0.4129872595692215\n",
      "W1: 9.526897849461829 W2: 1.740325915900475 b -5.033152814907717 Loss: 0.4129816371933206\n",
      "W1: 9.528394745078186 W2: 1.7404652703988335 b -5.033887659317226 Loss: 0.41297602748619916\n",
      "W1: 9.529889941272982 W2: 1.740604493535625 b -5.03462169646622 Loss: 0.4129704304167417\n",
      "W1: 9.531383440332547 W2: 1.7407435854279236 b -5.035354927383101 Loss: 0.41296484595391675\n",
      "W1: 9.53287524453937 W2: 1.7408825461927409 b -5.036087353094662 Loss: 0.41295927406677785\n",
      "W1: 9.534365356172106 W2: 1.741021375947026 b -5.036818974626096 Loss: 0.41295371472446263\n",
      "W1: 9.53585377750558 W2: 1.7411600748076657 b -5.037549793000995 Loss: 0.412948167896193\n",
      "W1: 9.537340510810798 W2: 1.741298642891483 b -5.038279809241357 Loss: 0.412942633551274\n",
      "W1: 9.538825558354958 W2: 1.7414370803152384 b -5.0390090243675845 Loss: 0.4129371116590953\n",
      "W1: 9.540308922401453 W2: 1.7415753871956292 b -5.039737439398491 Loss: 0.41293160218912883\n",
      "W1: 9.541790605209881 W2: 1.741713563649289 b -5.040465055351302 Loss: 0.41292610511093014\n",
      "W1: 9.543270609036055 W2: 1.7418516097927879 b -5.0411918732416625 Loss: 0.41292062039413735\n",
      "W1: 9.544748936132008 W2: 1.7419895257426317 b -5.041917894083632 Loss: 0.4129151480084712\n",
      "W1: 9.546225588746001 W2: 1.742127311615263 b -5.0426431188896945 Loss: 0.41290968792373445\n",
      "W1: 9.547700569122533 W2: 1.7422649675270596 b -5.04336754867076 Loss: 0.412904240109812\n",
      "W1: 9.549173879502348 W2: 1.7424024935943354 b -5.044091184436167 Loss: 0.41289880453667077\n",
      "W1: 9.550645522122444 W2: 1.7425398899333395 b -5.0448140271936825 Loss: 0.412893381174359\n",
      "W1: 9.552115499216077 W2: 1.7426771566602566 b -5.045536077949511 Loss: 0.412887969993006\n",
      "W1: 9.553583813012773 W2: 1.7428142938912063 b -5.046257337708293 Loss: 0.4128825709628223\n",
      "W1: 9.555050465738335 W2: 1.7429513017422436 b -5.04697780747311 Loss: 0.4128771840540994\n",
      "W1: 9.556515459614847 W2: 1.7430881803293579 b -5.047697488245486 Loss: 0.41287180923720884\n",
      "W1: 9.557978796860688 W2: 1.7432249297684734 b -5.048416381025394 Loss: 0.412866446482603\n",
      "W1: 9.559440479690538 W2: 1.7433615501754494 b -5.049134486811254 Loss: 0.4128610957608139\n",
      "W1: 9.560900510315381 W2: 1.7434980416660786 b -5.049851806599939 Loss: 0.41285575704245353\n",
      "W1: 9.56235889094252 W2: 1.7436344043560883 b -5.050568341386779 Loss: 0.41285043029821344\n",
      "W1: 9.563815623775575 W2: 1.7437706383611402 b -5.0512840921655595 Loss: 0.41284511549886443\n",
      "W1: 9.565270711014504 W2: 1.7439067437968294 b -5.051999059928531 Loss: 0.4128398126152561\n",
      "W1: 9.566724154855597 W2: 1.744042720778685 b -5.052713245666405 Loss: 0.4128345216183178\n",
      "W1: 9.568175957491496 W2: 1.7441785694221696 b -5.053426650368364 Loss: 0.4128292424790565\n",
      "W1: 9.56962612111119 W2: 1.744314289842679 b -5.054139275022057 Loss: 0.41282397516855784\n",
      "W1: 9.571074647900035 W2: 1.744449882155543 b -5.054851120613609 Loss: 0.41281871965798567\n",
      "W1: 9.572521540039753 W2: 1.7445853464760235 b -5.055562188127621 Loss: 0.4128134759185818\n",
      "W1: 9.573966799708442 W2: 1.744720682919316 b -5.0562724785471715 Loss: 0.4128082439216655\n",
      "W1: 9.575410429080586 W2: 1.7448558916005488 b -5.056981992853823 Loss: 0.4128030236386336\n",
      "W1: 9.576852430327058 W2: 1.7449909726347825 b -5.057690732027621 Loss: 0.41279781504095986\n",
      "W1: 9.578292805615131 W2: 1.7451259261370107 b -5.0583986970470995 Loss: 0.4127926181001953\n",
      "W1: 9.579731557108488 W2: 1.745260752222159 b -5.059105888889285 Loss: 0.4127874327879674\n",
      "W1: 9.581168686967219 W2: 1.7453954510050855 b -5.059812308529695 Loss: 0.4127822590759804\n",
      "W1: 9.582604197347843 W2: 1.7455300226005803 b -5.060517956942347 Loss: 0.41277709693601444\n",
      "W1: 9.584038090403302 W2: 1.7456644671233654 b -5.061222835099754 Loss: 0.412771946339926\n",
      "W1: 9.585470368282978 W2: 1.7457987846880945 b -5.061926943972934 Loss: 0.41276680725964715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 9.586901033132694 W2: 1.745932975409353 b -5.06263028453141 Loss: 0.4127616796671856\n",
      "W1: 9.588330087094727 W2: 1.7460670394016584 b -5.063332857743212 Loss: 0.4127565635346244\n",
      "W1: 9.58975753230781 W2: 1.7462009767794588 b -5.064034664574883 Loss: 0.4127514588341217\n",
      "W1: 9.591183370907146 W2: 1.746334787657134 b -5.064735705991476 Loss: 0.41274636553791044\n",
      "W1: 9.592607605024405 W2: 1.7464684721489947 b -5.065435982956564 Loss: 0.41274128361829826\n",
      "W1: 9.594030236787741 W2: 1.7466020303692826 b -5.0661354964322385 Loss: 0.4127362130476676\n",
      "W1: 9.595451268321797 W2: 1.7467354624321703 b -5.066834247379113 Loss: 0.4127311537984744\n",
      "W1: 9.59687070174771 W2: 1.7468687684517612 b -5.0675322367563265 Loss: 0.41272610584324904\n",
      "W1: 9.598288539183116 W2: 1.7470019485420891 b -5.068229465521546 Loss: 0.41272106915459567\n",
      "W1: 9.599704782742167 W2: 1.7471350028171186 b -5.068925934630969 Loss: 0.41271604370519194\n",
      "W1: 9.601119434535526 W2: 1.7472679313907442 b -5.0696216450393266 Loss: 0.4127110294677886\n",
      "W1: 9.602532496670385 W2: 1.7474007343767908 b -5.070316597699886 Loss: 0.4127060264152096\n",
      "W1: 9.603943971250462 W2: 1.7475334118890133 b -5.071010793564454 Loss: 0.4127010345203522\n",
      "W1: 9.605353860376018 W2: 1.7476659640410968 b -5.07170423358338 Loss: 0.4126960537561857\n",
      "W1: 9.60676216614386 W2: 1.747798390946656 b -5.0723969187055555 Loss: 0.4126910840957519\n",
      "W1: 9.60816889064734 W2: 1.7479306927192348 b -5.073088849878422 Loss: 0.4126861255121653\n",
      "W1: 9.609574035976378 W2: 1.7480628694723077 b -5.073780028047971 Loss: 0.41268117797861215\n",
      "W1: 9.610977604217458 W2: 1.7481949213192778 b -5.074470454158747 Loss: 0.41267624146835025\n",
      "W1: 9.612379597453637 W2: 1.748326848373478 b -5.075160129153849 Loss: 0.4126713159547093\n",
      "W1: 9.613780017764556 W2: 1.74845865074817 b -5.075849053974935 Loss: 0.4126664014110901\n",
      "W1: 9.61517886722644 W2: 1.748590328556545 b -5.076537229562224 Loss: 0.41266149781096517\n",
      "W1: 9.616576147912111 W2: 1.7487218819117227 b -5.077224656854502 Loss: 0.41265660512787716\n",
      "W1: 9.617971861890995 W2: 1.7488533109267523 b -5.077911336789117 Loss: 0.4126517233354401\n",
      "W1: 9.619366011229124 W2: 1.7489846157146112 b -5.078597270301989 Loss: 0.41264685240733806\n",
      "W1: 9.620758597989147 W2: 1.7491157963882054 b -5.079282458327611 Loss: 0.41264199231732557\n",
      "W1: 9.622149624230335 W2: 1.7492468530603695 b -5.0799669017990485 Loss: 0.4126371430392275\n",
      "W1: 9.623539092008594 W2: 1.7493777858438668 b -5.080650601647946 Loss: 0.41263230454693817\n",
      "W1: 9.624927003376461 W2: 1.7495085948513887 b -5.081333558804529 Loss: 0.412627476814422\n",
      "W1: 9.62631336038312 W2: 1.7496392801955543 b -5.082015774197604 Loss: 0.4126226598157125\n",
      "W1: 9.627698165074403 W2: 1.7497698419889112 b -5.082697248754564 Loss: 0.4126178535249128\n",
      "W1: 9.629081419492802 W2: 1.749900280343935 b -5.083377983401391 Loss: 0.4126130579161948\n",
      "W1: 9.630463125677473 W2: 1.7500305953730289 b -5.084057979062657 Loss: 0.4126082729637993\n",
      "W1: 9.631843285664242 W2: 1.7501607871885239 b -5.084737236661528 Loss: 0.4126034986420359\n",
      "W1: 9.633221901485614 W2: 1.7502908559026784 b -5.085415757119766 Loss: 0.4125987349252824\n",
      "W1: 9.63459897517078 W2: 1.750420801627679 b -5.086093541357734 Loss: 0.41259398178798484\n",
      "W1: 9.635974508745619 W2: 1.7505506244756388 b -5.0867705902943925 Loss: 0.41258923920465757\n",
      "W1: 9.637348504232712 W2: 1.7506803245585987 b -5.08744690484731 Loss: 0.4125845071498825\n",
      "W1: 9.638720963651345 W2: 1.7508099019885268 b -5.088122485932661 Loss: 0.4125797855983093\n",
      "W1: 9.640091889017512 W2: 1.7509393568773182 b -5.0887973344652275 Loss: 0.4125750745246551\n",
      "W1: 9.641461282343931 W2: 1.7510686893367948 b -5.089471451358406 Loss: 0.41257037390370394\n",
      "W1: 9.642829145640041 W2: 1.7511978994787056 b -5.090144837524208 Loss: 0.4125656837103072\n",
      "W1: 9.644195480912014 W2: 1.7513269874147266 b -5.09081749387326 Loss: 0.41256100391938305\n",
      "W1: 9.645560290162763 W2: 1.75145595325646 b -5.09148942131481 Loss: 0.41255633450591644\n",
      "W1: 9.646923575391943 W2: 1.751584797115435 b -5.0921606207567285 Loss: 0.4125516754449579\n",
      "W1: 9.648285338595963 W2: 1.751713519103107 b -5.092831093105511 Loss: 0.4125470267116253\n",
      "W1: 9.64964558176799 W2: 1.751842119330858 b -5.093500839266281 Loss: 0.41254238828110185\n",
      "W1: 9.651004306897956 W2: 1.751970597909996 b -5.094169860142792 Loss: 0.4125377601286371\n",
      "W1: 9.652361515972565 W2: 1.7520989549517556 b -5.0948381566374294 Loss: 0.4125331422295457\n",
      "W1: 9.6537172109753 W2: 1.7522271905672975 b -5.095505729651216 Loss: 0.41252853455920807\n",
      "W1: 9.655071393886427 W2: 1.7523553048677079 b -5.096172580083812 Loss: 0.41252393709306984\n",
      "W1: 9.656424066683003 W2: 1.7524832979639993 b -5.096838708833518 Loss: 0.4125193498066416\n",
      "W1: 9.657775231338887 W2: 1.75261116996711 b -5.097504116797277 Loss: 0.4125147726754989\n",
      "W1: 9.659124889824739 W2: 1.7527389209879043 b -5.09816880487068 Loss: 0.41251020567528207\n",
      "W1: 9.660473044108029 W2: 1.7528665511371717 b -5.098832773947962 Loss: 0.4125056487816956\n",
      "W1: 9.661819696153048 W2: 1.7529940605256276 b -5.099496024922014 Loss: 0.41250110197050865\n",
      "W1: 9.663164847920907 W2: 1.7531214492639124 b -5.1001585586843765 Loss: 0.41249656521755435\n",
      "W1: 9.66450850136955 W2: 1.7532487174625924 b -5.100820376125247 Loss: 0.41249203849872934\n",
      "W1: 9.665850658453758 W2: 1.753375865232159 b -5.101481478133482 Loss: 0.4124875217899948\n",
      "W1: 9.667191321125152 W2: 1.7535028926830287 b -5.102141865596597 Loss: 0.4124830150673746\n",
      "W1: 9.668530491332206 W2: 1.7536297999255435 b -5.102801539400772 Loss: 0.4124785183069566\n",
      "W1: 9.669868171020246 W2: 1.7537565870699698 b -5.103460500430855 Loss: 0.4124740314848916\n",
      "W1: 9.671204362131464 W2: 1.7538832542264997 b -5.104118749570358 Loss: 0.4124695545773933\n",
      "W1: 9.672539066604918 W2: 1.7540098015052497 b -5.104776287701468 Loss: 0.4124650875607381\n",
      "W1: 9.673872286376543 W2: 1.7541362290162612 b -5.105433115705042 Loss: 0.41246063041126513\n",
      "W1: 9.675204023379154 W2: 1.7542625368695002 b -5.106089234460614 Loss: 0.4124561831053764\n",
      "W1: 9.676534279542452 W2: 1.7543887251748576 b -5.106744644846398 Loss: 0.4124517456195353\n",
      "W1: 9.677863056793035 W2: 1.7545147940421488 b -5.1073993477392845 Loss: 0.4124473179302676\n",
      "W1: 9.679190357054399 W2: 1.7546407435811135 b -5.108053344014852 Loss: 0.4124429000141614\n",
      "W1: 9.680516182246947 W2: 1.754766573901416 b -5.108706634547363 Loss: 0.41243849184786596\n",
      "W1: 9.681840534287995 W2: 1.7548922851126445 b -5.109359220209766 Loss: 0.4124340934080922\n",
      "W1: 9.683163415091775 W2: 1.755017877324312 b -5.110011101873703 Loss: 0.41242970467161216\n",
      "W1: 9.684484826569447 W2: 1.7551433506458554 b -5.110662280409507 Loss: 0.4124253256152596\n",
      "W1: 9.685804770629101 W2: 1.7552687051866356 b -5.111312756686206 Loss: 0.4124209562159287\n",
      "W1: 9.687123249175766 W2: 1.7553939410559378 b -5.111962531571528 Loss: 0.41241659645057477\n",
      "W1: 9.68844026411141 W2: 1.755519058362971 b -5.1126116059319004 Loss: 0.41241224629621326\n",
      "W1: 9.689755817334957 W2: 1.7556440572168677 b -5.113259980632453 Loss: 0.4124079057299207\n",
      "W1: 9.691069910742282 W2: 1.755768937726685 b -5.11390765653702 Loss: 0.4124035747288332\n",
      "W1: 9.692382546226224 W2: 1.755893700001403 b -5.114554634508144 Loss: 0.41239925327014765\n",
      "W1: 9.693693725676587 W2: 1.7560183441499257 b -5.115200915407077 Loss: 0.4123949413311203\n",
      "W1: 9.695003450980153 W2: 1.756142870281081 b -5.1158465000937845 Loss: 0.4123906388890672\n",
      "W1: 9.696311724020683 W2: 1.75626727850362 b -5.116491389426945 Loss: 0.4123863459213642\n",
      "W1: 9.697618546678923 W2: 1.7563915689262168 b -5.117135584263955 Loss: 0.4123820624054464\n",
      "W1: 9.698923920832613 W2: 1.75651574165747 b -5.1177790854609295 Loss: 0.41237778831880784\n",
      "W1: 9.700227848356489 W2: 1.7566397968059004 b -5.118421893872707 Loss: 0.4123735236390022\n",
      "W1: 9.701530331122292 W2: 1.756763734479953 b -5.119064010352849 Loss: 0.4123692683436413\n",
      "W1: 9.702831370998776 W2: 1.7568875547879952 b -5.119705435753644 Loss: 0.4123650224103962\n",
      "W1: 9.704130969851708 W2: 1.757011257838318 b -5.1203461709261076 Loss: 0.4123607858169962\n",
      "W1: 9.705429129543877 W2: 1.757134843739135 b -5.12098621671999 Loss: 0.412356558541229\n",
      "W1: 9.706725851935103 W2: 1.7572583125985834 b -5.121625573983772 Loss: 0.4123523405609404\n",
      "W1: 9.708021138882238 W2: 1.7573816645247229 b -5.122264243564673 Loss: 0.41234813185403446\n",
      "W1: 9.709314992239173 W2: 1.7575048996255362 b -5.122902226308647 Loss: 0.4123439323984725\n",
      "W1: 9.71060741385685 W2: 1.7576280180089288 b -5.123539523060393 Loss: 0.4123397421722744\n",
      "W1: 9.711898405583257 W2: 1.7577510197827289 b -5.12417613466335 Loss: 0.4123355611535166\n",
      "W1: 9.713187969263442 W2: 1.7578739050546874 b -5.124812061959702 Loss: 0.41233138932033364\n",
      "W1: 9.714476106739518 W2: 1.7579966739324782 b -5.125447305790382 Loss: 0.4123272266509167\n",
      "W1: 9.715762819850665 W2: 1.758119326523697 b -5.126081866995072 Loss: 0.4123230731235139\n",
      "W1: 9.71704811043314 W2: 1.7582418629358625 b -5.1267157464122075 Loss: 0.4123189287164309\n",
      "W1: 9.718331980320281 W2: 1.7583642832764157 b -5.127348944878977 Loss: 0.4123147934080291\n",
      "W1: 9.71961443134251 W2: 1.75848658765272 b -5.127981463231327 Loss: 0.41231066717672693\n",
      "W1: 9.720895465327347 W2: 1.7586087761720615 b -5.128613302303961 Loss: 0.41230655000099925\n",
      "W1: 9.722175084099405 W2: 1.758730848941648 b -5.129244462930346 Loss: 0.4123024418593765\n",
      "W1: 9.723453289480405 W2: 1.7588528060686102 b -5.129874945942712 Loss: 0.41229834273044597\n",
      "W1: 9.724730083289177 W2: 1.7589746476600001 b -5.130504752172054 Loss: 0.41229425259284996\n",
      "W1: 9.726005467341668 W2: 1.7590963738227927 b -5.131133882448135 Loss: 0.41229017142528707\n",
      "W1: 9.727279443450943 W2: 1.7592179846638845 b -5.131762337599492 Loss: 0.41228609920651116\n",
      "W1: 9.728552013427196 W2: 1.7593394802900941 b -5.132390118453429 Loss: 0.4122820359153311\n",
      "W1: 9.729823179077755 W2: 1.7594608608081623 b -5.1330172258360305 Loss: 0.4122779815306117\n",
      "W1: 9.731092942207086 W2: 1.7595821263247515 b -5.133643660572154 Loss: 0.41227393603127244\n",
      "W1: 9.732361304616798 W2: 1.7597032769464462 b -5.134269423485438 Loss: 0.4122698993962872\n",
      "W1: 9.733628268105653 W2: 1.7598243127797528 b -5.134894515398302 Loss: 0.41226587160468564\n",
      "W1: 9.734893834469563 W2: 1.759945233931099 b -5.135518937131951 Loss: 0.41226185263555093\n",
      "W1: 9.736158005501608 W2: 1.760066040506835 b -5.136142689506375 Loss: 0.41225784246802133\n",
      "W1: 9.737420782992029 W2: 1.7601867326132314 b -5.136765773340353 Loss: 0.4122538410812889\n",
      "W1: 9.738682168728243 W2: 1.760307310356482 b -5.137388189451454 Loss: 0.41224984845460005\n",
      "W1: 9.739942164494842 W2: 1.7604277738427008 b -5.138009938656039 Loss: 0.41224586456725515\n",
      "W1: 9.741200772073604 W2: 1.7605481231779243 b -5.138631021769266 Loss: 0.4122418893986081\n",
      "W1: 9.742457993243496 W2: 1.76066835846811 b -5.139251439605087 Loss: 0.41223792292806655\n",
      "W1: 9.74371382978068 W2: 1.7607884798191367 b -5.1398711929762575 Loss: 0.4122339651350918\n",
      "W1: 9.744968283458514 W2: 1.760908487336805 b -5.140490282694332 Loss: 0.41223001599919784\n",
      "W1: 9.746221356047567 W2: 1.7610283811268368 b -5.141108709569669 Loss: 0.4122260754999529\n",
      "W1: 9.747473049315616 W2: 1.761148161294875 b -5.141726474411433 Loss: 0.41222214361697707\n",
      "W1: 9.748723365027658 W2: 1.761267827946484 b -5.142343578027597 Loss: 0.4122182203299438\n",
      "W1: 9.749972304945908 W2: 1.7613873811871492 b -5.142960021224944 Loss: 0.41221430561857936\n",
      "W1: 9.75121987082981 W2: 1.7615068211222775 b -5.14357580480907 Loss: 0.4122103994626625\n",
      "W1: 9.752466064436046 W2: 1.7616261478571966 b -5.144190929584386 Loss: 0.4122065018420242\n",
      "W1: 9.753710887518528 W2: 1.7617453614971557 b -5.144805396354118 Loss: 0.41220261273654746\n",
      "W1: 9.754954341828418 W2: 1.7618644621473247 b -5.145419205920312 Loss: 0.4121987321261679\n",
      "W1: 9.756196429114127 W2: 1.7619834499127949 b -5.146032359083836 Loss: 0.41219485999087285\n",
      "W1: 9.757437151121318 W2: 1.762102324898578 b -5.1466448566443805 Loss: 0.4121909963107014\n",
      "W1: 9.758676509592917 W2: 1.7622210872096074 b -5.147256699400461 Loss: 0.4121871410657441\n",
      "W1: 9.759914506269112 W2: 1.7623397369507365 b -5.1478678881494195 Loss: 0.4121832942361436\n",
      "W1: 9.761151142887368 W2: 1.7624582742267405 b -5.148478423687431 Loss: 0.41217945580209303\n",
      "W1: 9.76238642118242 W2: 1.7625766991423146 b -5.149088306809499 Loss: 0.4121756257438376\n",
      "W1: 9.76362034288629 W2: 1.7626950118020757 b -5.1496975383094625 Loss: 0.4121718040416727\n",
      "W1: 9.764852909728281 W2: 1.7628132123105604 b -5.150306118979996 Loss: 0.41216799067594523\n",
      "W1: 9.766084123434995 W2: 1.7629313007722272 b -5.150914049612613 Loss: 0.4121641856270527\n",
      "W1: 9.767313985730325 W2: 1.763049277291454 b -5.151521330997666 Loss: 0.4121603888754432\n",
      "W1: 9.768542498335473 W2: 1.7631671419725408 b -5.152127963924352 Loss: 0.4121566004016153\n",
      "W1: 9.769769662968944 W2: 1.7632848949197069 b -5.152733949180709 Loss: 0.41215282018611776\n",
      "W1: 9.77099548134656 W2: 1.763402536237093 b -5.1533392875536235 Loss: 0.4121490482095496\n",
      "W1: 9.772219955181459 W2: 1.7635200660287602 b -5.153943979828831 Loss: 0.41214528445255993\n",
      "W1: 9.773443086184106 W2: 1.7636374843986902 b -5.154548026790919 Loss: 0.4121415288958479\n",
      "W1: 9.774664876062293 W2: 1.7637547914507847 b -5.155151429223324 Loss: 0.41213778152016173\n",
      "W1: 9.775885326521145 W2: 1.7638719872888666 b -5.1557541879083395 Loss: 0.4121340423063003\n",
      "W1: 9.77710443926313 W2: 1.7639890720166786 b -5.156356303627117 Loss: 0.41213031123511085\n",
      "W1: 9.778322215988059 W2: 1.7641060457378845 b -5.156957777159666 Loss: 0.4121265882874908\n",
      "W1: 9.779538658393092 W2: 1.764222908556068 b -5.157558609284855 Loss: 0.4121228734443863\n",
      "W1: 9.780753768172744 W2: 1.7643396605747328 b -5.15815880078042 Loss: 0.41211916668679255\n",
      "W1: 9.781967547018894 W2: 1.7644563018973038 b -5.158758352422958 Loss: 0.41211546799575394\n",
      "W1: 9.783179996620781 W2: 1.7645728326271257 b -5.1593572649879365 Loss: 0.41211177735236304\n",
      "W1: 9.784391118665019 W2: 1.7646892528674636 b -5.15995553924969 Loss: 0.4121080947377618\n",
      "W1: 9.785600914835594 W2: 1.7648055627215027 b -5.160553175981425 Loss: 0.4121044201331399\n",
      "W1: 9.786809386813875 W2: 1.7649217622923488 b -5.161150175955222 Loss: 0.412100753519736\n",
      "W1: 9.788016536278617 W2: 1.7650378516830274 b -5.161746539942036 Loss: 0.4120970948788365\n",
      "W1: 9.789222364905964 W2: 1.7651538309964843 b -5.162342268711699 Loss: 0.4120934441917759\n",
      "W1: 9.790426874369457 W2: 1.7652697003355857 b -5.162937363032924 Loss: 0.41208980143993706\n",
      "W1: 9.791630066340039 W2: 1.7653854598031178 b -5.1635318236733045 Loss: 0.41208616660475\n",
      "W1: 9.792831942486057 W2: 1.765501109501787 b -5.164125651399318 Loss: 0.412082539667693\n",
      "W1: 9.79403250447327 W2: 1.7656166495342194 b -5.164718846976326 Loss: 0.4120789206102913\n",
      "W1: 9.795231753964854 W2: 1.7657320800029614 b -5.165311411168579 Loss: 0.4120753094141179\n",
      "W1: 9.796429692621405 W2: 1.7658474010104797 b -5.165903344739217 Loss: 0.41207170606079285\n",
      "W1: 9.797626322100946 W2: 1.7659626126591605 b -5.16649464845027 Loss: 0.41206811053198356\n",
      "W1: 9.798821644058929 W2: 1.7660777150513107 b -5.167085323062661 Loss: 0.412064522809404\n",
      "W1: 9.800015660148244 W2: 1.7661927082891564 b -5.167675369336212 Loss: 0.4120609428748155\n",
      "W1: 9.801208372019222 W2: 1.766307592474844 b -5.16826478802964 Loss: 0.4120573707100256\n",
      "W1: 9.80239978131964 W2: 1.7664223677104398 b -5.168853579900561 Loss: 0.4120538062968888\n",
      "W1: 9.803589889694724 W2: 1.76653703409793 b -5.169441745705493 Loss: 0.4120502496173057\n",
      "W1: 9.804778698787159 W2: 1.766651591739221 b -5.170029286199857 Loss: 0.41204670065322363\n",
      "W1: 9.805966210237086 W2: 1.7667660407361385 b -5.17061620213798 Loss: 0.4120431593866358\n",
      "W1: 9.807152425682117 W2: 1.7668803811904286 b -5.171202494273095 Loss: 0.4120396257995813\n",
      "W1: 9.808337346757332 W2: 1.7669946132037568 b -5.171788163357347 Loss: 0.4120360998741455\n",
      "W1: 9.809520975095285 W2: 1.767108736877709 b -5.172373210141788 Loss: 0.4120325815924597\n",
      "W1: 9.810703312326014 W2: 1.7672227523137902 b -5.172957635376386 Loss: 0.4120290709367003\n",
      "W1: 9.81188436007704 W2: 1.7673366596134257 b -5.173541439810024 Loss: 0.4120255678890896\n",
      "W1: 9.81306411997337 W2: 1.7674504588779603 b -5.174124624190501 Loss: 0.4120220724318951\n",
      "W1: 9.814242593637514 W2: 1.7675641502086588 b -5.174707189264535 Loss: 0.41201858454742984\n",
      "W1: 9.815419782689476 W2: 1.7676777337067056 b -5.175289135777766 Loss: 0.4120151042180518\n",
      "W1: 9.816595688746766 W2: 1.767791209473205 b -5.175870464474756 Loss: 0.41201163142616415\n",
      "W1: 9.8177703134244 W2: 1.7679045776091806 b -5.176451176098991 Loss: 0.4120081661542143\n",
      "W1: 9.818943658334915 W2: 1.7680178382155762 b -5.177031271392884 Loss: 0.4120047083846956\n",
      "W1: 9.82011572508836 W2: 1.7681309913932552 b -5.177610751097777 Loss: 0.41200125810014504\n",
      "W1: 9.821286515292313 W2: 1.7682440372430004 b -5.178189615953944 Loss: 0.4119978152831445\n",
      "W1: 9.822456030551875 W2: 1.7683569758655147 b -5.178767866700587 Loss: 0.41199437991632004\n",
      "W1: 9.823624272469685 W2: 1.7684698073614202 b -5.179345504075847 Loss: 0.41199095198234237\n",
      "W1: 9.824791242645917 W2: 1.768582531831259 b -5.179922528816799 Loss: 0.41198753146392586\n",
      "W1: 9.825956942678287 W2: 1.7686951493754923 b -5.1804989416594545 Loss: 0.4119841183438293\n",
      "W1: 9.82712137416206 W2: 1.768807660094502 b -5.181074743338768 Loss: 0.41198071260485475\n",
      "W1: 9.82828453869005 W2: 1.7689200640885885 b -5.181649934588634 Loss: 0.4119773142298491\n",
      "W1: 9.829446437852635 W2: 1.7690323614579726 b -5.182224516141892 Loss: 0.4119739232017016\n",
      "W1: 9.830607073237745 W2: 1.7691445523027942 b -5.182798488730325 Loss: 0.4119705395033461\n",
      "W1: 9.831766446430882 W2: 1.7692566367231128 b -5.183371853084664 Loss: 0.41196716311775905\n",
      "W1: 9.832924559015115 W2: 1.769368614818908 b -5.183944609934592 Loss: 0.41196379402796046\n",
      "W1: 9.834081412571091 W2: 1.7694804866900784 b -5.18451676000874 Loss: 0.4119604322170137\n",
      "W1: 9.835237008677035 W2: 1.7695922524364425 b -5.185088304034693 Loss: 0.4119570776680247\n",
      "W1: 9.836391348908759 W2: 1.769703912157738 b -5.185659242738991 Loss: 0.4119537303641429\n",
      "W1: 9.837544434839659 W2: 1.7698154659536227 b -5.186229576847132 Loss: 0.4119503902885599\n",
      "W1: 9.838696268040731 W2: 1.7699269139236737 b -5.18679930708357 Loss: 0.41194705742451015\n",
      "W1: 9.839846850080567 W2: 1.7700382561673875 b -5.187368434171722 Loss: 0.4119437317552709\n",
      "W1: 9.840996182525359 W2: 1.77014949278418 b -5.187936958833966 Loss: 0.4119404132641616\n",
      "W1: 9.84214426693891 W2: 1.7702606238733873 b -5.188504881791644 Loss: 0.41193710193454414\n",
      "W1: 9.843291104882633 W2: 1.7703716495342645 b -5.189072203765065 Loss: 0.41193379774982214\n",
      "W1: 9.84443669791556 W2: 1.7704825698659863 b -5.1896389254735045 Loss: 0.41193050069344195\n",
      "W1: 9.845581047594342 W2: 1.770593384967647 b -5.190205047635208 Loss: 0.4119272107488912\n",
      "W1: 9.846724155473256 W2: 1.7707040949382602 b -5.190770570967394 Loss: 0.41192392789969995\n",
      "W1: 9.847866023104208 W2: 1.7708146998767593 b -5.191335496186251 Loss: 0.4119206521294396\n",
      "W1: 9.849006652036742 W2: 1.7709251998819973 b -5.191899824006946 Loss: 0.41191738342172335\n",
      "W1: 9.850146043818038 W2: 1.771035595052746 b -5.19246355514362 Loss: 0.41191412176020575\n",
      "W1: 9.85128419999292 W2: 1.7711458854876978 b -5.193026690309395 Loss: 0.4119108671285826\n",
      "W1: 9.852421122103861 W2: 1.7712560712854637 b -5.193589230216372 Loss: 0.41190761951059096\n",
      "W1: 9.853556811690988 W2: 1.7713661525445747 b -5.1941511755756355 Loss: 0.4119043788900092\n",
      "W1: 9.854691270292081 W2: 1.771476129363481 b -5.194712527097253 Loss: 0.4119011452506569\n",
      "W1: 9.855824499442587 W2: 1.7715860018405527 b -5.195273285490278 Loss: 0.4118979185763939\n",
      "W1: 9.856956500675613 W2: 1.7716957700740787 b -5.195833451462752 Loss: 0.41189469885112123\n",
      "W1: 9.85808727552194 W2: 1.7718054341622682 b -5.196393025721705 Loss: 0.41189148605878073\n",
      "W1: 9.859216825510023 W2: 1.7719149942032495 b -5.1969520089731605 Loss: 0.4118882801833543\n",
      "W1: 9.860345152165996 W2: 1.7720244502950704 b -5.197510401922132 Loss: 0.411885081208865\n",
      "W1: 9.861472257013675 W2: 1.7721338025356983 b -5.198068205272631 Loss: 0.4118818891193753\n",
      "W1: 9.862598141574567 W2: 1.7722430510230203 b -5.198625419727662 Loss: 0.41187870389898856\n",
      "W1: 9.86372280736787 W2: 1.7723521958548425 b -5.199182045989231 Loss: 0.4118755255318483\n",
      "W1: 9.864846255910477 W2: 1.7724612371288908 b -5.199738084758341 Loss: 0.41187235400213745\n",
      "W1: 9.865968488716984 W2: 1.7725701749428109 b -5.200293536734999 Loss: 0.4118691892940793\n",
      "W1: 9.867089507299692 W2: 1.7726790093941676 b -5.200848402618215 Loss: 0.41186603139193667\n",
      "W1: 9.868209313168611 W2: 1.7727877405804453 b -5.2014026831060045 Loss: 0.4118628802800124\n",
      "W1: 9.869327907831465 W2: 1.772896368599048 b -5.20195637889539 Loss: 0.41185973594264796\n",
      "W1: 9.870445292793697 W2: 1.7730048935472993 b -5.202509490682401 Loss: 0.4118565983642256\n",
      "W1: 9.871561469558472 W2: 1.7731133155224421 b -5.203062019162082 Loss: 0.4118534675291659\n",
      "W1: 9.872676439626682 W2: 1.7732216346216392 b -5.2036139650284845 Loss: 0.41185034342192883\n",
      "W1: 9.87379020449695 W2: 1.7733298509419726 b -5.2041653289746765 Loss: 0.4118472260270138\n",
      "W1: 9.874902765665636 W2: 1.7734379645804441 b -5.2047161116927425 Loss: 0.41184411532895876\n",
      "W1: 9.876014124626836 W2: 1.7735459756339749 b -5.205266313873782 Loss: 0.4118410113123408\n",
      "W1: 9.877124282872394 W2: 1.7736538841994058 b -5.205815936207916 Loss: 0.41183791396177605\n",
      "W1: 9.878233241891902 W2: 1.7737616903734974 b -5.206364979384285 Loss: 0.41183482326191856\n",
      "W1: 9.879341003172701 W2: 1.7738693942529293 b -5.206913444091054 Loss: 0.4118317391974618\n",
      "W1: 9.880447568199891 W2: 1.7739769959343015 b -5.207461331015409 Loss: 0.41182866175313715\n",
      "W1: 9.881552938456332 W2: 1.7740844955141328 b -5.208008640843565 Loss: 0.4118255909137144\n",
      "W1: 9.882657115422653 W2: 1.774191893088862 b -5.208555374260762 Loss: 0.41182252666400204\n",
      "W1: 9.883760100577245 W2: 1.7742991887548476 b -5.209101531951273 Loss: 0.4118194689888458\n",
      "W1: 9.884861895396279 W2: 1.7744063826083674 b -5.209647114598398 Loss: 0.4118164178731302\n",
      "W1: 9.8859625013537 W2: 1.7745134747456188 b -5.2101921228844725 Loss: 0.4118133733017778\n",
      "W1: 9.887061919921235 W2: 1.7746204652627193 b -5.210736557490866 Loss: 0.41181033525974814\n",
      "W1: 9.8881601525684 W2: 1.7747273542557058 b -5.211280419097983 Loss: 0.41180730373203916\n",
      "W1: 9.889257200762497 W2: 1.7748341418205347 b -5.211823708385268 Loss: 0.4118042787036862\n",
      "W1: 9.890353065968625 W2: 1.774940828053082 b -5.212366426031202 Loss: 0.41180126015976215\n",
      "W1: 9.89144774964968 W2: 1.775047413049144 b -5.212908572713308 Loss: 0.4117982480853772\n",
      "W1: 9.892541253266362 W2: 1.7751538969044358 b -5.213450149108155 Loss: 0.411795242465679\n",
      "W1: 9.893633578277177 W2: 1.7752602797145929 b -5.213991155891353 Loss: 0.4117922432858524\n",
      "W1: 9.89472472613844 W2: 1.77536656157517 b -5.21453159373756 Loss: 0.4117892505311189\n",
      "W1: 9.895814698304282 W2: 1.7754727425816417 b -5.215071463320479 Loss: 0.41178626418673764\n",
      "W1: 9.896903496226653 W2: 1.7755788228294025 b -5.215610765312865 Loss: 0.41178328423800414\n",
      "W1: 9.897991121355327 W2: 1.7756848024137666 b -5.216149500386526 Loss: 0.41178031067025117\n",
      "W1: 9.899077575137904 W2: 1.7757906814299678 b -5.216687669212317 Loss: 0.4117773434688477\n",
      "W1: 9.900162859019813 W2: 1.7758964599731595 b -5.217225272460153 Loss: 0.4117743826191994\n",
      "W1: 9.901246974444323 W2: 1.7760021381384155 b -5.217762310799002 Loss: 0.4117714281067487\n",
      "W1: 9.902329922852537 W2: 1.7761077160207286 b -5.2182987848968905 Loss: 0.4117684799169743\n",
      "W1: 9.903411705683403 W2: 1.776213193715012 b -5.218834695420905 Loss: 0.4117655380353908\n",
      "W1: 9.904492324373718 W2: 1.7763185713160985 b -5.219370043037191 Loss: 0.41176260244754953\n",
      "W1: 9.905571780358128 W2: 1.7764238489187407 b -5.219904828410959 Loss: 0.4117596731390375\n",
      "W1: 9.906650075069136 W2: 1.7765290266176113 b -5.220439052206482 Loss: 0.41175675009547796\n",
      "W1: 9.907727209937102 W2: 1.7766341045073024 b -5.220972715087099 Loss: 0.41175383330252974\n",
      "W1: 9.90880318639025 W2: 1.7767390826823264 b -5.221505817715216 Loss: 0.4117509227458878\n",
      "W1: 9.90987800585467 W2: 1.7768439612371152 b -5.22203836075231 Loss: 0.4117480184112825\n",
      "W1: 9.910951669754327 W2: 1.776948740266021 b -5.222570344858928 Loss: 0.4117451202844799\n",
      "W1: 9.912024179511059 W2: 1.7770534198633157 b -5.223101770694687 Loss: 0.4117422283512816\n",
      "W1: 9.91309553654458 W2: 1.7771580001231913 b -5.223632638918281 Loss: 0.4117393425975244\n",
      "W1: 9.91416574227249 W2: 1.7772624811397595 b -5.224162950187477 Loss: 0.4117364630090807\n",
      "W1: 9.915234798110275 W2: 1.7773668630070523 b -5.2246927051591205 Loss: 0.41173358957185774\n",
      "W1: 9.916302705471312 W2: 1.7774711458190213 b -5.225221904489135 Loss: 0.41173072227179797\n",
      "W1: 9.917369465766873 W2: 1.7775753296695385 b -5.225750548832524 Loss: 0.41172786109487913\n",
      "W1: 9.918435080406129 W2: 1.7776794146523955 b -5.2262786388433735 Loss: 0.41172500602711337\n",
      "W1: 9.91949955079615 W2: 1.7777834008613045 b -5.226806175174853 Loss: 0.4117221570545481\n",
      "W1: 9.920562878341917 W2: 1.7778872883898973 b -5.227333158479216 Loss: 0.4117193141632649\n",
      "W1: 9.921625064446317 W2: 1.7779910773317258 b -5.227859589407804 Loss: 0.4117164773393806\n",
      "W1: 9.922686110510156 W2: 1.7780947677802623 b -5.2283854686110445 Loss: 0.41171364656904624\n",
      "W1: 9.923746017932153 W2: 1.7781983598288988 b -5.2289107967384565 Loss: 0.41171082183844715\n",
      "W1: 9.924804788108952 W2: 1.778301853570948 b -5.22943557443865 Loss: 0.41170800313380307\n",
      "W1: 9.925862422435122 W2: 1.778405249099642 b -5.2299598023593274 Loss: 0.4117051904413682\n",
      "W1: 9.926918922303159 W2: 1.7785085465081338 b -5.230483481147286 Loss: 0.4117023837474307\n",
      "W1: 9.927974289103496 W2: 1.778611745889496 b -5.231006611448418 Loss: 0.41169958303831256\n",
      "W1: 9.929028524224499 W2: 1.778714847336722 b -5.231529193907714 Loss: 0.41169678830037043\n",
      "W1: 9.930081629052479 W2: 1.7788178509427248 b -5.232051229169263 Loss: 0.4116939995199939\n",
      "W1: 9.93113360497169 W2: 1.7789207568003382 b -5.232572717876256 Loss: 0.411691216683607\n",
      "W1: 9.932184453364332 W2: 1.779023565002316 b -5.233093660670985 Loss: 0.4116884397776671\n",
      "W1: 9.933234175610563 W2: 1.7791262756413324 b -5.233614058194845 Loss: 0.4116856687886654\n",
      "W1: 9.93428277308849 W2: 1.7792288888099816 b -5.234133911088336 Loss: 0.41168290370312627\n",
      "W1: 9.935330247174187 W2: 1.7793314046007784 b -5.234653219991068 Loss: 0.4116801445076079\n",
      "W1: 9.936376599241685 W2: 1.7794338231061582 b -5.235171985541755 Loss: 0.4116773911887016\n",
      "W1: 9.937421830662986 W2: 1.7795361444184763 b -5.235690208378224 Loss: 0.4116746437330315\n",
      "W1: 9.938465942808062 W2: 1.7796383686300086 b -5.236207889137412 Loss: 0.4116719021272555\n",
      "W1: 9.93950893704486 W2: 1.7797404958329517 b -5.236725028455369 Loss: 0.4116691663580641\n",
      "W1: 9.940550814739304 W2: 1.7798425261194222 b -5.237241626967258 Loss: 0.41166643641218104\n",
      "W1: 9.941591577255302 W2: 1.7799444595814573 b -5.23775768530736 Loss: 0.4116637122763626\n",
      "W1: 9.942631225954747 W2: 1.7800462963110149 b -5.238273204109074 Loss: 0.41166099393739836\n",
      "W1: 9.943669762197523 W2: 1.7801480363999733 b -5.238788184004914 Loss: 0.41165828138210975\n",
      "W1: 9.944707187341505 W2: 1.7802496799401313 b -5.239302625626518 Loss: 0.41165557459735136\n",
      "W1: 9.945743502742566 W2: 1.780351227023208 b -5.239816529604645 Loss: 0.41165287357001046\n",
      "W1: 9.94677870975458 W2: 1.7804526777408438 b -5.240329896569176 Loss: 0.4116501782870062\n",
      "W1: 9.947812809729424 W2: 1.780554032184599 b -5.240842727149119 Loss: 0.4116474887352902\n",
      "W1: 9.948845804016985 W2: 1.780655290445955 b -5.241355021972607 Loss: 0.4116448049018468\n",
      "W1: 9.949877693965158 W2: 1.7807564526163135 b -5.241866781666901 Loss: 0.4116421267736916\n",
      "W1: 9.950908480919857 W2: 1.780857518786997 b -5.242378006858392 Loss: 0.411639454337873\n",
      "W1: 9.951938166225013 W2: 1.7809584890492491 b -5.2428886981726 Loss: 0.4116367875814712\n",
      "W1: 9.95296675122258 W2: 1.7810593634942335 b -5.243398856234181 Loss: 0.41163412649159814\n",
      "W1: 9.953994237252536 W2: 1.7811601422130352 b -5.243908481666922 Loss: 0.41163147105539727\n",
      "W1: 9.955020625652892 W2: 1.7812608252966595 b -5.2444175750937445 Loss: 0.4116288212600447\n",
      "W1: 9.95604591775969 W2: 1.7813614128360329 b -5.244926137136709 Loss: 0.4116261770927471\n",
      "W1: 9.95707011490701 W2: 1.7814619049220026 b -5.245434168417012 Loss: 0.41162353854074324\n",
      "W1: 9.95809321842697 W2: 1.7815623016453368 b -5.245941669554993 Loss: 0.4116209055913034\n",
      "W1: 9.959115229649736 W2: 1.7816626030967242 b -5.246448641170129 Loss: 0.41161827823172903\n",
      "W1: 9.960136149903517 W2: 1.7817628093667748 b -5.246955083881042 Loss: 0.41161565644935244\n",
      "W1: 9.961155980514578 W2: 1.7818629205460195 b -5.247460998305497 Loss: 0.41161304023153833\n",
      "W1: 9.962174722807234 W2: 1.7819629367249101 b -5.247966385060405 Loss: 0.41161042956568133\n",
      "W1: 9.96319237810386 W2: 1.7820628579938196 b -5.248471244761823 Loss: 0.41160782443920746\n",
      "W1: 9.964208947724895 W2: 1.7821626844430416 b -5.2489755780249565 Loss: 0.4116052248395741\n",
      "W1: 9.96522443298884 W2: 1.7822624161627911 b -5.249479385464163 Loss: 0.4116026307542688\n",
      "W1: 9.966238835212266 W2: 1.782362053243204 b -5.249982667692948 Loss: 0.4116000421708103\n",
      "W1: 9.967252155709817 W2: 1.7824615957743375 b -5.250485425323973 Loss: 0.41159745907674844\n",
      "W1: 9.968264395794211 W2: 1.7825610438461696 b -5.25098765896905 Loss: 0.41159488145966255\n",
      "W1: 9.969275556776246 W2: 1.7826603975486002 b -5.251489369239151 Loss: 0.4115923093071634\n",
      "W1: 9.970285639964803 W2: 1.7827596569714494 b -5.2519905567444 Loss: 0.41158974260689196\n",
      "W1: 9.971294646666852 W2: 1.7828588222044595 b -5.252491222094084 Loss: 0.4115871813465194\n",
      "W1: 9.972302578187447 W2: 1.7829578933372932 b -5.252991365896647 Loss: 0.41158462551374747\n",
      "W1: 9.973309435829739 W2: 1.783056870459535 b -5.253490988759696 Loss: 0.41158207509630773\n",
      "W1: 9.974315220894974 W2: 1.7831557536606908 b -5.253990091289999 Loss: 0.4115795300819624\n",
      "W1: 9.975319934682501 W2: 1.7832545430301874 b -5.254488674093489 Loss: 0.4115769904585031\n",
      "W1: 9.976323578489769 W2: 1.7833532386573734 b -5.254986737775265 Loss: 0.41157445621375177\n",
      "W1: 9.977326153612335 W2: 1.7834518406315185 b -5.255484282939592 Loss: 0.4115719273355602\n",
      "W1: 9.978327661343867 W2: 1.783550349041814 b -5.255981310189904 Loss: 0.4115694038118099\n",
      "W1: 9.979328102976146 W2: 1.783648763977373 b -5.256477820128805 Loss: 0.41156688563041216\n",
      "W1: 9.98032747979907 W2: 1.7837470855272293 b -5.256973813358069 Loss: 0.41156437277930763\n",
      "W1: 9.98132579310066 W2: 1.7838453137803387 b -5.257469290478643 Loss: 0.4115618652464672\n",
      "W1: 9.98232304416706 W2: 1.7839434488255788 b -5.257964252090649 Loss: 0.4115593630198901\n",
      "W1: 9.983319234282538 W2: 1.7840414907517483 b -5.258458698793383 Loss: 0.4115568660876061\n",
      "W1: 9.984314364729496 W2: 1.784139439647568 b -5.258952631185318 Loss: 0.4115543744376737\n",
      "W1: 9.98530843678847 W2: 1.7842372956016799 b -5.259446049864105 Loss: 0.4115518880581805\n",
      "W1: 9.986301451738132 W2: 1.7843350587026479 b -5.259938955426575 Loss: 0.41154940693724384\n",
      "W1: 9.987293410855298 W2: 1.7844327290389577 b -5.26043134846874 Loss: 0.41154693106300927\n",
      "W1: 9.988284315414923 W2: 1.7845303066990166 b -5.260923229585793 Loss: 0.41154446042365217\n",
      "W1: 9.989274166690114 W2: 1.784627791771154 b -5.261414599372111 Loss: 0.4115419950073765\n",
      "W1: 9.990262965952128 W2: 1.7847251843436205 b -5.261905458421258 Loss: 0.41153953480241495\n",
      "W1: 9.991250714470375 W2: 1.7848224845045892 b -5.262395807325982 Loss: 0.41153707979702897\n",
      "W1: 9.992237413512424 W2: 1.7849196923421549 b -5.262885646678218 Loss: 0.4115346299795091\n",
      "W1: 9.993223064344 W2: 1.7850168079443338 b -5.263374977069094 Loss: 0.41153218533817404\n",
      "W1: 9.994207668229002 W2: 1.7851138313990649 b -5.263863799088924 Loss: 0.41152974586137103\n",
      "W1: 9.995191226429487 W2: 1.7852107627942084 b -5.264352113327216 Loss: 0.4115273115374759\n",
      "W1: 9.996173740205686 W2: 1.7853076022175471 b -5.264839920372671 Loss: 0.41152488235489315\n",
      "W1: 9.997155210816004 W2: 1.7854043497567855 b -5.265327220813185 Loss: 0.4115224583020551\n",
      "W1: 9.998135639517026 W2: 1.7855010054995504 b -5.265814015235848 Loss: 0.4115200393674222\n",
      "W1: 9.999115027563512 W2: 1.7855975695333908 b -5.26630030422695 Loss: 0.4115176255394839\n",
      "W1: 10.000093376208412 W2: 1.7856940419457774 b -5.266786088371976 Loss: 0.41151521680675685\n",
      "W1: 10.001070686702858 W2: 1.7857904228241035 b -5.2672713682556145 Loss: 0.4115128131577857\n",
      "W1: 10.002046960296177 W2: 1.7858867122556845 b -5.267756144461752 Loss: 0.41151041458114396\n",
      "W1: 10.003022198235882 W2: 1.785982910327758 b -5.26824041757348 Loss: 0.4115080210654318\n",
      "W1: 10.003996401767692 W2: 1.786079017127484 b -5.268724188173093 Loss: 0.411505632599278\n",
      "W1: 10.00496957213552 W2: 1.7861750327419448 b -5.269207456842089 Loss: 0.4115032491713386\n",
      "W1: 10.005941710581485 W2: 1.786270957258145 b -5.2696902241611765 Loss: 0.4115008707702976\n",
      "W1: 10.00691281834591 W2: 1.7863667907630116 b -5.2701724907102685 Loss: 0.4114984973848663\n",
      "W1: 10.007882896667331 W2: 1.786462533343394 b -5.270654257068488 Loss: 0.41149612900378346\n",
      "W1: 10.008851946782494 W2: 1.7865581850860643 b -5.271135523814168 Loss: 0.41149376561581524\n",
      "W1: 10.009819969926362 W2: 1.786653746077717 b -5.271616291524856 Loss: 0.4114914072097553\n",
      "W1: 10.010786967332116 W2: 1.7867492164049688 b -5.2720965607773085 Loss: 0.4114890537744245\n",
      "W1: 10.011752940231164 W2: 1.7868445961543593 b -5.2725763321475 Loss: 0.41148670529867104\n",
      "W1: 10.012717889853132 W2: 1.7869398854123508 b -5.273055606210619 Loss: 0.41148436177136977\n",
      "W1: 10.013681817425882 W2: 1.7870350842653282 b -5.273534383541071 Loss: 0.41148202318142296\n",
      "W1: 10.014644724175504 W2: 1.7871301927995988 b -5.2740126647124805 Loss: 0.41147968951775965\n",
      "W1: 10.015606611326325 W2: 1.787225211101393 b -5.274490450297692 Loss: 0.411477360769336\n",
      "W1: 10.016567480100909 W2: 1.7873201392568638 b -5.274967740868769 Loss: 0.4114750369251347\n",
      "W1: 10.01752733172006 W2: 1.787414977352087 b -5.275444536997 Loss: 0.4114727179741653\n",
      "W1: 10.01848616740283 W2: 1.7875097254730612 b -5.275920839252895 Loss: 0.41147040390546435\n",
      "W1: 10.019443988366517 W2: 1.7876043837057078 b -5.276396648206189 Loss: 0.41146809470809453\n",
      "W1: 10.020400795826665 W2: 1.7876989521358715 b -5.276871964425845 Loss: 0.4114657903711452\n",
      "W1: 10.021356590997081 W2: 1.7877934308493193 b -5.27734678848005 Loss: 0.4114634908837323\n",
      "W1: 10.022311375089823 W2: 1.7878878199317416 b -5.277821120936223 Loss: 0.4114611962349983\n",
      "W1: 10.023265149315208 W2: 1.787982119468752 b -5.278294962361012 Loss: 0.4114589064141116\n",
      "W1: 10.02421791488182 W2: 1.7880763295458868 b -5.278768313320295 Loss: 0.41145662141026695\n",
      "W1: 10.025169672996508 W2: 1.7881704502486055 b -5.279241174379184 Loss: 0.4114543412126857\n",
      "W1: 10.02612042486439 W2: 1.788264481662291 b -5.279713546102023 Loss: 0.41145206581061466\n",
      "W1: 10.027070171688854 W2: 1.788358423872249 b -5.280185429052394 Loss: 0.4114497951933273\n",
      "W1: 10.028018914671566 W2: 1.7884522769637083 b -5.280656823793113 Loss: 0.4114475293501227\n",
      "W1: 10.028966655012471 W2: 1.7885460410218217 b -5.281127730886234 Loss: 0.4114452682703258\n",
      "W1: 10.029913393909794 W2: 1.7886397161316645 b -5.28159815089305 Loss: 0.41144301194328786\n",
      "W1: 10.030859132560044 W2: 1.7887333023782357 b -5.282068084374094 Loss: 0.41144076035838517\n",
      "W1: 10.03180387215802 W2: 1.7888267998464578 b -5.282537531889141 Loss: 0.41143851350502025\n",
      "W1: 10.03274761389681 W2: 1.7889202086211764 b -5.283006493997208 Loss: 0.4114362713726214\n",
      "W1: 10.033690358967794 W2: 1.7890135287871607 b -5.283474971256555 Loss: 0.41143403395064193\n",
      "W1: 10.034632108560652 W2: 1.7891067604291033 b -5.283942964224689 Loss: 0.4114318012285608\n",
      "W1: 10.035572863863363 W2: 1.7891999036316204 b -5.284410473458363 Loss: 0.411429573195883\n",
      "W1: 10.036512626062207 W2: 1.7892929584792518 b -5.284877499513576 Loss: 0.41142734984213775\n",
      "W1: 10.037451396341769 W2: 1.789385925056461 b -5.285344042945578 Loss: 0.41142513115688073\n",
      "W1: 10.038389175884944 W2: 1.7894788034476348 b -5.285810104308867 Loss: 0.41142291712969215\n",
      "W1: 10.03932596587294 W2: 1.7895715937370842 b -5.286275684157194 Loss: 0.4114207077501774\n",
      "W1: 10.04026176748528 W2: 1.7896642960090434 b -5.286740783043561 Loss: 0.4114185030079676\n",
      "W1: 10.0411965818998 W2: 1.789756910347671 b -5.287205401520225 Loss: 0.411416302892718\n",
      "W1: 10.04213041029266 W2: 1.7898494368370486 b -5.287669540138698 Loss: 0.4114141073941093\n",
      "W1: 10.043063253838344 W2: 1.7899418755611822 b -5.2881331994497485 Loss: 0.41141191650184683\n",
      "W1: 10.043995113709661 W2: 1.7900342266040017 b -5.288596380003401 Loss: 0.41140973020566135\n",
      "W1: 10.04492599107775 W2: 1.7901264900493608 b -5.28905908234894 Loss: 0.4114075484953078\n",
      "W1: 10.045855887112083 W2: 1.790218665981037 b -5.28952130703491 Loss: 0.411405371360566\n",
      "W1: 10.046784802980465 W2: 1.7903107544827324 b -5.289983054609116 Loss: 0.4114031987912404\n",
      "W1: 10.047712739849041 W2: 1.7904027556380726 b -5.290444325618624 Loss: 0.41140103077715984\n",
      "W1: 10.048639698882297 W2: 1.7904946695306074 b -5.290905120609767 Loss: 0.41139886730817815\n",
      "W1: 10.049565681243063 W2: 1.7905864962438107 b -5.29136544012814 Loss: 0.41139670837417286\n",
      "W1: 10.050490688092516 W2: 1.7906782358610809 b -5.2918252847186045 Loss: 0.4113945539650466\n",
      "W1: 10.051414720590182 W2: 1.7907698884657404 b -5.2922846549252895 Loss: 0.41139240407072586\n",
      "W1: 10.052337779893943 W2: 1.7908614541410357 b -5.292743551291593 Loss: 0.4113902586811616\n",
      "W1: 10.05325986716003 W2: 1.7909529329701381 b -5.293201974360181 Loss: 0.4113881177863286\n",
      "W1: 10.05418098354304 W2: 1.7910443250361427 b -5.293659924672991 Loss: 0.41138598137622645\n",
      "W1: 10.055101130195926 W2: 1.7911356304220694 b -5.294117402771234 Loss: 0.4113838494408782\n",
      "W1: 10.056020308270007 W2: 1.791226849210862 b -5.294574409195391 Loss: 0.41138172197033057\n",
      "W1: 10.05693851891497 W2: 1.7913179814853897 b -5.29503094448522 Loss: 0.4113795989546555\n",
      "W1: 10.057855763278873 W2: 1.7914090273284453 b -5.295487009179754 Loss: 0.4113774803839473\n",
      "W1: 10.058772042508144 W2: 1.7914999868227466 b -5.295942603817303 Loss: 0.41137536624832494\n",
      "W1: 10.059687357747586 W2: 1.7915908600509358 b -5.296397728935453 Loss: 0.4113732565379312\n",
      "W1: 10.060601710140386 W2: 1.79168164709558 b -5.2968523850710705 Loss: 0.41137115124293183\n",
      "W1: 10.061515100828105 W2: 1.7917723480391712 b -5.297306572760302 Loss: 0.41136905035351695\n",
      "W1: 10.062427530950695 W2: 1.7918629629641254 b -5.297760292538577 Loss: 0.41136695385989996\n",
      "W1: 10.06333900164649 W2: 1.791953491952784 b -5.298213544940604 Loss: 0.4113648617523174\n",
      "W1: 10.064249514052218 W2: 1.7920439350874129 b -5.29866633050038 Loss: 0.4113627740210299\n",
      "W1: 10.065159069302995 W2: 1.7921342924502028 b -5.299118649751183 Loss: 0.4113606906563205\n",
      "W1: 10.066067668532336 W2: 1.79222456412327 b -5.299570503225578 Loss: 0.4113586116484967\n",
      "W1: 10.066975312872154 W2: 1.7923147501886547 b -5.300021891455419 Loss: 0.4113565369878884\n",
      "W1: 10.06788200345276 W2: 1.792404850728323 b -5.3004728149718465 Loss: 0.4113544666648489\n",
      "W1: 10.068787741402874 W2: 1.7924948658241657 b -5.300923274305291 Loss: 0.4113524006697549\n",
      "W1: 10.069692527849618 W2: 1.7925847955579985 b -5.3013732699854765 Loss: 0.4113503389930056\n",
      "W1: 10.070596363918524 W2: 1.7926746400115623 b -5.301822802541414 Loss: 0.4113482816250238\n",
      "W1: 10.071499250733538 W2: 1.7927643992665234 b -5.302271872501412 Loss: 0.41134622855625474\n",
      "W1: 10.072401189417022 W2: 1.7928540734044733 b -5.302720480393069 Loss: 0.4113441797771669\n",
      "W1: 10.073302181089751 W2: 1.7929436625069284 b -5.303168626743283 Loss: 0.4113421352782513\n",
      "W1: 10.074202226870923 W2: 1.7930331666553307 b -5.303616312078247 Loss: 0.4113400950500219\n",
      "W1: 10.075101327878162 W2: 1.7931225859310476 b -5.30406353692345 Loss: 0.4113380590830154\n",
      "W1: 10.075999485227513 W2: 1.7932119204153716 b -5.304510301803682 Loss: 0.41133602736779085\n",
      "W1: 10.076896700033451 W2: 1.7933011701895207 b -5.304956607243033 Loss: 0.41133399989493\n",
      "W1: 10.077792973408885 W2: 1.793390335334639 b -5.305402453764892 Loss: 0.4113319766550374\n",
      "W1: 10.078688306465155 W2: 1.7934794159317953 b -5.305847841891953 Loss: 0.4113299576387399\n",
      "W1: 10.07958270031204 W2: 1.7935684120619844 b -5.306292772146209 Loss: 0.4113279428366864\n",
      "W1: 10.080476156057756 W2: 1.7936573238061266 b -5.3067372450489625 Loss: 0.41132593223954855\n",
      "W1: 10.081368674808964 W2: 1.7937461512450679 b -5.307181261120819 Loss: 0.4113239258380204\n",
      "W1: 10.082260257670768 W2: 1.79383489445958 b -5.307624820881691 Loss: 0.41132192362281733\n",
      "W1: 10.083150905746722 W2: 1.7939235535303606 b -5.308067924850799 Loss: 0.4113199255846782\n",
      "W1: 10.084040620138827 W2: 1.7940121285380326 b -5.3085105735466716 Loss: 0.41131793171436326\n",
      "W1: 10.084929401947539 W2: 1.7941006195631453 b -5.308952767487149 Loss: 0.4113159420026544\n",
      "W1: 10.085817252271768 W2: 1.7941890266861735 b -5.309394507189382 Loss: 0.41131395644035657\n",
      "W1: 10.086704172208885 W2: 1.7942773499875184 b -5.3098357931698335 Loss: 0.4113119750182957\n",
      "W1: 10.087590162854719 W2: 1.7943655895475068 b -5.3102766259442795 Loss: 0.41130999772732013\n",
      "W1: 10.088475225303565 W2: 1.7944537454463916 b -5.3107170060278115 Loss: 0.41130802455829957\n",
      "W1: 10.089359360648183 W2: 1.7945418177643517 b -5.311156933934837 Loss: 0.4113060555021262\n",
      "W1: 10.090242569979802 W2: 1.7946298065814925 b -5.311596410179077 Loss: 0.411304090549713\n",
      "W1: 10.091124854388124 W2: 1.794717711977845 b -5.312035435273575 Loss: 0.41130212969199564\n",
      "W1: 10.092006214961323 W2: 1.794805534033367 b -5.312474009730691 Loss: 0.41130017291993043\n",
      "W1: 10.092886652786051 W2: 1.7948932728279423 b -5.312912134062104 Loss: 0.41129822022449575\n",
      "W1: 10.09376616894744 W2: 1.7949809284413807 b -5.313349808778817 Loss: 0.41129627159669135\n",
      "W1: 10.094644764529104 W2: 1.7950685009534189 b -5.313787034391153 Loss: 0.41129432702753826\n",
      "W1: 10.09552244061314 W2: 1.7951559904437195 b -5.314223811408759 Loss: 0.4112923865080791\n",
      "W1: 10.096399198280134 W2: 1.795243396991872 b -5.314660140340607 Loss: 0.4112904500293777\n",
      "W1: 10.097275038609162 W2: 1.795330720677392 b -5.315096021694993 Loss: 0.41128851758251916\n",
      "W1: 10.098149962677793 W2: 1.795417961579722 b -5.315531455979542 Loss: 0.4112865891586099\n",
      "W1: 10.099023971562088 W2: 1.7955051197782308 b -5.315966443701205 Loss: 0.4112846647487771\n",
      "W1: 10.09989706633661 W2: 1.7955921953522138 b -5.316400985366262 Loss: 0.4112827443441695\n",
      "W1: 10.100769248074418 W2: 1.7956791883808934 b -5.316835081480323 Loss: 0.4112808279359567\n",
      "W1: 10.101640517847075 W2: 1.7957660989434183 b -5.317268732548329 Loss: 0.4112789155153292\n",
      "W1: 10.102510876724654 W2: 1.7958529271188646 b -5.317701939074553 Loss: 0.4112770070734984\n",
      "W1: 10.10338032577573 W2: 1.7959396729862345 b -5.3181347015626015 Loss: 0.4112751026016968\n",
      "W1: 10.10424886606739 W2: 1.7960263366244575 b -5.318567020515414 Loss: 0.4112732020911776\n",
      "W1: 10.105116498665238 W2: 1.79611291811239 b -5.318998896435266 Loss: 0.4112713055332147\n",
      "W1: 10.10598322463339 W2: 1.7961994175288152 b -5.31943032982377 Loss: 0.4112694129191027\n",
      "W1: 10.10684904503448 W2: 1.7962858349524433 b -5.319861321181874 Loss: 0.411267524240157\n",
      "W1: 10.107713960929663 W2: 1.7963721704619118 b -5.320291871009867 Loss: 0.41126563948771344\n",
      "W1: 10.10857797337862 W2: 1.796458424135785 b -5.320721979807375 Loss: 0.4112637586531287\n",
      "W1: 10.109441083439554 W2: 1.7965445960525548 b -5.321151648073365 Loss: 0.41126188172777955\n",
      "W1: 10.110303292169199 W2: 1.7966306862906398 b -5.321580876306148 Loss: 0.41126000870306356\n",
      "W1: 10.11116460062282 W2: 1.7967166949283861 b -5.322009665003374 Loss: 0.4112581395703984\n",
      "W1: 10.11202500985421 W2: 1.796802622044067 b -5.32243801466204 Loss: 0.4112562743212224\n",
      "W1: 10.112884520915708 W2: 1.7968884677158832 b -5.322865925778485 Loss: 0.4112544129469937\n",
      "W1: 10.113743134858181 W2: 1.7969742320219628 b -5.323293398848397 Loss: 0.41125255543919137\n",
      "W1: 10.114600852731042 W2: 1.7970599150403614 b -5.323720434366807 Loss: 0.4112507017893139\n",
      "W1: 10.115457675582249 W2: 1.797145516849062 b -5.3241470328280975 Loss: 0.4112488519888806\n",
      "W1: 10.116313604458302 W2: 1.797231037525975 b -5.324573194725997 Loss: 0.41124700602943026\n",
      "W1: 10.11716864040425 W2: 1.797316477148939 b -5.324998920553586 Loss: 0.4112451639025221\n",
      "W1: 10.118022784463696 W2: 1.7974018357957193 b -5.325424210803296 Loss: 0.41124332559973503\n",
      "W1: 10.118876037678792 W2: 1.7974871135440096 b -5.325849065966908 Loss: 0.4112414911126681\n",
      "W1: 10.11972840109025 W2: 1.797572310471431 b -5.32627348653556 Loss: 0.4112396604329404\n",
      "W1: 10.120579875737334 W2: 1.7976574266555325 b -5.326697472999741 Loss: 0.4112378335521901\n",
      "W1: 10.121430462657877 W2: 1.797742462173791 b -5.327121025849297 Loss: 0.4112360104620759\n",
      "W1: 10.122280162888266 W2: 1.797827417103611 b -5.327544145573429 Loss: 0.41123419115427606\n",
      "W1: 10.123128977463463 W2: 1.7979122915223256 b -5.327966832660697 Loss: 0.41123237562048837\n",
      "W1: 10.123976907416989 W2: 1.797997085507195 b -5.3283890875990165 Loss: 0.4112305638524299\n",
      "W1: 10.124823953780941 W2: 1.7980817991354079 b -5.3288109108756645 Loss: 0.411228755841838\n",
      "W1: 10.125670117585988 W2: 1.798166432484081 b -5.329232302977277 Loss: 0.41122695158046896\n",
      "W1: 10.126515399861374 W2: 1.7982509856302589 b -5.329653264389853 Loss: 0.411225151060099\n",
      "W1: 10.127359801634919 W2: 1.7983354586509148 b -5.330073795598751 Loss: 0.4112233542725232\n",
      "W1: 10.128203323933025 W2: 1.7984198516229501 b -5.3304938970886955 Loss: 0.41122156120955644\n",
      "W1: 10.129045967780677 W2: 1.798504164623194 b -5.330913569343774 Loss: 0.4112197718630327\n",
      "W1: 10.129887734201443 W2: 1.7985883977284045 b -5.331332812847439 Loss: 0.4112179862248054\n",
      "W1: 10.130728624217479 W2: 1.7986725510152675 b -5.331751628082511 Loss: 0.41121620428674704\n",
      "W1: 10.131568638849531 W2: 1.7987566245603976 b -5.332170015531177 Loss: 0.4112144260407492\n",
      "W1: 10.132407779116939 W2: 1.7988406184403383 b -5.332587975674992 Loss: 0.41121265147872266\n",
      "W1: 10.133246046037632 W2: 1.7989245327315606 b -5.333005508994881 Loss: 0.4112108805925976\n",
      "W1: 10.134083440628142 W2: 1.799008367510465 b -5.333422615971139 Loss: 0.4112091133743224\n",
      "W1: 10.134919963903597 W2: 1.79909212285338 b -5.333839297083432 Loss: 0.41120734981586526\n",
      "W1: 10.135755616877727 W2: 1.7991757988365633 b -5.334255552810799 Loss: 0.411205589909213\n",
      "W1: 10.136590400562866 W2: 1.7992593955362008 b -5.334671383631652 Loss: 0.411203833646371\n",
      "W1: 10.137424315969957 W2: 1.7993429130284075 b -5.335086790023778 Loss: 0.4112020810193638\n",
      "W1: 10.138257364108547 W2: 1.7994263513892272 b -5.335501772464339 Loss: 0.4112003320202346\n",
      "W1: 10.139089545986796 W2: 1.7995097106946323 b -5.335916331429874 Loss: 0.41119858664104536\n",
      "W1: 10.139920862611477 W2: 1.7995929910205244 b -5.336330467396297 Loss: 0.4111968448738768\n",
      "W1: 10.140751314987982 W2: 1.7996761924427338 b -5.3367441808389025 Loss: 0.41119510671082815\n",
      "W1: 10.14158090412032 W2: 1.7997593150370201 b -5.337157472232364 Loss: 0.41119337214401724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.142409631011114 W2: 1.799842358879072 b -5.337570342050735 Loss: 0.4111916411655802\n",
      "W1: 10.143237496661618 W2: 1.7999253240445068 b -5.33798279076745 Loss: 0.4111899137676722\n",
      "W1: 10.144064502071707 W2: 1.8000082106088715 b -5.338394818855327 Loss: 0.4111881899424663\n",
      "W1: 10.144890648239883 W2: 1.8000910186476422 b -5.338806426786565 Loss: 0.4111864696821545\n",
      "W1: 10.145715936163281 W2: 1.8001737482362241 b -5.33921761503275 Loss: 0.4111847529789463\n",
      "W1: 10.146540366837664 W2: 1.8002563994499519 b -5.33962838406485 Loss: 0.4111830398250703\n",
      "W1: 10.147363941257431 W2: 1.8003389723640895 b -5.3400387343532225 Loss: 0.41118133021277326\n",
      "W1: 10.14818666041562 W2: 1.80042146705383 b -5.340448666367609 Loss: 0.41117962413431947\n",
      "W1: 10.149008525303902 W2: 1.8005038835942968 b -5.340858180577142 Loss: 0.4111779215819924\n",
      "W1: 10.149829536912595 W2: 1.800586222060542 b -5.341267277450339 Loss: 0.4111762225480927\n",
      "W1: 10.150649696230657 W2: 1.8006684825275476 b -5.341675957455113 Loss: 0.41117452702493956\n",
      "W1: 10.151469004245694 W2: 1.8007506650702252 b -5.342084221058763 Loss: 0.41117283500487006\n",
      "W1: 10.152287461943958 W2: 1.8008327697634159 b -5.342492068727983 Loss: 0.41117114648023917\n",
      "W1: 10.153105070310353 W2: 1.8009147966818908 b -5.342899500928859 Loss: 0.41116946144342026\n",
      "W1: 10.153921830328434 W2: 1.8009967459003506 b -5.34330651812687 Loss: 0.4111677798868037\n",
      "W1: 10.15473774298041 W2: 1.801078617493426 b -5.343713120786891 Loss: 0.4111661018027987\n",
      "W1: 10.155552809247151 W2: 1.801160411535677 b -5.344119309373191 Loss: 0.4111644271838315\n",
      "W1: 10.156367030108184 W2: 1.8012421281015942 b -5.344525084349438 Loss: 0.41116275602234625\n",
      "W1: 10.157180406541695 W2: 1.801323767265598 b -5.3449304461786955 Loss: 0.41116108831080495\n",
      "W1: 10.157992939524538 W2: 1.8014053291020387 b -5.345335395323428 Loss: 0.41115942404168726\n",
      "W1: 10.15880463003223 W2: 1.8014868136851965 b -5.345739932245497 Loss: 0.4111577632074903\n",
      "W1: 10.15961547903896 W2: 1.801568221089282 b -5.346144057406167 Loss: 0.4111561058007289\n",
      "W1: 10.160425487517582 W2: 1.8016495513884363 b -5.346547771266101 Loss: 0.41115445181393534\n",
      "W1: 10.161234656439627 W2: 1.80173080465673 b -5.346951074285367 Loss: 0.4111528012396591\n",
      "W1: 10.1620429867753 W2: 1.8018119809681643 b -5.347353966923436 Loss: 0.41115115407046776\n",
      "W1: 10.16285047949348 W2: 1.8018930803966708 b -5.3477564496391805 Loss: 0.41114951029894536\n",
      "W1: 10.163657135561731 W2: 1.8019741030161116 b -5.3481585228908814 Loss: 0.4111478699176944\n",
      "W1: 10.164462955946297 W2: 1.802055048900279 b -5.348560187136224 Loss: 0.41114623291933355\n",
      "W1: 10.165267941612102 W2: 1.8021359181228958 b -5.348961442832301 Loss: 0.4111445992964995\n",
      "W1: 10.166072093522759 W2: 1.8022167107576152 b -5.3493622904356135 Loss: 0.4111429690418457\n",
      "W1: 10.166875412640568 W2: 1.8022974268780216 b -5.349762730402071 Loss: 0.41114134214804304\n",
      "W1: 10.16767789992652 W2: 1.8023780665576294 b -5.350162763186994 Loss: 0.4111397186077793\n",
      "W1: 10.1684795563403 W2: 1.802458629869884 b -5.350562389245111 Loss: 0.4111380984137597\n",
      "W1: 10.169280382840284 W2: 1.8025391168881613 b -5.3509616090305645 Loss: 0.4111364815587063\n",
      "W1: 10.170080380383551 W2: 1.8026195276857682 b -5.351360422996908 Loss: 0.4111348680353577\n",
      "W1: 10.170879549925871 W2: 1.8026998623359423 b -5.351758831597111 Loss: 0.41113325783647026\n",
      "W1: 10.171677892421721 W2: 1.8027801209118524 b -5.352156835283556 Loss: 0.4111316509548166\n",
      "W1: 10.17247540882428 W2: 1.8028603034865978 b -5.352554434508039 Loss: 0.4111300473831864\n",
      "W1: 10.17327210008543 W2: 1.8029404101332092 b -5.352951629721775 Loss: 0.4111284471143863\n",
      "W1: 10.174067967155766 W2: 1.803020440924648 b -5.3533484213753955 Loss: 0.4111268501412397\n",
      "W1: 10.174863010984588 W2: 1.803100395933807 b -5.353744809918949 Loss: 0.4111252564565863\n",
      "W1: 10.17565723251991 W2: 1.80318027523351 b -5.354140795801903 Loss: 0.41112366605328315\n",
      "W1: 10.17645063270846 W2: 1.803260078896512 b -5.354536379473146 Loss: 0.41112207892420344\n",
      "W1: 10.177243212495684 W2: 1.8033398069954996 b -5.354931561380987 Loss: 0.4111204950622371\n",
      "W1: 10.178034972825742 W2: 1.80341945960309 b -5.355326341973156 Loss: 0.4111189144602907\n",
      "W1: 10.178825914641516 W2: 1.8034990367918322 b -5.355720721696807 Loss: 0.4111173371112873\n",
      "W1: 10.179616038884614 W2: 1.803578538634207 b -5.356114700998515 Loss: 0.4111157630081665\n",
      "W1: 10.180405346495366 W2: 1.8036579652026257 b -5.356508280324282 Loss: 0.41111419214388395\n",
      "W1: 10.18119383841283 W2: 1.803737316569432 b -5.356901460119534 Loss: 0.4111126245114122\n",
      "W1: 10.181981515574789 W2: 1.8038165928069005 b -5.357294240829123 Loss: 0.41111106010373993\n",
      "W1: 10.182768378917762 W2: 1.803895793987238 b -5.357686622897329 Loss: 0.4111094989138722\n",
      "W1: 10.183554429377 W2: 1.8039749201825828 b -5.35807860676786 Loss: 0.4111079409348303\n",
      "W1: 10.184339667886489 W2: 1.8040539714650046 b -5.358470192883851 Loss: 0.4111063861596515\n",
      "W1: 10.185124095378951 W2: 1.8041329479065054 b -5.358861381687867 Loss: 0.4111048345813897\n",
      "W1: 10.18590771278585 W2: 1.8042118495790185 b -5.359252173621907 Loss: 0.4111032861931148\n",
      "W1: 10.18669052103739 W2: 1.8042906765544093 b -5.359642569127397 Loss: 0.4111017409879125\n",
      "W1: 10.187472521062515 W2: 1.8043694289044754 b -5.360032568645199 Loss: 0.411100198958885\n",
      "W1: 10.188253713788923 W2: 1.804448106700946 b -5.360422172615606 Loss: 0.41109866009915036\n",
      "W1: 10.189034100143052 W2: 1.8045267100154823 b -5.360811381478346 Loss: 0.41109712440184226\n",
      "W1: 10.189813681050095 W2: 1.804605238919678 b -5.361200195672581 Loss: 0.41109559186011085\n",
      "W1: 10.190592457433995 W2: 1.804683693485059 b -5.361588615636912 Loss: 0.41109406246712205\n",
      "W1: 10.191370430217448 W2: 1.8047620737830825 b -5.361976641809373 Loss: 0.4110925362160574\n",
      "W1: 10.192147600321908 W2: 1.804840379885139 b -5.362364274627438 Loss: 0.4110910131001148\n",
      "W1: 10.192923968667584 W2: 1.8049186118625504 b -5.362751514528017 Loss: 0.41108949311250736\n",
      "W1: 10.193699536173447 W2: 1.8049967697865719 b -5.363138361947462 Loss: 0.4110879762464638\n",
      "W1: 10.194474303757232 W2: 1.8050748537283903 b -5.363524817321566 Loss: 0.41108646249522934\n",
      "W1: 10.195248272335434 W2: 1.8051528637591252 b -5.36391088108556 Loss: 0.4110849518520643\n",
      "W1: 10.196021442823318 W2: 1.8052307999498287 b -5.3642965536741185 Loss: 0.41108344431024474\n",
      "W1: 10.196793816134914 W2: 1.8053086623714854 b -5.364681835521359 Loss: 0.4110819398630621\n",
      "W1: 10.197565393183027 W2: 1.8053864510950126 b -5.365066727060842 Loss: 0.41108043850382364\n",
      "W1: 10.198336174879229 W2: 1.80546416619126 b -5.365451228725575 Loss: 0.41107894022585223\n",
      "W1: 10.19910616213387 W2: 1.8055418077310106 b -5.365835340948006 Loss: 0.4110774450224859\n",
      "W1: 10.199875355856072 W2: 1.8056193757849794 b -5.366219064160035 Loss: 0.411075952887078\n",
      "W1: 10.200643756953742 W2: 1.8056968704238148 b -5.366602398793004 Loss: 0.4110744638129978\n",
      "W1: 10.201411366333561 W2: 1.8057742917180977 b -5.366985345277708 Loss: 0.41107297779362945\n",
      "W1: 10.202178184900998 W2: 1.8058516397383422 b -5.367367904044388 Loss: 0.4110714948223728\n",
      "W1: 10.2029442135603 W2: 1.8059289145549953 b -5.367750075522732 Loss: 0.41107001489264233\n",
      "W1: 10.203709453214506 W2: 1.806006116238437 b -5.368131860141885 Loss: 0.41106853799786863\n",
      "W1: 10.20447390476544 W2: 1.8060832448589805 b -5.368513258330438 Loss: 0.4110670641314966\n",
      "W1: 10.205237569113716 W2: 1.806160300486872 b -5.368894270516436 Loss: 0.41106559328698694\n",
      "W1: 10.206000447158743 W2: 1.8062372831922908 b -5.3692748971273785 Loss: 0.4110641254578151\n",
      "W1: 10.206762539798722 W2: 1.8063141930453497 b -5.3696551385902165 Loss: 0.41106266063747193\n",
      "W1: 10.207523847930652 W2: 1.8063910301160944 b -5.370034995331357 Loss: 0.4110611988194633\n",
      "W1: 10.208284372450327 W2: 1.8064677944745045 b -5.370414467776663 Loss: 0.41105973999730955\n",
      "W1: 10.209044114252347 W2: 1.8065444861904927 b -5.370793556351453 Loss: 0.4110582841645467\n",
      "W1: 10.209803074230107 W2: 1.806621105333905 b -5.371172261480503 Loss: 0.41105683131472515\n",
      "W1: 10.210561253275811 W2: 1.806697651974521 b -5.371550583588047 Loss: 0.41105538144141057\n",
      "W1: 10.211318652280468 W2: 1.8067741261820542 b -5.37192852309778 Loss: 0.41105393453818323\n",
      "W1: 10.212075272133895 W2: 1.8068505280261515 b -5.372306080432852 Loss: 0.4110524905986383\n",
      "W1: 10.212831113724718 W2: 1.806926857576393 b -5.372683256015879 Loss: 0.411051049616386\n",
      "W1: 10.213586177940375 W2: 1.8070031149022934 b -5.373060050268935 Loss: 0.4110496115850506\n",
      "W1: 10.214340465667119 W2: 1.8070793000733003 b -5.373436463613558 Loss: 0.41104817649827186\n",
      "W1: 10.215093977790017 W2: 1.8071554131587957 b -5.373812496470747 Loss: 0.41104674434970395\n",
      "W1: 10.215846715192956 W2: 1.8072314542280952 b -5.374188149260967 Loss: 0.41104531513301534\n",
      "W1: 10.216598678758642 W2: 1.8073074233504482 b -5.3745634224041465 Loss: 0.4110438888418894\n",
      "W1: 10.217349869368599 W2: 1.8073833205950387 b -5.37493831631968 Loss: 0.41104246547002404\n",
      "W1: 10.21810028790318 W2: 1.8074591460309841 b -5.375312831426429 Loss: 0.4110410450111317\n",
      "W1: 10.21884993524156 W2: 1.8075348997273362 b -5.375686968142721 Loss: 0.4110396274589393\n",
      "W1: 10.219598812261742 W2: 1.8076105817530808 b -5.376060726886352 Loss: 0.41103821280718816\n",
      "W1: 10.220346919840557 W2: 1.8076861921771379 b -5.376434108074586 Loss: 0.41103680104963397\n",
      "W1: 10.22109425885367 W2: 1.8077617310683618 b -5.376807112124159 Loss: 0.4110353921800467\n",
      "W1: 10.221840830175577 W2: 1.807837198495541 b -5.377179739451275 Loss: 0.41103398619221126\n",
      "W1: 10.222586634679608 W2: 1.8079125945273986 b -5.37755199047161 Loss: 0.41103258307992613\n",
      "W1: 10.223331673237933 W2: 1.8079879192325918 b -5.377923865600312 Loss: 0.41103118283700424\n",
      "W1: 10.224075946721555 W2: 1.8080631726797127 b -5.3782953652520025 Loss: 0.4110297854572733\n",
      "W1: 10.224819456000326 W2: 1.8081383549372874 b -5.378666489840776 Loss: 0.41102839093457444\n",
      "W1: 10.225562201942932 W2: 1.8082134660737765 b -5.379037239780201 Loss: 0.41102699926276354\n",
      "W1: 10.226304185416907 W2: 1.808288506157576 b -5.379407615483323 Loss: 0.4110256104357102\n",
      "W1: 10.227045407288633 W2: 1.8083634752570155 b -5.37977761736266 Loss: 0.41102422444729814\n",
      "W1: 10.227785868423338 W2: 1.8084383734403602 b -5.380147245830212 Loss: 0.4110228412914257\n",
      "W1: 10.228525569685099 W2: 1.8085132007758098 b -5.380516501297453 Loss: 0.41102146096200476\n",
      "W1: 10.229264511936845 W2: 1.8085879573314985 b -5.380885384175337 Loss: 0.41102008345296087\n",
      "W1: 10.230002696040362 W2: 1.808662643175496 b -5.381253894874296 Loss: 0.4110187087582343\n",
      "W1: 10.230740122856288 W2: 1.8087372583758063 b -5.381622033804241 Loss: 0.4110173368717788\n",
      "W1: 10.23147679324412 W2: 1.8088118030003688 b -5.381989801374568 Loss: 0.411015967787562\n",
      "W1: 10.232212708062212 W2: 1.8088862771170577 b -5.382357197994152 Loss: 0.4110146014995654\n",
      "W1: 10.232947868167782 W2: 1.8089606807936824 b -5.382724224071349 Loss: 0.41101323800178446\n",
      "W1: 10.23368227441691 W2: 1.8090350140979876 b -5.3830908800140005 Loss: 0.41101187728822824\n",
      "W1: 10.23441592766454 W2: 1.809109277097653 b -5.383457166229432 Loss: 0.4110105193529197\n",
      "W1: 10.23514882876448 W2: 1.8091834698602933 b -5.383823083124453 Loss: 0.41100916418989536\n",
      "W1: 10.235880978569414 W2: 1.8092575924534593 b -5.384188631105357 Loss: 0.41100781179320545\n",
      "W1: 10.236612377930888 W2: 1.8093316449446362 b -5.384553810577927 Loss: 0.4110064621569142\n",
      "W1: 10.237343027699325 W2: 1.8094056274012453 b -5.384918621947431 Loss: 0.4110051152750987\n",
      "W1: 10.23807292872402 W2: 1.8094795398906431 b -5.3852830656186255 Loss: 0.41100377114185027\n",
      "W1: 10.238802081853143 W2: 1.8095533824801215 b -5.385647141995756 Loss: 0.4110024297512736\n",
      "W1: 10.239530487933743 W2: 1.8096271552369083 b -5.386010851482557 Loss: 0.41100109109748667\n",
      "W1: 10.24025814781175 W2: 1.8097008582281668 b -5.3863741944822525 Loss: 0.4109997551746212\n",
      "W1: 10.240985062331971 W2: 1.8097744915209957 b -5.386737171397559 Loss: 0.41099842197682235\n",
      "W1: 10.241711232338098 W2: 1.8098480551824296 b -5.387099782630685 Loss: 0.41099709149824837\n",
      "W1: 10.242436658672707 W2: 1.8099215492794392 b -5.387462028583329 Loss: 0.41099576373307145\n",
      "W1: 10.243161342177263 W2: 1.8099949738789305 b -5.387823909656684 Loss: 0.4109944386754764\n",
      "W1: 10.243885283692116 W2: 1.8100683290477457 b -5.3881854262514395 Loss: 0.41099311631966184\n",
      "W1: 10.244608484056506 W2: 1.810141614852663 b -5.388546578767777 Loss: 0.4109917966598396\n",
      "W1: 10.245330944108568 W2: 1.8102148313603965 b -5.388907367605373 Loss: 0.4109904796902347\n",
      "W1: 10.24605266468533 W2: 1.810287978637596 b -5.3892677931634045 Loss: 0.41098916540508523\n",
      "W1: 10.24677364662271 W2: 1.8103610567508481 b -5.389627855840541 Loss: 0.41098785379864283\n",
      "W1: 10.247493890755532 W2: 1.810434065766675 b -5.389987556034952 Loss: 0.4109865448651718\n",
      "W1: 10.248213397917512 W2: 1.8105070057515353 b -5.390346894144306 Loss: 0.4109852385989498\n",
      "W1: 10.24893216894127 W2: 1.8105798767718237 b -5.390705870565771 Loss: 0.4109839349942677\n",
      "W1: 10.249650204658327 W2: 1.8106526788938717 b -5.391064485696013 Loss: 0.41098263404542923\n",
      "W1: 10.25036750589911 W2: 1.8107254121839464 b -5.391422739931202 Loss: 0.41098133574675105\n",
      "W1: 10.25108407349295 W2: 1.810798076708252 b -5.3917806336670075 Loss: 0.41098004009256317\n",
      "W1: 10.251799908268087 W2: 1.810870672532929 b -5.392138167298602 Loss: 0.410978747077208\n",
      "W1: 10.252515011051669 W2: 1.8109431997240542 b -5.392495341220661 Loss: 0.4109774566950415\n",
      "W1: 10.253229382669758 W2: 1.811015658347641 b -5.392852155827364 Loss: 0.4109761689404319\n",
      "W1: 10.253943023947327 W2: 1.8110880484696399 b -5.393208611512396 Loss: 0.41097488380776087\n",
      "W1: 10.254655935708264 W2: 1.8111603701559373 b -5.393564708668947 Loss: 0.41097360129142224\n",
      "W1: 10.255368118775374 W2: 1.811232623472357 b -5.3939204476897125 Loss: 0.4109723213858233\n",
      "W1: 10.25607957397038 W2: 1.8113048084846592 b -5.3942758289668955 Loss: 0.41097104408538365\n",
      "W1: 10.256790302113924 W2: 1.8113769252585412 b -5.394630852892206 Loss: 0.4109697693845357\n",
      "W1: 10.25750030402557 W2: 1.811448973859637 b -5.3949855198568635 Loss: 0.41096849727772483\n",
      "W1: 10.258209580523806 W2: 1.811520954353518 b -5.395339830251595 Loss: 0.4109672277594088\n",
      "W1: 10.258918132426045 W2: 1.8115928668056918 b -5.39569378446664 Loss: 0.4109659608240579\n",
      "W1: 10.259625960548627 W2: 1.8116647112816036 b -5.396047382891745 Loss: 0.41096469646615524\n",
      "W1: 10.26033306570682 W2: 1.8117364878466358 b -5.396400625916172 Loss: 0.41096343468019664\n",
      "W1: 10.261039448714822 W2: 1.8118081965661075 b -5.396753513928691 Loss: 0.4109621754606902\n",
      "W1: 10.261745110385764 W2: 1.8118798375052754 b -5.397106047317588 Loss: 0.4109609188021563\n",
      "W1: 10.26245005153171 W2: 1.8119514107293335 b -5.39745822647066 Loss: 0.41095966469912854\n",
      "W1: 10.263154272963659 W2: 1.812022916303413 b -5.397810051775221 Loss: 0.4109584131461521\n",
      "W1: 10.263857775491546 W2: 1.812094354292582 b -5.398161523618097 Loss: 0.4109571641377855\n",
      "W1: 10.264560559924249 W2: 1.812165724761847 b -5.398512642385633 Loss: 0.4109559176685986\n",
      "W1: 10.26526262706958 W2: 1.812237027776151 b -5.398863408463687 Loss: 0.41095467373317446\n",
      "W1: 10.2659639777343 W2: 1.8123082634003753 b -5.399213822237637 Loss: 0.41095343232610815\n",
      "W1: 10.266664612724108 W2: 1.8123794316993385 b -5.399563884092377 Loss: 0.41095219344200695\n",
      "W1: 10.267364532843652 W2: 1.8124505327377967 b -5.39991359441232 Loss: 0.41095095707549056\n",
      "W1: 10.268063738896526 W2: 1.8125215665804437 b -5.4002629535814 Loss: 0.410949723221191\n",
      "W1: 10.268762231685272 W2: 1.8125925332919113 b -5.40061196198307 Loss: 0.4109484918737519\n",
      "W1: 10.269460012011384 W2: 1.8126634329367688 b -5.400960620000301 Loss: 0.41094726302782997\n",
      "W1: 10.270157080675308 W2: 1.8127342655795236 b -5.401308928015591 Loss: 0.4109460366780933\n",
      "W1: 10.270853438476442 W2: 1.812805031284621 b -5.401656886410956 Loss: 0.4109448128192225\n",
      "W1: 10.27154908621314 W2: 1.8128757301164438 b -5.402004495567937 Loss: 0.4109435914459103\n",
      "W1: 10.272244024682717 W2: 1.8129463621393134 b -5.402351755867596 Loss: 0.41094237255286115\n",
      "W1: 10.27293825468144 W2: 1.813016927417489 b -5.402698667690524 Loss: 0.4109411561347917\n",
      "W1: 10.273631777004542 W2: 1.813087426015168 b -5.403045231416833 Loss: 0.4109399421864307\n",
      "W1: 10.274324592446217 W2: 1.8131578579964858 b -5.403391447426161 Loss: 0.4109387307025188\n",
      "W1: 10.275016701799618 W2: 1.8132282234255164 b -5.403737316097675 Loss: 0.41093752167780867\n",
      "W1: 10.275708105856872 W2: 1.8132985223662714 b -5.4040828378100665 Loss: 0.41093631510706424\n",
      "W1: 10.276398805409064 W2: 1.8133687548827013 b -5.404428012941557 Loss: 0.4109351109850623\n",
      "W1: 10.277088801246254 W2: 1.813438921038695 b -5.404772841869897 Loss: 0.4109339093065911\n",
      "W1: 10.277778094157469 W2: 1.8135090208980793 b -5.4051173249723625 Loss: 0.4109327100664505\n",
      "W1: 10.27846668493071 W2: 1.8135790545246202 b -5.405461462625763 Loss: 0.4109315132594522\n",
      "W1: 10.27915457435295 W2: 1.8136490219820216 b -5.405805255206439 Loss: 0.4109303188804199\n",
      "W1: 10.279841763210136 W2: 1.8137189233339264 b -5.40614870309026 Loss: 0.41092912692418887\n",
      "W1: 10.280528252287196 W2: 1.8137887586439159 b -5.406491806652629 Loss: 0.410927937385606\n",
      "W1: 10.281214042368031 W2: 1.8138585279755104 b -5.406834566268482 Loss: 0.4109267502595302\n",
      "W1: 10.281899134235527 W2: 1.8139282313921687 b -5.407176982312287 Loss: 0.41092556554083154\n",
      "W1: 10.282583528671548 W2: 1.8139978689572884 b -5.4075190551580485 Loss: 0.4109243832243921\n",
      "W1: 10.283267226456944 W2: 1.8140674407342061 b -5.407860785179303 Loss: 0.41092320330510523\n",
      "W1: 10.283950228371546 W2: 1.814136946786197 b -5.408202172749126 Loss: 0.41092202577787623\n",
      "W1: 10.284632535194175 W2: 1.8142063871764758 b -5.408543218240126 Loss: 0.4109208506376216\n",
      "W1: 10.285314147702639 W2: 1.8142757619681955 b -5.408883922024451 Loss: 0.41091967787926936\n",
      "W1: 10.285995066673735 W2: 1.8143450712244489 b -5.409224284473785 Loss: 0.4109185074977592\n",
      "W1: 10.28667529288325 W2: 1.8144143150082674 b -5.409564305959351 Loss: 0.4109173394880423\n",
      "W1: 10.287354827105968 W2: 1.814483493382622 b -5.409903986851911 Loss: 0.41091617384508083\n",
      "W1: 10.288033670115663 W2: 1.8145526064104225 b -5.4102433275217665 Loss: 0.4109150105638488\n",
      "W1: 10.288711822685105 W2: 1.8146216541545181 b -5.4105823283387595 Loss: 0.41091384963933153\n",
      "W1: 10.289389285586065 W2: 1.8146906366776976 b -5.410920989672273 Loss: 0.4109126910665253\n",
      "W1: 10.29006605958931 W2: 1.8147595540426888 b -5.411259311891232 Loss: 0.4109115348404382\n",
      "W1: 10.29074214546461 W2: 1.8148284063121594 b -5.411597295364104 Loss: 0.4109103809560892\n",
      "W1: 10.291417543980737 W2: 1.814897193548716 b -5.411934940458899 Loss: 0.41090922940850894\n",
      "W1: 10.292092255905462 W2: 1.8149659158149052 b -5.412272247543171 Loss: 0.4109080801927388\n",
      "W1: 10.292766282005568 W2: 1.815034573173213 b -5.412609216984018 Loss: 0.4109069333038318\n",
      "W1: 10.293439623046842 W2: 1.815103165686065 b -5.412945849148085 Loss: 0.4109057887368515\n",
      "W1: 10.294112279794078 W2: 1.8151716934158268 b -5.41328214440156 Loss: 0.4109046464868735\n",
      "W1: 10.294784253011082 W2: 1.8152401564248035 b -5.4136181031101795 Loss: 0.410903506548984\n",
      "W1: 10.295455543460672 W2: 1.81530855477524 b -5.413953725639226 Loss: 0.4109023689182802\n",
      "W1: 10.296126151904678 W2: 1.8153768885293209 b -5.414289012353532 Loss: 0.41090123358987024\n",
      "W1: 10.296796079103945 W2: 1.8154451577491713 b -5.414623963617475 Loss: 0.41090010055887394\n",
      "W1: 10.297465325818335 W2: 1.8155133624968556 b -5.414958579794985 Loss: 0.41089896982042173\n",
      "W1: 10.298133892806725 W2: 1.8155815028343785 b -5.415292861249539 Loss: 0.4108978413696549\n",
      "W1: 10.298801780827015 W2: 1.8156495788236848 b -5.415626808344167 Loss: 0.41089671520172577\n",
      "W1: 10.299468990636123 W2: 1.8157175905266596 b -5.415960421441449 Loss: 0.4108955913117979\n",
      "W1: 10.300135522989992 W2: 1.8157855380051278 b -5.416293700903516 Loss: 0.41089446969504523\n",
      "W1: 10.300801378643586 W2: 1.8158534213208546 b -5.416626647092053 Loss: 0.410893350346653\n",
      "W1: 10.301466558350894 W2: 1.8159212405355456 b -5.416959260368296 Loss: 0.41089223326181706\n",
      "W1: 10.302131062864937 W2: 1.8159889957108468 b -5.417291541093037 Loss: 0.4108911184357443\n",
      "W1: 10.30279489293776 W2: 1.8160566869083443 b -5.417623489626621 Loss: 0.4108900058636518\n",
      "W1: 10.303458049320438 W2: 1.816124314189565 b -5.417955106328949 Loss: 0.4108888955407685\n",
      "W1: 10.304120532763081 W2: 1.8161918776159762 b -5.418286391559478 Loss: 0.4108877874623331\n",
      "W1: 10.304782344014827 W2: 1.8162593772489855 b -5.41861734567722 Loss: 0.4108866816235956\n",
      "W1: 10.305443483823852 W2: 1.816326813149941 b -5.4189479690407465 Loss: 0.41088557801981623\n",
      "W1: 10.306103952937368 W2: 1.816394185380132 b -5.419278262008183 Loss: 0.4108844766462662\n",
      "W1: 10.306763752101624 W2: 1.816461494000788 b -5.419608224937217 Loss: 0.4108833774982274\n",
      "W1: 10.307422882061905 W2: 1.8165287390730793 b -5.419937858185092 Loss: 0.41088228057099213\n",
      "W1: 10.308081343562542 W2: 1.8165959206581175 b -5.420267162108614 Loss: 0.41088118585986316\n",
      "W1: 10.308739137346905 W2: 1.8166630388169545 b -5.4205961370641464 Loss: 0.4108800933601545\n",
      "W1: 10.309396264157405 W2: 1.8167300936105832 b -5.420924783407616 Loss: 0.41087900306718966\n",
      "W1: 10.310052724735502 W2: 1.8167970850999378 b -5.421253101494512 Loss: 0.4108779149763037\n",
      "W1: 10.310708519821704 W2: 1.816864013345893 b -5.421581091679881 Loss: 0.41087682908284134\n",
      "W1: 10.311363650155561 W2: 1.816930878409265 b -5.421908754318338 Loss: 0.4108757453821584\n",
      "W1: 10.312018116475675 W2: 1.816997680350811 b -5.422236089764057 Loss: 0.4108746638696207\n",
      "W1: 10.312671919519701 W2: 1.817064419231229 b -5.422563098370781 Loss: 0.4108735845406045\n",
      "W1: 10.313325060024345 W2: 1.817131095111159 b -5.422889780491813 Loss: 0.4108725073904966\n",
      "W1: 10.313977538725366 W2: 1.8171977080511814 b -5.423216136480025 Loss: 0.41087143241469426\n",
      "W1: 10.314629356357578 W2: 1.8172642581118184 b -5.423542166687852 Loss: 0.4108703596086048\n",
      "W1: 10.315280513654855 W2: 1.8173307453535334 b -5.423867871467299 Loss: 0.41086928896764596\n",
      "W1: 10.315931011350125 W2: 1.8173971698367317 b -5.424193251169935 Loss: 0.41086822048724586\n",
      "W1: 10.316580850175379 W2: 1.8174635316217596 b -5.424518306146901 Loss: 0.41086715416284253\n",
      "W1: 10.317230030861666 W2: 1.8175298307689047 b -5.424843036748903 Loss: 0.41086608998988494\n",
      "W1: 10.317878554139101 W2: 1.8175960673383968 b -5.425167443326218 Loss: 0.4108650279638315\n",
      "W1: 10.31852642073686 W2: 1.8176622413904073 b -5.425491526228692 Loss: 0.4108639680801512\n",
      "W1: 10.319173631383189 W2: 1.8177283529850488 b -5.425815285805742 Loss: 0.4108629103343231\n",
      "W1: 10.319820186805394 W2: 1.817794402182376 b -5.426138722406356 Loss: 0.41086185472183645\n",
      "W1: 10.320466087729857 W2: 1.8178603890423852 b -5.426461836379095 Loss: 0.4108608012381907\n",
      "W1: 10.321111334882024 W2: 1.8179263136250148 b -5.426784628072089 Loss: 0.41085974987889495\n",
      "W1: 10.321755928986416 W2: 1.8179921759901447 b -5.427107097833045 Loss: 0.41085870063946894\n",
      "W1: 10.322399870766626 W2: 1.8180579761975972 b -5.427429246009242 Loss: 0.4108576535154421\n",
      "W1: 10.323043160945318 W2: 1.8181237143071363 b -5.427751072947533 Loss: 0.4108566085023538\n",
      "W1: 10.323685800244235 W2: 1.8181893903784683 b -5.428072578994345 Loss: 0.41085556559575376\n",
      "W1: 10.324327789384196 W2: 1.818255004471241 b -5.428393764495683 Loss: 0.4108545247912014\n",
      "W1: 10.3249691290851 W2: 1.8183205566450455 b -5.428714629797126 Loss: 0.41085348608426603\n",
      "W1: 10.325609820065923 W2: 1.818386046959414 b -5.42903517524383 Loss: 0.410852449470527\n",
      "W1: 10.326249863044723 W2: 1.8184514754738215 b -5.42935540118053 Loss: 0.41085141494557365\n",
      "W1: 10.326889258738642 W2: 1.818516842247685 b -5.429675307951537 Loss: 0.410850382505005\n",
      "W1: 10.327528007863906 W2: 1.8185821473403643 b -5.429994895900741 Loss: 0.4108493521444301\n",
      "W1: 10.328166111135825 W2: 1.8186473908111613 b -5.430314165371612 Loss: 0.41084832385946746\n",
      "W1: 10.328803569268798 W2: 1.8187125727193205 b -5.430633116707199 Loss: 0.41084729764574573\n",
      "W1: 10.32944038297631 W2: 1.8187776931240287 b -5.430951750250132 Loss: 0.4108462734989033\n",
      "W1: 10.330076552970938 W2: 1.8188427520844155 b -5.431270066342621 Loss: 0.4108452514145883\n",
      "W1: 10.330712079964348 W2: 1.8189077496595532 b -5.431588065326459 Loss: 0.4108442313884584\n",
      "W1: 10.3313469646673 W2: 1.8189726859084563 b -5.431905747543022 Loss: 0.41084321341618113\n",
      "W1: 10.331981207789648 W2: 1.8190375608900826 b -5.432223113333266 Loss: 0.41084219749343376\n",
      "W1: 10.33261481004034 W2: 1.8191023746633326 b -5.432540163037732 Loss: 0.41084118361590305\n",
      "W1: 10.333247772127423 W2: 1.819167127287049 b -5.4328568969965465 Loss: 0.41084017177928556\n",
      "W1: 10.33388009475804 W2: 1.8192318188200183 b -5.433173315549418 Loss: 0.41083916197928727\n",
      "W1: 10.334511778638433 W2: 1.8192964493209693 b -5.4334894190356415 Loss: 0.4108381542116239\n",
      "W1: 10.335142824473948 W2: 1.819361018848574 b -5.433805207794099 Loss: 0.4108371484720206\n",
      "W1: 10.33577323296903 W2: 1.8194255274614475 b -5.434120682163257 Loss: 0.41083614475621244\n",
      "W1: 10.336403004827229 W2: 1.8194899752181477 b -5.43443584248117 Loss: 0.4108351430599434\n",
      "W1: 10.337032140751202 W2: 1.819554362177176 b -5.43475068908548 Loss: 0.41083414337896734\n",
      "W1: 10.337660641442707 W2: 1.8196186883969765 b -5.435065222313419 Loss: 0.41083314570904766\n",
      "W1: 10.338288507602615 W2: 1.8196829539359372 b -5.435379442501804 Loss: 0.410832150045957\n",
      "W1: 10.338915739930904 W2: 1.819747158852389 b -5.435693349987045 Loss: 0.41083115638547746\n",
      "W1: 10.339542339126663 W2: 1.8198113032046062 b -5.436006945105142 Loss: 0.41083016472340045\n",
      "W1: 10.340168305888092 W2: 1.8198753870508064 b -5.436320228191682 Loss: 0.41082917505552713\n",
      "W1: 10.340793640912505 W2: 1.8199394104491509 b -5.4366331995818475 Loss: 0.4108281873776679\n",
      "W1: 10.34141834489633 W2: 1.820003373457744 b -5.436945859610411 Loss: 0.41082720168564196\n",
      "W1: 10.34204241853511 W2: 1.8200672761346344 b -5.437258208611737 Loss: 0.41082621797527863\n",
      "W1: 10.342665862523509 W2: 1.8201311185378135 b -5.437570246919783 Loss: 0.4108252362424158\n",
      "W1: 10.343288677555305 W2: 1.820194900725217 b -5.437881974868102 Loss: 0.4108242564829013\n",
      "W1: 10.3439108643234 W2: 1.8202586227547237 b -5.438193392789839 Loss: 0.41082327869259144\n",
      "W1: 10.344532423519812 W2: 1.820322284684157 b -5.438504501017735 Loss: 0.4108223028673528\n",
      "W1: 10.345153355835688 W2: 1.8203858865712832 b -5.4388152998841255 Loss: 0.41082132900306\n",
      "W1: 10.345773661961294 W2: 1.820449428473813 b -5.4391257897209435 Loss: 0.41082035709559767\n",
      "W1: 10.346393342586024 W2: 1.8205129104494011 b -5.439435970859717 Loss: 0.41081938714085914\n",
      "W1: 10.3470123983984 W2: 1.8205763325556457 b -5.43974584363157 Loss: 0.4108184191347473\n",
      "W1: 10.347630830086066 W2: 1.8206396948500891 b -5.440055408367228 Loss: 0.41081745307317363\n",
      "W1: 10.348248638335802 W2: 1.8207029973902182 b -5.440364665397012 Loss: 0.4108164889520591\n",
      "W1: 10.348865823833515 W2: 1.8207662402334635 b -5.440673615050843 Loss: 0.4108155267673338\n",
      "W1: 10.349482387264244 W2: 1.8208294234371996 b -5.44098225765824 Loss: 0.41081456651493653\n",
      "W1: 10.350098329312162 W2: 1.8208925470587456 b -5.441290593548322 Loss: 0.4108136081908152\n",
      "W1: 10.350713650660579 W2: 1.8209556111553646 b -5.441598623049812 Loss: 0.41081265179092713\n",
      "W1: 10.351328351991937 W2: 1.8210186157842645 b -5.441906346491029 Loss: 0.41081169731123807\n",
      "W1: 10.351942433987817 W2: 1.8210815610025972 b -5.442213764199899 Loss: 0.4108107447477229\n",
      "W1: 10.352555897328939 W2: 1.821144446867459 b -5.442520876503945 Loss: 0.41080979409636575\n",
      "W1: 10.35316874269516 W2: 1.8212072734358906 b -5.442827683730298 Loss: 0.4108088453531593\n",
      "W1: 10.353780970765484 W2: 1.8212700407648776 b -5.443134186205688 Loss: 0.4108078985141054\n",
      "W1: 10.354392582218052 W2: 1.8213327489113498 b -5.443440384256452 Loss: 0.4108069535752145\n",
      "W1: 10.355003577730152 W2: 1.8213953979321817 b -5.443746278208532 Loss: 0.41080601053250604\n",
      "W1: 10.355613957978212 W2: 1.8214579878841928 b -5.444051868387472 Loss: 0.4108050693820085\n",
      "W1: 10.356223723637815 W2: 1.8215205188241468 b -5.444357155118424 Loss: 0.4108041301197588\n",
      "W1: 10.356832875383684 W2: 1.8215829908087524 b -5.444662138726146 Loss: 0.4108031927418029\n",
      "W1: 10.357441413889696 W2: 1.8216454038946632 b -5.444966819535003 Loss: 0.4108022572441954\n",
      "W1: 10.358049339828872 W2: 1.8217077581384777 b -5.445271197868967 Loss: 0.41080132362299976\n",
      "W1: 10.358656653873393 W2: 1.8217700535967392 b -5.445575274051618 Loss: 0.41080039187428824\n",
      "W1: 10.359263356694585 W2: 1.8218322903259359 b -5.445879048406144 Loss: 0.41079946199414147\n",
      "W1: 10.359869448962934 W2: 1.8218944683825014 b -5.446182521255343 Loss: 0.4107985339786492\n",
      "W1: 10.360474931348078 W2: 1.8219565878228139 b -5.446485692921624 Loss: 0.4107976078239097\n",
      "W1: 10.361079804518813 W2: 1.822018648703197 b -5.4467885637270035 Loss: 0.41079668352602955\n",
      "W1: 10.361684069143092 W2: 1.8220806510799197 b -5.44709113399311 Loss: 0.4107957610811244\n",
      "W1: 10.362287725888027 W2: 1.8221425950091958 b -5.4473934040411836 Loss: 0.4107948404853184\n",
      "W1: 10.362890775419894 W2: 1.8222044805471846 b -5.447695374192076 Loss: 0.41079392173474416\n",
      "W1: 10.363493218404127 W2: 1.8222663077499905 b -5.447997044766251 Loss: 0.41079300482554293\n",
      "W1: 10.364095055505322 W2: 1.8223280766736636 b -5.448298416083786 Loss: 0.41079208975386466\n",
      "W1: 10.364696287387243 W2: 1.8223897873741992 b -5.448599488464373 Loss: 0.4107911765158674\n",
      "W1: 10.365296914712818 W2: 1.8224514399075382 b -5.448900262227315 Loss: 0.4107902651077181\n",
      "W1: 10.365896938144143 W2: 1.822513034329567 b -5.449200737691532 Loss: 0.41078935552559204\n",
      "W1: 10.366496358342479 W2: 1.8225745706961176 b -5.44950091517556 Loss: 0.410788447765673\n",
      "W1: 10.367095175968258 W2: 1.8226360490629676 b -5.449800794997548 Loss: 0.4107875418241532\n",
      "W1: 10.367693391681083 W2: 1.8226974694858404 b -5.450100377475264 Loss: 0.4107866376972334\n",
      "W1: 10.36829100613973 W2: 1.822758832020405 b -5.450399662926092 Loss: 0.4107857353811225\n",
      "W1: 10.368888020002144 W2: 1.8228201367222758 b -5.450698651667032 Loss: 0.41078483487203776\n",
      "W1: 10.369484433925448 W2: 1.8228813836470141 b -5.450997344014705 Loss: 0.4107839361662053\n",
      "W1: 10.370080248565941 W2: 1.822942572850126 b -5.451295740285347 Loss: 0.4107830392598589\n",
      "W1: 10.370675464579096 W2: 1.8230037043870642 b -5.451593840794815 Loss: 0.4107821441492415\n",
      "W1: 10.371270082619565 W2: 1.823064778313227 b -5.451891645858585 Loss: 0.4107812508306034\n",
      "W1: 10.371864103341183 W2: 1.823125794683959 b -5.452189155791754 Loss: 0.4107803593002038\n",
      "W1: 10.372457527396959 W2: 1.8231867535545505 b -5.45248637090904 Loss: 0.41077946955430994\n",
      "W1: 10.373050355439087 W2: 1.8232476549802383 b -5.45278329152478 Loss: 0.41077858158919756\n",
      "W1: 10.373642588118946 W2: 1.8233084990162054 b -5.453079917952934 Loss: 0.41077769540115044\n",
      "W1: 10.374234226087095 W2: 1.823369285717581 b -5.453376250507086 Loss: 0.4107768109864603\n",
      "W1: 10.374825269993282 W2: 1.8234300151394403 b -5.45367228950044 Loss: 0.41077592834142745\n",
      "W1: 10.37541572048644 W2: 1.823490687336805 b -5.453968035245824 Loss: 0.4107750474623603\n",
      "W1: 10.376005578214691 W2: 1.8235513023646435 b -5.454263488055691 Loss: 0.41077416834557534\n",
      "W1: 10.376594843825345 W2: 1.82361186027787 b -5.454558648242119 Loss: 0.4107732909873969\n",
      "W1: 10.377183517964902 W2: 1.8236723611313457 b -5.454853516116809 Loss: 0.4107724153841582\n",
      "W1: 10.377771601279054 W2: 1.823732804979878 b -5.455148091991089 Loss: 0.4107715415321996\n",
      "W1: 10.378359094412687 W2: 1.8237931918782213 b -5.455442376175911 Loss: 0.4107706694278702\n",
      "W1: 10.378945998009879 W2: 1.8238535218810763 b -5.455736368981857 Loss: 0.410769799067527\n",
      "W1: 10.379532312713906 W2: 1.8239137950430904 b -5.456030070719134 Loss: 0.4107689304475348\n",
      "W1: 10.380118039167236 W2: 1.8239740114188576 b -5.456323481697575 Loss: 0.41076806356426654\n",
      "W1: 10.380703178011538 W2: 1.824034171062919 b -5.456616602226645 Loss: 0.4107671984141033\n",
      "W1: 10.38128772988768 W2: 1.8240942740297625 b -5.456909432615434 Loss: 0.4107663349934342\n",
      "W1: 10.381871695435725 W2: 1.8241543203738229 b -5.457201973172663 Loss: 0.4107654732986558\n",
      "W1: 10.382455075294946 W2: 1.8242143101494814 b -5.457494224206683 Loss: 0.4107646133261733\n",
      "W1: 10.38303787010381 W2: 1.8242742434110668 b -5.4577861860254755 Loss: 0.4107637550723991\n",
      "W1: 10.383620080499991 W2: 1.824334120212855 b -5.458077858936651 Loss: 0.4107628985337543\n",
      "W1: 10.38420170712037 W2: 1.8243939406090681 b -5.4583692432474535 Loss: 0.41076204370666697\n",
      "W1: 10.38478275060103 W2: 1.8244537046538762 b -5.458660339264757 Loss: 0.41076119058757393\n",
      "W1: 10.385363211577262 W2: 1.8245134124013964 b -5.4589511472950685 Loss: 0.4107603391729191\n",
      "W1: 10.385943090683568 W2: 1.8245730639056927 b -5.459241667644529 Loss: 0.4107594894591548\n",
      "W1: 10.386522388553658 W2: 1.8246326592207769 b -5.459531900618911 Loss: 0.41075864144274077\n",
      "W1: 10.38710110582045 W2: 1.8246921984006075 b -5.459821846523623 Loss: 0.41075779512014493\n",
      "W1: 10.387679243116077 W2: 1.824751681499091 b -5.460111505663705 Loss: 0.41075695048784233\n",
      "W1: 10.388256801071885 W2: 1.8248111085700807 b -5.460400878343835 Loss: 0.41075610754231656\n",
      "W1: 10.388833780318432 W2: 1.8248704796673778 b -5.460689964868324 Loss: 0.4107552662800584\n",
      "W1: 10.389410181485493 W2: 1.824929794844731 b -5.460978765541122 Loss: 0.41075442669756634\n",
      "W1: 10.38998600520206 W2: 1.8249890541558365 b -5.461267280665812 Loss: 0.410753588791347\n",
      "W1: 10.39056125209634 W2: 1.8250482576543379 b -5.461555510545616 Loss: 0.41075275255791427\n",
      "W1: 10.391135922795764 W2: 1.8251074053938268 b -5.461843455483393 Loss: 0.41075191799378974\n",
      "W1: 10.391710017926977 W2: 1.8251664974278425 b -5.4621311157816415 Loss: 0.4107510850955029\n",
      "W1: 10.392283538115851 W2: 1.825225533809872 b -5.462418491742495 Loss: 0.41075025385959063\n",
      "W1: 10.392856483987476 W2: 1.8252845145933496 b -5.462705583667731 Loss: 0.4107494242825976\n",
      "W1: 10.393428856166166 W2: 1.8253434398316584 b -5.462992391858761 Loss: 0.4107485963610759\n",
      "W1: 10.39400065527546 W2: 1.8254023095781287 b -5.463278916616642 Loss: 0.41074777009158525\n",
      "W1: 10.394571881938127 W2: 1.825461123886039 b -5.4635651582420675 Loss: 0.41074694547069296\n",
      "W1: 10.395142536776158 W2: 1.825519882808616 b -5.463851117035373 Loss: 0.4107461224949736\n",
      "W1: 10.395712620410771 W2: 1.8255785863990344 b -5.464136793296538 Loss: 0.41074530116100977\n",
      "W1: 10.39628213346242 W2: 1.8256372347104166 b -5.46442218732518 Loss: 0.41074448146539133\n",
      "W1: 10.396851076550782 W2: 1.8256958277958335 b -5.464707299420563 Loss: 0.4107436634047153\n",
      "W1: 10.39741945029477 W2: 1.8257543657083042 b -5.464992129881591 Loss: 0.41074284697558683\n",
      "W1: 10.397987255312529 W2: 1.8258128485007958 b -5.4652766790068155 Loss: 0.4107420321746179\n",
      "W1: 10.398554492221438 W2: 1.8258712762262244 b -5.465560947094428 Loss: 0.41074121899842814\n",
      "W1: 10.399121161638108 W2: 1.8259296489374535 b -5.4658449344422655 Loss: 0.4107404074436449\n",
      "W1: 10.39968726417839 W2: 1.8259879666872956 b -5.4661286413478125 Loss: 0.4107395975069023\n",
      "W1: 10.40025280045737 W2: 1.8260462295285116 b -5.4664120681081965 Loss: 0.4107387891848424\n",
      "W1: 10.400817771089372 W2: 1.826104437513811 b -5.466695215020192 Loss: 0.41073798247411425\n",
      "W1: 10.401382176687962 W2: 1.8261625906958514 b -5.466978082380221 Loss: 0.41073717737137466\n",
      "W1: 10.401946017865946 W2: 1.8262206891272394 b -5.46726067048435 Loss: 0.41073637387328715\n",
      "W1: 10.402509295235369 W2: 1.82627873286053 b -5.467542979628297 Loss: 0.4107355719765231\n",
      "W1: 10.403072009407522 W2: 1.8263367219482272 b -5.467825010107424 Loss: 0.410734771677761\n",
      "W1: 10.403634160992937 W2: 1.826394656442783 b -5.468106762216744 Loss: 0.4107339729736866\n",
      "W1: 10.404195750601394 W2: 1.8264525363965993 b -5.468388236250918 Loss: 0.4107331758609927\n",
      "W1: 10.404756778841918 W2: 1.826510361862026 b -5.468669432504259 Loss: 0.41073238033637977\n",
      "W1: 10.405317246322781 W2: 1.8265681328913623 b -5.468950351270727 Loss: 0.4107315863965551\n",
      "W1: 10.405877153651504 W2: 1.8266258495368561 b -5.469230992843933 Loss: 0.4107307940382335\n",
      "W1: 10.406436501434857 W2: 1.8266835118507045 b -5.469511357517141 Loss: 0.41073000325813686\n",
      "W1: 10.406995290278862 W2: 1.8267411198850534 b -5.469791445583264 Loss: 0.41072921405299395\n",
      "W1: 10.407553520788792 W2: 1.8267986736919979 b -5.47007125733487 Loss: 0.41072842641954127\n",
      "W1: 10.40811119356917 W2: 1.8268561733235822 b -5.470350793064175 Loss: 0.410727640354522\n",
      "W1: 10.408668309223778 W2: 1.8269136188317996 b -5.4706300530630525 Loss: 0.41072685585468655\n",
      "W1: 10.409224868355649 W2: 1.8269710102685928 b -5.470909037623028 Loss: 0.4107260729167926\n",
      "W1: 10.409780871567074 W2: 1.8270283476858535 b -5.471187747035279 Loss: 0.4107252915376046\n",
      "W1: 10.410336319459603 W2: 1.8270856311354233 b -5.471466181590641 Loss: 0.41072451171389446\n",
      "W1: 10.410891212634041 W2: 1.8271428606690925 b -5.471744341579601 Loss: 0.4107237334424408\n",
      "W1: 10.411445551690456 W2: 1.8272000363386012 b -5.472022227292304 Loss: 0.41072295672002956\n",
      "W1: 10.41199933722817 W2: 1.8272571581956387 b -5.472299839018548 Loss: 0.41072218154345363\n",
      "W1: 10.412552569845776 W2: 1.827314226291844 b -5.472577177047792 Loss: 0.41072140790951256\n",
      "W1: 10.41310525014112 W2: 1.8273712406788056 b -5.472854241669146 Loss: 0.4107206358150133\n",
      "W1: 10.41365737871132 W2: 1.8274282014080618 b -5.473131033171382 Loss: 0.4107198652567697\n",
      "W1: 10.414208956152756 W2: 1.8274851085311001 b -5.473407551842927 Loss: 0.4107190962316025\n",
      "W1: 10.414759983061069 W2: 1.8275419620993583 b -5.4736837979718675 Loss: 0.4107183287363396\n",
      "W1: 10.415310460031176 W2: 1.8275987621642233 b -5.47395977184595 Loss: 0.41071756276781524\n",
      "W1: 10.415860387657254 W2: 1.8276555087770325 b -5.474235473752577 Loss: 0.4107167983228711\n",
      "W1: 10.416409766532755 W2: 1.8277122019890726 b -5.474510903978813 Loss: 0.41071603539835577\n",
      "W1: 10.4169585972504 W2: 1.8277688418515803 b -5.474786062811383 Loss: 0.4107152739911244\n",
      "W1: 10.417506880402177 W2: 1.8278254284157422 b -5.47506095053667 Loss: 0.4107145140980391\n",
      "W1: 10.418054616579353 W2: 1.8278819617326953 b -5.475335567440721 Loss: 0.410713755715969\n",
      "W1: 10.418601806372463 W2: 1.8279384418535263 b -5.475609913809245 Loss: 0.41071299884178986\n",
      "W1: 10.41914845037132 W2: 1.8279948688292718 b -5.47588398992761 Loss: 0.4107122434723843\n",
      "W1: 10.419694549165012 W2: 1.8280512427109188 b -5.476157796080848 Loss: 0.4107114896046419\n",
      "W1: 10.4202401033419 W2: 1.8281075635494046 b -5.476431332553655 Loss: 0.41071073723545887\n",
      "W1: 10.420785113489629 W2: 1.8281638313956166 b -5.476704599630389 Loss: 0.4107099863617378\n",
      "W1: 10.421329580195117 W2: 1.8282200463003921 b -5.476977597595073 Loss: 0.4107092369803888\n",
      "W1: 10.421873504044566 W2: 1.8282762083145194 b -5.477250326731393 Loss: 0.41070848908832835\n",
      "W1: 10.422416885623456 W2: 1.8283323174887367 b -5.477522787322702 Loss: 0.4107077426824795\n",
      "W1: 10.42295972551655 W2: 1.8283883738737325 b -5.477794979652017 Loss: 0.41070699775977215\n",
      "W1: 10.423502024307897 W2: 1.8284443775201464 b -5.47806690400202 Loss: 0.41070625431714286\n",
      "W1: 10.424043782580824 W2: 1.828500328478568 b -5.478338560655061 Loss: 0.41070551235153485\n",
      "W1: 10.424585000917947 W2: 1.8285562267995372 b -5.478609949893156 Loss: 0.41070477185989823\n",
      "W1: 10.425125679901168 W2: 1.8286120725335453 b -5.4788810719979875 Loss: 0.4107040328391893\n",
      "W1: 10.425665820111673 W2: 1.8286678657310338 b -5.479151927250907 Loss: 0.41070329528637134\n",
      "W1: 10.426205422129941 W2: 1.8287236064423946 b -5.479422515932933 Loss: 0.41070255919841403\n",
      "W1: 10.426744486535739 W2: 1.828779294717971 b -5.479692838324754 Loss: 0.4107018245722937\n",
      "W1: 10.42728301390812 W2: 1.8288349306080567 b -5.479962894706725 Loss: 0.41070109140499333\n",
      "W1: 10.427821004825434 W2: 1.8288905141628962 b -5.480232685358873 Loss: 0.41070035969350266\n",
      "W1: 10.42835845986532 W2: 1.8289460454326851 b -5.480502210560893 Loss: 0.4106996294348173\n",
      "W1: 10.428895379604711 W2: 1.8290015244675697 b -5.480771470592152 Loss: 0.4106989006259401\n",
      "W1: 10.429431764619835 W2: 1.8290569513176476 b -5.481040465731687 Loss: 0.4106981732638802\n",
      "W1: 10.429967615486216 W2: 1.829112326032967 b -5.4813091962582075 Loss: 0.41069744734565283\n",
      "W1: 10.430502932778673 W2: 1.8291676486635273 b -5.481577662450093 Loss: 0.41069672286828074\n",
      "W1: 10.431037717071323 W2: 1.8292229192592795 b -5.481845864585395 Loss: 0.4106959998287918\n",
      "W1: 10.43157196893758 W2: 1.8292781378701253 b -5.482113802941841 Loss: 0.41069527822422136\n",
      "W1: 10.432105688950163 W2: 1.8293333045459175 b -5.482381477796828 Loss: 0.41069455805161076\n",
      "W1: 10.432638877681084 W2: 1.8293884193364605 b -5.482648889427428 Loss: 0.410693839308008\n",
      "W1: 10.433171535701662 W2: 1.82944348229151 b -5.482916038110386 Loss: 0.41069312199046737\n",
      "W1: 10.433703663582516 W2: 1.8294984934607728 b -5.483182924122124 Loss: 0.4106924060960495\n",
      "W1: 10.43423526189357 W2: 1.829553452893907 b -5.483449547738736 Loss: 0.41069169162182145\n",
      "W1: 10.43476633120405 W2: 1.8296083606405227 b -5.483715909235995 Loss: 0.4106909785648565\n",
      "W1: 10.435296872082493 W2: 1.8296632167501812 b -5.483982008889345 Loss: 0.4106902669222347\n",
      "W1: 10.435826885096738 W2: 1.8297180212723951 b -5.48424784697391 Loss: 0.410689556691042\n",
      "W1: 10.436356370813932 W2: 1.829772774256629 b -5.484513423764491 Loss: 0.4106888478683708\n",
      "W1: 10.436885329800532 W2: 1.8298274757522988 b -5.484778739535562 Loss: 0.41068814045132024\n",
      "W1: 10.437413762622304 W2: 1.8298821258087723 b -5.485043794561279 Loss: 0.410687434436995\n",
      "W1: 10.437941669844326 W2: 1.8299367244753688 b -5.4853085891154745 Loss: 0.41068672982250637\n",
      "W1: 10.438469052030985 W2: 1.8299912718013598 b -5.485573123471658 Loss: 0.4106860266049722\n",
      "W1: 10.438995909745984 W2: 1.830045767835968 b -5.485837397903021 Loss: 0.41068532478151615\n",
      "W1: 10.439522243552334 W2: 1.8301002126283685 b -5.486101412682432 Loss: 0.4106846243492683\n",
      "W1: 10.440048054012367 W2: 1.830154606227688 b -5.48636516808244 Loss: 0.410683925305365\n",
      "W1: 10.440573341687728 W2: 1.8302089486830055 b -5.486628664375274 Loss: 0.4106832276469488\n",
      "W1: 10.441098107139378 W2: 1.8302632400433514 b -5.486891901832846 Loss: 0.4106825313711681\n",
      "W1: 10.441622350927597 W2: 1.8303174803577087 b -5.487154880726744 Loss: 0.41068183647517825\n",
      "W1: 10.442146073611982 W2: 1.8303716696750123 b -5.487417601328244 Loss: 0.41068114295614\n",
      "W1: 10.44266927575145 W2: 1.8304258080441493 b -5.487680063908298 Loss: 0.4106804508112205\n",
      "W1: 10.44319195790424 W2: 1.8304798955139592 b -5.487942268737545 Loss: 0.4106797600375931\n",
      "W1: 10.443714120627911 W2: 1.830533932133233 b -5.488204216086305 Loss: 0.4106790706324372\n",
      "W1: 10.444235764479345 W2: 1.8305879179507147 b -5.488465906224581 Loss: 0.4106783825929387\n",
      "W1: 10.444756890014746 W2: 1.8306418530151005 b -5.488727339422061 Loss: 0.4106776959162886\n",
      "W1: 10.445277497789647 W2: 1.8306957373750388 b -5.488988515948115 Loss: 0.41067701059968525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.4457975883589 W2: 1.8307495710791302 b -5.489249436071801 Loss: 0.41067632664033216\n",
      "W1: 10.446317162276689 W2: 1.8308033541759283 b -5.4895101000618585 Loss: 0.410675644035439\n",
      "W1: 10.446836220096522 W2: 1.830857086713939 b -5.489770508186715 Loss: 0.41067496278222165\n",
      "W1: 10.447354762371237 W2: 1.8309107687416206 b -5.490030660714482 Loss: 0.4106742828779024\n",
      "W1: 10.447872789653001 W2: 1.8309644003073842 b -5.49029055791296 Loss: 0.4106736043197086\n",
      "W1: 10.448390302493312 W2: 1.8310179814595933 b -5.490550200049634 Loss: 0.41067292710487463\n",
      "W1: 10.448907301442997 W2: 1.8310715122465642 b -5.490809587391676 Loss: 0.4106722512306401\n",
      "W1: 10.449423787052217 W2: 1.831124992716566 b -5.4910687202059485 Loss: 0.4106715766942509\n",
      "W1: 10.449939759870466 W2: 1.8311784229178207 b -5.491327598758998 Loss: 0.41067090349295854\n",
      "W1: 10.450455220446571 W2: 1.8312318028985028 b -5.491586223317063 Loss: 0.41067023162402144\n",
      "W1: 10.450970169328697 W2: 1.83128513270674 b -5.49184459414607 Loss: 0.4106695610847026\n",
      "W1: 10.45148460706434 W2: 1.831338412390613 b -5.492102711511633 Loss: 0.4106688918722718\n",
      "W1: 10.45199853420034 W2: 1.8313916419981549 b -5.492360575679058 Loss: 0.4106682239840046\n",
      "W1: 10.452511951282869 W2: 1.8314448215773522 b -5.49261818691334 Loss: 0.41066755741718225\n",
      "W1: 10.45302485885744 W2: 1.8314979511761447 b -5.492875545479166 Loss: 0.41066689216909186\n",
      "W1: 10.453537257468906 W2: 1.8315510308424248 b -5.493132651640912 Loss: 0.4106662282370269\n",
      "W1: 10.45404914766146 W2: 1.8316040606240382 b -5.493389505662647 Loss: 0.4106655656182859\n",
      "W1: 10.454560529978638 W2: 1.831657040568784 b -5.493646107808132 Loss: 0.41066490431017366\n",
      "W1: 10.45507140496332 W2: 1.8317099707244144 b -5.493902458340819 Loss: 0.4106642443100009\n",
      "W1: 10.455581773157727 W2: 1.8317628511386348 b -5.494158557523853 Loss: 0.4106635856150839\n",
      "W1: 10.456091635103423 W2: 1.831815681859104 b -5.494414405620073 Loss: 0.41066292822274497\n",
      "W1: 10.456600991341322 W2: 1.8318684629334343 b -5.494670002892012 Loss: 0.4106622721303118\n",
      "W1: 10.457109842411683 W2: 1.831921194409191 b -5.494925349601895 Loss: 0.41066161733511825\n",
      "W1: 10.457618188854111 W2: 1.8319738763338935 b -5.495180446011644 Loss: 0.41066096383450373\n",
      "W1: 10.458126031207561 W2: 1.8320265087550143 b -5.495435292382873 Loss: 0.4106603116258134\n",
      "W1: 10.458633370010334 W2: 1.8320790917199794 b -5.4956898889768935 Loss: 0.41065966070639826\n",
      "W1: 10.459140205800086 W2: 1.8321316252761686 b -5.495944236054711 Loss: 0.4106590110736148\n",
      "W1: 10.459646539113821 W2: 1.832184109470915 b -5.496198333877028 Loss: 0.41065836272482553\n",
      "W1: 10.460152370487897 W2: 1.8322365443515058 b -5.496452182704243 Loss: 0.41065771565739834\n",
      "W1: 10.460657700458023 W2: 1.832288929965182 b -5.496705782796454 Loss: 0.4106570698687069\n",
      "W1: 10.461162529559262 W2: 1.8323412663591379 b -5.496959134413451 Loss: 0.4106564253561307\n",
      "W1: 10.461666858326033 W2: 1.8323935535805218 b -5.497212237814727 Loss: 0.4106557821170544\n",
      "W1: 10.462170687292112 W2: 1.8324457916764363 b -5.4974650932594695 Loss: 0.4106551401488689\n",
      "W1: 10.462674016990627 W2: 1.8324979806939372 b -5.497717701006566 Loss: 0.4106544994489703\n",
      "W1: 10.46317684795407 W2: 1.8325501206800348 b -5.497970061314604 Loss: 0.4106538600147607\n",
      "W1: 10.463679180714287 W2: 1.832602211681693 b -5.498222174441867 Loss: 0.41065322184364705\n",
      "W1: 10.464181015802485 W2: 1.8326542537458301 b -5.498474040646343 Loss: 0.41065258493304263\n",
      "W1: 10.464682353749229 W2: 1.8327062469193183 b -5.498725660185716 Loss: 0.4106519492803663\n",
      "W1: 10.46518319508445 W2: 1.832758191248984 b -5.498977033317373 Loss: 0.41065131488304174\n",
      "W1: 10.465683540337436 W2: 1.832810086781608 b -5.499228160298401 Loss: 0.4106506817384989\n",
      "W1: 10.466183390036843 W2: 1.8328619335639245 b -5.499479041385588 Loss: 0.4106500498441729\n",
      "W1: 10.466682744710686 W2: 1.832913731642623 b -5.499729676835425 Loss: 0.41064941919750436\n",
      "W1: 10.467181604886349 W2: 1.8329654810643465 b -5.499980066904105 Loss: 0.41064878979593983\n",
      "W1: 10.46767997109058 W2: 1.833017181875693 b -5.500230211847523 Loss: 0.4106481616369307\n",
      "W1: 10.468177843849496 W2: 1.8330688341232146 b -5.500480111921276 Loss: 0.4106475347179343\n",
      "W1: 10.468675223688576 W2: 1.8331204378534178 b -5.500729767380667 Loss: 0.4106469090364135\n",
      "W1: 10.469172111132673 W2: 1.8331719931127637 b -5.500979178480701 Loss: 0.410646284589836\n",
      "W1: 10.469668506706006 W2: 1.8332234999476678 b -5.501228345476088 Loss: 0.41064566137567565\n",
      "W1: 10.470164410932167 W2: 1.8332749584045 b -5.501477268621241 Loss: 0.4106450393914114\n",
      "W1: 10.470659824334117 W2: 1.8333263685295855 b -5.5017259481702805 Loss: 0.41064441863452766\n",
      "W1: 10.471154747434191 W2: 1.8333777303692036 b -5.501974384377031 Loss: 0.41064379910251425\n",
      "W1: 10.471649180754095 W2: 1.8334290439695884 b -5.502222577495023 Loss: 0.4106431807928663\n",
      "W1: 10.472143124814911 W2: 1.8334803093769287 b -5.5024705277774935 Loss: 0.41064256370308444\n",
      "W1: 10.472636580137095 W2: 1.8335315266373686 b -5.502718235477385 Loss: 0.4106419478306749\n",
      "W1: 10.473129547240479 W2: 1.8335826957970063 b -5.502965700847348 Loss: 0.4106413331731485\n",
      "W1: 10.473622026644268 W2: 1.8336338169018953 b -5.50321292413974 Loss: 0.4106407197280222\n",
      "W1: 10.47411401886705 W2: 1.833684889998044 b -5.503459905606628 Loss: 0.41064010749281793\n",
      "W1: 10.474605524426787 W2: 1.8337359151314157 b -5.5037066454997845 Loss: 0.410639496465063\n",
      "W1: 10.475096543840822 W2: 1.8337868923479286 b -5.5039531440706915 Loss: 0.4106388866422899\n",
      "W1: 10.47558707762588 W2: 1.8338378216934563 b -5.504199401570541 Loss: 0.4106382780220368\n",
      "W1: 10.476077126298062 W2: 1.8338887032138274 b -5.504445418250234 Loss: 0.4106376706018466\n",
      "W1: 10.476566690372856 W2: 1.8339395369548253 b -5.50469119436038 Loss: 0.4106370643792678\n",
      "W1: 10.477055770365128 W2: 1.833990322962189 b -5.504936730151299 Loss: 0.4106364593518542\n",
      "W1: 10.477544366789132 W2: 1.8340410612816127 b -5.505182025873024 Loss: 0.41063585551716475\n",
      "W1: 10.478032480158504 W2: 1.8340917519587456 b -5.505427081775296 Loss: 0.41063525287276337\n",
      "W1: 10.478520110986265 W2: 1.8341423950391924 b -5.505671898107568 Loss: 0.41063465141622013\n",
      "W1: 10.479007259784824 W2: 1.8341929905685133 b -5.5059164751190055 Loss: 0.41063405114510904\n",
      "W1: 10.479493927065974 W2: 1.8342435385922236 b -5.506160813058486 Loss: 0.41063345205701013\n",
      "W1: 10.4799801133409 W2: 1.8342940391557943 b -5.506404912174598 Loss: 0.41063285414950834\n",
      "W1: 10.480465819120173 W2: 1.8343444923046517 b -5.5066487727156455 Loss: 0.4106322574201941\n",
      "W1: 10.480951044913754 W2: 1.834394898084178 b -5.506892394929643 Loss: 0.4106316618666623\n",
      "W1: 10.481435791230995 W2: 1.8344452565397107 b -5.507135779064321 Loss: 0.41063106748651373\n",
      "W1: 10.48192005858064 W2: 1.8344955677165429 b -5.507378925367123 Loss: 0.41063047427735405\n",
      "W1: 10.482403847470824 W2: 1.8345458316599232 b -5.507621834085206 Loss: 0.410629882236794\n",
      "W1: 10.482887158409074 W2: 1.8345960484150565 b -5.507864505465443 Loss: 0.41062929136244936\n",
      "W1: 10.483369991902315 W2: 1.834646218027103 b -5.5081069397544224 Loss: 0.4106287016519412\n",
      "W1: 10.483852348456862 W2: 1.834696340541179 b -5.508349137198447 Loss: 0.41062811310289543\n",
      "W1: 10.484334228578431 W2: 1.834746416002356 b -5.508591098043537 Loss: 0.4106275257129435\n",
      "W1: 10.48481563277213 W2: 1.8347964444556624 b -5.508832822535427 Loss: 0.4106269394797213\n",
      "W1: 10.485296561542464 W2: 1.8348464259460815 b -5.509074310919571 Loss: 0.4106263544008703\n",
      "W1: 10.48577701539334 W2: 1.834896360518553 b -5.509315563441137 Loss: 0.41062577047403687\n",
      "W1: 10.486256994828064 W2: 1.834946248217973 b -5.509556580345014 Loss: 0.41062518769687223\n",
      "W1: 10.486736500349338 W2: 1.8349960890891932 b -5.509797361875805 Loss: 0.41062460606703266\n",
      "W1: 10.487215532459267 W2: 1.8350458831770216 b -5.510037908277833 Loss: 0.41062402558217975\n",
      "W1: 10.487694091659357 W2: 1.835095630526222 b -5.510278219795141 Loss: 0.41062344623997993\n",
      "W1: 10.488172178450517 W2: 1.835145331181515 b -5.510518296671489 Loss: 0.41062286803810455\n",
      "W1: 10.488649793333058 W2: 1.8351949851875766 b -5.510758139150358 Loss: 0.41062229097423\n",
      "W1: 10.489126936806699 W2: 1.83524459258904 b -5.5109977474749465 Loss: 0.4106217150460374\n",
      "W1: 10.489603609370558 W2: 1.8352941534304938 b -5.5112371218881755 Loss: 0.41062114025121316\n",
      "W1: 10.490079811523165 W2: 1.8353436677564838 b -5.5114762626326845 Loss: 0.41062056658744855\n",
      "W1: 10.490555543762452 W2: 1.8353931356115119 b -5.511715169950835 Loss: 0.4106199940524395\n",
      "W1: 10.491030806585762 W2: 1.8354425570400361 b -5.511953844084711 Loss: 0.4106194226438875\n",
      "W1: 10.491505600489841 W2: 1.8354919320864713 b -5.512192285276114 Loss: 0.41061885235949824\n",
      "W1: 10.49197992597085 W2: 1.8355412607951886 b -5.512430493766571 Loss: 0.4106182831969826\n",
      "W1: 10.492453783524358 W2: 1.835590543210516 b -5.512668469797331 Loss: 0.41061771515405643\n",
      "W1: 10.492927173645342 W2: 1.8356397793767378 b -5.512906213609366 Loss: 0.4106171482284405\n",
      "W1: 10.493400096828193 W2: 1.8356889693380953 b -5.513143725443369 Loss: 0.41061658241786014\n",
      "W1: 10.493872553566716 W2: 1.8357381131387862 b -5.513381005539758 Loss: 0.4106160177200458\n",
      "W1: 10.494344544354126 W2: 1.8357872108229651 b -5.513618054138675 Loss: 0.41061545413273276\n",
      "W1: 10.494816069683054 W2: 1.8358362624347435 b -5.513854871479985 Loss: 0.4106148916536608\n",
      "W1: 10.495287130045545 W2: 1.8358852680181894 b -5.514091457803279 Loss: 0.41061433028057515\n",
      "W1: 10.495757725933062 W2: 1.8359342276173278 b -5.514327813347872 Loss: 0.4106137700112252\n",
      "W1: 10.496227857836482 W2: 1.8359831412761407 b -5.514563938352805 Loss: 0.4106132108433656\n",
      "W1: 10.496697526246098 W2: 1.836032009038567 b -5.514799833056844 Loss: 0.4106126527747554\n",
      "W1: 10.497166731651626 W2: 1.8360808309485024 b -5.515035497698482 Loss: 0.41061209580315905\n",
      "W1: 10.497635474542196 W2: 1.8361296070498 b -5.515270932515937 Loss: 0.41061153992634497\n",
      "W1: 10.498103755406362 W2: 1.8361783373862701 b -5.5155061377471535 Loss: 0.4106109851420868\n",
      "W1: 10.498571574732095 W2: 1.8362270220016794 b -5.515741113629806 Loss: 0.41061043144816317\n",
      "W1: 10.49903893300679 W2: 1.8362756609397524 b -5.515975860401294 Loss: 0.4106098788423567\n",
      "W1: 10.499505830717263 W2: 1.8363242542441705 b -5.516210378298745 Loss: 0.41060932732245536\n",
      "W1: 10.499972268349753 W2: 1.8363728019585723 b -5.516444667559016 Loss: 0.4106087768862517\n",
      "W1: 10.500438246389923 W2: 1.8364213041265542 b -5.5166787284186904 Loss: 0.41060822753154275\n",
      "W1: 10.500903765322862 W2: 1.8364697607916693 b -5.516912561114084 Loss: 0.4106076792561305\n",
      "W1: 10.501368825633083 W2: 1.8365181719974284 b -5.517146165881238 Loss: 0.4106071320578215\n",
      "W1: 10.501833427804524 W2: 1.8365665377872997 b -5.517379542955926 Loss: 0.4106065859344268\n",
      "W1: 10.502297572320552 W2: 1.8366148582047086 b -5.517612692573651 Loss: 0.4106060408837626\n",
      "W1: 10.502761259663963 W2: 1.8366631332930385 b -5.517845614969645 Loss: 0.4106054969036493\n",
      "W1: 10.503224490316978 W2: 1.8367113630956298 b -5.518078310378874 Loss: 0.4106049539919121\n",
      "W1: 10.503687264761249 W2: 1.8367595476557808 b -5.51831077903603 Loss: 0.4106044121463807\n",
      "W1: 10.50414958347786 W2: 1.8368076870167473 b -5.5185430211755415 Loss: 0.4106038713648896\n",
      "W1: 10.504611446947324 W2: 1.836855781221743 b -5.518775037031567 Loss: 0.41060333164527785\n",
      "W1: 10.505072855649587 W2: 1.836903830313939 b -5.5190068268379955 Loss: 0.4106027929853891\n",
      "W1: 10.505533810064028 W2: 1.8369518343364641 b -5.519238390828451 Loss: 0.41060225538307144\n",
      "W1: 10.505994310669458 W2: 1.8369997933324054 b -5.519469729236289 Loss: 0.4106017188361779\n",
      "W1: 10.50645435794412 W2: 1.837047707344807 b -5.519700842294599 Loss: 0.4106011833425656\n",
      "W1: 10.506913952365698 W2: 1.8370955764166719 b -5.519931730236203 Loss: 0.4106006489000965\n",
      "W1: 10.507373094411307 W2: 1.8371434005909602 b -5.520162393293657 Loss: 0.41060011550663716\n",
      "W1: 10.5078317845575 W2: 1.83719117991059 b -5.520392831699254 Loss: 0.41059958316005873\n",
      "W1: 10.508290023280267 W2: 1.837238914418438 b -5.520623045685017 Loss: 0.41059905185823636\n",
      "W1: 10.508747811055038 W2: 1.8372866041573384 b -5.520853035482709 Loss: 0.41059852159905025\n",
      "W1: 10.509205148356678 W2: 1.8373342491700835 b -5.521082801323825 Loss: 0.410597992380385\n",
      "W1: 10.509662035659495 W2: 1.837381849499424 b -5.521312343439596 Loss: 0.41059746420012966\n",
      "W1: 10.510118473437238 W2: 1.8374294051880686 b -5.52154166206099 Loss: 0.41059693705617767\n",
      "W1: 10.510574462163094 W2: 1.8374769162786844 b -5.521770757418712 Loss: 0.4105964109464269\n",
      "W1: 10.511030002309692 W2: 1.8375243828138963 b -5.521999629743202 Loss: 0.4105958858687801\n",
      "W1: 10.511485094349107 W2: 1.8375718048362877 b -5.522228279264637 Loss: 0.41059536182114387\n",
      "W1: 10.511939738752856 W2: 1.8376191823884005 b -5.522456706212934 Loss: 0.41059483880143\n",
      "W1: 10.5123939359919 W2: 1.837666515512735 b -5.522684910817746 Loss: 0.41059431680755376\n",
      "W1: 10.512847686536647 W2: 1.8377138042517496 b -5.522912893308463 Loss: 0.41059379583743566\n",
      "W1: 10.513300990856948 W2: 1.8377610486478613 b -5.523140653914215 Loss: 0.4105932758890003\n",
      "W1: 10.5137538494221 W2: 1.8378082487434455 b -5.523368192863872 Loss: 0.41059275696017683\n",
      "W1: 10.514206262700851 W2: 1.8378554045808364 b -5.52359551038604 Loss: 0.41059223904889847\n",
      "W1: 10.514658231161395 W2: 1.8379025162023264 b -5.523822606709069 Loss: 0.41059172215310297\n",
      "W1: 10.515109755271375 W2: 1.8379495836501667 b -5.524049482061043 Loss: 0.4105912062707326\n",
      "W1: 10.515560835497885 W2: 1.8379966069665672 b -5.5242761366697914 Loss: 0.41059069139973414\n",
      "W1: 10.516011472307467 W2: 1.8380435861936966 b -5.524502570762881 Loss: 0.41059017753805804\n",
      "W1: 10.516461666166116 W2: 1.8380905213736818 b -5.524728784567622 Loss: 0.41058966468366015\n",
      "W1: 10.516911417539278 W2: 1.8381374125486092 b -5.524954778311064 Loss: 0.4105891528344996\n",
      "W1: 10.517360726891853 W2: 1.8381842597605236 b -5.525180552219998 Loss: 0.4105886419885403\n",
      "W1: 10.517809594688195 W2: 1.8382310630514285 b -5.5254061065209585 Loss: 0.4105881321437506\n",
      "W1: 10.518258021392109 W2: 1.8382778224632867 b -5.525631441440221 Loss: 0.41058762329810305\n",
      "W1: 10.518706007466857 W2: 1.83832453803802 b -5.525856557203804 Loss: 0.41058711544957444\n",
      "W1: 10.519153553375158 W2: 1.8383712098175085 b -5.5260814540374685 Loss: 0.41058660859614604\n",
      "W1: 10.519600659579185 W2: 1.8384178378435918 b -5.526306132166719 Loss: 0.41058610273580276\n",
      "W1: 10.520047326540569 W2: 1.8384644221580688 b -5.526530591816805 Loss: 0.41058559786653465\n",
      "W1: 10.5204935547204 W2: 1.838510962802697 b -5.526754833212717 Loss: 0.4105850939863355\n",
      "W1: 10.520939344579226 W2: 1.8385574598191934 b -5.526978856579193 Loss: 0.4105845910932038\n",
      "W1: 10.521384696577055 W2: 1.8386039132492338 b -5.527202662140713 Loss: 0.41058408918514144\n",
      "W1: 10.521829611173354 W2: 1.8386503231344535 b -5.527426250121504 Loss: 0.4105835882601554\n",
      "W1: 10.522274088827052 W2: 1.8386966895164472 b -5.527649620745537 Loss: 0.4105830883162563\n",
      "W1: 10.522718129996539 W2: 1.8387430124367685 b -5.527872774236529 Loss: 0.4105825893514593\n",
      "W1: 10.523161735139668 W2: 1.8387892919369306 b -5.528095710817943 Loss: 0.41058209136378354\n",
      "W1: 10.523604904713755 W2: 1.838835528058406 b -5.528318430712988 Loss: 0.41058159435125285\n",
      "W1: 10.524047639175581 W2: 1.838881720842627 b -5.52854093414462 Loss: 0.4105810983118945\n",
      "W1: 10.52448993898139 W2: 1.8389278703309844 b -5.528763221335542 Loss: 0.41058060324374035\n",
      "W1: 10.52493180458689 W2: 1.8389739765648294 b -5.528985292508205 Loss: 0.4105801091448264\n",
      "W1: 10.52537323644726 W2: 1.8390200395854726 b -5.529207147884806 Loss: 0.4105796160131929\n",
      "W1: 10.525814235017142 W2: 1.8390660594341837 b -5.529428787687291 Loss: 0.41057912384688394\n",
      "W1: 10.526254800750646 W2: 1.8391120361521924 b -5.529650212137353 Loss: 0.41057863264394795\n",
      "W1: 10.526694934101352 W2: 1.8391579697806884 b -5.529871421456437 Loss: 0.4105781424024375\n",
      "W1: 10.527134635522307 W2: 1.8392038603608203 b -5.530092415865733 Loss: 0.4105776531204091\n",
      "W1: 10.52757390546603 W2: 1.8392497079336971 b -5.5303131955861815 Loss: 0.4105771647959239\n",
      "W1: 10.528012744384508 W2: 1.8392955125403871 b -5.530533760838474 Loss: 0.4105766774270462\n",
      "W1: 10.5284511527292 W2: 1.8393412742219188 b -5.53075411184305 Loss: 0.4105761910118452\n",
      "W1: 10.52888913095104 W2: 1.8393869930192803 b -5.530974248820102 Loss: 0.410575705548394\n",
      "W1: 10.52932667950043 W2: 1.83943266897342 b -5.531194171989569 Loss: 0.41057522103476957\n",
      "W1: 10.529763798827249 W2: 1.8394783021252454 b -5.5314138815711456 Loss: 0.4105747374690532\n",
      "W1: 10.530200489380848 W2: 1.839523892515625 b -5.531633377784273 Loss: 0.4105742548493297\n",
      "W1: 10.530636751610054 W2: 1.8395694401853866 b -5.531852660848148 Loss: 0.41057377317368887\n",
      "W1: 10.531072585963168 W2: 1.8396149451753183 b -5.532071730981717 Loss: 0.4105732924402236\n",
      "W1: 10.53150799288797 W2: 1.8396604075261684 b -5.532290588403679 Loss: 0.4105728126470314\n",
      "W1: 10.531942972831715 W2: 1.839705827278645 b -5.532509233332486 Loss: 0.41057233379221325\n",
      "W1: 10.532377526241135 W2: 1.839751204473417 b -5.532727665986342 Loss: 0.4105718558738749\n",
      "W1: 10.532811653562442 W2: 1.8397965391511129 b -5.532945886583205 Loss: 0.4105713788901255\n",
      "W1: 10.533245355241329 W2: 1.8398418313523215 b -5.5331638953407865 Loss: 0.41057090283907827\n",
      "W1: 10.533678631722966 W2: 1.8398870811175922 b -5.533381692476551 Loss: 0.4105704277188506\n",
      "W1: 10.534111483452001 W2: 1.8399322884874345 b -5.533599278207719 Loss: 0.4105699535275638\n",
      "W1: 10.534543910872571 W2: 1.8399774535023186 b -5.533816652751263 Loss: 0.410569480263343\n",
      "W1: 10.534975914428287 W2: 1.8400225762026745 b -5.534033816323912 Loss: 0.41056900792431744\n",
      "W1: 10.535407494562248 W2: 1.8400676566288934 b -5.534250769142149 Loss: 0.41056853650862024\n",
      "W1: 10.535838651717034 W2: 1.8401126948213264 b -5.534467511422215 Loss: 0.4105680660143884\n",
      "W1: 10.53626938633471 W2: 1.8401576908202855 b -5.5346840433801034 Loss: 0.41056759643976304\n",
      "W1: 10.536699698856827 W2: 1.8402026446660429 b -5.534900365231565 Loss: 0.41056712778288895\n",
      "W1: 10.537129589724417 W2: 1.8402475563988316 b -5.535116477192108 Loss: 0.4105666600419149\n",
      "W1: 10.537559059378003 W2: 1.8402924260588456 b -5.535332379476996 Loss: 0.41056619321499377\n",
      "W1: 10.537988108257593 W2: 1.840337253686239 b -5.53554807230125 Loss: 0.4105657273002821\n",
      "W1: 10.538416736802684 W2: 1.840382039321127 b -5.535763555879647 Loss: 0.41056526229594037\n",
      "W1: 10.53884494545226 W2: 1.8404267830035852 b -5.535978830426726 Loss: 0.4105647982001331\n",
      "W1: 10.539272734644792 W2: 1.8404714847736505 b -5.536193896156779 Loss: 0.41056433501102824\n",
      "W1: 10.539700104818245 W2: 1.8405161446713203 b -5.536408753283858 Loss: 0.410563872726798\n",
      "W1: 10.540127056410071 W2: 1.8405607627365528 b -5.5366234020217755 Loss: 0.41056341134561847\n",
      "W1: 10.540553589857215 W2: 1.8406053390092674 b -5.5368378425841005 Loss: 0.4105629508656692\n",
      "W1: 10.540979705596113 W2: 1.8406498735293442 b -5.537052075184162 Loss: 0.41056249128513417\n",
      "W1: 10.541405404062695 W2: 1.8406943663366244 b -5.5372661000350485 Loss: 0.41056203260220026\n",
      "W1: 10.541830685692382 W2: 1.8407388174709105 b -5.537479917349609 Loss: 0.4105615748150592\n",
      "W1: 10.542255550920089 W2: 1.8407832269719657 b -5.537693527340451 Loss: 0.4105611179219059\n",
      "W1: 10.542680000180226 W2: 1.8408275948795143 b -5.537906930219945 Loss: 0.41056066192093926\n",
      "W1: 10.543104033906701 W2: 1.840871921233242 b -5.53812012620022 Loss: 0.41056020681036165\n",
      "W1: 10.543527652532912 W2: 1.8409162060727957 b -5.538333115493168 Loss: 0.41055975258838\n",
      "W1: 10.54395085649176 W2: 1.8409604494377831 b -5.53854589831044 Loss: 0.410559299253204\n",
      "W1: 10.54437364621564 W2: 1.8410046513677738 b -5.538758474863452 Loss: 0.41055884680304794\n",
      "W1: 10.544796022136444 W2: 1.841048811902298 b -5.538970845363379 Loss: 0.41055839523612947\n",
      "W1: 10.545217984685564 W2: 1.841092931080848 b -5.53918301002116 Loss: 0.4105579445506701\n",
      "W1: 10.545639534293894 W2: 1.8411370089428767 b -5.539394969047496 Loss: 0.41055749474489484\n",
      "W1: 10.546060671391823 W2: 1.841181045527799 b -5.5396067226528505 Loss: 0.41055704581703284\n",
      "W1: 10.546481396409243 W2: 1.841225040874991 b -5.5398182710474515 Loss: 0.4105565977653167\n",
      "W1: 10.546901709775549 W2: 1.8412689950237904 b -5.54002961444129 Loss: 0.4105561505879827\n",
      "W1: 10.547321611919633 W2: 1.8413129080134965 b -5.540240753044121 Loss: 0.41055570428327104\n",
      "W1: 10.547741103269898 W2: 1.8413567798833697 b -5.540451687065463 Loss: 0.4105552588494255\n",
      "W1: 10.548160184254241 W2: 1.8414006106726326 b -5.540662416714601 Loss: 0.4105548142846935\n",
      "W1: 10.548578855300072 W2: 1.8414444004204693 b -5.540872942200582 Loss: 0.41055437058732597\n",
      "W1: 10.548997116834299 W2: 1.8414881491660253 b -5.541083263732219 Loss: 0.41055392775557825\n",
      "W1: 10.549414969283337 W2: 1.841531856948408 b -5.541293381518091 Loss: 0.4105534857877084\n",
      "W1: 10.54983241307311 W2: 1.8415755238066869 b -5.541503295766544 Loss: 0.4105530446819787\n",
      "W1: 10.550249448629046 W2: 1.8416191497798926 b -5.541713006685688 Loss: 0.41055260443665487\n",
      "W1: 10.55066607637608 W2: 1.8416627349070183 b -5.5419225144833995 Loss: 0.4105521650500066\n",
      "W1: 10.551082296738658 W2: 1.8417062792270182 b -5.542131819367321 Loss: 0.4105517265203065\n",
      "W1: 10.551498110140733 W2: 1.8417497827788094 b -5.542340921544864 Loss: 0.4105512888458316\n",
      "W1: 10.551913517005765 W2: 1.84179324560127 b -5.542549821223206 Loss: 0.4105508520248622\n",
      "W1: 10.55232851775673 W2: 1.8418366677332407 b -5.5427585186092925 Loss: 0.41055041605568215\n",
      "W1: 10.552743112816106 W2: 1.841880049213524 b -5.542967013909836 Loss: 0.41054998093657885\n",
      "W1: 10.553157302605891 W2: 1.841923390080885 b -5.5431753073313175 Loss: 0.41054954666584353\n",
      "W1: 10.553571087547592 W2: 1.8419666903740497 b -5.543383399079986 Loss: 0.41054911324177096\n",
      "W1: 10.553984468062227 W2: 1.8420099501317075 b -5.543591289361861 Loss: 0.4105486806626592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.554397444570329 W2: 1.8420531693925093 b -5.543798978382728 Loss: 0.4105482489268102\n",
      "W1: 10.554810017491945 W2: 1.8420963481950683 b -5.544006466348145 Loss: 0.4105478180325294\n",
      "W1: 10.555222187246637 W2: 1.84213948657796 b -5.544213753463438 Loss: 0.4105473879781256\n",
      "W1: 10.55563395425348 W2: 1.8421825845797222 b -5.544420839933704 Loss: 0.4105469587619114\n",
      "W1: 10.556045318931067 W2: 1.842225642238855 b -5.544627725963807 Loss: 0.4105465303822029\n",
      "W1: 10.556456281697509 W2: 1.842268659593821 b -5.5448344117583845 Loss: 0.41054610283731957\n",
      "W1: 10.55686684297043 W2: 1.842311636683045 b -5.545040897521845 Loss: 0.4105456761255844\n",
      "W1: 10.557277003166977 W2: 1.8423545735449143 b -5.545247183458366 Loss: 0.41054525024532396\n",
      "W1: 10.557686762703812 W2: 1.8423974702177788 b -5.5454532697718975 Loss: 0.41054482519486873\n",
      "W1: 10.558096121997117 W2: 1.8424403267399507 b -5.5456591566661615 Loss: 0.4105444009725519\n",
      "W1: 10.558505081462597 W2: 1.8424831431497048 b -5.545864844344652 Loss: 0.41054397757671063\n",
      "W1: 10.558913641515472 W2: 1.8425259194852788 b -5.546070333010635 Loss: 0.4105435550056857\n",
      "W1: 10.559321802570487 W2: 1.8425686557848726 b -5.5462756228671495 Loss: 0.410543133257821\n",
      "W1: 10.559729565041907 W2: 1.842611352086649 b -5.546480714117005 Loss: 0.41054271233146394\n",
      "W1: 10.560136929343523 W2: 1.8426540084287333 b -5.546685606962789 Loss: 0.41054229222496574\n",
      "W1: 10.560543895888644 W2: 1.8426966248492138 b -5.546890301606856 Loss: 0.4105418729366805\n",
      "W1: 10.560950465090105 W2: 1.8427392013861414 b -5.54709479825134 Loss: 0.4105414544649664\n",
      "W1: 10.561356637360268 W2: 1.84278173807753 b -5.547299097098146 Loss: 0.4105410368081845\n",
      "W1: 10.561762413111014 W2: 1.842824234961356 b -5.547503198348954 Loss: 0.41054061996469965\n",
      "W1: 10.562167792753755 W2: 1.8428666920755588 b -5.547707102205219 Loss: 0.41054020393288\n",
      "W1: 10.562572776699428 W2: 1.842909109458041 b -5.547910808868171 Loss: 0.41053978871109714\n",
      "W1: 10.562977365358496 W2: 1.842951487146668 b -5.548114318538812 Loss: 0.4105393742977259\n",
      "W1: 10.56338155914095 W2: 1.842993825179268 b -5.548317631417925 Loss: 0.4105389606911448\n",
      "W1: 10.563785358456311 W2: 1.8430361235936323 b -5.548520747706065 Loss: 0.4105385478897357\n",
      "W1: 10.564188763713625 W2: 1.8430783824275156 b -5.548723667603564 Loss: 0.41053813589188337\n",
      "W1: 10.56459177532147 W2: 1.8431206017186355 b -5.5489263913105304 Loss: 0.4105377246959767\n",
      "W1: 10.564994393687952 W2: 1.8431627815046723 b -5.549128919026849 Loss: 0.4105373143004074\n",
      "W1: 10.565396619220712 W2: 1.8432049218232702 b -5.549331250952181 Loss: 0.4105369047035707\n",
      "W1: 10.565798452326918 W2: 1.8432470227120363 b -5.549533387285966 Loss: 0.4105364959038653\n",
      "W1: 10.566199893413273 W2: 1.843289084208541 b -5.549735328227421 Loss: 0.41053608789969315\n",
      "W1: 10.566600942886012 W2: 1.8433311063503177 b -5.549937073975539 Loss: 0.4105356806894594\n",
      "W1: 10.567001601150901 W2: 1.8433730891748634 b -5.550138624729094 Loss: 0.4105352742715729\n",
      "W1: 10.56740186861324 W2: 1.8434150327196386 b -5.550339980686634 Loss: 0.4105348686444454\n",
      "W1: 10.567801745677867 W2: 1.8434569370220668 b -5.550541142046491 Loss: 0.41053446380649206\n",
      "W1: 10.568201232749153 W2: 1.8434988021195353 b -5.550742109006771 Loss: 0.4105340597561317\n",
      "W1: 10.568600330231005 W2: 1.8435406280493947 b -5.550942881765363 Loss: 0.41053365649178625\n",
      "W1: 10.568999038526865 W2: 1.843582414848959 b -5.551143460519932 Loss: 0.4105332540118807\n",
      "W1: 10.569397358039712 W2: 1.8436241625555059 b -5.551343845467926 Loss: 0.4105328523148435\n",
      "W1: 10.569795289172065 W2: 1.8436658712062768 b -5.55154403680657 Loss: 0.4105324513991064\n",
      "W1: 10.570192832325981 W2: 1.8437075408384764 b -5.551744034732872 Loss: 0.4105320512631044\n",
      "W1: 10.570589987903052 W2: 1.8437491714892733 b -5.551943839443619 Loss: 0.41053165190527585\n",
      "W1: 10.570986756304414 W2: 1.8437907631957997 b -5.55214345113538 Loss: 0.41053125332406226\n",
      "W1: 10.57138313793074 W2: 1.8438323159951513 b -5.552342870004503 Loss: 0.4105308555179085\n",
      "W1: 10.571779133182245 W2: 1.843873829924388 b -5.552542096247121 Loss: 0.4105304584852622\n",
      "W1: 10.572174742458685 W2: 1.8439153050205332 b -5.552741130059145 Loss: 0.4105300622245753\n",
      "W1: 10.572569966159358 W2: 1.8439567413205744 b -5.5529399716362695 Loss: 0.4105296667343017\n",
      "W1: 10.572964804683105 W2: 1.8439981388614628 b -5.5531386211739715 Loss: 0.41052927201289946\n",
      "W1: 10.573359258428308 W2: 1.844039497680113 b -5.553337078867511 Loss: 0.4105288780588292\n",
      "W1: 10.573753327792895 W2: 1.8440808178134047 b -5.553535344911929 Loss: 0.4105284848705555\n",
      "W1: 10.574147013174338 W2: 1.8441220992981804 b -5.553733419502052 Loss: 0.41052809244654537\n",
      "W1: 10.574540314969653 W2: 1.8441633421712473 b -5.5539313028324875 Loss: 0.41052770078526957\n",
      "W1: 10.5749332335754 W2: 1.8442045464693764 b -5.554128995097629 Loss: 0.4105273098852015\n",
      "W1: 10.57532576938769 W2: 1.8442457122293028 b -5.554326496491651 Loss: 0.41052691974481836\n",
      "W1: 10.575717922802179 W2: 1.8442868394877259 b -5.554523807208516 Loss: 0.4105265303626004\n",
      "W1: 10.576109694214065 W2: 1.844327928281309 b -5.554720927441967 Loss: 0.4105261417370304\n",
      "W1: 10.5765010840181 W2: 1.8443689786466797 b -5.554917857385536 Loss: 0.41052575386659507\n",
      "W1: 10.576892092608583 W2: 1.8444099906204299 b -5.555114597232535 Loss: 0.4105253667497839\n",
      "W1: 10.577282720379362 W2: 1.8444509642391156 b -5.555311147176066 Loss: 0.4105249803850896\n",
      "W1: 10.577672967723833 W2: 1.8444918995392572 b -5.555507507409013 Loss: 0.4105245947710081\n",
      "W1: 10.578062835034947 W2: 1.8445327965573395 b -5.555703678124048 Loss: 0.4105242099060382\n",
      "W1: 10.5784523227052 W2: 1.8445736553298115 b -5.555899659513628 Loss: 0.41052382578868224\n",
      "W1: 10.578841431126643 W2: 1.844614475893087 b -5.556095451769997 Loss: 0.41052344241744515\n",
      "W1: 10.579230160690878 W2: 1.8446552582835434 b -5.556291055085187 Loss: 0.4105230597908356\n",
      "W1: 10.579618511789063 W2: 1.8446960025375236 b -5.556486469651014 Loss: 0.4105226779073647\n",
      "W1: 10.580006484811904 W2: 1.8447367086913342 b -5.5566816956590825 Loss: 0.41052229676554736\n",
      "W1: 10.580394080149663 W2: 1.844777376781247 b -5.556876733300785 Loss: 0.41052191636390095\n",
      "W1: 10.580781298192157 W2: 1.8448180068434976 b -5.5570715827673025 Loss: 0.4105215367009461\n",
      "W1: 10.58116813932876 W2: 1.8448585989142872 b -5.557266244249601 Loss: 0.41052115777520676\n",
      "W1: 10.581554603948398 W2: 1.8448991530297807 b -5.557460717938437 Loss: 0.41052077958521005\n",
      "W1: 10.581940692439556 W2: 1.8449396692261082 b -5.557655004024356 Loss: 0.41052040212948526\n",
      "W1: 10.582326405190274 W2: 1.8449801475393643 b -5.557849102697691 Loss: 0.4105200254065659\n",
      "W1: 10.58271174258815 W2: 1.8450205880056088 b -5.5580430141485655 Loss: 0.4105196494149878\n",
      "W1: 10.583096705020342 W2: 1.8450609906608657 b -5.55823673856689 Loss: 0.4105192741532902\n",
      "W1: 10.583481292873563 W2: 1.8451013555411242 b -5.558430276142367 Loss: 0.41051889962001487\n",
      "W1: 10.583865506534089 W2: 1.8451416826823384 b -5.558623627064487 Loss: 0.4105185258137071\n",
      "W1: 10.584249346387752 W2: 1.845181972120427 b -5.558816791522533 Loss: 0.4105181527329155\n",
      "W1: 10.584632812819947 W2: 1.8452222238912739 b -5.559009769705576 Loss: 0.41051778037619063\n",
      "W1: 10.585015906215629 W2: 1.8452624380307276 b -5.559202561802479 Loss: 0.41051740874208686\n",
      "W1: 10.585398626959316 W2: 1.845302614574602 b -5.559395168001896 Loss: 0.4105170378291616\n",
      "W1: 10.585780975435085 W2: 1.8453427535586762 b -5.559587588492271 Loss: 0.4105166676359749\n",
      "W1: 10.586162952026578 W2: 1.8453828550186937 b -5.559779823461842 Loss: 0.41051629816109\n",
      "W1: 10.586544557117001 W2: 1.8454229189903637 b -5.559971873098635 Loss: 0.41051592940307297\n",
      "W1: 10.586925791089122 W2: 1.84546294550936 b -5.5601637375904716 Loss: 0.4105155613604932\n",
      "W1: 10.587306654325273 W2: 1.8455029346113223 b -5.560355417124963 Loss: 0.4105151940319225\n",
      "W1: 10.587687147207353 W2: 1.845542886331855 b -5.560546911889515 Loss: 0.41051482741593615\n",
      "W1: 10.588067270116824 W2: 1.8455828007065278 b -5.5607382220713255 Loss: 0.4105144615111121\n",
      "W1: 10.588447023434716 W2: 1.8456226777708757 b -5.560929347857384 Loss: 0.4105140963160314\n",
      "W1: 10.588826407541626 W2: 1.8456625175603991 b -5.5611202894344745 Loss: 0.41051373182927803\n",
      "W1: 10.589205422817718 W2: 1.8457023201105636 b -5.561311046989176 Loss: 0.4105133680494388\n",
      "W1: 10.589584069642724 W2: 1.8457420854568003 b -5.561501620707859 Loss: 0.41051300497510357\n",
      "W1: 10.589962348395943 W2: 1.8457818136345059 b -5.56169201077669 Loss: 0.41051264260486503\n",
      "W1: 10.590340259456244 W2: 1.8458215046790423 b -5.561882217381627 Loss: 0.410512280937319\n",
      "W1: 10.590717803202065 W2: 1.8458611586257367 b -5.562072240708427 Loss: 0.4105119199710638\n",
      "W1: 10.591094980011414 W2: 1.8459007755098824 b -5.562262080942638 Loss: 0.41051155970470093\n",
      "W1: 10.591471790261872 W2: 1.8459403553667377 b -5.562451738269605 Loss: 0.41051120013683506\n",
      "W1: 10.59184823433059 W2: 1.845979898231527 b -5.5626412128744676 Loss: 0.41051084126607323\n",
      "W1: 10.592224312594286 W2: 1.8460194041394398 b -5.562830504942161 Loss: 0.4105104830910257\n",
      "W1: 10.59260002542926 W2: 1.8460588731256315 b -5.563019614657417 Loss: 0.4105101256103054\n",
      "W1: 10.592975373211376 W2: 1.8460983052252233 b -5.563208542204764 Loss: 0.4105097688225284\n",
      "W1: 10.593350356316076 W2: 1.846137700473302 b -5.563397287768526 Loss: 0.4105094127263134\n",
      "W1: 10.593724975118375 W2: 1.84617705890492 b -5.563585851532823 Loss: 0.4105090573202819\n",
      "W1: 10.594099229992864 W2: 1.846216380555096 b -5.563774233681572 Loss: 0.41050870260305866\n",
      "W1: 10.594473121313706 W2: 1.846255665458814 b -5.563962434398491 Loss: 0.41050834857327095\n",
      "W1: 10.594846649454643 W2: 1.8462949136510243 b -5.5641504538670885 Loss: 0.41050799522954906\n",
      "W1: 10.595219814788992 W2: 1.8463341251666425 b -5.564338292270677 Loss: 0.4105076425705258\n",
      "W1: 10.595592617689645 W2: 1.846373300040551 b -5.5645259497923645 Loss: 0.41050729059483737\n",
      "W1: 10.595965058529076 W2: 1.8464124383075973 b -5.5647134266150555 Loss: 0.4105069393011222\n",
      "W1: 10.596337137679333 W2: 1.8464515400025954 b -5.564900722921457 Loss: 0.4105065886880217\n",
      "W1: 10.596708855512043 W2: 1.8464906051603251 b -5.56508783889407 Loss: 0.41050623875418046\n",
      "W1: 10.597080212398412 W2: 1.8465296338155326 b -5.565274774715198 Loss: 0.41050588949824557\n",
      "W1: 10.597451208709227 W2: 1.84656862600293 b -5.565461530566943 Loss: 0.4105055409188669\n",
      "W1: 10.597821844814856 W2: 1.8466075817571952 b -5.5656481066312065 Loss: 0.41050519301469723\n",
      "W1: 10.598192121085244 W2: 1.846646501112973 b -5.565834503089688 Loss: 0.41050484578439206\n",
      "W1: 10.598562037889922 W2: 1.8466853841048736 b -5.566020720123889 Loss: 0.41050449922660964\n",
      "W1: 10.598931595597998 W2: 1.846724230767474 b -5.566206757915111 Loss: 0.41050415334001117\n",
      "W1: 10.599300794578165 W2: 1.8467630411353175 b -5.566392616644455 Loss: 0.41050380812326054\n",
      "W1: 10.599669635198698 W2: 1.8468018152429133 b -5.566578296492823 Loss: 0.41050346357502404\n",
      "W1: 10.600038117827458 W2: 1.8468405531247374 b -5.5667637976409186 Loss: 0.41050311969397146\n",
      "W1: 10.600406242831886 W2: 1.8468792548152315 b -5.566949120269245 Loss: 0.41050277647877453\n",
      "W1: 10.600774010579011 W2: 1.8469179203488046 b -5.56713426455811 Loss: 0.41050243392810865\n",
      "W1: 10.601141421435445 W2: 1.8469565497598315 b -5.5673192306876205 Loss: 0.41050209204065075\n",
      "W1: 10.601508475767385 W2: 1.8469951430826534 b -5.5675040188376865 Loss: 0.4105017508150816\n",
      "W1: 10.601875173940618 W2: 1.8470337003515784 b -5.567688629188019 Loss: 0.4105014102500844\n",
      "W1: 10.602241516320513 W2: 1.8470722216008812 b -5.567873061918133 Loss: 0.4105010703443445\n",
      "W1: 10.60260750327203 W2: 1.8471107068648027 b -5.568057317207346 Loss: 0.41050073109655083\n",
      "W1: 10.602973135159711 W2: 1.8471491561775506 b -5.568241395234777 Loss: 0.41050039250539444\n",
      "W1: 10.603338412347696 W2: 1.847187569573299 b -5.56842529617935 Loss: 0.4105000545695692\n",
      "W1: 10.603703335199706 W2: 1.8472259470861894 b -5.5686090202197915 Loss: 0.41049971728777196\n",
      "W1: 10.604067904079052 W2: 1.847264288750329 b -5.568792567534632 Loss: 0.41049938065870156\n",
      "W1: 10.604432119348639 W2: 1.8473025945997923 b -5.568975938302206 Loss: 0.4104990446810606\n",
      "W1: 10.604795981370959 W2: 1.8473408646686207 b -5.569159132700651 Loss: 0.4104987093535535\n",
      "W1: 10.605159490508095 W2: 1.847379098990822 b -5.569342150907913 Loss: 0.4104983746748875\n",
      "W1: 10.605522647121724 W2: 1.8474172976003713 b -5.569524993101736 Loss: 0.41049804064377277\n",
      "W1: 10.605885451573114 W2: 1.8474554605312101 b -5.5697076594596755 Loss: 0.4104977072589222\n",
      "W1: 10.606247904223125 W2: 1.8474935878172472 b -5.569890150159088 Loss: 0.4104973745190507\n",
      "W1: 10.60661000543221 W2: 1.847531679492358 b -5.570072465377137 Loss: 0.4104970424228767\n",
      "W1: 10.606971755560416 W2: 1.847569735590385 b -5.570254605290792 Loss: 0.4104967109691206\n",
      "W1: 10.607333154967383 W2: 1.847607756145138 b -5.5704365700768275 Loss: 0.4104963801565058\n",
      "W1: 10.60769420401235 W2: 1.8476457411903937 b -5.570618359911824 Loss: 0.4104960499837583\n",
      "W1: 10.608054903054146 W2: 1.8476836907598955 b -5.57079997497217 Loss: 0.4104957204496065\n",
      "W1: 10.608415252451199 W2: 1.8477216048873542 b -5.5709814154340584 Loss: 0.41049539155278175\n",
      "W1: 10.60877525256153 W2: 1.8477594836064475 b -5.57116268147349 Loss: 0.4104950632920177\n",
      "W1: 10.609134903742763 W2: 1.8477973269508208 b -5.571343773266274 Loss: 0.4104947356660508\n",
      "W1: 10.609494206352112 W2: 1.8478351349540862 b -5.571524690988025 Loss: 0.41049440867362025\n",
      "W1: 10.609853160746393 W2: 1.8478729076498233 b -5.571705434814167 Loss: 0.41049408231346746\n",
      "W1: 10.61021176728202 W2: 1.8479106450715788 b -5.571886004919929 Loss: 0.4104937565843366\n",
      "W1: 10.610570026315008 W2: 1.8479483472528666 b -5.572066401480351 Loss: 0.41049343148497486\n",
      "W1: 10.610927938200966 W2: 1.8479860142271685 b -5.57224662467028 Loss: 0.41049310701413105\n",
      "W1: 10.611285503295106 W2: 1.848023646027933 b -5.572426674664372 Loss: 0.4104927831705577\n",
      "W1: 10.61164272195224 W2: 1.8480612426885763 b -5.572606551637091 Loss: 0.41049245995300904\n",
      "W1: 10.611999594526782 W2: 1.848098804242482 b -5.572786255762711 Loss: 0.41049213736024215\n",
      "W1: 10.612356121372748 W2: 1.8481363307230012 b -5.572965787215316 Loss: 0.410491815391017\n",
      "W1: 10.612712302843756 W2: 1.8481738221634525 b -5.573145146168796 Loss: 0.41049149404409546\n",
      "W1: 10.613068139293022 W2: 1.848211278597122 b -5.573324332796855 Loss: 0.4104911733182426\n",
      "W1: 10.61342363107337 W2: 1.8482487000572634 b -5.573503347273005 Loss: 0.4104908532122255\n",
      "W1: 10.613778778537226 W2: 1.8482860865770978 b -5.573682189770567 Loss: 0.41049053372481425\n",
      "W1: 10.61413358203662 W2: 1.8483234381898141 b -5.573860860462674 Loss: 0.4104902148547811\n",
      "W1: 10.614488041923188 W2: 1.848360754928569 b -5.574039359522271 Loss: 0.41048989660090096\n",
      "W1: 10.614842158548168 W2: 1.8483980368264865 b -5.57421768712211 Loss: 0.41048957896195143\n",
      "W1: 10.615195932262406 W2: 1.8484352839166587 b -5.574395843434759 Loss: 0.41048926193671226\n",
      "W1: 10.615549363416354 W2: 1.8484724962321453 b -5.574573828632594 Loss: 0.41048894552396625\n",
      "W1: 10.615902452360071 W2: 1.8485096738059736 b -5.574751642887803 Loss: 0.41048862972249806\n",
      "W1: 10.616255199443222 W2: 1.848546816671139 b -5.574929286372386 Loss: 0.4104883145310953\n",
      "W1: 10.616607605015078 W2: 1.8485839248606046 b -5.575106759258158 Loss: 0.4104879999485481\n",
      "W1: 10.61695966942452 W2: 1.8486209984073017 b -5.575284061716741 Loss: 0.4104876859736487\n",
      "W1: 10.617311393020042 W2: 1.848658037344129 b -5.575461193919574 Loss: 0.4104873726051922\n",
      "W1: 10.61766277614974 W2: 1.8486950417039536 b -5.575638156037908 Loss: 0.4104870598419758\n",
      "W1: 10.618013819161321 W2: 1.8487320115196102 b -5.575814948242804 Loss: 0.41048674768279986\n",
      "W1: 10.618364522402107 W2: 1.8487689468239017 b -5.575991570705139 Loss: 0.4104864361264664\n",
      "W1: 10.618714886219026 W2: 1.8488058476495992 b -5.576168023595605 Loss: 0.4104861251717805\n",
      "W1: 10.619064910958619 W2: 1.8488427140294417 b -5.576344307084703 Loss: 0.4104858148175493\n",
      "W1: 10.619414596967038 W2: 1.8488795459961362 b -5.576520421342753 Loss: 0.41048550506258247\n",
      "W1: 10.61976394459005 W2: 1.8489163435823581 b -5.576696366539886 Loss: 0.4104851959056925\n",
      "W1: 10.62011295417303 W2: 1.8489531068207508 b -5.576872142846047 Loss: 0.4104848873456937\n",
      "W1: 10.620461626060967 W2: 1.8489898357439258 b -5.5770477504309985 Loss: 0.4104845793814034\n",
      "W1: 10.620809960598468 W2: 1.8490265303844633 b -5.577223189464316 Loss: 0.4104842720116412\n",
      "W1: 10.62115795812975 W2: 1.849063190774911 b -5.577398460115391 Loss: 0.410483965235229\n",
      "W1: 10.621505618998645 W2: 1.849099816947786 b -5.577573562553428 Loss: 0.41048365905099077\n",
      "W1: 10.621852943548603 W2: 1.8491364089355724 b -5.57774849694745 Loss: 0.41048335345775383\n",
      "W1: 10.622199932122689 W2: 1.8491729667707237 b -5.577923263466294 Loss: 0.41048304845434697\n",
      "W1: 10.62254658506358 W2: 1.8492094904856613 b -5.578097862278614 Loss: 0.41048274403960205\n",
      "W1: 10.622892902713573 W2: 1.8492459801127752 b -5.578272293552881 Loss: 0.41048244021235286\n",
      "W1: 10.623238885414583 W2: 1.8492824356844237 b -5.5784465574573785 Loss: 0.410482136971436\n",
      "W1: 10.623584533508142 W2: 1.849318857232934 b -5.578620654160212 Loss: 0.4104818343156902\n",
      "W1: 10.623929847335399 W2: 1.8493552447906012 b -5.578794583829301 Loss: 0.41048153224395656\n",
      "W1: 10.624274827237121 W2: 1.8493915983896894 b -5.578968346632381 Loss: 0.4104812307550786\n",
      "W1: 10.624619473553699 W2: 1.8494279180624311 b -5.579141942737008 Loss: 0.41048092984790235\n",
      "W1: 10.624963786625136 W2: 1.8494642038410276 b -5.579315372310554 Loss: 0.41048062952127606\n",
      "W1: 10.62530776679106 W2: 1.8495004557576487 b -5.5794886355202085 Loss: 0.4104803297740504\n",
      "W1: 10.62565141439072 W2: 1.8495366738444328 b -5.57966173253298 Loss: 0.41048003060507826\n",
      "W1: 10.625994729762985 W2: 1.8495728581334872 b -5.579834663515694 Loss: 0.4104797320132153\n",
      "W1: 10.626337713246343 W2: 1.849609008656888 b -5.580007428634995 Loss: 0.41047943399731895\n",
      "W1: 10.626680365178908 W2: 1.8496451254466797 b -5.580180028057348 Loss: 0.4104791365562495\n",
      "W1: 10.627022685898414 W2: 1.8496812085348757 b -5.580352461949033 Loss: 0.41047883968886917\n",
      "W1: 10.62736467574222 W2: 1.8497172579534586 b -5.580524730476154 Loss: 0.4104785433940428\n",
      "W1: 10.627706335047307 W2: 1.8497532737343796 b -5.58069683380463 Loss: 0.41047824767063745\n",
      "W1: 10.62804766415028 W2: 1.8497892559095586 b -5.580868772100204 Loss: 0.4104779525175225\n",
      "W1: 10.62838866338737 W2: 1.8498252045108847 b -5.581040545528435 Loss: 0.41047765793356966\n",
      "W1: 10.62872933309443 W2: 1.8498611195702162 b -5.581212154254702 Loss: 0.410477363917653\n",
      "W1: 10.629069673606942 W2: 1.8498970011193798 b -5.581383598444209 Loss: 0.4104770704686489\n",
      "W1: 10.629409685260011 W2: 1.8499328491901716 b -5.581554878261975 Loss: 0.41047677758543577\n",
      "W1: 10.62974936838837 W2: 1.8499686638143567 b -5.581725993872842 Loss: 0.4104764852668947\n",
      "W1: 10.630088723326379 W2: 1.850004445023669 b -5.581896945441475 Loss: 0.410476193511909\n",
      "W1: 10.630427750408023 W2: 1.850040192849812 b -5.582067733132356 Loss: 0.410475902319364\n",
      "W1: 10.630766449966918 W2: 1.850075907324458 b -5.582238357109792 Loss: 0.41047561168814783\n",
      "W1: 10.631104822336306 W2: 1.8501115884792485 b -5.582408817537909 Loss: 0.4104753216171501\n",
      "W1: 10.63144286784906 W2: 1.8501472363457945 b -5.582579114580657 Loss: 0.41047503210526365\n",
      "W1: 10.63178058683768 W2: 1.850182850955676 b -5.582749248401806 Loss: 0.4104747431513827\n",
      "W1: 10.632117979634295 W2: 1.850218432340442 b -5.582919219164951 Loss: 0.4104744547544045\n",
      "W1: 10.632455046570668 W2: 1.8502539805316114 b -5.583089027033505 Loss: 0.41047416691322797\n",
      "W1: 10.632791787978189 W2: 1.850289495560672 b -5.583258672170709 Loss: 0.41047387962675475\n",
      "W1: 10.633128204187882 W2: 1.8503249774590809 b -5.583428154739623 Loss: 0.41047359289388813\n",
      "W1: 10.6334642955304 W2: 1.850360426258265 b -5.583597474903133 Loss: 0.4104733067135342\n",
      "W1: 10.63380006233603 W2: 1.8503958419896203 b -5.583766632823945 Loss: 0.41047302108460126\n",
      "W1: 10.634135504934692 W2: 1.8504312246845123 b -5.583935628664592 Loss: 0.4104727360059996\n",
      "W1: 10.634470623655936 W2: 1.850466574374276 b -5.584104462587428 Loss: 0.41047245147664185\n",
      "W1: 10.634805418828947 W2: 1.850501891090216 b -5.584273134754633 Loss: 0.4104721674954426\n",
      "W1: 10.635139890782545 W2: 1.8505371748636064 b -5.58444164532821 Loss: 0.41047188406131935\n",
      "W1: 10.635474039845185 W2: 1.8505724257256906 b -5.5846099944699885 Loss: 0.41047160117319076\n",
      "W1: 10.635807866344955 W2: 1.850607643707682 b -5.584778182341619 Loss: 0.41047131882997906\n",
      "W1: 10.636141370609577 W2: 1.8506428288407635 b -5.58494620910458 Loss: 0.41047103703060744\n",
      "W1: 10.636474552966412 W2: 1.8506779811560876 b -5.585114074920175 Loss: 0.41047075577400194\n",
      "W1: 10.636807413742456 W2: 1.8507131006847766 b -5.58528177994953 Loss: 0.4104704750590908\n",
      "W1: 10.637139953264343 W2: 1.8507481874579226 b -5.585449324353599 Loss: 0.410470194884804\n",
      "W1: 10.637472171858342 W2: 1.850783241506587 b -5.585616708293161 Loss: 0.41046991525007415\n",
      "W1: 10.63780406985036 W2: 1.8508182628618015 b -5.585783931928821 Loss: 0.4104696361538361\n",
      "W1: 10.638135647565944 W2: 1.8508532515545675 b -5.585950995421011 Loss: 0.41046935759502645\n",
      "W1: 10.638466905330278 W2: 1.850888207615856 b -5.586117898929987 Loss: 0.4104690795725841\n",
      "W1: 10.638797843468184 W2: 1.850923131076608 b -5.586284642615834 Loss: 0.4104688020854507\n",
      "W1: 10.639128462304129 W2: 1.8509580219677348 b -5.586451226638463 Loss: 0.41046852513256926\n",
      "W1: 10.639458762162212 W2: 1.850992880320117 b -5.586617651157612 Loss: 0.41046824871288534\n",
      "W1: 10.639788743366179 W2: 1.8510277061646054 b -5.586783916332845 Loss: 0.4104679728253466\n",
      "W1: 10.640118406239411 W2: 1.851062499532021 b -5.586950022323555 Loss: 0.410467697468903\n",
      "W1: 10.640447751104936 W2: 1.8510972604531548 b -5.587115969288964 Loss: 0.4104674226425063\n",
      "W1: 10.640776778285423 W2: 1.8511319889587674 b -5.587281757388117 Loss: 0.4104671483451105\n",
      "W1: 10.641105488103179 W2: 1.85116668507959 b -5.587447386779892 Loss: 0.4104668745756721\n",
      "W1: 10.641433880880157 W2: 1.8512013488463237 b -5.587612857622992 Loss: 0.41046660133314955\n",
      "W1: 10.641761956937954 W2: 1.8512359802896399 b -5.587778170075952 Loss: 0.410466328616503\n",
      "W1: 10.642089716597807 W2: 1.8512705794401798 b -5.5879433242971315 Loss: 0.4104660564246954\n",
      "W1: 10.6424171601806 W2: 1.8513051463285555 b -5.5881083204447215 Loss: 0.41046578475669127\n",
      "W1: 10.64274428800686 W2: 1.8513396809853484 b -5.588273158676742 Loss: 0.4104655136114575\n",
      "W1: 10.64307110039676 W2: 1.851374183441111 b -5.588437839151041 Loss: 0.4104652429879632\n",
      "W1: 10.64339759767012 W2: 1.8514086537263659 b -5.588602362025297 Loss: 0.41046497288517936\n",
      "W1: 10.643723780146402 W2: 1.8514430918716056 b -5.588766727457018 Loss: 0.410464703302079\n",
      "W1: 10.644049648144717 W2: 1.8514774979072932 b -5.588930935603543 Loss: 0.4104644342376378\n",
      "W1: 10.644375201983824 W2: 1.8515118718638623 b -5.5890949866220385 Loss: 0.4104641656908326\n",
      "W1: 10.644700441982124 W2: 1.8515462137717171 b -5.5892588806695045 Loss: 0.41046389766064323\n",
      "W1: 10.64502536845767 W2: 1.8515805236612317 b -5.58942261790277 Loss: 0.4104636301460509\n",
      "W1: 10.645349981728163 W2: 1.8516148015627512 b -5.589586198478494 Loss: 0.41046336314603954\n",
      "W1: 10.645674282110951 W2: 1.8516490475065905 b -5.589749622553167 Loss: 0.41046309665959485\n",
      "W1: 10.645998269923032 W2: 1.851683261523036 b -5.589912890283111 Loss: 0.41046283068570416\n",
      "W1: 10.646321945481052 W2: 1.851717443642344 b -5.590076001824481 Loss: 0.4104625652233578\n",
      "W1: 10.64664530910131 W2: 1.8517515938947415 b -5.59023895733326 Loss: 0.41046230027154723\n",
      "W1: 10.64696836109975 W2: 1.8517857123104262 b -5.590401756965266 Loss: 0.41046203582926655\n",
      "W1: 10.647291101791973 W2: 1.8518197989195664 b -5.590564400876148 Loss: 0.4104617718955119\n",
      "W1: 10.647613531493228 W2: 1.851853853752301 b -5.5907268892213855 Loss: 0.41046150846928114\n",
      "W1: 10.647935650518415 W2: 1.8518878768387401 b -5.590889222156293 Loss: 0.41046124554957436\n",
      "W1: 10.648257459182087 W2: 1.8519218682089638 b -5.591051399836016 Loss: 0.41046098313539364\n",
      "W1: 10.648578957798449 W2: 1.8519558278930235 b -5.591213422415533 Loss: 0.4104607212257434\n",
      "W1: 10.648900146681362 W2: 1.851989755920941 b -5.5913752900496565 Loss: 0.4104604598196294\n",
      "W1: 10.649221026144335 W2: 1.8520236523227094 b -5.591537002893031 Loss: 0.41046019891606006\n",
      "W1: 10.649541596500535 W2: 1.8520575171282923 b -5.591698561100135 Loss: 0.4104599385140457\n",
      "W1: 10.649861858062783 W2: 1.8520913503676242 b -5.591859964825281 Loss: 0.41045967861259847\n",
      "W1: 10.650181811143552 W2: 1.8521251520706106 b -5.592021214222615 Loss: 0.4104594192107326\n",
      "W1: 10.650501456054974 W2: 1.852158922267128 b -5.592182309446116 Loss: 0.4104591603074645\n",
      "W1: 10.650820793108833 W2: 1.8521926609870238 b -5.5923432506495985 Loss: 0.4104589019018123\n",
      "W1: 10.651139822616571 W2: 1.8522263682601166 b -5.5925040379867115 Loss: 0.41045864399279613\n",
      "W1: 10.651458544889286 W2: 1.8522600441161954 b -5.592664671610938 Loss: 0.4104583865794385\n",
      "W1: 10.651776960237733 W2: 1.852293688585021 b -5.592825151675595 Loss: 0.4104581296607636\n",
      "W1: 10.652095068972324 W2: 1.8523273016963249 b -5.592985478333838 Loss: 0.41045787323579774\n",
      "W1: 10.65241287140313 W2: 1.85236088347981 b -5.593145651738654 Loss: 0.4104576173035689\n",
      "W1: 10.652730367839878 W2: 1.85239443396515 b -5.593305672042867 Loss: 0.41045736186310755\n",
      "W1: 10.653047558591956 W2: 1.8524279531819898 b -5.593465539399135 Loss: 0.4104571069134458\n",
      "W1: 10.653364443968409 W2: 1.8524614411599458 b -5.593625253959956 Loss: 0.4104568524536177\n",
      "W1: 10.653681024277942 W2: 1.8524948979286056 b -5.593784815877658 Loss: 0.41045659848265964\n",
      "W1: 10.653997299828921 W2: 1.8525283235175276 b -5.593944225304411 Loss: 0.4104563449996095\n",
      "W1: 10.654313270929372 W2: 1.852561717956242 b -5.594103482392218 Loss: 0.410456092003507\n",
      "W1: 10.65462893788698 W2: 1.8525950812742498 b -5.594262587292921 Loss: 0.4104558394933948\n",
      "W1: 10.654944301009094 W2: 1.852628413501024 b -5.594421540158195 Loss: 0.4104555874683164\n",
      "W1: 10.655259360602722 W2: 1.8526617146660087 b -5.594580341139556 Loss: 0.41045533592731775\n",
      "W1: 10.655574116974536 W2: 1.8526949847986192 b -5.594738990388356 Loss: 0.4104550848694467\n",
      "W1: 10.65588857043087 W2: 1.8527282239282425 b -5.594897488055782 Loss: 0.4104548342937529\n",
      "W1: 10.656202721277719 W2: 1.852761432084237 b -5.595055834292863 Loss: 0.41045458419928826\n",
      "W1: 10.656516569820743 W2: 1.8527946092959322 b -5.595214029250462 Loss: 0.4104543345851065\n",
      "W1: 10.656830116365267 W2: 1.8528277555926298 b -5.595372073079282 Loss: 0.41045408545026274\n",
      "W1: 10.657143361216278 W2: 1.8528608710036025 b -5.595529965929864 Loss: 0.41045383679381475\n",
      "W1: 10.65745630467843 W2: 1.852893955558095 b -5.595687707952587 Loss: 0.4104535886148218\n",
      "W1: 10.657768947056038 W2: 1.8529270092853234 b -5.595845299297668 Loss: 0.4104533409123453\n",
      "W1: 10.658081288653086 W2: 1.8529600322144753 b -5.596002740115164 Loss: 0.4104530936854484\n",
      "W1: 10.658393329773222 W2: 1.85299302437471 b -5.596160030554971 Loss: 0.41045284693319634\n",
      "W1: 10.658705070719762 W2: 1.8530259857951585 b -5.596317170766824 Loss: 0.4104526006546557\n",
      "W1: 10.659016511795686 W2: 1.8530589165049238 b -5.5964741609002955 Loss: 0.4104523548488958\n",
      "W1: 10.659327653303643 W2: 1.8530918165330803 b -5.5966310011048 Loss: 0.41045210951498734\n",
      "W1: 10.65963849554595 W2: 1.8531246859086745 b -5.596787691529591 Loss: 0.41045186465200295\n",
      "W1: 10.65994903882459 W2: 1.8531575246607244 b -5.596944232323762 Loss: 0.4104516202590174\n",
      "W1: 10.660259283441219 W2: 1.8531903328182198 b -5.597100623636245 Loss: 0.4104513763351068\n",
      "W1: 10.660569229697154 W2: 1.8532231104101227 b -5.597256865615816 Loss: 0.41045113287934976\n",
      "W1: 10.660878877893387 W2: 1.8532558574653666 b -5.5974129584110885 Loss: 0.4104508898908263\n",
      "W1: 10.661188228330577 W2: 1.8532885740128573 b -5.597568902170517 Loss: 0.41045064736861864\n",
      "W1: 10.661497281309055 W2: 1.8533212600814724 b -5.5977246970423975 Loss: 0.4104504053118106\n",
      "W1: 10.661806037128821 W2: 1.8533539157000611 b -5.597880343174868 Loss: 0.4104501637194881\n",
      "W1: 10.662114496089547 W2: 1.853386540897445 b -5.598035840715906 Loss: 0.41044992259073854\n",
      "W1: 10.662422658490575 W2: 1.853419135702418 b -5.598191189813332 Loss: 0.41044968192465153\n",
      "W1: 10.662730524630918 W2: 1.8534517001437452 b -5.598346390614808 Loss: 0.41044944172031866\n",
      "W1: 10.663038094809263 W2: 1.8534842342501645 b -5.598501443267837 Loss: 0.41044920197683293\n",
      "W1: 10.663345369323968 W2: 1.8535167380503859 b -5.598656347919765 Loss: 0.41044896269328923\n",
      "W1: 10.663652348473066 W2: 1.853549211573091 b -5.598811104717779 Loss: 0.41044872386878456\n",
      "W1: 10.663959032554262 W2: 1.853581654846934 b -5.5989657138089095 Loss: 0.4104484855024176\n",
      "W1: 10.664265421864933 W2: 1.8536140679005413 b -5.59912017534003 Loss: 0.4104482475932891\n",
      "W1: 10.664571516702132 W2: 1.8536464507625114 b -5.599274489457855 Loss: 0.4104480101405009\n",
      "W1: 10.664877317362588 W2: 1.8536788034614151 b -5.599428656308944 Loss: 0.4104477731431579\n",
      "W1: 10.665182824142702 W2: 1.8537111260257952 b -5.599582676039699 Loss: 0.41044753660036526\n",
      "W1: 10.66548803733855 W2: 1.8537434184841672 b -5.599736548796365 Loss: 0.4104473005112315\n",
      "W1: 10.665792957245886 W2: 1.8537756808650188 b -5.599890274725031 Loss: 0.410447064874866\n",
      "W1: 10.66609758416014 W2: 1.85380791319681 b -5.600043853971631 Loss: 0.41044682969038015\n",
      "W1: 10.666401918376417 W2: 1.8538401155079733 b -5.600197286681939 Loss: 0.41044659495688696\n",
      "W1: 10.6667059601895 W2: 1.8538722878269136 b -5.600350573001578 Loss: 0.4104463606735018\n",
      "W1: 10.667009709893849 W2: 1.853904430182008 b -5.600503713076012 Loss: 0.41044612683934134\n",
      "W1: 10.667313167783602 W2: 1.8539365426016063 b -5.600656707050551 Loss: 0.410445893453524\n",
      "W1: 10.667616334152575 W2: 1.853968625114031 b -5.60080955507035 Loss: 0.4104456605151707\n",
      "W1: 10.667919209294261 W2: 1.8540006777475768 b -5.600962257280407 Loss: 0.410445428023403\n",
      "W1: 10.668221793501836 W2: 1.8540327005305108 b -5.601114813825567 Loss: 0.41044519597734525\n",
      "W1: 10.668524087068151 W2: 1.8540646934910734 b -5.601267224850519 Loss: 0.41044496437612316\n",
      "W1: 10.66882609028574 W2: 1.8540966566574766 b -5.601419490499798 Loss: 0.41044473321886393\n",
      "W1: 10.669127803446816 W2: 1.8541285900579059 b -5.6015716109177855 Loss: 0.4104445025046971\n",
      "W1: 10.66942922684327 W2: 1.854160493720519 b -5.601723586248708 Loss: 0.41044427223275365\n",
      "W1: 10.669730360766678 W2: 1.8541923676734466 b -5.601875416636637 Loss: 0.4104440424021663\n",
      "W1: 10.670031205508295 W2: 1.8542242119447918 b -5.602027102225492 Loss: 0.4104438130120698\n",
      "W1: 10.670331761359057 W2: 1.8542560265626307 b -5.6021786431590375 Loss: 0.41044358406160025\n",
      "W1: 10.670632028609585 W2: 1.8542878115550119 b -5.6023300395808855 Loss: 0.41044335554989575\n",
      "W1: 10.670932007550181 W2: 1.8543195669499573 b -5.602481291634494 Loss: 0.410443127476096\n",
      "W1: 10.67123169847083 W2: 1.8543512927754608 b -5.602632399463169 Loss: 0.4104428998393429\n",
      "W1: 10.6715311016612 W2: 1.85438298905949 b -5.602783363210062 Loss: 0.41044267263877926\n",
      "W1: 10.671830217410642 W2: 1.854414655829985 b -5.6029341830181725 Loss: 0.41044244587355044\n",
      "W1: 10.672129046008193 W2: 1.8544462931148589 b -5.603084859030349 Loss: 0.4104422195428031\n",
      "W1: 10.672427587742572 W2: 1.8544779009419974 b -5.603235391389285 Loss: 0.4104419936456854\n",
      "W1: 10.672725842902185 W2: 1.8545094793392598 b -5.603385780237524 Loss: 0.41044176818134803\n",
      "W1: 10.673023811775124 W2: 1.8545410283344779 b -5.603536025717456 Loss: 0.4104415431489425\n",
      "W1: 10.673321494649164 W2: 1.8545725479554565 b -5.60368612797132 Loss: 0.4104413185476229\n",
      "W1: 10.673618891811767 W2: 1.8546040382299736 b -5.603836087141204 Loss: 0.4104410943765439\n",
      "W1: 10.673916003550083 W2: 1.8546354991857803 b -5.603985903369043 Loss: 0.4104408706348632\n",
      "W1: 10.674212830150948 W2: 1.854666930850601 b -5.604135576796622 Loss: 0.410440647321739\n",
      "W1: 10.674509371900882 W2: 1.8546983332521327 b -5.604285107565574 Loss: 0.4104404244363323\n",
      "W1: 10.674805629086098 W2: 1.8547297064180461 b -5.604434495817382 Loss: 0.41044020197780484\n",
      "W1: 10.675101601992495 W2: 1.8547610503759846 b -5.604583741693379 Loss: 0.4104399799453206\n",
      "W1: 10.675397290905657 W2: 1.8547923651535652 b -5.604732845334744 Loss: 0.4104397583380452\n",
      "W1: 10.675692696110863 W2: 1.8548236507783777 b -5.60488180688251 Loss: 0.41043953715514586\n",
      "W1: 10.675987817893075 W2: 1.8548549072779856 b -5.605030626477557 Loss: 0.41043931639579134\n",
      "W1: 10.67628265653695 W2: 1.8548861346799255 b -5.605179304260616 Loss: 0.41043909605915235\n",
      "W1: 10.67657721232683 W2: 1.8549173330117072 b -5.605327840372269 Loss: 0.41043887614440117\n",
      "W1: 10.67687148554675 W2: 1.854948502300814 b -5.6054762349529454 Loss: 0.4104386566507116\n",
      "W1: 10.677165476480434 W2: 1.8549796425747027 b -5.6056244881429285 Loss: 0.41043843757725945\n",
      "W1: 10.677459185411301 W2: 1.8550107538608032 b -5.605772600082351 Loss: 0.4104382189232218\n",
      "W1: 10.677752612622458 W2: 1.8550418361865186 b -5.605920570911196 Loss: 0.41043800068777775\n",
      "W1: 10.678045758396703 W2: 1.8550728895792261 b -5.606068400769298 Loss: 0.4104377828701077\n",
      "W1: 10.678338623016527 W2: 1.8551039140662762 b -5.6062160897963444 Loss: 0.41043756546939425\n",
      "W1: 10.678631206764118 W2: 1.8551349096749923 b -5.606363638131871 Loss: 0.41043734848482083\n",
      "W1: 10.67892350992135 W2: 1.8551658764326722 b -5.606511045915267 Loss: 0.4104371319155735\n",
      "W1: 10.679215532769797 W2: 1.8551968143665865 b -5.606658313285775 Loss: 0.41043691576083907\n",
      "W1: 10.679507275590721 W2: 1.8552277235039798 b -5.606805440382485 Loss: 0.41043670001980653\n",
      "W1: 10.679798738665081 W2: 1.8552586038720704 b -5.606952427344343 Loss: 0.4104364846916663\n",
      "W1: 10.680089922273531 W2: 1.85528945549805 b -5.607099274310147 Loss: 0.41043626977561054\n",
      "W1: 10.680380826696418 W2: 1.8553202784090836 b -5.607245981418545 Loss: 0.41043605527083304\n",
      "W1: 10.680671452213785 W2: 1.8553510726323108 b -5.607392548808042 Loss: 0.41043584117652904\n",
      "W1: 10.68096179910537 W2: 1.8553818381948441 b -5.607538976616991 Loss: 0.41043562749189577\n",
      "W1: 10.68125186765061 W2: 1.85541257512377 b -5.6076852649836 Loss: 0.41043541421613167\n",
      "W1: 10.681541658128635 W2: 1.855443283446149 b -5.607831414045933 Loss: 0.410435201348437\n",
      "W1: 10.681831170818272 W2: 1.855473963189015 b -5.607977423941902 Loss: 0.41043498888801333\n",
      "W1: 10.682120405998047 W2: 1.8555046143793759 b -5.6081232948092765 Loss: 0.4104347768340647\n",
      "W1: 10.682409363946183 W2: 1.8555352370442135 b -5.6082690267856785 Loss: 0.4104345651857957\n",
      "W1: 10.682698044940599 W2: 1.8555658312104835 b -5.608414620008584 Loss: 0.41043435394241334\n",
      "W1: 10.682986449258914 W2: 1.855596396905115 b -5.608560074615323 Loss: 0.41043414310312554\n",
      "W1: 10.683274577178446 W2: 1.8556269341550118 b -5.608705390743078 Loss: 0.4104339326671424\n",
      "W1: 10.683562428976211 W2: 1.8556574429870512 b -5.608850568528891 Loss: 0.41043372263367545\n",
      "W1: 10.683850004928924 W2: 1.8556879234280843 b -5.608995608109653 Loss: 0.41043351300193753\n",
      "W1: 10.684137305313001 W2: 1.8557183755049367 b -5.609140509622112 Loss: 0.4104333037711433\n",
      "W1: 10.684424330404557 W2: 1.8557487992444077 b -5.609285273202872 Loss: 0.4104330949405092\n",
      "W1: 10.684711080479406 W2: 1.8557791946732707 b -5.60942989898839 Loss: 0.41043288650925286\n",
      "W1: 10.684997555813068 W2: 1.855809561818273 b -5.60957438711498 Loss: 0.4104326784765934\n",
      "W1: 10.685283756680757 W2: 1.8558399007061364 b -5.609718737718811 Loss: 0.41043247084175244\n",
      "W1: 10.685569683357395 W2: 1.8558702113635566 b -5.609862950935907 Loss: 0.41043226360395196\n",
      "W1: 10.685855336117601 W2: 1.8559004938172032 b -5.610007026902148 Loss: 0.41043205676241623\n",
      "W1: 10.686140715235702 W2: 1.8559307480937206 b -5.610150965753269 Loss: 0.4104318503163709\n",
      "W1: 10.686425820985722 W2: 1.8559609742197267 b -5.610294767624865 Loss: 0.4104316442650431\n",
      "W1: 10.68671065364139 W2: 1.8559911722218143 b -5.610438432652382 Loss: 0.4104314386076618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.68699521347614 W2: 1.85602134212655 b -5.6105819609711265 Loss: 0.4104312333434572\n",
      "W1: 10.687279500763106 W2: 1.8560514839604745 b -5.610725352716259 Loss: 0.41043102847166096\n",
      "W1: 10.68756351577513 W2: 1.8560815977501035 b -5.610868608022799 Loss: 0.4104308239915071\n",
      "W1: 10.687847258784759 W2: 1.8561116835219267 b -5.611011727025622 Loss: 0.4104306199022299\n",
      "W1: 10.68813073006424 W2: 1.856141741302408 b -5.611154709859461 Loss: 0.41043041620306636\n",
      "W1: 10.688413929885527 W2: 1.8561717711179857 b -5.611297556658904 Loss: 0.4104302128932542\n",
      "W1: 10.688696858520284 W2: 1.8562017729950726 b -5.6114402675584 Loss: 0.4104300099720334\n",
      "W1: 10.688979516239876 W2: 1.856231746960056 b -5.611582842692254 Loss: 0.4104298074386447\n",
      "W1: 10.689261903315375 W2: 1.8562616930392977 b -5.611725282194628 Loss: 0.410429605292331\n",
      "W1: 10.68954402001756 W2: 1.8562916112591337 b -5.611867586199544 Loss: 0.4104294035323363\n",
      "W1: 10.689825866616921 W2: 1.856321501645875 b -5.612009754840881 Loss: 0.4104292021579061\n",
      "W1: 10.69010744338365 W2: 1.8563513642258065 b -5.612151788252376 Loss: 0.4104290011682881\n",
      "W1: 10.690388750587646 W2: 1.8563811990251884 b -5.612293686567625 Loss: 0.41042880056273073\n",
      "W1: 10.69066978849852 W2: 1.8564110060702548 b -5.612435449920082 Loss: 0.4104286003404843\n",
      "W1: 10.690950557385591 W2: 1.856440785387215 b -5.612577078443061 Loss: 0.4104284005008004\n",
      "W1: 10.691231057517886 W2: 1.856470537002252 b -5.612718572269734 Loss: 0.4104282010429325\n",
      "W1: 10.691511289164138 W2: 1.8565002609415249 b -5.612859931533133 Loss: 0.4104280019661351\n",
      "W1: 10.691791252592797 W2: 1.8565299572311662 b -5.613001156366148 Loss: 0.4104278032696648\n",
      "W1: 10.692070948072015 W2: 1.8565596258972838 b -5.613142246901531 Loss: 0.410427604952779\n",
      "W1: 10.692350375869658 W2: 1.8565892669659603 b -5.613283203271891 Loss: 0.41042740701473696\n",
      "W1: 10.692629536253303 W2: 1.8566188804632526 b -5.613424025609698 Loss: 0.4104272094547998\n",
      "W1: 10.692908429490238 W2: 1.8566484664151932 b -5.613564714047282 Loss: 0.4104270122722296\n",
      "W1: 10.69318705584746 W2: 1.8566780248477885 b -5.613705268716833 Loss: 0.41042681546628956\n",
      "W1: 10.693465415591678 W2: 1.8567075557870205 b -5.613845689750401 Loss: 0.4104266190362454\n",
      "W1: 10.693743508989316 W2: 1.8567370592588455 b -5.6139859772798975 Loss: 0.41042642298136384\n",
      "W1: 10.694021336306506 W2: 1.8567665352891949 b -5.614126131437093 Loss: 0.4104262273009123\n",
      "W1: 10.694298897809096 W2: 1.8567959839039752 b -5.614266152353621 Loss: 0.41042603199416133\n",
      "W1: 10.694576193762646 W2: 1.8568254051290676 b -5.614406040160974 Loss: 0.41042583706038144\n",
      "W1: 10.69485322443243 W2: 1.8568547989903286 b -5.614545794990507 Loss: 0.4104256424988451\n",
      "W1: 10.695129990083435 W2: 1.8568841655135893 b -5.614685416973435 Loss: 0.41042544830882677\n",
      "W1: 10.695406490980362 W2: 1.8569135047246559 b -5.614824906240837 Loss: 0.41042525448960154\n",
      "W1: 10.695682727387625 W2: 1.8569428166493098 b -5.61496426292365 Loss: 0.41042506104044646\n",
      "W1: 10.695958699569356 W2: 1.8569721013133074 b -5.615103487152675 Loss: 0.4104248679606399\n",
      "W1: 10.696234407789401 W2: 1.8570013587423801 b -5.615242579058575 Loss: 0.4104246752494616\n",
      "W1: 10.69650985231132 W2: 1.8570305889622345 b -5.615381538771874 Loss: 0.41042448290619277\n",
      "W1: 10.696785033398388 W2: 1.8570597919985523 b -5.615520366422961 Loss: 0.41042429093011634\n",
      "W1: 10.697059951313602 W2: 1.8570889678769906 b -5.615659062142084 Loss: 0.4104240993205163\n",
      "W1: 10.69733460631967 W2: 1.8571181166231814 b -5.615797626059356 Loss: 0.41042390807667845\n",
      "W1: 10.697608998679017 W2: 1.8571472382627319 b -5.615936058304751 Loss: 0.41042371719788934\n",
      "W1: 10.697883128653789 W2: 1.8571763328212247 b -5.616074359008107 Loss: 0.410423526683438\n",
      "W1: 10.698156996505844 W2: 1.8572054003242175 b -5.616212528299125 Loss: 0.41042333653261404\n",
      "W1: 10.698430602496764 W2: 1.8572344407972436 b -5.61635056630737 Loss: 0.41042314674470876\n",
      "W1: 10.698703946887843 W2: 1.8572634542658113 b -5.616488473162268 Loss: 0.41042295731901485\n",
      "W1: 10.6989770299401 W2: 1.8572924407554043 b -5.616626248993112 Loss: 0.41042276825482665\n",
      "W1: 10.699249851914267 W2: 1.857321400291482 b -5.616763893929055 Loss: 0.4104225795514394\n",
      "W1: 10.699522413070799 W2: 1.8573503328994785 b -5.6169014080991175 Loss: 0.4104223912081505\n",
      "W1: 10.69979471366987 W2: 1.857379238604804 b -5.617038791632181 Loss: 0.4104222032242582\n",
      "W1: 10.700066753971374 W2: 1.8574081174328438 b -5.617176044656994 Loss: 0.41042201559906205\n",
      "W1: 10.700338534234923 W2: 1.8574369694089587 b -5.617313167302168 Loss: 0.4104218283318636\n",
      "W1: 10.700610054719855 W2: 1.8574657945584852 b -5.617450159696177 Loss: 0.41042164142196547\n",
      "W1: 10.700881315685221 W2: 1.8574945929067348 b -5.617587021967363 Loss: 0.41042145486867126\n",
      "W1: 10.7011523173898 W2: 1.857523364478995 b -5.617723754243933 Loss: 0.4104212686712867\n",
      "W1: 10.70142306009209 W2: 1.857552109300529 b -5.6178603566539556 Loss: 0.4104210828291184\n",
      "W1: 10.701693544050311 W2: 1.8575808273965748 b -5.617996829325367 Loss: 0.4104208973414749\n",
      "W1: 10.701963769522406 W2: 1.857609518792347 b -5.618133172385969 Loss: 0.41042071220766535\n",
      "W1: 10.702233736766042 W2: 1.857638183513035 b -5.618269385963427 Loss: 0.41042052742700114\n",
      "W1: 10.702503446038603 W2: 1.8576668215838041 b -5.618405470185274 Loss: 0.4104203429987942\n",
      "W1: 10.702772897597205 W2: 1.8576954330297957 b -5.618541425178908 Loss: 0.4104201589223587\n",
      "W1: 10.70304209169868 W2: 1.8577240178761265 b -5.618677251071593 Loss: 0.4104199751970093\n",
      "W1: 10.70331102859959 W2: 1.857752576147889 b -5.618812947990459 Loss: 0.41041979182206273\n",
      "W1: 10.703579708556216 W2: 1.8577811078701514 b -5.618948516062503 Loss: 0.4104196087968368\n",
      "W1: 10.703848131824568 W2: 1.8578096130679578 b -5.619083955414586 Loss: 0.41041942612065047\n",
      "W1: 10.704116298660379 W2: 1.857838091766328 b -5.61921926617344 Loss: 0.41041924379282474\n",
      "W1: 10.704384209319107 W2: 1.8578665439902577 b -5.619354448465659 Loss: 0.41041906181268134\n",
      "W1: 10.704651864055936 W2: 1.8578949697647187 b -5.619489502417707 Loss: 0.4104188801795435\n",
      "W1: 10.704919263125777 W2: 1.8579233691146582 b -5.619624428155914 Loss: 0.4104186988927358\n",
      "W1: 10.705186406783266 W2: 1.8579517420649994 b -5.619759225806478 Loss: 0.4104185179515846\n",
      "W1: 10.705453295282766 W2: 1.8579800886406417 b -5.619893895495462 Loss: 0.410418337355417\n",
      "W1: 10.705719928878366 W2: 1.8580084088664603 b -5.620028437348799 Loss: 0.4104181571035618\n",
      "W1: 10.705986307823887 W2: 1.8580367027673064 b -5.62016285149229 Loss: 0.41041797719534895\n",
      "W1: 10.706252432372871 W2: 1.8580649703680068 b -5.620297138051601 Loss: 0.41041779763010966\n",
      "W1: 10.706518302778592 W2: 1.858093211693365 b -5.620431297152269 Loss: 0.410417618407177\n",
      "W1: 10.706783919294054 W2: 1.8581214267681603 b -5.620565328919697 Loss: 0.410417439525885\n",
      "W1: 10.707049282171983 W2: 1.8581496156171475 b -5.620699233479158 Loss: 0.4104172609855689\n",
      "W1: 10.707314391664841 W2: 1.8581777782650584 b -5.620833010955792 Loss: 0.4104170827855656\n",
      "W1: 10.707579248024814 W2: 1.8582059147366004 b -5.6209666614746086 Loss: 0.4104169049252129\n",
      "W1: 10.70784385150382 W2: 1.858234025056457 b -5.621100185160485 Loss: 0.4104167274038504\n",
      "W1: 10.708108202353511 W2: 1.8582621092492884 b -5.621233582138169 Loss: 0.41041655022081885\n",
      "W1: 10.70837230082526 W2: 1.85829016733973 b -5.621366852532276 Loss: 0.41041637337546005\n",
      "W1: 10.708636147170179 W2: 1.8583181993523943 b -5.621499996467291 Loss: 0.4104161968671176\n",
      "W1: 10.708899741639105 W2: 1.8583462053118696 b -5.6216330140675685 Loss: 0.41041602069513594\n",
      "W1: 10.709163084482611 W2: 1.8583741852427207 b -5.621765905457333 Loss: 0.4104158448588612\n",
      "W1: 10.709426175951 W2: 1.8584021391694885 b -5.621898670760678 Loss: 0.41041566935764046\n",
      "W1: 10.709689016294304 W2: 1.8584300671166902 b -5.622031310101567 Loss: 0.41041549419082235\n",
      "W1: 10.70995160576229 W2: 1.8584579691088197 b -5.622163823603834 Loss: 0.41041531935775705\n",
      "W1: 10.710213944604458 W2: 1.8584858451703465 b -5.622296211391181 Loss: 0.41041514485779546\n",
      "W1: 10.71047603307004 W2: 1.858513695325717 b -5.622428473587184 Loss: 0.41041497069029015\n",
      "W1: 10.710737871408002 W2: 1.8585415195993542 b -5.622560610315286 Loss: 0.4104147968545947\n",
      "W1: 10.710999459867041 W2: 1.858569318015657 b -5.622692621698803 Loss: 0.4104146233500646\n",
      "W1: 10.71126079869559 W2: 1.8585970905990012 b -5.62282450786092 Loss: 0.4104144501760558\n",
      "W1: 10.711521888141817 W2: 1.8586248373737388 b -5.6229562689246935 Loss: 0.41041427733192626\n",
      "W1: 10.71178272845362 W2: 1.8586525583641982 b -5.623087905013051 Loss: 0.4104141048170348\n",
      "W1: 10.712043319878639 W2: 1.8586802535946847 b -5.623219416248792 Loss: 0.4104139326307415\n",
      "W1: 10.712303662664242 W2: 1.8587079230894796 b -5.623350802754585 Loss: 0.41041376077240804\n",
      "W1: 10.712563757057536 W2: 1.8587355668728414 b -5.623482064652973 Loss: 0.41041358924139715\n",
      "W1: 10.712823603305363 W2: 1.8587631849690047 b -5.62361320206637 Loss: 0.4104134180370728\n",
      "W1: 10.713083201654301 W2: 1.8587907774021808 b -5.623744215117059 Loss: 0.4104132471588004\n",
      "W1: 10.713342552350666 W2: 1.8588183441965578 b -5.6238751039271975 Loss: 0.4104130766059466\n",
      "W1: 10.713601655640508 W2: 1.8588458853763004 b -5.6240058686188155 Loss: 0.410412906377879\n",
      "W1: 10.713860511769616 W2: 1.8588734009655499 b -5.624136509313813 Loss: 0.410412736473967\n",
      "W1: 10.714119120983515 W2: 1.8589008909884244 b -5.624267026133965 Loss: 0.4104125668935808\n",
      "W1: 10.714377483527468 W2: 1.8589283554690186 b -5.624397419200917 Loss: 0.410412397636092\n",
      "W1: 10.714635599646478 W2: 1.8589557944314041 b -5.624527688636188 Loss: 0.41041222870087357\n",
      "W1: 10.714893469585283 W2: 1.8589832078996293 b -5.624657834561169 Loss: 0.41041206008729963\n",
      "W1: 10.71515109358836 W2: 1.8590105958977192 b -5.624787857097125 Loss: 0.4104118917947455\n",
      "W1: 10.715408471899929 W2: 1.8590379584496757 b -5.624917756365194 Loss: 0.4104117238225882\n",
      "W1: 10.715665604763943 W2: 1.8590652955794775 b -5.625047532486387 Loss: 0.4104115561702052\n",
      "W1: 10.7159224924241 W2: 1.8590926073110803 b -5.625177185581588 Loss: 0.41041138883697564\n",
      "W1: 10.716179135123836 W2: 1.8591198936684166 b -5.625306715771556 Loss: 0.41041122182228024\n",
      "W1: 10.716435533106324 W2: 1.8591471546753957 b -5.625436123176922 Loss: 0.4104110551255001\n",
      "W1: 10.716691686614482 W2: 1.8591743903559041 b -5.625565407918191 Loss: 0.4104108887460184\n",
      "W1: 10.716947595890966 W2: 1.8592016007338052 b -5.625694570115743 Loss: 0.4104107226832191\n",
      "W1: 10.717203261178176 W2: 1.8592287858329393 b -5.625823609889832 Loss: 0.4104105569364876\n",
      "W1: 10.717458682718249 W2: 1.8592559456771234 b -5.625952527360586 Loss: 0.4104103915052104\n",
      "W1: 10.717713860753067 W2: 1.859283080290152 b -5.626081322648007 Loss: 0.41041022638877506\n",
      "W1: 10.717968795524254 W2: 1.8593101896957966 b -5.626209995871973 Loss: 0.4104100615865708\n",
      "W1: 10.718223487273173 W2: 1.8593372739178058 b -5.626338547152234 Loss: 0.4104098970979877\n",
      "W1: 10.718477936240935 W2: 1.8593643329799048 b -5.626466976608418 Loss: 0.4104097329224173\n",
      "W1: 10.71873214266839 W2: 1.8593913669057962 b -5.626595284360026 Loss: 0.4104095690592519\n",
      "W1: 10.718986106796132 W2: 1.8594183757191602 b -5.626723470526436 Loss: 0.41040940550788585\n",
      "W1: 10.719239828864499 W2: 1.8594453594436535 b -5.626851535226898 Loss: 0.4104092422677137\n",
      "W1: 10.719493309113572 W2: 1.8594723181029102 b -5.626979478580541 Loss: 0.41040907933813187\n",
      "W1: 10.71974654778318 W2: 1.859499251720542 b -5.627107300706368 Loss: 0.41040891671853785\n",
      "W1: 10.71999954511289 W2: 1.8595261603201372 b -5.627235001723258 Loss: 0.4104087544083306\n",
      "W1: 10.720252301342017 W2: 1.8595530439252617 b -5.627362581749965 Loss: 0.4104085924069093\n",
      "W1: 10.720504816709623 W2: 1.8595799025594586 b -5.627490040905122 Loss: 0.41040843071367555\n",
      "W1: 10.720757091454512 W2: 1.8596067362462485 b -5.6276173793072335 Loss: 0.41040826932803154\n",
      "W1: 10.721009125815238 W2: 1.859633545009129 b -5.627744597074685 Loss: 0.4104081082493804\n",
      "W1: 10.721260920030096 W2: 1.8596603288715754 b -5.6278716943257345 Loss: 0.410407947477127\n",
      "W1: 10.721512474337128 W2: 1.85968708785704 b -5.627998671178519 Loss: 0.4104077870106772\n",
      "W1: 10.721763788974128 W2: 1.8597138219889526 b -5.628125527751052 Loss: 0.4104076268494378\n",
      "W1: 10.72201486417863 W2: 1.8597405312907207 b -5.6282522641612225 Loss: 0.41040746699281727\n",
      "W1: 10.722265700187922 W2: 1.8597672157857288 b -5.628378880526799 Loss: 0.4104073074402248\n",
      "W1: 10.722516297239032 W2: 1.859793875497339 b -5.628505376965424 Loss: 0.4104071481910708\n",
      "W1: 10.72276665556874 W2: 1.8598205104488912 b -5.628631753594621 Loss: 0.4104069892447672\n",
      "W1: 10.723016775413576 W2: 1.8598471206637024 b -5.628758010531787 Loss: 0.41040683060072686\n",
      "W1: 10.723266657009816 W2: 1.8598737061650674 b -5.6288841478942 Loss: 0.4104066722583639\n",
      "W1: 10.723516300593483 W2: 1.8599002669762583 b -5.629010165799015 Loss: 0.41040651421709345\n",
      "W1: 10.723765706400352 W2: 1.859926803120525 b -5.629136064363262 Loss: 0.41040635647633167\n",
      "W1: 10.724014874665945 W2: 1.8599533146210947 b -5.629261843703853 Loss: 0.4104061990354965\n",
      "W1: 10.724263805625537 W2: 1.8599798015011726 b -5.629387503937576 Loss: 0.4104060418940065\n",
      "W1: 10.72451249951415 W2: 1.8600062637839412 b -5.629513045181096 Loss: 0.41040588505128156\n",
      "W1: 10.724760956566556 W2: 1.8600327014925608 b -5.6296384675509605 Loss: 0.4104057285067426\n",
      "W1: 10.725009177017279 W2: 1.8600591146501695 b -5.629763771163592 Loss: 0.4104055722598119\n",
      "W1: 10.725257161100593 W2: 1.8600855032798829 b -5.629888956135294 Loss: 0.41040541630991273\n",
      "W1: 10.725504909050525 W2: 1.8601118674047943 b -5.630014022582246 Loss: 0.4104052606564697\n",
      "W1: 10.725752421100848 W2: 1.8601382070479748 b -5.630138970620511 Loss: 0.41040510529890833\n",
      "W1: 10.725999697485095 W2: 1.8601645222324736 b -5.630263800366025 Loss: 0.41040495023665535\n",
      "W1: 10.726246738436544 W2: 1.8601908129813174 b -5.63038851193461 Loss: 0.4104047954691389\n",
      "W1: 10.726493544188227 W2: 1.8602170793175106 b -5.630513105441962 Loss: 0.4104046409957877\n",
      "W1: 10.72674011497293 W2: 1.8602433212640355 b -5.63063758100366 Loss: 0.4104044868160321\n",
      "W1: 10.726986451023192 W2: 1.8602695388438524 b -5.630761938735161 Loss: 0.41040433292930345\n",
      "W1: 10.727232552571303 W2: 1.8602957320798994 b -5.630886178751803 Loss: 0.4104041793350341\n",
      "W1: 10.727478419849309 W2: 1.8603219009950926 b -5.631010301168802 Loss: 0.41040402603265774\n",
      "W1: 10.727724053089007 W2: 1.860348045612326 b -5.631134306101255 Loss: 0.4104038730216091\n",
      "W1: 10.727969452521952 W2: 1.8603741659544712 b -5.631258193664141 Loss: 0.41040372030132394\n",
      "W1: 10.728214618379448 W2: 1.8604002620443783 b -5.631381963972317 Loss: 0.41040356787123905\n",
      "W1: 10.728459550892559 W2: 1.860426333904875 b -5.6315056171405224 Loss: 0.4104034157307927\n",
      "W1: 10.7287042502921 W2: 1.8604523815587672 b -5.631629153283376 Loss: 0.4104032638794241\n",
      "W1: 10.728948716808643 W2: 1.8604784050288388 b -5.631752572515378 Loss: 0.4104031123165735\n",
      "W1: 10.729192950672516 W2: 1.8605044043378516 b -5.631875874950909 Loss: 0.4104029610416824\n",
      "W1: 10.7294369521138 W2: 1.8605303795085457 b -5.631999060704231 Loss: 0.4104028100541932\n",
      "W1: 10.729680721362337 W2: 1.8605563305636394 b -5.6321221298894875 Loss: 0.4104026593535496\n",
      "W1: 10.72992425864772 W2: 1.8605822575258288 b -5.6322450826207024 Loss: 0.4104025089391963\n",
      "W1: 10.730167564199304 W2: 1.8606081604177884 b -5.632367919011783 Loss: 0.4104023588105793\n",
      "W1: 10.730410638246195 W2: 1.8606340392621705 b -5.632490639176516 Loss: 0.4104022089671453\n",
      "W1: 10.73065348101726 W2: 1.8606598940816061 b -5.632613243228572 Loss: 0.4104020594083427\n",
      "W1: 10.730896092741123 W2: 1.860685724898704 b -5.6327357312815005 Loss: 0.41040191013362026\n",
      "W1: 10.731138473646165 W2: 1.8607115317360516 b -5.632858103448736 Loss: 0.4104017611424285\n",
      "W1: 10.731380623960527 W2: 1.860737314616214 b -5.632980359843595 Loss: 0.41040161243421863\n",
      "W1: 10.731622543912106 W2: 1.860763073561735 b -5.633102500579273 Loss: 0.4104014640084433\n",
      "W1: 10.73186423372856 W2: 1.860788808595137 b -5.633224525768852 Loss: 0.4104013158645557\n",
      "W1: 10.732105693637303 W2: 1.8608145197389196 b -5.633346435525294 Loss: 0.4104011680020106\n",
      "W1: 10.732346923865512 W2: 1.860840207015562 b -5.633468229961445 Loss: 0.4104010204202636\n",
      "W1: 10.73258792464012 W2: 1.8608658704475212 b -5.633589909190034 Loss: 0.41040087311877166\n",
      "W1: 10.732828696187822 W2: 1.8608915100572323 b -5.633711473323672 Loss: 0.4104007260969924\n",
      "W1: 10.733069238735071 W2: 1.8609171258671093 b -5.633832922474852 Loss: 0.41040057935438484\n",
      "W1: 10.733309552508084 W2: 1.8609427178995444 b -5.6339542567559535 Loss: 0.41040043289040895\n",
      "W1: 10.733549637732835 W2: 1.8609682861769081 b -5.634075476279237 Loss: 0.41040028670452594\n",
      "W1: 10.733789494635062 W2: 1.86099383072155 b -5.634196581156847 Loss: 0.41040014079619785\n",
      "W1: 10.73402912344026 W2: 1.8610193515557971 b -5.634317571500812 Loss: 0.41039999516488757\n",
      "W1: 10.734268524373691 W2: 1.861044848701956 b -5.634438447423045 Loss: 0.41039984981005995\n",
      "W1: 10.734507697660375 W2: 1.861070322182311 b -5.63455920903534 Loss: 0.41039970473118004\n",
      "W1: 10.734746643525094 W2: 1.861095772019126 b -5.634679856449377 Loss: 0.41039955992771426\n",
      "W1: 10.734985362192393 W2: 1.861121198234642 b -5.634800389776722 Loss: 0.41039941539913\n",
      "W1: 10.735223853886582 W2: 1.8611466008510797 b -5.634920809128823 Loss: 0.41039927114489566\n",
      "W1: 10.73546211883173 W2: 1.8611719798906383 b -5.635041114617012 Loss: 0.4103991271644814\n",
      "W1: 10.735700157251673 W2: 1.8611973353754951 b -5.635161306352508 Loss: 0.41039898345735715\n",
      "W1: 10.735937969370008 W2: 1.8612226673278067 b -5.635281384446412 Loss: 0.410398840022995\n",
      "W1: 10.736175555410096 W2: 1.861247975769708 b -5.635401349009711 Loss: 0.4103986968608675\n",
      "W1: 10.736412915595063 W2: 1.861273260723313 b -5.635521200153277 Loss: 0.4103985539704484\n",
      "W1: 10.736650050147798 W2: 1.8612985222107135 b -5.635640937987867 Loss: 0.41039841135121286\n",
      "W1: 10.736886959290956 W2: 1.861323760253981 b -5.635760562624125 Loss: 0.41039826900263604\n",
      "W1: 10.737123643246957 W2: 1.8613489748751653 b -5.635880074172578 Loss: 0.4103981269241956\n",
      "W1: 10.737360102237982 W2: 1.8613741660962952 b -5.635999472743638 Loss: 0.410397985115369\n",
      "W1: 10.737596336485984 W2: 1.8613993339393784 b -5.636118758447605 Loss: 0.4103978435756352\n",
      "W1: 10.737832346212677 W2: 1.861424478426401 b -5.636237931394663 Loss: 0.41039770230447453\n",
      "W1: 10.738068131639544 W2: 1.861449599579328 b -5.636356991694883 Loss: 0.4103975613013678\n",
      "W1: 10.73830369298783 W2: 1.8614746974201042 b -5.6364759394582205 Loss: 0.410397420565797\n",
      "W1: 10.738539030478552 W2: 1.8614997719706519 b -5.636594774794519 Loss: 0.4103972800972455\n",
      "W1: 10.73877414433249 W2: 1.8615248232528732 b -5.636713497813507 Loss: 0.41039713989519727\n",
      "W1: 10.739009034770191 W2: 1.8615498512886488 b -5.636832108624801 Loss: 0.4103969999591372\n",
      "W1: 10.739243702011972 W2: 1.8615748560998384 b -5.636950607337901 Loss: 0.4103968602885517\n",
      "W1: 10.739478146277916 W2: 1.861599837708281 b -5.637068994062198 Loss: 0.41039672088292806\n",
      "W1: 10.739712367787874 W2: 1.8616247961357941 b -5.637187268906966 Loss: 0.41039658174175436\n",
      "W1: 10.739946366761465 W2: 1.8616497314041747 b -5.637305431981367 Loss: 0.41039644286451976\n",
      "W1: 10.740180143418076 W2: 1.8616746435351983 b -5.63742348339445 Loss: 0.41039630425071444\n",
      "W1: 10.740413697976864 W2: 1.8616995325506198 b -5.637541423255152 Loss: 0.41039616589982975\n",
      "W1: 10.740647030656755 W2: 1.8617243984721734 b -5.637659251672298 Loss: 0.4103960278113577\n",
      "W1: 10.740880141676442 W2: 1.861749241321572 b -5.637776968754599 Loss: 0.4103958899847919\n",
      "W1: 10.74111303125439 W2: 1.8617740611205076 b -5.637894574610653 Loss: 0.4103957524196264\n",
      "W1: 10.741345699608832 W2: 1.8617988578906515 b -5.638012069348946 Loss: 0.41039561511535644\n",
      "W1: 10.741578146957774 W2: 1.8618236316536543 b -5.638129453077853 Loss: 0.41039547807147836\n",
      "W1: 10.74181037351899 W2: 1.8618483824311456 b -5.638246725905637 Loss: 0.4103953412874893\n",
      "W1: 10.742042379510023 W2: 1.8618731102447341 b -5.6383638879404465 Loss: 0.4103952047628875\n",
      "W1: 10.74227416514819 W2: 1.861897815116008 b -5.638480939290322 Loss: 0.41039506849717233\n",
      "W1: 10.74250573065058 W2: 1.8619224970665347 b -5.638597880063191 Loss: 0.4103949324898442\n",
      "W1: 10.742737076234047 W2: 1.8619471561178607 b -5.638714710366867 Loss: 0.4103947967404038\n",
      "W1: 10.742968202115224 W2: 1.8619717922915118 b -5.638831430309055 Loss: 0.41039466124835366\n",
      "W1: 10.743199108510513 W2: 1.861996405608993 b -5.638948039997348 Loss: 0.41039452601319704\n",
      "W1: 10.74342979563609 W2: 1.8620209960917893 b -5.639064539539227 Loss: 0.4103943910344379\n",
      "W1: 10.743660263707898 W2: 1.8620455637613642 b -5.6391809290420625 Loss: 0.4103942563115817\n",
      "W1: 10.74389051294166 W2: 1.862070108639161 b -5.639297208613114 Loss: 0.4103941218441344\n",
      "W1: 10.744120543552865 W2: 1.862094630746602 b -5.639413378359532 Loss: 0.41039398763160295\n",
      "W1: 10.744350355756783 W2: 1.8621191301050897 b -5.639529438388354 Loss: 0.4103938536734958\n",
      "W1: 10.74457994976845 W2: 1.8621436067360053 b -5.639645388806506 Loss: 0.4103937199693217\n",
      "W1: 10.744809325802681 W2: 1.8621680606607098 b -5.639761229720807 Loss: 0.41039358651859104\n",
      "W1: 10.745038484074064 W2: 1.8621924919005437 b -5.639876961237963 Loss: 0.41039345332081445\n",
      "W1: 10.745267424796959 W2: 1.8622169004768265 b -5.639992583464572 Loss: 0.41039332037550413\n",
      "W1: 10.745496148185502 W2: 1.862241286410858 b -5.64010809650712 Loss: 0.410393187682173\n",
      "W1: 10.745724654453607 W2: 1.8622656497239167 b -5.640223500471985 Loss: 0.410393055240335\n",
      "W1: 10.745952943814958 W2: 1.8622899904372614 b -5.640338795465434 Loss: 0.4103929230495048\n",
      "W1: 10.746181016483018 W2: 1.8623143085721299 b -5.640453981593623 Loss: 0.4103927911091984\n",
      "W1: 10.746408872671024 W2: 1.86233860414974 b -5.640569058962602 Loss: 0.4103926594189325\n",
      "W1: 10.746636512591989 W2: 1.862362877191289 b -5.640684027678309 Loss: 0.41039252797822506\n",
      "W1: 10.746863936458704 W2: 1.8623871277179536 b -5.6407988878465725 Loss: 0.4103923967865944\n",
      "W1: 10.747091144483733 W2: 1.8624113557508901 b -5.640913639573113 Loss: 0.4103922658435604\n",
      "W1: 10.74731813687942 W2: 1.862435561311235 b -5.641028282963542 Loss: 0.410392135148644\n",
      "W1: 10.747544913857885 W2: 1.8624597444201043 b -5.641142818123362 Loss: 0.4103920047013661\n",
      "W1: 10.747771475631025 W2: 1.8624839050985935 b -5.641257245157966 Loss: 0.41039187450124964\n",
      "W1: 10.747997822410513 W2: 1.8625080433677779 b -5.64137156417264 Loss: 0.41039174454781774\n",
      "W1: 10.748223954407802 W2: 1.8625321592487125 b -5.6414857752725585 Loss: 0.4103916148405949\n",
      "W1: 10.748449871834124 W2: 1.8625562527624324 b -5.641599878562791 Loss: 0.4103914853791066\n",
      "W1: 10.748675574900485 W2: 1.862580323929952 b -5.641713874148296 Loss: 0.4103913561628788\n",
      "W1: 10.748901063817675 W2: 1.8626043727722663 b -5.641827762133926 Loss: 0.4103912271914391\n",
      "W1: 10.749126338796257 W2: 1.8626283993103492 b -5.641941542624424 Loss: 0.4103910984643153\n",
      "W1: 10.749351400046578 W2: 1.8626524035651548 b -5.642055215724425 Loss: 0.4103909699810366\n",
      "W1: 10.74957624777876 W2: 1.8626763855576174 b -5.642168781538457 Loss: 0.4103908417411329\n",
      "W1: 10.74980088220271 W2: 1.8627003453086508 b -5.64228224017094 Loss: 0.41039071374413516\n",
      "W1: 10.750025303528108 W2: 1.862724282839149 b -5.642395591726187 Loss: 0.41039058598957523\n",
      "W1: 10.750249511964421 W2: 1.8627481981699858 b -5.642508836308402 Loss: 0.4103904584769858\n",
      "W1: 10.750473507720892 W2: 1.862772091322015 b -5.642621974021684 Loss: 0.41039033120590085\n",
      "W1: 10.750697291006546 W2: 1.8627959623160701 b -5.642735004970023 Loss: 0.41039020417585464\n",
      "W1: 10.750920862030187 W2: 1.862819811172965 b -5.642847929257301 Loss: 0.41039007738638295\n",
      "W1: 10.751144221000402 W2: 1.8628436379134934 b -5.642960746987296 Loss: 0.41038995083702223\n",
      "W1: 10.75136736812556 W2: 1.862867442558429 b -5.643073458263679 Loss: 0.4103898245273098\n",
      "W1: 10.751590303613812 W2: 1.8628912251285257 b -5.643186063190011 Loss: 0.41038969845678375\n",
      "W1: 10.751813027673087 W2: 1.8629149856445173 b -5.643298561869749 Loss: 0.4103895726249834\n",
      "W1: 10.752035540511102 W2: 1.862938724127118 b -5.643410954406243 Loss: 0.41038944703144914\n",
      "W1: 10.75225784233535 W2: 1.8629624405970218 b -5.643523240902737 Loss: 0.41038932167572156\n",
      "W1: 10.75247993335311 W2: 1.8629861350749028 b -5.643635421462368 Loss: 0.4103891965573427\n",
      "W1: 10.752701813771445 W2: 1.8630098075814157 b -5.643747496188167 Loss: 0.4103890716758556\n",
      "W1: 10.752923483797199 W2: 1.8630334581371946 b -5.643859465183061 Loss: 0.4103889470308037\n",
      "W1: 10.753144943636999 W2: 1.8630570867628546 b -5.643971328549868 Loss: 0.4103888226217318\n",
      "W1: 10.753366193497259 W2: 1.8630806934789907 b -5.644083086391301 Loss: 0.41038869844818554\n",
      "W1: 10.753587233584174 W2: 1.8631042783061782 b -5.64419473880997 Loss: 0.41038857450971095\n",
      "W1: 10.753808064103723 W2: 1.8631278412649723 b -5.644306285908376 Loss: 0.4103884508058558\n",
      "W1: 10.75402868526167 W2: 1.8631513823759087 b -5.644417727788918 Loss: 0.410388327336168\n",
      "W1: 10.754249097263564 W2: 1.8631749016595036 b -5.644529064553886 Loss: 0.4103882041001967\n",
      "W1: 10.75446930031474 W2: 1.8631983991362533 b -5.644640296305468 Loss: 0.410388081097492\n",
      "W1: 10.754689294620317 W2: 1.8632218748266343 b -5.644751423145745 Loss: 0.41038795832760466\n",
      "W1: 10.754909080385199 W2: 1.8632453287511037 b -5.644862445176695 Loss: 0.41038783579008664\n",
      "W1: 10.755128657814074 W2: 1.8632687609300989 b -5.64497336250019 Loss: 0.4103877134844902\n",
      "W1: 10.75534802711142 W2: 1.8632921713840376 b -5.645084175217996 Loss: 0.4103875914103693\n",
      "W1: 10.7555671884815 W2: 1.863315560133318 b -5.6451948834317776 Loss: 0.41038746956727823\n",
      "W1: 10.75578614212836 W2: 1.8633389271983187 b -5.645305487243092 Loss: 0.41038734795477205\n",
      "W1: 10.756004888255836 W2: 1.8633622725993988 b -5.6454159867533935 Loss: 0.4103872265724073\n",
      "W1: 10.756223427067551 W2: 1.8633855963568977 b -5.645526382064032 Loss: 0.41038710541974077\n",
      "W1: 10.756441758766913 W2: 1.8634088984911354 b -5.645636673276255 Loss: 0.41038698449633043\n",
      "W1: 10.75665988355712 W2: 1.8634321790224126 b -5.645746860491202 Loss: 0.41038686380173517\n",
      "W1: 10.756877801641155 W2: 1.86345543797101 b -5.645856943809912 Loss: 0.4103867433355145\n",
      "W1: 10.757095513221788 W2: 1.8634786753571893 b -5.64596692333332 Loss: 0.41038662309722923\n",
      "W1: 10.757313018501582 W2: 1.8635018912011927 b -5.646076799162255 Loss: 0.41038650308644037\n",
      "W1: 10.757530317682885 W2: 1.8635250855232428 b -5.646186571397447 Loss: 0.41038638330271043\n",
      "W1: 10.757747410967834 W2: 1.863548258343543 b -5.646296240139517 Loss: 0.4103862637456024\n",
      "W1: 10.757964298558356 W2: 1.8635714096822773 b -5.646405805488986 Loss: 0.41038614441468035\n",
      "W1: 10.758180980656165 W2: 1.86359453955961 b -5.646515267546273 Loss: 0.41038602530950924\n",
      "W1: 10.758397457462767 W2: 1.8636176479956865 b -5.6466246264116915 Loss: 0.4103859064296545\n",
      "W1: 10.758613729179453 W2: 1.8636407350106328 b -5.646733882185452 Loss: 0.41038578777468293\n",
      "W1: 10.75882979600731 W2: 1.8636638006245552 b -5.646843034967665 Loss: 0.4103856693441619\n",
      "W1: 10.75904565814721 W2: 1.8636868448575412 b -5.646952084858334 Loss: 0.4103855511376595\n",
      "W1: 10.759261315799819 W2: 1.8637098677296589 b -5.647061031957365 Loss: 0.4103854331547449\n",
      "W1: 10.75947676916559 W2: 1.863732869260957 b -5.647169876364557 Loss: 0.4103853153949882\n",
      "W1: 10.759692018444769 W2: 1.8637558494714652 b -5.64727861817961 Loss: 0.41038519785796007\n",
      "W1: 10.759907063837394 W2: 1.863778808381194 b -5.647387257502119 Loss: 0.41038508054323236\n",
      "W1: 10.760121905543294 W2: 1.8638017460101342 b -5.64749579443158 Loss: 0.4103849634503774\n",
      "W1: 10.760336543762087 W2: 1.863824662378258 b -5.647604229067384 Loss: 0.4103848465789685\n",
      "W1: 10.760550978693184 W2: 1.8638475575055182 b -5.647712561508822 Loss: 0.4103847299285801\n",
      "W1: 10.760765210535789 W2: 1.8638704314118486 b -5.647820791855082 Loss: 0.4103846134987869\n",
      "W1: 10.760979239488899 W2: 1.8638932841171638 b -5.647928920205252 Loss: 0.4103844972891649\n",
      "W1: 10.7611930657513 W2: 1.8639161156413593 b -5.6480369466583165 Loss: 0.410384381299291\n",
      "W1: 10.761406689521575 W2: 1.8639389260043115 b -5.64814487131316 Loss: 0.4103842655287423\n",
      "W1: 10.761620110998097 W2: 1.863961715225878 b -5.648252694268565 Loss: 0.41038414997709743\n",
      "W1: 10.761833330379032 W2: 1.863984483325897 b -5.6483604156232134 Loss: 0.4103840346439355\n",
      "W1: 10.762046347862341 W2: 1.8640072303241877 b -5.648468035475686 Loss: 0.4103839195288366\n",
      "W1: 10.76225916364578 W2: 1.8640299562405507 b -5.648575553924461 Loss: 0.41038380463138163\n",
      "W1: 10.762471777926896 W2: 1.8640526610947672 b -5.6486829710679185 Loss: 0.41038368995115204\n",
      "W1: 10.762684190903032 W2: 1.8640753449065997 b -5.648790287004335 Loss: 0.4103835754877304\n",
      "W1: 10.762896402771323 W2: 1.8640980076957914 b -5.648897501831889 Loss: 0.4103834612407002\n",
      "W1: 10.763108413728704 W2: 1.864120649482067 b -5.649004615648656 Loss: 0.4103833472096454\n",
      "W1: 10.763320223971897 W2: 1.8641432702851322 b -5.649111628552614 Loss: 0.410383233394151\n",
      "W1: 10.763531833697426 W2: 1.8641658701246735 b -5.6492185406416375 Loss: 0.41038311979380276\n",
      "W1: 10.763743243101608 W2: 1.864188449020359 b -5.649325352013504 Loss: 0.41038300640818726\n",
      "W1: 10.763954452380554 W2: 1.8642110069918378 b -5.649432062765888 Loss: 0.41038289323689187\n",
      "W1: 10.764165461730174 W2: 1.8642335440587399 b -5.649538672996365 Loss: 0.41038278027950487\n",
      "W1: 10.76437627134617 W2: 1.8642560602406766 b -5.649645182802413 Loss: 0.4103826675356153\n",
      "W1: 10.764586881424046 W2: 1.8642785555572405 b -5.649751592281406 Loss: 0.41038255500481297\n",
      "W1: 10.764797292159097 W2: 1.8643010300280056 b -5.6498579015306225 Loss: 0.41038244268668844\n",
      "W1: 10.765007503746416 W2: 1.8643234836725266 b -5.649964110647239 Loss: 0.410382330580833\n",
      "W1: 10.765217516380895 W2: 1.8643459165103402 b -5.650070219728333 Loss: 0.41038221868683933\n",
      "W1: 10.765427330257221 W2: 1.8643683285609638 b -5.650176228870883 Loss: 0.41038210700430006\n",
      "W1: 10.765636945569883 W2: 1.8643907198438963 b -5.65028213817177 Loss: 0.41038199553280935\n",
      "W1: 10.76584636251316 W2: 1.8644130903786178 b -5.650387947727772 Loss: 0.4103818842719617\n",
      "W1: 10.766055581281137 W2: 1.86443544018459 b -5.650493657635572 Loss: 0.41038177322135233\n",
      "W1: 10.76626460206769 W2: 1.8644577692812556 b -5.650599267991751 Loss: 0.4103816623805778\n",
      "W1: 10.766473425066499 W2: 1.8644800776880393 b -5.650704778892795 Loss: 0.4103815517492352\n",
      "W1: 10.76668205047104 W2: 1.8645023654243462 b -5.650810190435087 Loss: 0.4103814413269221\n",
      "W1: 10.766890478474588 W2: 1.864524632509564 b -5.6509155027149145 Loss: 0.41038133111323716\n",
      "W1: 10.767098709270218 W2: 1.8645468789630606 b -5.651020715828466 Loss: 0.41038122110777986\n",
      "W1: 10.767306743050804 W2: 1.8645691048041864 b -5.65112582987183 Loss: 0.41038111131015037\n",
      "W1: 10.767514580009019 W2: 1.8645913100522724 b -5.651230844941001 Loss: 0.4103810017199497\n",
      "W1: 10.767722220337335 W2: 1.8646134947266317 b -5.65133576113187 Loss: 0.4103808923367794\n",
      "W1: 10.767929664228028 W2: 1.864635658846559 b -5.651440578540234 Loss: 0.41038078316024235\n",
      "W1: 10.76813691187317 W2: 1.8646578024313296 b -5.651545297261792 Loss: 0.4103806741899417\n",
      "W1: 10.768343963464632 W2: 1.8646799255002016 b -5.651649917392143 Loss: 0.41038056542548135\n",
      "W1: 10.768550819194093 W2: 1.8647020280724136 b -5.651754439026789 Loss: 0.4103804568664664\n",
      "W1: 10.768757479253026 W2: 1.8647241101671863 b -5.651858862261135 Loss: 0.4103803485125027\n",
      "W1: 10.768963943832707 W2: 1.864746171803722 b -5.65196318719049 Loss: 0.4103802403631962\n",
      "W1: 10.769170213124216 W2: 1.8647682130012042 b -5.652067413910064 Loss: 0.41038013241815446\n",
      "W1: 10.769376287318432 W2: 1.8647902337787985 b -5.65217154251497 Loss: 0.4103800246769854\n",
      "W1: 10.769582166606035 W2: 1.864812234155652 b -5.652275573100224 Loss: 0.4103799171392977\n",
      "W1: 10.769787851177512 W2: 1.8648342141508933 b -5.652379505760744 Loss: 0.410379809804701\n",
      "W1: 10.769993341223147 W2: 1.864856173783633 b -5.6524833405913535 Loss: 0.4103797026728053\n",
      "W1: 10.770198636933028 W2: 1.8648781130729633 b -5.6525870776867775 Loss: 0.410379595743222\n",
      "W1: 10.770403738497047 W2: 1.8649000320379578 b -5.6526907171416445 Loss: 0.4103794890155625\n",
      "W1: 10.770608646104897 W2: 1.8649219306976723 b -5.652794259050487 Loss: 0.41037938248943995\n",
      "W1: 10.770813359946077 W2: 1.8649438090711439 b -5.652897703507741 Loss: 0.4103792761644671\n",
      "W1: 10.771017880209888 W2: 1.8649656671773918 b -5.653001050607746 Loss: 0.4103791700402585\n",
      "W1: 10.771222207085433 W2: 1.864987505035417 b -5.653104300444745 Loss: 0.41037906411642844\n",
      "W1: 10.771426340761622 W2: 1.865009322664202 b -5.653207453112886 Loss: 0.4103789583925932\n",
      "W1: 10.771630281427166 W2: 1.8650311200827114 b -5.653310508706219 Loss: 0.41037885286836845\n",
      "W1: 10.771834029270583 W2: 1.8650528973098919 b -5.653413467318699 Loss: 0.41037874754337195\n",
      "W1: 10.772037584480193 W2: 1.8650746543646715 b -5.653516329044186 Loss: 0.4103786424172211\n",
      "W1: 10.772240947244123 W2: 1.8650963912659602 b -5.653619093976444 Loss: 0.41037853748953484\n",
      "W1: 10.772444117750304 W2: 1.8651181080326502 b -5.653721762209142 Loss: 0.41037843275993213\n",
      "W1: 10.772647096186473 W2: 1.8651398046836156 b -5.653824333835851 Loss: 0.41037832822803355\n",
      "W1: 10.772849882740172 W2: 1.865161481237712 b -5.6539268089500485 Loss: 0.41037822389345957\n",
      "W1: 10.773052477598746 W2: 1.8651831377137773 b -5.654029187645118 Loss: 0.41037811975583216\n",
      "W1: 10.77325488094935 W2: 1.8652047741306315 b -5.654131470014344 Loss: 0.41037801581477323\n",
      "W1: 10.773457092978946 W2: 1.8652263905070763 b -5.654233656150922 Loss: 0.4103779120699062\n",
      "W1: 10.773659113874297 W2: 1.8652479868618956 b -5.654335746147946 Loss: 0.41037780852085465\n",
      "W1: 10.773860943821976 W2: 1.8652695632138552 b -5.654437740098419 Loss: 0.4103777051672433\n",
      "W1: 10.774062583008362 W2: 1.8652911195817028 b -5.6545396380952475 Loss: 0.4103776020086974\n",
      "W1: 10.774264031619643 W2: 1.8653126559841686 b -5.654641440231245 Loss: 0.410377499044843\n",
      "W1: 10.77446528984181 W2: 1.8653341724399646 b -5.65474314659913 Loss: 0.4103773962753067\n",
      "W1: 10.774666357860665 W2: 1.8653556689677846 b -5.654844757291526 Loss: 0.4103772936997164\n",
      "W1: 10.774867235861818 W2: 1.8653771455863053 b -5.654946272400962 Loss: 0.41037719131769984\n",
      "W1: 10.775067924030683 W2: 1.8653986023141846 b -5.655047692019874 Loss: 0.41037708912888626\n",
      "W1: 10.775268422552488 W2: 1.8654200391700633 b -5.655149016240602 Loss: 0.41037698713290527\n",
      "W1: 10.775468731612262 W2: 1.8654414561725638 b -5.655250245155395 Loss: 0.4103768853293873\n",
      "W1: 10.77566885139485 W2: 1.8654628533402913 b -5.655351378856405 Loss: 0.4103767837179634\n",
      "W1: 10.775868782084899 W2: 1.8654842306918327 b -5.655452417435692 Loss: 0.4103766822982655\n",
      "W1: 10.77606852386687 W2: 1.8655055882457572 b -5.655553360985221 Loss: 0.4103765810699262\n",
      "W1: 10.776268076925032 W2: 1.8655269260206164 b -5.6556542095968645 Loss: 0.4103764800325788\n",
      "W1: 10.77646744144346 W2: 1.8655482440349442 b -5.655754963362402 Loss: 0.41037637918585707\n",
      "W1: 10.776666617606043 W2: 1.8655695423072565 b -5.655855622373519 Loss: 0.4103762785293961\n",
      "W1: 10.776865605596479 W2: 1.8655908208560517 b -5.655956186721807 Loss: 0.4103761780628311\n",
      "W1: 10.777064405598274 W2: 1.8656120796998104 b -5.656056656498764 Loss: 0.41037607778579854\n",
      "W1: 10.777263017794747 W2: 1.8656333188569956 b -5.656157031795797 Loss: 0.4103759776979347\n",
      "W1: 10.777461442369026 W2: 1.8656545383460525 b -5.656257312704219 Loss: 0.41037587779887785\n",
      "W1: 10.77765967950405 W2: 1.865675738185409 b -5.6563574993152494 Loss: 0.4103757780882659\n",
      "W1: 10.777857729382566 W2: 1.8656969183934748 b -5.656457591720017 Loss: 0.41037567856573776\n",
      "W1: 10.778055592187139 W2: 1.8657180789886427 b -5.656557590009554 Loss: 0.41037557923093343\n",
      "W1: 10.778253268100139 W2: 1.8657392199892875 b -5.656657494274804 Loss: 0.41037548008349317\n",
      "W1: 10.77845075730375 W2: 1.8657603414137662 b -5.656757304606617 Loss: 0.4103753811230581\n",
      "W1: 10.778648059979968 W2: 1.8657814432804187 b -5.65685702109575 Loss: 0.4103752823492701\n",
      "W1: 10.7788451763106 W2: 1.8658025256075672 b -5.656956643832867 Loss: 0.4103751837617718\n",
      "W1: 10.779042106477268 W2: 1.8658235884135164 b -5.6570561729085425 Loss: 0.41037508536020617\n",
      "W1: 10.779238850661402 W2: 1.8658446317165533 b -5.657155608413256 Loss: 0.4103749871442173\n",
      "W1: 10.779435409044249 W2: 1.8658656555349478 b -5.657254950437398 Loss: 0.41037488911344977\n",
      "W1: 10.779631781806865 W2: 1.865886659886952 b -5.657354199071265 Loss: 0.4103747912675491\n",
      "W1: 10.779827969130121 W2: 1.8659076447908007 b -5.657453354405062 Loss: 0.4103746936061608\n",
      "W1: 10.780023971194701 W2: 1.8659286102647112 b -5.657552416528903 Loss: 0.410374596128932\n",
      "W1: 10.780219788181105 W2: 1.8659495563268835 b -5.65765138553281 Loss: 0.41037449883550997\n",
      "W1: 10.780415420269643 W2: 1.8659704829955002 b -5.657750261506714 Loss: 0.4103744017255428\n",
      "W1: 10.780610867640439 W2: 1.8659913902887262 b -5.657849044540455 Loss: 0.4103743047986793\n",
      "W1: 10.780806130473433 W2: 1.8660122782247095 b -5.6579477347237805 Loss: 0.4103742080545689\n",
      "W1: 10.78100120894838 W2: 1.8660331468215803 b -5.658046332146348 Loss: 0.4103741114928617\n",
      "W1: 10.781196103244849 W2: 1.8660539960974518 b -5.6581448368977245 Loss: 0.4103740151132085\n",
      "W1: 10.78139081354222 W2: 1.86607482607042 b -5.658243249067384 Loss: 0.41037391891526104\n",
      "W1: 10.781585340019694 W2: 1.8660956367585633 b -5.658341568744711 Loss: 0.41037382289867125\n",
      "W1: 10.781779682856282 W2: 1.8661164281799427 b -5.658439796019 Loss: 0.4103737270630922\n",
      "W1: 10.781973842230814 W2: 1.8661372003526022 b -5.658537930979453 Loss: 0.4103736314081775\n",
      "W1: 10.782167818321934 W2: 1.8661579532945687 b -5.658635973715183 Loss: 0.41037353593358117\n",
      "W1: 10.782361611308103 W2: 1.8661786870238515 b -5.658733924315212 Loss: 0.41037344063895825\n",
      "W1: 10.782555221367597 W2: 1.866199401558443 b -5.6588317828684715 Loss: 0.4103733455239642\n",
      "W1: 10.782748648678506 W2: 1.8662200969163183 b -5.658929549463805 Loss: 0.4103732505882554\n",
      "W1: 10.782941893418743 W2: 1.8662407731154351 b -5.659027224189962 Loss: 0.41037315583148876\n",
      "W1: 10.783134955766029 W2: 1.8662614301737344 b -5.659124807135604 Loss: 0.41037306125332196\n",
      "W1: 10.783327835897909 W2: 1.8662820681091397 b -5.659222298389303 Loss: 0.4103729668534131\n",
      "W1: 10.783520533991743 W2: 1.8663026869395574 b -5.659319698039541 Loss: 0.4103728726314213\n",
      "W1: 10.783713050224705 W2: 1.8663232866828767 b -5.659417006174709 Loss: 0.4103727785870061\n",
      "W1: 10.78390538477379 W2: 1.8663438673569703 b -5.65951422288311 Loss: 0.4103726847198276\n",
      "W1: 10.78409753781581 W2: 1.8663644289796932 b -5.659611348252957 Loss: 0.41037259102954715\n",
      "W1: 10.784289509527397 W2: 1.8663849715688834 b -5.659708382372373 Loss: 0.41037249751582583\n",
      "W1: 10.784481300084996 W2: 1.866405495142362 b -5.659805325329392 Loss: 0.41037240417832627\n",
      "W1: 10.784672909664874 W2: 1.8664259997179335 b -5.6599021772119595 Loss: 0.41037231101671134\n",
      "W1: 10.784864338443116 W2: 1.8664464853133846 b -5.659998938107931 Loss: 0.41037221803064444\n",
      "W1: 10.785055586595625 W2: 1.8664669519464854 b -5.660095608105072 Loss: 0.41037212521979005\n",
      "W1: 10.785246654298122 W2: 1.8664873996349889 b -5.660192187291062 Loss: 0.4103720325838129\n",
      "W1: 10.78543754172615 W2: 1.8665078283966314 b -5.660288675753489 Loss: 0.41037194012237865\n",
      "W1: 10.78562824905507 W2: 1.8665282382491322 b -5.660385073579853 Loss: 0.41037184783515346\n",
      "W1: 10.785818776460061 W2: 1.8665486292101934 b -5.660481380857566 Loss: 0.41037175572180407\n",
      "W1: 10.786009124116125 W2: 1.8665690012975005 b -5.66057759767395 Loss: 0.4103716637819982\n",
      "W1: 10.78619929219808 W2: 1.866589354528722 b -5.660673724116241 Loss: 0.41037157201540375\n",
      "W1: 10.786389280880567 W2: 1.8666096889215094 b -5.6607697602715845 Loss: 0.41037148042168975\n",
      "W1: 10.786579090338046 W2: 1.8666300044934974 b -5.660865706227038 Loss: 0.41037138900052544\n",
      "W1: 10.786768720744798 W2: 1.8666503012623041 b -5.660961562069573 Loss: 0.4103712977515814\n",
      "W1: 10.786958172274925 W2: 1.8666705792455305 b -5.661057327886069 Loss: 0.4103712066745276\n",
      "W1: 10.78714744510235 W2: 1.8666908384607608 b -5.661153003763321 Loss: 0.41037111576903607\n",
      "W1: 10.787336539400817 W2: 1.8667110789255625 b -5.661248589788034 Loss: 0.4103710250347786\n",
      "W1: 10.787525455343891 W2: 1.8667313006574866 b -5.661344086046827 Loss: 0.41037093447142775\n",
      "W1: 10.787714193104959 W2: 1.8667515036740667 b -5.661439492626231 Loss: 0.41037084407865704\n",
      "W1: 10.78790275285723 W2: 1.8667716879928202 b -5.661534809612688 Loss: 0.4103707538561402\n",
      "W1: 10.788091134773733 W2: 1.8667918536312473 b -5.661630037092554 Loss: 0.410370663803552\n",
      "W1: 10.788279339027323 W2: 1.866812000606832 b -5.661725175152096 Loss: 0.41037057392056764\n",
      "W1: 10.788467365790673 W2: 1.8668321289370415 b -5.661820223877496 Loss: 0.41037048420686284\n",
      "W1: 10.78865521523628 W2: 1.866852238639326 b -5.6619151833548464 Loss: 0.41037039466211417\n",
      "W1: 10.788842887536468 W2: 1.8668723297311196 b -5.662010053670155 Loss: 0.4103703052859988\n",
      "W1: 10.789030382863379 W2: 1.866892402229839 b -5.662104834909341 Loss: 0.41037021607819424\n",
      "W1: 10.789217701388978 W2: 1.866912456152885 b -5.662199527158236 Loss: 0.4103701270383791\n",
      "W1: 10.789404843285055 W2: 1.866932491517641 b -5.662294130502588 Loss: 0.4103700381662323\n",
      "W1: 10.789591808723227 W2: 1.8669525083414749 b -5.662388645028053 Loss: 0.4103699494614334\n",
      "W1: 10.789778597874928 W2: 1.866972506641737 b -5.662483070820206 Loss: 0.41036986092366273\n",
      "W1: 10.78996521091142 W2: 1.8669924864357617 b -5.662577407964531 Loss: 0.41036977255260126\n",
      "W1: 10.79015164800379 W2: 1.8670124477408663 b -5.662671656546429 Loss: 0.41036968434793036\n",
      "W1: 10.790337909322945 W2: 1.8670323905743522 b -5.662765816651213 Loss: 0.41036959630933223\n",
      "W1: 10.79052399503962 W2: 1.8670523149535037 b -5.6628598883641095 Loss: 0.4103695084364894\n",
      "W1: 10.790709905324377 W2: 1.867072220895589 b -5.662953871770259 Loss: 0.4103694207290855\n",
      "W1: 10.790895640347598 W2: 1.8670921084178596 b -5.663047766954718 Loss: 0.41036933318680435\n",
      "W1: 10.791081200279493 W2: 1.8671119775375506 b -5.663141574002453 Loss: 0.4103692458093305\n",
      "W1: 10.791266585290096 W2: 1.867131828271881 b -5.6632352929983485 Loss: 0.4103691585963494\n",
      "W1: 10.791451795549268 W2: 1.8671516606380525 b -5.663328924027201 Loss: 0.41036907154754676\n",
      "W1: 10.791636831226693 W2: 1.8671714746532513 b -5.663422467173723 Loss: 0.41036898466260907\n",
      "W1: 10.791821692491885 W2: 1.8671912703346467 b -5.66351592252254 Loss: 0.41036889794122294\n",
      "W1: 10.79200637951418 W2: 1.8672110476993917 b -5.663609290158193 Loss: 0.4103688113830765\n",
      "W1: 10.792190892462745 W2: 1.867230806764623 b -5.663702570165135 Loss: 0.4103687249878579\n",
      "W1: 10.792375231506568 W2: 1.8672505475474612 b -5.663795762627738 Loss: 0.4103686387552561\n",
      "W1: 10.792559396814468 W2: 1.86727027006501 b -5.663888867630287 Loss: 0.4103685526849606\n",
      "W1: 10.79274338855509 W2: 1.8672899743343572 b -5.663981885256979 Loss: 0.4103684667766611\n",
      "W1: 10.792927206896906 W2: 1.867309660372574 b -5.664074815591931 Loss: 0.4103683810300487\n",
      "W1: 10.793110852008214 W2: 1.8673293281967158 b -5.664167658719172 Loss: 0.4103682954448145\n",
      "W1: 10.79329432405714 W2: 1.8673489778238213 b -5.664260414722645 Loss: 0.41036821002065055\n",
      "W1: 10.793477623211638 W2: 1.8673686092709127 b -5.664353083686213 Loss: 0.4103681247572492\n",
      "W1: 10.793660749639491 W2: 1.867388222554997 b -5.664445665693649 Loss: 0.4103680396543036\n",
      "W1: 10.793843703508308 W2: 1.8674078176930637 b -5.664538160828645 Loss: 0.41036795471150744\n",
      "W1: 10.79402648498553 W2: 1.8674273947020872 b -5.664630569174807 Loss: 0.41036786992855495\n",
      "W1: 10.79420909423842 W2: 1.867446953599025 b -5.664722890815656 Loss: 0.41036778530514123\n",
      "W1: 10.794391531434076 W2: 1.8674664944008186 b -5.6648151258346315 Loss: 0.4103677008409615\n",
      "W1: 10.794573796739423 W2: 1.8674860171243934 b -5.664907274315087 Loss: 0.41036761653571197\n",
      "W1: 10.794755890321213 W2: 1.8675055217866587 b -5.664999336340291 Loss: 0.4103675323890894\n",
      "W1: 10.79493781234603 W2: 1.8675250084045074 b -5.665091311993429 Loss: 0.4103674484007907\n",
      "W1: 10.795119562980284 W2: 1.8675444769948166 b -5.665183201357603 Loss: 0.4103673645705141\n",
      "W1: 10.795301142390219 W2: 1.8675639275744473 b -5.6652750045158315 Loss: 0.41036728089795793\n",
      "W1: 10.795482550741905 W2: 1.8675833601602443 b -5.665366721551048 Loss: 0.41036719738282096\n",
      "W1: 10.795663788201244 W2: 1.8676027747690362 b -5.665458352546103 Loss: 0.4103671140248031\n",
      "W1: 10.795844854933968 W2: 1.8676221714176362 b -5.665549897583762 Loss: 0.41036703082360454\n",
      "W1: 10.796025751105638 W2: 1.8676415501228405 b -5.665641356746711 Loss: 0.41036694777892585\n",
      "W1: 10.796206476881647 W2: 1.86766091090143 b -5.665732730117549 Loss: 0.4103668648904686\n",
      "W1: 10.79638703242722 W2: 1.867680253770169 b -5.665824017778792 Loss: 0.4103667821579346\n",
      "W1: 10.796567417907408 W2: 1.8676995787458068 b -5.6659152198128755 Loss: 0.41036669958102634\n",
      "W1: 10.7967476334871 W2: 1.867718885845076 b -5.666006336302148 Loss: 0.4103666171594471\n",
      "W1: 10.796927679331013 W2: 1.8677381750846929 b -5.666097367328879 Loss: 0.4103665348929004\n",
      "W1: 10.797107555603693 W2: 1.8677574464813587 b -5.666188312975252 Loss: 0.4103664527810907\n",
      "W1: 10.797287262469522 W2: 1.8677767000517582 b -5.666279173323369 Loss: 0.41036637082372257\n",
      "W1: 10.79746680009271 W2: 1.8677959358125604 b -5.666369948455251 Loss: 0.4103662890205016\n",
      "W1: 10.797646168637304 W2: 1.8678151537804186 b -5.666460638452832 Loss: 0.4103662073711337\n",
      "W1: 10.797825368267178 W2: 1.86783435397197 b -5.666551243397967 Loss: 0.4103661258753253\n",
      "W1: 10.798004399146041 W2: 1.8678535364038356 b -5.666641763372428 Loss: 0.41036604453278386\n",
      "W1: 10.798183261437435 W2: 1.8678727010926213 b -5.666732198457904 Loss: 0.41036596334321673\n",
      "W1: 10.798361955304735 W2: 1.8678918480549167 b -5.666822548736002 Loss: 0.4103658823063325\n",
      "W1: 10.798540480911148 W2: 1.8679109773072957 b -5.6669128142882474 Loss: 0.41036580142183965\n",
      "W1: 10.798718838419715 W2: 1.8679300888663166 b -5.667002995196082 Loss: 0.41036572068944766\n",
      "W1: 10.79889702799331 W2: 1.8679491827485215 b -5.667093091540867 Loss: 0.41036564010886684\n",
      "W1: 10.799075049794638 W2: 1.867968258970437 b -5.667183103403881 Loss: 0.41036555967980726\n",
      "W1: 10.799252903986243 W2: 1.867987317548574 b -5.66727303086632 Loss: 0.4103654794019803\n",
      "W1: 10.7994305907305 W2: 1.8680063584994273 b -5.667362874009301 Loss: 0.41036539927509763\n",
      "W1: 10.799608110189618 W2: 1.8680253818394765 b -5.667452632913857 Loss: 0.4103653192988711\n",
      "W1: 10.79978546252564 W2: 1.8680443875851853 b -5.66754230766094 Loss: 0.41036523947301407\n",
      "W1: 10.799962647900447 W2: 1.8680633757530014 b -5.667631898331421 Loss: 0.4103651597972393\n",
      "W1: 10.800139666475749 W2: 1.8680823463593574 b -5.6677214050060885 Loss: 0.4103650802712609\n",
      "W1: 10.800316518413094 W2: 1.8681012994206698 b -5.667810827765651 Loss: 0.41036500089479344\n",
      "W1: 10.800493203873867 W2: 1.8681202349533395 b -5.6679001666907345 Loss: 0.41036492166755195\n",
      "W1: 10.800669723019285 W2: 1.8681391529737519 b -5.667989421861885 Loss: 0.4103648425892516\n",
      "W1: 10.800846076010401 W2: 1.868158053498277 b -5.668078593359568 Loss: 0.41036476365960906\n",
      "W1: 10.801022263008106 W2: 1.8681769365432686 b -5.668167681264166 Loss: 0.41036468487834055\n",
      "W1: 10.801198284173124 W2: 1.8681958021250653 b -5.668256685655983 Loss: 0.41036460624516324\n",
      "W1: 10.801374139666015 W2: 1.8682146502599903 b -5.66834560661524 Loss: 0.41036452775979537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.801549829647177 W2: 1.868233480964351 b -5.668434444222079 Loss: 0.4103644494219548\n",
      "W1: 10.801725354276845 W2: 1.8682522942544393 b -5.668523198556561 Loss: 0.4103643712313607\n",
      "W1: 10.801900713715089 W2: 1.8682710901465316 b -5.668611869698666 Loss: 0.4103642931877321\n",
      "W1: 10.802075908121813 W2: 1.868289868656889 b -5.668700457728295 Loss: 0.4103642152907892\n",
      "W1: 10.802250937656762 W2: 1.8683086298017566 b -5.668788962725266 Loss: 0.4103641375402528\n",
      "W1: 10.802425802479519 W2: 1.8683273735973647 b -5.668877384769319 Loss: 0.41036405993584335\n",
      "W1: 10.802600502749499 W2: 1.8683461000599273 b -5.668965723940113 Loss: 0.41036398247728273\n",
      "W1: 10.80277503862596 W2: 1.8683648092056437 b -5.669053980317229 Loss: 0.41036390516429305\n",
      "W1: 10.802949410267994 W2: 1.8683835010506977 b -5.6691421539801645 Loss: 0.41036382799659693\n",
      "W1: 10.803123617834531 W2: 1.8684021756112572 b -5.66923024500834 Loss: 0.4103637509739176\n",
      "W1: 10.803297661484342 W2: 1.8684208329034753 b -5.6693182534810935 Loss: 0.41036367409597874\n",
      "W1: 10.80347154137603 W2: 1.868439472943489 b -5.669406179477686 Loss: 0.41036359736250466\n",
      "W1: 10.803645257668045 W2: 1.8684580957474208 b -5.669494023077298 Loss: 0.41036352077322036\n",
      "W1: 10.803818810518669 W2: 1.8684767013313772 b -5.669581784359029 Loss: 0.4103634443278507\n",
      "W1: 10.803992200086025 W2: 1.8684952897114495 b -5.669669463401902 Loss: 0.41036336802612206\n",
      "W1: 10.804165426528074 W2: 1.8685138609037137 b -5.669757060284857 Loss: 0.41036329186776077\n",
      "W1: 10.804338490002618 W2: 1.8685324149242308 b -5.669844575086758 Loss: 0.4103632158524935\n",
      "W1: 10.804511390667296 W2: 1.868550951789046 b -5.669932007886389 Loss: 0.4103631399800479\n",
      "W1: 10.804684128679586 W2: 1.8685694715141894 b -5.6700193587624526 Loss: 0.41036306425015195\n",
      "W1: 10.804856704196808 W2: 1.8685879741156761 b -5.670106627793575 Loss: 0.41036298866253423\n",
      "W1: 10.805029117376122 W2: 1.8686064596095058 b -5.670193815058303 Loss: 0.4103629132169237\n",
      "W1: 10.805201368374526 W2: 1.8686249280116627 b -5.670280920635103 Loss: 0.4103628379130501\n",
      "W1: 10.805373457348857 W2: 1.8686433793381163 b -5.670367944602365 Loss: 0.4103627627506434\n",
      "W1: 10.805545384455796 W2: 1.8686618136048203 b -5.670454887038399 Loss: 0.4103626877294342\n",
      "W1: 10.80571714985186 W2: 1.8686802308277137 b -5.670541748021435 Loss: 0.41036261284915393\n",
      "W1: 10.805888753693413 W2: 1.86869863102272 b -5.670628527629628 Loss: 0.4103625381095339\n",
      "W1: 10.806060196136654 W2: 1.8687170142057479 b -5.670715225941052 Loss: 0.41036246351030653\n",
      "W1: 10.806231477337626 W2: 1.8687353803926905 b -5.670801843033703 Loss: 0.41036238905120437\n",
      "W1: 10.80640259745221 W2: 1.868753729599426 b -5.6708883789855 Loss: 0.41036231473196094\n",
      "W1: 10.806573556636135 W2: 1.8687720618418178 b -5.670974833874281 Loss: 0.41036224055230974\n",
      "W1: 10.806744355044962 W2: 1.8687903771357135 b -5.671061207777809 Loss: 0.4103621665119853\n",
      "W1: 10.806914992834104 W2: 1.8688086754969464 b -5.671147500773768 Loss: 0.4103620926107221\n",
      "W1: 10.807085470158807 W2: 1.868826956941334 b -5.671233712939763 Loss: 0.41036201884825557\n",
      "W1: 10.807255787174165 W2: 1.8688452214846794 b -5.671319844353323 Loss: 0.4103619452243217\n",
      "W1: 10.807425944035112 W2: 1.8688634691427701 b -5.6714058950918975 Loss: 0.41036187173865657\n",
      "W1: 10.807595940896425 W2: 1.868881699931379 b -5.67149186523286 Loss: 0.4103617983909972\n",
      "W1: 10.807765777912723 W2: 1.8688999138662639 b -5.671577754853505 Loss: 0.41036172518108066\n",
      "W1: 10.807935455238466 W2: 1.8689181109631674 b -5.671663564031051 Loss: 0.4103616521086452\n",
      "W1: 10.808104973027962 W2: 1.8689362912378171 b -5.671749292842637 Loss: 0.410361579173429\n",
      "W1: 10.808274331435358 W2: 1.868954454705926 b -5.671834941365327 Loss: 0.41036150637517094\n",
      "W1: 10.808443530614646 W2: 1.868972601383192 b -5.671920509676105 Loss: 0.4103614337136103\n",
      "W1: 10.80861257071966 W2: 1.8689907312852978 b -5.6720059978518815 Loss: 0.41036136118848726\n",
      "W1: 10.80878145190408 W2: 1.8690088444279116 b -5.6720914059694865 Loss: 0.4103612887995419\n",
      "W1: 10.808950174321426 W2: 1.8690269408266862 b -5.672176734105675 Loss: 0.4103612165465153\n",
      "W1: 10.809118738125067 W2: 1.86904502049726 b -5.672261982337125 Loss: 0.4103611444291488\n",
      "W1: 10.809287143468211 W2: 1.8690630834552562 b -5.672347150740436 Loss: 0.4103610724471843\n",
      "W1: 10.809455390503915 W2: 1.869081129716283 b -5.672432239392133 Loss: 0.4103610006003642\n",
      "W1: 10.809623479385078 W2: 1.8690991592959345 b -5.6725172483686634 Loss: 0.4103609288884313\n",
      "W1: 10.809791410264443 W2: 1.869117172209789 b -5.6726021777463975 Loss: 0.4103608573111293\n",
      "W1: 10.809959183294602 W2: 1.8691351684734105 b -5.672687027601629 Loss: 0.41036078586820196\n",
      "W1: 10.810126798627985 W2: 1.8691531481023484 b -5.672771798010577 Loss: 0.4103607145593937\n",
      "W1: 10.810294256416874 W2: 1.8691711111121367 b -5.672856489049382 Loss: 0.41036064338444905\n",
      "W1: 10.810461556813392 W2: 1.8691890575182952 b -5.67294110079411 Loss: 0.4103605723431139\n",
      "W1: 10.81062869996951 W2: 1.8692069873363286 b -5.67302563332075 Loss: 0.41036050143513375\n",
      "W1: 10.810795686037043 W2: 1.869224900581727 b -5.673110086705214 Loss: 0.4103604306602555\n",
      "W1: 10.810962515167654 W2: 1.8692427972699657 b -5.673194461023341 Loss: 0.41036036001822535\n",
      "W1: 10.81112918751285 W2: 1.8692606774165053 b -5.673278756350891 Loss: 0.410360289508791\n",
      "W1: 10.811295703223987 W2: 1.8692785410367916 b -5.67336297276355 Loss: 0.4103602191317002\n",
      "W1: 10.811462062452263 W2: 1.869296388146256 b -5.673447110336927 Loss: 0.4103601488867014\n",
      "W1: 10.811628265348723 W2: 1.8693142187603151 b -5.673531169146555 Loss: 0.4103600787735434\n",
      "W1: 10.811794312064265 W2: 1.8693320328943706 b -5.673615149267894 Loss: 0.4103600087919754\n",
      "W1: 10.811960202749628 W2: 1.8693498305638097 b -5.673699050776326 Loss: 0.41035993894174716\n",
      "W1: 10.812125937555399 W2: 1.869367611784005 b -5.673782873747159 Loss: 0.4103598692226092\n",
      "W1: 10.812291516632014 W2: 1.8693853765703146 b -5.673866618255625 Loss: 0.4103597996343122\n",
      "W1: 10.812456940129755 W2: 1.8694031249380818 b -5.67395028437688 Loss: 0.4103597301766072\n",
      "W1: 10.812622208198752 W2: 1.8694208569026354 b -5.674033872186007 Loss: 0.41035966084924597\n",
      "W1: 10.812787320988983 W2: 1.8694385724792895 b -5.674117381758011 Loss: 0.410359591651981\n",
      "W1: 10.812952278650274 W2: 1.8694562716833438 b -5.6742008131678245 Loss: 0.41035952258456465\n",
      "W1: 10.813117081332297 W2: 1.8694739545300836 b -5.674284166490304 Loss: 0.4103594536467503\n",
      "W1: 10.813281729184576 W2: 1.8694916210347794 b -5.674367441800231 Loss: 0.4103593848382916\n",
      "W1: 10.813446222356479 W2: 1.8695092712126873 b -5.6744506391723135 Loss: 0.4103593161589425\n",
      "W1: 10.813610560997226 W2: 1.8695269050790486 b -5.674533758681182 Loss: 0.41035924760845766\n",
      "W1: 10.813774745255886 W2: 1.8695445226490908 b -5.674616800401395 Loss: 0.41035917918659215\n",
      "W1: 10.813938775281374 W2: 1.869562123938026 b -5.674699764407436 Loss: 0.41035911089310145\n",
      "W1: 10.814102651222456 W2: 1.8695797089610526 b -5.674782650773714 Loss: 0.41035904272774176\n",
      "W1: 10.814266373227747 W2: 1.8695972777333545 b -5.674865459574562 Loss: 0.4103589746902696\n",
      "W1: 10.814429941445713 W2: 1.8696148302701006 b -5.674948190884241 Loss: 0.4103589067804416\n",
      "W1: 10.814593356024668 W2: 1.8696323665864458 b -5.675030844776937 Loss: 0.4103588389980157\n",
      "W1: 10.814756617112774 W2: 1.8696498866975306 b -5.675113421326761 Loss: 0.4103587713427493\n",
      "W1: 10.814919724858045 W2: 1.869667390618481 b -5.6751959206077505 Loss: 0.41035870381440115\n",
      "W1: 10.815082679408345 W2: 1.8696848783644089 b -5.67527834269387 Loss: 0.41035863641272974\n",
      "W1: 10.815245480911388 W2: 1.8697023499504113 b -5.675360687659009 Loss: 0.41035856913749474\n",
      "W1: 10.81540812951474 W2: 1.8697198053915711 b -5.675442955576984 Loss: 0.4103585019884557\n",
      "W1: 10.815570625365813 W2: 1.8697372447029572 b -5.675525146521537 Loss: 0.41035843496537283\n",
      "W1: 10.815732968611876 W2: 1.869754667899624 b -5.675607260566335 Loss: 0.4103583680680071\n",
      "W1: 10.815895159400043 W2: 1.8697720749966111 b -5.675689297784975 Loss: 0.41035830129611933\n",
      "W1: 10.816057197877283 W2: 1.8697894660089445 b -5.675771258250977 Loss: 0.41035823464947135\n",
      "W1: 10.816219084190417 W2: 1.8698068409516355 b -5.6758531420377905 Loss: 0.4103581681278254\n",
      "W1: 10.816380818486111 W2: 1.8698241998396812 b -5.67593494921879 Loss: 0.4103581017309436\n",
      "W1: 10.81654240091089 W2: 1.8698415426880646 b -5.676016679867276 Loss: 0.4103580354585892\n",
      "W1: 10.816703831611127 W2: 1.8698588695117544 b -5.676098334056477 Loss: 0.41035796931052587\n",
      "W1: 10.816865110733048 W2: 1.8698761803257051 b -5.67617991185955 Loss: 0.41035790328651717\n",
      "W1: 10.817026238422729 W2: 1.869893475144857 b -5.676261413349575 Loss: 0.4103578373863277\n",
      "W1: 10.817187214826102 W2: 1.869910753984136 b -5.676342838599563 Loss: 0.41035777160972225\n",
      "W1: 10.817348040088948 W2: 1.869928016858454 b -5.67642418768245 Loss: 0.410357705956466\n",
      "W1: 10.817508714356903 W2: 1.8699452637827088 b -5.676505460671099 Loss: 0.41035764042632494\n",
      "W1: 10.817669237775453 W2: 1.869962494771784 b -5.6765866576383015 Loss: 0.41035757501906506\n",
      "W1: 10.81782961048994 W2: 1.8699797098405488 b -5.676667778656775 Loss: 0.4103575097344532\n",
      "W1: 10.817989832645555 W2: 1.8699969090038586 b -5.676748823799166 Loss: 0.41035744457225615\n",
      "W1: 10.818149904387347 W2: 1.8700140922765547 b -5.676829793138047 Loss: 0.41035737953224183\n",
      "W1: 10.818309825860215 W2: 1.870031259673464 b -5.67691068674592 Loss: 0.41035731461417785\n",
      "W1: 10.818469597208912 W2: 1.8700484112093998 b -5.676991504695213 Loss: 0.41035724981783317\n",
      "W1: 10.818629218578046 W2: 1.8700655468991607 b -5.677072247058282 Loss: 0.41035718514297626\n",
      "W1: 10.818788690112077 W2: 1.8700826667575317 b -5.677152913907412 Loss: 0.4103571205893765\n",
      "W1: 10.818948011955321 W2: 1.8700997707992837 b -5.677233505314815 Loss: 0.4103570561568041\n",
      "W1: 10.819107184251946 W2: 1.8701168590391735 b -5.67731402135263 Loss: 0.41035699184502883\n",
      "W1: 10.819266207145976 W2: 1.8701339314919438 b -5.677394462092925 Loss: 0.4103569276538215\n",
      "W1: 10.819425080781288 W2: 1.8701509881723235 b -5.677474827607698 Loss: 0.41035686358295326\n",
      "W1: 10.819583805301615 W2: 1.8701680290950273 b -5.677555117968873 Loss: 0.4103567996321958\n",
      "W1: 10.819742380850546 W2: 1.8701850542747562 b -5.677635333248301 Loss: 0.410356735801321\n",
      "W1: 10.819900807571521 W2: 1.8702020637261971 b -5.6777154735177655 Loss: 0.4103566720901011\n",
      "W1: 10.82005908560784 W2: 1.8702190574640227 b -5.677795538848975 Loss: 0.41035660849830946\n",
      "W1: 10.820217215102652 W2: 1.8702360355028922 b -5.677875529313567 Loss: 0.4103565450257191\n",
      "W1: 10.820375196198967 W2: 1.8702529978574505 b -5.677955444983111 Loss: 0.4103564816721039\n",
      "W1: 10.82053302903965 W2: 1.870269944542329 b -5.6780352859290995 Loss: 0.41035641843723797\n",
      "W1: 10.82069071376742 W2: 1.870286875572145 b -5.6781150522229575 Loss: 0.41035635532089604\n",
      "W1: 10.82084825052485 W2: 1.8703037909615015 b -5.6781947439360385 Loss: 0.41035629232285326\n",
      "W1: 10.821005639454373 W2: 1.8703206907249883 b -5.678274361139625 Loss: 0.41035622944288463\n",
      "W1: 10.821162880698278 W2: 1.870337574877181 b -5.6783539039049264 Loss: 0.41035616668076674\n",
      "W1: 10.821319974398707 W2: 1.8703544434326418 b -5.678433372303084 Loss: 0.4103561040362757\n",
      "W1: 10.82147692069766 W2: 1.8703712964059185 b -5.678512766405167 Loss: 0.4103560415091884\n",
      "W1: 10.821633719736997 W2: 1.8703881338115451 b -5.6785920862821735 Loss: 0.4103559790992819\n",
      "W1: 10.82179037165843 W2: 1.8704049556640423 b -5.678671332005031 Loss: 0.410355916806334\n",
      "W1: 10.82194687660353 W2: 1.8704217619779167 b -5.678750503644596 Loss: 0.4103558546301228\n",
      "W1: 10.822103234713726 W2: 1.870438552767661 b -5.678829601271656 Loss: 0.4103557925704269\n",
      "W1: 10.822259446130303 W2: 1.8704553280477545 b -5.678908624956927 Loss: 0.410355730627025\n",
      "W1: 10.822415510994405 W2: 1.8704720878326626 b -5.678987574771054 Loss: 0.41035566879969676\n",
      "W1: 10.822571429447033 W2: 1.870488832136837 b -5.679066450784613 Loss: 0.41035560708822183\n",
      "W1: 10.822727201629045 W2: 1.8705055609747152 b -5.679145253068108 Loss: 0.41035554549238057\n",
      "W1: 10.822882827681156 W2: 1.8705222743607217 b -5.679223981691974 Loss: 0.41035548401195343\n",
      "W1: 10.823038307743941 W2: 1.8705389723092671 b -5.679302636726577 Loss: 0.41035542264672176\n",
      "W1: 10.823193641957834 W2: 1.8705556548347482 b -5.679381218242211 Loss: 0.4103553613964669\n",
      "W1: 10.823348830463127 W2: 1.8705723219515482 b -5.6794597263091005 Loss: 0.4103553002609707\n",
      "W1: 10.823503873399968 W2: 1.8705889736740366 b -5.6795381609974 Loss: 0.4103552392400157\n",
      "W1: 10.823658770908366 W2: 1.8706056100165693 b -5.679616522377196 Loss: 0.4103551783333847\n",
      "W1: 10.82381352312819 W2: 1.8706222309934886 b -5.679694810518503 Loss: 0.41035511754086057\n",
      "W1: 10.823968130199162 W2: 1.8706388366191231 b -5.679773025491267 Loss: 0.4103550568622273\n",
      "W1: 10.824122592260872 W2: 1.870655426907788 b -5.6798511673653636 Loss: 0.4103549962972686\n",
      "W1: 10.824276909452763 W2: 1.8706720018737846 b -5.6799292362106 Loss: 0.4103549358457691\n",
      "W1: 10.82443108191414 W2: 1.870688561531401 b -5.680007232096713 Loss: 0.4103548755075135\n",
      "W1: 10.824585109784167 W2: 1.8707051058949118 b -5.680085155093371 Loss: 0.41035481528228723\n",
      "W1: 10.824738993201866 W2: 1.8707216349785774 b -5.680163005270172 Loss: 0.4103547551698759\n",
      "W1: 10.824892732306122 W2: 1.8707381487966452 b -5.680240782696646 Loss: 0.41035469517006573\n",
      "W1: 10.825046327235679 W2: 1.8707546473633494 b -5.680318487442252 Loss: 0.4103546352826431\n",
      "W1: 10.825199778129143 W2: 1.8707711306929098 b -5.680396119576382 Loss: 0.4103545755073949\n",
      "W1: 10.825353085124975 W2: 1.8707875987995335 b -5.680473679168357 Loss: 0.4103545158441085\n",
      "W1: 10.825506248361503 W2: 1.8708040516974136 b -5.680551166287432 Loss: 0.4103544562925718\n",
      "W1: 10.825659267976912 W2: 1.8708204894007299 b -5.680628581002791 Loss: 0.4103543968525726\n",
      "W1: 10.825812144109248 W2: 1.870836911923649 b -5.680705923383549 Loss: 0.4103543375238999\n",
      "W1: 10.82596487689642 W2: 1.8708533192803238 b -5.680783193498753 Loss: 0.41035427830634236\n",
      "W1: 10.826117466476196 W2: 1.8708697114848938 b -5.680860391417381 Loss: 0.41035421919968956\n",
      "W1: 10.826269912986207 W2: 1.870886088551485 b -5.680937517208345 Loss: 0.4103541602037311\n",
      "W1: 10.826422216563945 W2: 1.8709024504942104 b -5.681014570940484 Loss: 0.41035410131825734\n",
      "W1: 10.82657437734676 W2: 1.8709187973271693 b -5.681091552682571 Loss: 0.41035404254305874\n",
      "W1: 10.826726395471871 W2: 1.8709351290644474 b -5.681168462503312 Loss: 0.41035398387792626\n",
      "W1: 10.826878271076353 W2: 1.8709514457201175 b -5.681245300471342 Loss: 0.41035392532265164\n",
      "W1: 10.827030004297146 W2: 1.870967747308239 b -5.6813220666552295 Loss: 0.4103538668770263\n",
      "W1: 10.827181595271052 W2: 1.8709840338428576 b -5.681398761123475 Loss: 0.4103538085408425\n",
      "W1: 10.82733304413473 W2: 1.871000305338006 b -5.68147538394451 Loss: 0.41035375031389304\n",
      "W1: 10.827484351024713 W2: 1.8710165618077035 b -5.6815519351866985 Loss: 0.4103536921959709\n",
      "W1: 10.827635516077386 W2: 1.8710328032659562 b -5.681628414918337 Loss: 0.4103536341868693\n",
      "W1: 10.827786539429 W2: 1.8710490297267568 b -5.681704823207653 Loss: 0.4103535762863821\n",
      "W1: 10.827937421215672 W2: 1.8710652412040847 b -5.681781160122808 Loss: 0.4103535184943038\n",
      "W1: 10.82808816157338 W2: 1.871081437711906 b -5.681857425731895 Loss: 0.4103534608104285\n",
      "W1: 10.828238760637962 W2: 1.871097619264174 b -5.681933620102939 Loss: 0.4103534032345515\n",
      "W1: 10.828389218545125 W2: 1.8711137858748281 b -5.6820097433038965 Loss: 0.4103533457664683\n",
      "W1: 10.828539535430437 W2: 1.871129937557795 b -5.68208579540266 Loss: 0.41035328840597435\n",
      "W1: 10.828689711429329 W2: 1.871146074326988 b -5.682161776467051 Loss: 0.41035323115286604\n",
      "W1: 10.828839746677097 W2: 1.8711621961963074 b -5.682237686564826 Loss: 0.41035317400694\n",
      "W1: 10.828989641308901 W2: 1.8711783031796398 b -5.682313525763672 Loss: 0.4103531169679931\n",
      "W1: 10.829139395459764 W2: 1.8711943952908592 b -5.6823892941312115 Loss: 0.41035306003582245\n",
      "W1: 10.829289009264574 W2: 1.871210472543826 b -5.6824649917349985 Loss: 0.4103530032102263\n",
      "W1: 10.829438482858086 W2: 1.8712265349523882 b -5.68254061864252 Loss: 0.4103529464910023\n",
      "W1: 10.829587816374914 W2: 1.8712425825303798 b -5.682616174921195 Loss: 0.4103528898779492\n",
      "W1: 10.829737009949543 W2: 1.871258615291622 b -5.682691660638378 Loss: 0.410352833370866\n",
      "W1: 10.829886063716318 W2: 1.871274633249923 b -5.682767075861355 Loss: 0.41035277696955197\n",
      "W1: 10.83003497780945 W2: 1.871290636419078 b -5.6828424206573445 Loss: 0.4103527206738067\n",
      "W1: 10.830183752363018 W2: 1.871306624812869 b -5.682917695093502 Loss: 0.41035266448343016\n",
      "W1: 10.830332387510964 W2: 1.8713225984450648 b -5.682992899236911 Loss: 0.41035260839822296\n",
      "W1: 10.830480883387095 W2: 1.8713385573294212 b -5.683068033154594 Loss: 0.41035255241798596\n",
      "W1: 10.830629240125084 W2: 1.8713545014796813 b -5.683143096913503 Loss: 0.41035249654252026\n",
      "W1: 10.830777457858474 W2: 1.871370430909575 b -5.683218090580525 Loss: 0.41035244077162775\n",
      "W1: 10.830925536720667 W2: 1.8713863456328186 b -5.683293014222481 Loss: 0.41035238510511\n",
      "W1: 10.831073476844935 W2: 1.8714022456631163 b -5.683367867906125 Loss: 0.4103523295427696\n",
      "W1: 10.831221278364415 W2: 1.871418131014159 b -5.6834426516981456 Loss: 0.4103522740844095\n",
      "W1: 10.831368941412112 W2: 1.8714340016996245 b -5.683517365665165 Loss: 0.41035221872983246\n",
      "W1: 10.831516466120897 W2: 1.8714498577331775 b -5.683592009873739 Loss: 0.4103521634788423\n",
      "W1: 10.831663852623507 W2: 1.8714656991284702 b -5.683666584390358 Loss: 0.41035210833124247\n",
      "W1: 10.831811101052544 W2: 1.8714815258991413 b -5.683741089281446 Loss: 0.4103520532868379\n",
      "W1: 10.83195821154048 W2: 1.871497338058817 b -5.683815524613362 Loss: 0.4103519983454327\n",
      "W1: 10.832105184219651 W2: 1.8715131356211103 b -5.683889890452398 Loss: 0.4103519435068321\n",
      "W1: 10.832252019222265 W2: 1.871528918599622 b -5.683964186864781 Loss: 0.41035188877084144\n",
      "W1: 10.832398716680395 W2: 1.871544687007939 b -5.684038413916673 Loss: 0.41035183413726634\n",
      "W1: 10.832545276725977 W2: 1.871560440859636 b -5.684112571674168 Loss: 0.41035177960591335\n",
      "W1: 10.832691699490821 W2: 1.8715761801682747 b -5.684186660203299 Loss: 0.41035172517658863\n",
      "W1: 10.832837985106604 W2: 1.8715919049474037 b -5.684260679570029 Loss: 0.41035167084909907\n",
      "W1: 10.832984133704867 W2: 1.8716076152105592 b -5.684334629840258 Loss: 0.41035161662325237\n",
      "W1: 10.833130145417023 W2: 1.8716233109712643 b -5.684408511079821 Loss: 0.41035156249885546\n",
      "W1: 10.83327602037435 W2: 1.8716389922430294 b -5.6844823233544854 Loss: 0.41035150847571694\n",
      "W1: 10.833421758707999 W2: 1.871654659039352 b -5.684556066729957 Loss: 0.41035145455364486\n",
      "W1: 10.833567360548985 W2: 1.8716703113737168 b -5.684629741271874 Loss: 0.41035140073244825\n",
      "W1: 10.833712826028192 W2: 1.8716859492595956 b -5.684703347045811 Loss: 0.41035134701193576\n",
      "W1: 10.833858155276376 W2: 1.871701572710448 b -5.684776884117275 Loss: 0.4103512933919173\n",
      "W1: 10.83400334842416 W2: 1.8717171817397205 b -5.684850352551711 Loss: 0.4103512398722025\n",
      "W1: 10.834148405602035 W2: 1.8717327763608465 b -5.6849237524145 Loss: 0.4103511864526016\n",
      "W1: 10.834293326940363 W2: 1.8717483565872473 b -5.684997083770955 Loss: 0.4103511331329251\n",
      "W1: 10.834438112569375 W2: 1.8717639224323308 b -5.6850703466863255 Loss: 0.4103510799129842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.83458276261917 W2: 1.871779473909493 b -5.6851435412257985 Loss: 0.4103510267925899\n",
      "W1: 10.83472727721972 W2: 1.8717950110321169 b -5.685216667454494 Loss: 0.41035097377155405\n",
      "W1: 10.834871656500864 W2: 1.8718105338135724 b -5.685289725437468 Loss: 0.4103509208496885\n",
      "W1: 10.83501590059231 W2: 1.8718260422672175 b -5.685362715239714 Loss: 0.410350868026806\n",
      "W1: 10.835160009623639 W2: 1.8718415364063967 b -5.685435636926158 Loss: 0.4103508153027187\n",
      "W1: 10.835303983724302 W2: 1.8718570162444428 b -5.685508490561665 Loss: 0.4103507626772403\n",
      "W1: 10.835447823023618 W2: 1.871872481794675 b -5.685581276211033 Loss: 0.41035071015018415\n",
      "W1: 10.835591527650777 W2: 1.8718879330704008 b -5.685653993938997 Loss: 0.41035065772136375\n",
      "W1: 10.835735097734842 W2: 1.8719033700849144 b -5.68572664381023 Loss: 0.41035060539059354\n",
      "W1: 10.835878533404744 W2: 1.8719187928514975 b -5.685799225889338 Loss: 0.41035055315768804\n",
      "W1: 10.836021834789285 W2: 1.87193420138342 b -5.685871740240865 Loss: 0.410350501022462\n",
      "W1: 10.836165002017143 W2: 1.871949595693938 b -5.685944186929289 Loss: 0.4103504489847309\n",
      "W1: 10.836308035216861 W2: 1.8719649757962962 b -5.686016566019028 Loss: 0.4103503970443103\n",
      "W1: 10.836450934516856 W2: 1.871980341703726 b -5.686088877574432 Loss: 0.4103503452010162\n",
      "W1: 10.836593700045416 W2: 1.8719956934294466 b -5.686161121659789 Loss: 0.41035029345466467\n",
      "W1: 10.8367363319307 W2: 1.8720110309866647 b -5.686233298339326 Loss: 0.4103502418050725\n",
      "W1: 10.83687883030074 W2: 1.8720263543885742 b -5.686305407677203 Loss: 0.4103501902520568\n",
      "W1: 10.837021195283441 W2: 1.872041663648357 b -5.686377449737519 Loss: 0.41035013879543497\n",
      "W1: 10.837163427006576 W2: 1.872056958779182 b -5.686449424584306 Loss: 0.4103500874350248\n",
      "W1: 10.837305525597795 W2: 1.872072239794206 b -5.686521332281537 Loss: 0.41035003617064414\n",
      "W1: 10.837447491184616 W2: 1.8720875067065732 b -5.686593172893121 Loss: 0.41034998500211156\n",
      "W1: 10.837589323894433 W2: 1.8721027595294155 b -5.686664946482901 Loss: 0.4103499339292457\n",
      "W1: 10.83773102385451 W2: 1.8721179982758522 b -5.68673665311466 Loss: 0.4103498829518658\n",
      "W1: 10.837872591191983 W2: 1.8721332229589902 b -5.686808292852116 Loss: 0.4103498320697913\n",
      "W1: 10.838014026033866 W2: 1.872148433591924 b -5.686879865758925 Loss: 0.4103497812828421\n",
      "W1: 10.83815532850704 W2: 1.872163630187736 b -5.6869513718986795 Loss: 0.4103497305908384\n",
      "W1: 10.838296498738263 W2: 1.8721788127594956 b -5.68702281133491 Loss: 0.41034967999360034\n",
      "W1: 10.838437536854164 W2: 1.8721939813202604 b -5.687094184131084 Loss: 0.4103496294909492\n",
      "W1: 10.838578442981246 W2: 1.8722091358830755 b -5.687165490350605 Loss: 0.4103495790827061\n",
      "W1: 10.838719217245886 W2: 1.8722242764609736 b -5.687236730056815 Loss: 0.41034952876869235\n",
      "W1: 10.838859859774336 W2: 1.872239403066975 b -5.687307903312995 Loss: 0.41034947854873\n",
      "W1: 10.83900037069272 W2: 1.8722545157140875 b -5.687379010182361 Loss: 0.41034942842264144\n",
      "W1: 10.839140750127035 W2: 1.8722696144153073 b -5.687450050728066 Loss: 0.41034937839024893\n",
      "W1: 10.839280998203153 W2: 1.8722846991836175 b -5.687521025013204 Loss: 0.4103493284513757\n",
      "W1: 10.839421115046822 W2: 1.8722997700319894 b -5.687591933100805 Loss: 0.41034927860584475\n",
      "W1: 10.839561100783662 W2: 1.8723148269733818 b -5.687662775053835 Loss: 0.4103492288534796\n",
      "W1: 10.839700955539168 W2: 1.8723298700207414 b -5.6877335509352 Loss: 0.4103491791941043\n",
      "W1: 10.839840679438712 W2: 1.8723448991870026 b -5.687804260807744 Loss: 0.4103491296275432\n",
      "W1: 10.839980272607537 W2: 1.8723599144850875 b -5.687874904734247 Loss: 0.4103490801536211\n",
      "W1: 10.840119735170765 W2: 1.872374915927906 b -5.68794548277743 Loss: 0.4103490307721625\n",
      "W1: 10.840259067253388 W2: 1.8723899035283558 b -5.688015994999947 Loss: 0.4103489814829928\n",
      "W1: 10.840398268980278 W2: 1.8724048772993223 b -5.688086441464397 Loss: 0.41034893228593766\n",
      "W1: 10.840537340476178 W2: 1.8724198372536789 b -5.688156822233312 Loss: 0.4103488831808233\n",
      "W1: 10.840676281865711 W2: 1.8724347834042867 b -5.688227137369164 Loss: 0.41034883416747553\n",
      "W1: 10.840815093273372 W2: 1.8724497157639948 b -5.688297386934365 Loss: 0.4103487852457213\n",
      "W1: 10.840953774823532 W2: 1.87246463434564 b -5.688367570991263 Loss: 0.41034873641538744\n",
      "W1: 10.84109232664044 W2: 1.8724795391620466 b -5.688437689602144 Loss: 0.4103486876763011\n",
      "W1: 10.84123074884822 W2: 1.8724944302260276 b -5.688507742829235 Loss: 0.41034863902829016\n",
      "W1: 10.841369041570871 W2: 1.8725093075503831 b -5.688577730734701 Loss: 0.41034859047118244\n",
      "W1: 10.841507204932268 W2: 1.8725241711479017 b -5.688647653380643 Loss: 0.41034854200480625\n",
      "W1: 10.841645239056167 W2: 1.8725390210313595 b -5.688717510829106 Loss: 0.41034849362899\n",
      "W1: 10.841783144066193 W2: 1.8725538572135205 b -5.6887873031420675 Loss: 0.4103484453435628\n",
      "W1: 10.841920920085853 W2: 1.8725686797071368 b -5.688857030381449 Loss: 0.41034839714835397\n",
      "W1: 10.84205856723853 W2: 1.8725834885249486 b -5.688926692609108 Loss: 0.4103483490431929\n",
      "W1: 10.842196085647481 W2: 1.8725982836796837 b -5.688996289886843 Loss: 0.41034830102790987\n",
      "W1: 10.842333475435845 W2: 1.872613065184058 b -5.6890658222763895 Loss: 0.41034825310233464\n",
      "W1: 10.842470736726634 W2: 1.8726278330507755 b -5.689135289839424 Loss: 0.4103482052662981\n",
      "W1: 10.84260786964274 W2: 1.872642587292528 b -5.689204692637561 Loss: 0.410348157519631\n",
      "W1: 10.842744874306927 W2: 1.8726573279219956 b -5.689274030732355 Loss: 0.41034810986216463\n",
      "W1: 10.842881750841846 W2: 1.8726720549518459 b -5.689343304185298 Loss: 0.41034806229373033\n",
      "W1: 10.843018499370016 W2: 1.8726867683947348 b -5.689412513057825 Loss: 0.4103480148141605\n",
      "W1: 10.843155120013842 W2: 1.8727014682633065 b -5.6894816574113065 Loss: 0.41034796742328683\n",
      "W1: 10.8432916128956 W2: 1.872716154570193 b -5.689550737307055 Loss: 0.41034792012094184\n",
      "W1: 10.843427978137449 W2: 1.872730827328014 b -5.689619752806322 Loss: 0.41034787290695857\n",
      "W1: 10.843564215861424 W2: 1.872745486549378 b -5.689688703970298 Loss: 0.41034782578117013\n",
      "W1: 10.843700326189438 W2: 1.872760132246881 b -5.689757590860115 Loss: 0.41034777874340994\n",
      "W1: 10.843836309243285 W2: 1.8727747644331072 b -5.689826413536841 Loss: 0.4103477317935118\n",
      "W1: 10.843972165144633 W2: 1.8727893831206293 b -5.6898951720614885 Loss: 0.41034768493130985\n",
      "W1: 10.844107894015034 W2: 1.8728039883220076 b -5.689963866495007 Loss: 0.41034763815663844\n",
      "W1: 10.844243495975915 W2: 1.8728185800497907 b -5.6900324968982865 Loss: 0.41034759146933236\n",
      "W1: 10.844378971148585 W2: 1.8728331583165156 b -5.690101063332158 Loss: 0.4103475448692267\n",
      "W1: 10.844514319654229 W2: 1.8728477231347072 b -5.69016956585739 Loss: 0.41034749835615686\n",
      "W1: 10.844649541613913 W2: 1.8728622745168784 b -5.690238004534695 Loss: 0.4103474519299583\n",
      "W1: 10.844784637148585 W2: 1.8728768124755304 b -5.690306379424722 Loss: 0.41034740559046745\n",
      "W1: 10.844919606379067 W2: 1.8728913370231528 b -5.690374690588063 Loss: 0.41034735933752026\n",
      "W1: 10.845054449426064 W2: 1.8729058481722234 b -5.690442938085248 Loss: 0.4103473131709535\n",
      "W1: 10.84518916641016 W2: 1.8729203459352077 b -5.6905111219767495 Loss: 0.4103472670906043\n",
      "W1: 10.845323757451819 W2: 1.87293483032456 b -5.690579242322979 Loss: 0.4103472210963096\n",
      "W1: 10.845458222671384 W2: 1.8729493013527225 b -5.69064729918429 Loss: 0.41034717518790714\n",
      "W1: 10.845592562189081 W2: 1.8729637590321258 b -5.6907152926209745 Loss: 0.4103471293652347\n",
      "W1: 10.845726776125014 W2: 1.8729782033751887 b -5.690783222693267 Loss: 0.4103470836281308\n",
      "W1: 10.845860864599167 W2: 1.8729926343943182 b -5.690851089461342 Loss: 0.4103470379764335\n",
      "W1: 10.845994827731408 W2: 1.8730070521019095 b -5.690918892985314 Loss: 0.4103469924099818\n",
      "W1: 10.84612866564148 W2: 1.8730214565103465 b -5.690986633325241 Loss: 0.410346946928615\n",
      "W1: 10.846262378449012 W2: 1.8730358476320008 b -5.6910543105411175 Loss: 0.4103469015321723\n",
      "W1: 10.846395966273512 W2: 1.873050225479233 b -5.691121924692883 Loss: 0.4103468562204936\n",
      "W1: 10.846529429234367 W2: 1.8730645900643912 b -5.6911894758404165 Loss: 0.4103468109934188\n",
      "W1: 10.84666276745085 W2: 1.8730789413998126 b -5.691256964043538 Loss: 0.4103467658507885\n",
      "W1: 10.846795981042108 W2: 1.8730932794978223 b -5.691324389362009 Loss: 0.4103467207924431\n",
      "W1: 10.846929070127178 W2: 1.873107604370734 b -5.691391751855531 Loss: 0.4103466758182236\n",
      "W1: 10.847062034824972 W2: 1.8731219160308494 b -5.691459051583748 Loss: 0.4103466309279715\n",
      "W1: 10.847194875254289 W2: 1.873136214490459 b -5.691526288606245 Loss: 0.410346586121528\n",
      "W1: 10.847327591533803 W2: 1.8731504997618416 b -5.691593462982549 Loss: 0.41034654139873533\n",
      "W1: 10.847460183782076 W2: 1.8731647718572642 b -5.691660574772127 Loss: 0.4103464967594355\n",
      "W1: 10.84759265211755 W2: 1.8731790307889822 b -5.69172762403439 Loss: 0.410346452203471\n",
      "W1: 10.847724996658547 W2: 1.8731932765692396 b -5.691794610828686 Loss: 0.41034640773068465\n",
      "W1: 10.847857217523277 W2: 1.873207509210269 b -5.69186153521431 Loss: 0.4103463633409196\n",
      "W1: 10.847989314829826 W2: 1.8732217287242907 b -5.6919283972504955 Loss: 0.41034631903401914\n",
      "W1: 10.848121288696166 W2: 1.8732359351235146 b -5.691995196996419 Loss: 0.4103462748098268\n",
      "W1: 10.848253139240152 W2: 1.8732501284201382 b -5.692061934511197 Loss: 0.41034623066818693\n",
      "W1: 10.84838486657952 W2: 1.8732643086263474 b -5.69212860985389 Loss: 0.41034618660894373\n",
      "W1: 10.84851647083189 W2: 1.8732784757543173 b -5.692195223083501 Loss: 0.41034614263194147\n",
      "W1: 10.848647952114767 W2: 1.8732926298162111 b -5.692261774258972 Loss: 0.4103460987370253\n",
      "W1: 10.848779310545535 W2: 1.8733067708241804 b -5.6923282634391885 Loss: 0.41034605492404047\n",
      "W1: 10.848910546241463 W2: 1.8733208987903656 b -5.692394690682979 Loss: 0.4103460111928324\n",
      "W1: 10.849041659319704 W2: 1.8733350137268954 b -5.692461056049114 Loss: 0.4103459675432466\n",
      "W1: 10.849172649897296 W2: 1.873349115645887 b -5.692527359596304 Loss: 0.4103459239751293\n",
      "W1: 10.849303518091158 W2: 1.8733632045594464 b -5.692593601383205 Loss: 0.41034588048832693\n",
      "W1: 10.849434264018095 W2: 1.873377280479668 b -5.692659781468414 Loss: 0.4103458370826863\n",
      "W1: 10.849564887794795 W2: 1.873391343418635 b -5.692725899910471 Loss: 0.41034579375805386\n",
      "W1: 10.84969538953783 W2: 1.8734053933884187 b -5.692791956767856 Loss: 0.4103457505142776\n",
      "W1: 10.849825769363655 W2: 1.8734194304010796 b -5.692857952098994 Loss: 0.4103457073512042\n",
      "W1: 10.849956027388611 W2: 1.8734334544686666 b -5.692923885962252 Loss: 0.41034566426868224\n",
      "W1: 10.850086163728923 W2: 1.873447465603217 b -5.692989758415941 Loss: 0.41034562126655916\n",
      "W1: 10.850216178500702 W2: 1.8734614638167568 b -5.693055569518311 Loss: 0.4103455783446839\n",
      "W1: 10.85034607181994 W2: 1.8734754491213008 b -5.693121319327559 Loss: 0.41034553550290503\n",
      "W1: 10.850475843802517 W2: 1.8734894215288524 b -5.693187007901822 Loss: 0.41034549274107124\n",
      "W1: 10.850605494564197 W2: 1.873503381051404 b -5.693252635299182 Loss: 0.4103454500590323\n",
      "W1: 10.85073502422063 W2: 1.8735173277009356 b -5.693318201577662 Loss: 0.4103454074566374\n",
      "W1: 10.850864432887347 W2: 1.8735312614894173 b -5.693383706795228 Loss: 0.4103453649337364\n",
      "W1: 10.850993720679769 W2: 1.873545182428807 b -5.693449151009792 Loss: 0.4103453224901797\n",
      "W1: 10.851122887713203 W2: 1.8735590905310515 b -5.693514534279206 Loss: 0.41034528012581767\n",
      "W1: 10.851251934102837 W2: 1.8735729858080863 b -5.693579856661267 Loss: 0.4103452378405008\n",
      "W1: 10.851380859963747 W2: 1.873586868271836 b -5.6936451182137136 Loss: 0.4103451956340802\n",
      "W1: 10.851509665410896 W2: 1.8736007379342132 b -5.693710318994229 Loss: 0.4103451535064073\n",
      "W1: 10.851638350559131 W2: 1.8736145948071201 b -5.693775459060439 Loss: 0.4103451114573334\n",
      "W1: 10.851766915523188 W2: 1.8736284389024471 b -5.693840538469914 Loss: 0.4103450694867105\n",
      "W1: 10.851895360417684 W2: 1.8736422702320734 b -5.693905557280167 Loss: 0.41034502759439095\n",
      "W1: 10.852023685357127 W2: 1.8736560888078673 b -5.693970515548655 Loss: 0.41034498578022677\n",
      "W1: 10.852151890455907 W2: 1.8736698946416857 b -5.694035413332778 Loss: 0.41034494404407096\n",
      "W1: 10.852279975828306 W2: 1.8736836877453742 b -5.694100250689881 Loss: 0.4103449023857762\n",
      "W1: 10.852407941588488 W2: 1.8736974681307674 b -5.694165027677251 Loss: 0.4103448608051961\n",
      "W1: 10.852535787850508 W2: 1.8737112358096888 b -5.694229744352119 Loss: 0.4103448193021839\n",
      "W1: 10.852663514728302 W2: 1.8737249907939506 b -5.6942944007716605 Loss: 0.41034477787659385\n",
      "W1: 10.852791122335699 W2: 1.8737387330953539 b -5.694358996992996 Loss: 0.4103447365282797\n",
      "W1: 10.85291861078641 W2: 1.8737524627256885 b -5.694423533073188 Loss: 0.41034469525709566\n",
      "W1: 10.853045980194038 W2: 1.8737661796967333 b -5.694488009069244 Loss: 0.4103446540628969\n",
      "W1: 10.85317323067207 W2: 1.873779884020256 b -5.694552425038116 Loss: 0.4103446129455381\n",
      "W1: 10.853300362333881 W2: 1.873793575708013 b -5.694616781036698 Loss: 0.41034457190487417\n",
      "W1: 10.853427375292735 W2: 1.8738072547717501 b -5.694681077121832 Loss: 0.4103445309407613\n",
      "W1: 10.853554269661783 W2: 1.8738209212232015 b -5.6947453133503 Loss: 0.41034449005305473\n",
      "W1: 10.853681045554064 W2: 1.8738345750740908 b -5.69480948977883 Loss: 0.4103444492416106\n",
      "W1: 10.853807703082504 W2: 1.8738482163361299 b -5.694873606464097 Loss: 0.4103444085062854\n",
      "W1: 10.853934242359918 W2: 1.8738618450210203 b -5.694937663462716 Loss: 0.41034436784693545\n",
      "W1: 10.854060663499007 W2: 1.873875461140452 b -5.695001660831251 Loss: 0.410344327263418\n",
      "W1: 10.854186966612366 W2: 1.8738890647061044 b -5.695065598626205 Loss: 0.41034428675559\n",
      "W1: 10.854313151812471 W2: 1.8739026557296454 b -5.6951294769040315 Loss: 0.4103442463233087\n",
      "W1: 10.854439219211692 W2: 1.8739162342227325 b -5.695193295721125 Loss: 0.41034420596643195\n",
      "W1: 10.854565168922285 W2: 1.8739298001970115 b -5.695257055133824 Loss: 0.4103441656848178\n",
      "W1: 10.854691001056397 W2: 1.8739433536641177 b -5.695320755198416 Loss: 0.41034412547832433\n",
      "W1: 10.85481671572606 W2: 1.873956894635675 b -5.69538439597113 Loss: 0.4103440853468101\n",
      "W1: 10.854942313043198 W2: 1.873970423123297 b -5.695447977508141 Loss: 0.41034404529013385\n",
      "W1: 10.855067793119625 W2: 1.8739839391385857 b -5.695511499865567 Loss: 0.4103440053081547\n",
      "W1: 10.855193156067044 W2: 1.8739974426931327 b -5.6955749630994745 Loss: 0.4103439654007319\n",
      "W1: 10.855318401997044 W2: 1.874010933798518 b -5.695638367265873 Loss: 0.41034392556772514\n",
      "W1: 10.855443531021107 W2: 1.8740244124663112 b -5.695701712420716 Loss: 0.4103438858089941\n",
      "W1: 10.855568543250603 W2: 1.874037878708071 b -5.695764998619905 Loss: 0.4103438461243989\n",
      "W1: 10.855693438796793 W2: 1.8740513325353447 b -5.695828225919284 Loss: 0.4103438065138002\n",
      "W1: 10.855818217770825 W2: 1.8740647739596694 b -5.695891394374644 Loss: 0.4103437669770583\n",
      "W1: 10.85594288028374 W2: 1.8740782029925709 b -5.695954504041721 Loss: 0.4103437275140344\n",
      "W1: 10.856067426446469 W2: 1.874091619645564 b -5.696017554976196 Loss: 0.4103436881245896\n",
      "W1: 10.85619185636983 W2: 1.8741050239301529 b -5.696080547233697 Loss: 0.41034364880858515\n",
      "W1: 10.856316170164535 W2: 1.874118415857831 b -5.696143480869795 Loss: 0.41034360956588306\n",
      "W1: 10.856440367941184 W2: 1.8741317954400807 b -5.696206355940008 Loss: 0.41034357039634545\n",
      "W1: 10.85656444981027 W2: 1.8741451626883736 b -5.6962691724998 Loss: 0.410343531299834\n",
      "W1: 10.856688415882171 W2: 1.8741585176141704 b -5.696331930604581 Loss: 0.41034349227621153\n",
      "W1: 10.856812266267164 W2: 1.8741718602289212 b -5.696394630309704 Loss: 0.4103434533253408\n",
      "W1: 10.856936001075413 W2: 1.8741851905440654 b -5.696457271670471 Loss: 0.4103434144470847\n",
      "W1: 10.85705962041697 W2: 1.874198508571031 b -5.696519854742127 Loss: 0.4103433756413068\n",
      "W1: 10.857183124401782 W2: 1.874211814321236 b -5.696582379579867 Loss: 0.4103433369078706\n",
      "W1: 10.857306513139687 W2: 1.8742251078060872 b -5.696644846238828 Loss: 0.4103432982466398\n",
      "W1: 10.857429786740411 W2: 1.8742383890369805 b -5.696707254774095 Loss: 0.41034325965747853\n",
      "W1: 10.857552945313577 W2: 1.8742516580253012 b -5.696769605240698 Loss: 0.4103432211402509\n",
      "W1: 10.857675988968694 W2: 1.8742649147824244 b -5.696831897693615 Loss: 0.4103431826948219\n",
      "W1: 10.857798917815167 W2: 1.8742781593197135 b -5.696894132187768 Loss: 0.41034314432105606\n",
      "W1: 10.85792173196229 W2: 1.874291391648522 b -5.696956308778026 Loss: 0.4103431060188187\n",
      "W1: 10.858044431519248 W2: 1.8743046117801923 b -5.697018427519206 Loss: 0.41034306778797497\n",
      "W1: 10.858167016595123 W2: 1.8743178197260562 b -5.697080488466068 Loss: 0.4103430296283906\n",
      "W1: 10.858289487298887 W2: 1.8743310154974349 b -5.697142491673322 Loss: 0.4103429915399317\n",
      "W1: 10.8584118437394 W2: 1.8743441991056389 b -5.697204437195621 Loss: 0.410342953522464\n",
      "W1: 10.858534086025418 W2: 1.8743573705619678 b -5.6972663250875675 Loss: 0.4103429155758542\n",
      "W1: 10.858656214265592 W2: 1.874370529877711 b -5.697328155403709 Loss: 0.41034287769996874\n",
      "W1: 10.85877822856846 W2: 1.8743836770641464 b -5.6973899281985405 Loss: 0.4103428398946746\n",
      "W1: 10.858900129042455 W2: 1.8743968121325425 b -5.697451643526503 Loss: 0.41034280215983915\n",
      "W1: 10.859021915795907 W2: 1.8744099350941563 b -5.697513301441985 Loss: 0.4103427644953294\n",
      "W1: 10.859143588937032 W2: 1.8744230459602345 b -5.69757490199932 Loss: 0.4103427269010133\n",
      "W1: 10.859265148573945 W2: 1.8744361447420128 b -5.697636445252791 Loss: 0.41034268937675866\n",
      "W1: 10.85938659481465 W2: 1.874449231450717 b -5.697697931256626 Loss: 0.4103426519224337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.859507927767046 W2: 1.8744623060975618 b -5.697759360065001 Loss: 0.41034261453790677\n",
      "W1: 10.859629147538925 W2: 1.8744753686937516 b -5.697820731732039 Loss: 0.41034257722304646\n",
      "W1: 10.859750254237973 W2: 1.87448841925048 b -5.697882046311808 Loss: 0.4103425399777221\n",
      "W1: 10.85987124797177 W2: 1.8745014577789303 b -5.697943303858326 Loss: 0.41034250280180246\n",
      "W1: 10.859992128847786 W2: 1.874514484290275 b -5.6980045044255565 Loss: 0.41034246569515676\n",
      "W1: 10.86011289697339 W2: 1.8745274987956764 b -5.698065648067411 Loss: 0.4103424286576553\n",
      "W1: 10.860233552455846 W2: 1.8745405013062861 b -5.698126734837748 Loss: 0.41034239168916753\n",
      "W1: 10.860354095402304 W2: 1.8745534918332452 b -5.698187764790374 Loss: 0.41034235478956377\n",
      "W1: 10.860474525919816 W2: 1.8745664703876839 b -5.698248737979042 Loss: 0.4103423179587146\n",
      "W1: 10.860594844115324 W2: 1.8745794369807227 b -5.698309654457453 Loss: 0.41034228119649024\n",
      "W1: 10.860715050095667 W2: 1.874592391623471 b -5.6983705142792545 Loss: 0.410342244502762\n",
      "W1: 10.860835143967577 W2: 1.8746053343270281 b -5.698431317498043 Loss: 0.41034220787740094\n",
      "W1: 10.860955125837682 W2: 1.8746182651024828 b -5.698492064167362 Loss: 0.41034217132027845\n",
      "W1: 10.861074995812501 W2: 1.8746311839609129 b -5.698552754340703 Loss: 0.4103421348312661\n",
      "W1: 10.861194753998454 W2: 1.8746440909133866 b -5.698613388071505 Loss: 0.4103420984102357\n",
      "W1: 10.86131440050185 W2: 1.8746569859709612 b -5.698673965413153 Loss: 0.4103420620570596\n",
      "W1: 10.861433935428897 W2: 1.8746698691446837 b -5.698734486418984 Loss: 0.4103420257716101\n",
      "W1: 10.861553358885695 W2: 1.8746827404455906 b -5.69879495114228 Loss: 0.4103419895537597\n",
      "W1: 10.861672670978242 W2: 1.874695599884708 b -5.698855359636271 Loss: 0.4103419534033815\n",
      "W1: 10.861791871812432 W2: 1.8747084474730518 b -5.698915711954135 Loss: 0.4103419173203484\n",
      "W1: 10.861910961494052 W2: 1.8747212832216273 b -5.698976008149 Loss: 0.4103418813045339\n",
      "W1: 10.862029940128785 W2: 1.8747341071414296 b -5.699036248273939 Loss: 0.4103418453558115\n",
      "W1: 10.86214880782221 W2: 1.8747469192434434 b -5.6990964323819755 Loss: 0.4103418094740551\n",
      "W1: 10.862267564679804 W2: 1.874759719538643 b -5.699156560526081 Loss: 0.4103417736591386\n",
      "W1: 10.862386210806937 W2: 1.8747725080379922 b -5.699216632759174 Loss: 0.4103417379109364\n",
      "W1: 10.862504746308876 W2: 1.8747852847524449 b -5.699276649134123 Loss: 0.41034170222932326\n",
      "W1: 10.862623171290785 W2: 1.8747980496929444 b -5.699336609703743 Loss: 0.41034166661417365\n",
      "W1: 10.862741485857724 W2: 1.8748108028704236 b -5.699396514520799 Loss: 0.4103416310653627\n",
      "W1: 10.862859690114648 W2: 1.8748235442958054 b -5.699456363638005 Loss: 0.4103415955827659\n",
      "W1: 10.86297778416641 W2: 1.8748362739800022 b -5.699516157108021 Loss: 0.41034156016625845\n",
      "W1: 10.863095768117761 W2: 1.8748489919339162 b -5.699575894983457 Loss: 0.41034152481571623\n",
      "W1: 10.863213642073344 W2: 1.8748616981684392 b -5.699635577316873 Loss: 0.41034148953101524\n",
      "W1: 10.863331406137704 W2: 1.8748743926944529 b -5.6996952041607765 Loss: 0.4103414543120316\n",
      "W1: 10.86344906041528 W2: 1.8748870755228288 b -5.699754775567623 Loss: 0.4103414191586419\n",
      "W1: 10.863566605010407 W2: 1.874899746664428 b -5.699814291589817 Loss: 0.41034138407072296\n",
      "W1: 10.863684040027321 W2: 1.8749124061301012 b -5.699873752279713 Loss: 0.4103413490481511\n",
      "W1: 10.863801365570152 W2: 1.8749250539306896 b -5.699933157689615 Loss: 0.41034131409080427\n",
      "W1: 10.86391858174293 W2: 1.8749376900770234 b -5.699992507871773 Loss: 0.4103412791985592\n",
      "W1: 10.86403568864958 W2: 1.8749503145799231 b -5.700051802878388 Loss: 0.41034124437129377\n",
      "W1: 10.864152686393924 W2: 1.8749629274501987 b -5.700111042761611 Loss: 0.410341209608886\n",
      "W1: 10.864269575079685 W2: 1.87497552869865 b -5.7001702275735395 Loss: 0.4103411749112137\n",
      "W1: 10.864386354810483 W2: 1.874988118336067 b -5.700229357366223 Loss: 0.4103411402781555\n",
      "W1: 10.864503025689833 W2: 1.8750006963732293 b -5.700288432191658 Loss: 0.4103411057095897\n",
      "W1: 10.864619587821151 W2: 1.8750132628209062 b -5.700347452101792 Loss: 0.41034107120539504\n",
      "W1: 10.86473604130775 W2: 1.875025817689857 b -5.700406417148521 Loss: 0.41034103676545075\n",
      "W1: 10.864852386252842 W2: 1.8750383609908314 b -5.700465327383689 Loss: 0.41034100238963606\n",
      "W1: 10.864968622759536 W2: 1.875050892734568 b -5.700524182859093 Loss: 0.4103409680778304\n",
      "W1: 10.865084750930839 W2: 1.8750634129317958 b -5.700582983626475 Loss: 0.4103409338299133\n",
      "W1: 10.86520077086966 W2: 1.8750759215932338 b -5.700641729737531 Loss: 0.4103408996457649\n",
      "W1: 10.865316682678802 W2: 1.8750884187295906 b -5.700700421243903 Loss: 0.4103408655252654\n",
      "W1: 10.865432486460971 W2: 1.8751009043515652 b -5.700759058197185 Loss: 0.41034083146829503\n",
      "W1: 10.865548182318769 W2: 1.875113378469846 b -5.70081764064892 Loss: 0.4103407974747347\n",
      "W1: 10.865663770354697 W2: 1.8751258410951115 b -5.700876168650601 Loss: 0.41034076354446486\n",
      "W1: 10.865779250671158 W2: 1.8751382922380304 b -5.700934642253669 Loss: 0.4103407296773668\n",
      "W1: 10.865894623370451 W2: 1.875150731909261 b -5.700993061509517 Loss: 0.4103406958733217\n",
      "W1: 10.866009888554776 W2: 1.875163160119452 b -5.701051426469487 Loss: 0.4103406621322113\n",
      "W1: 10.866125046326232 W2: 1.8751755768792417 b -5.701109737184871 Loss: 0.4103406284539173\n",
      "W1: 10.866240096786816 W2: 1.8751879821992585 b -5.701167993706912 Loss: 0.41034059483832164\n",
      "W1: 10.866355040038428 W2: 1.8752003760901208 b -5.701226196086801 Loss: 0.4103405612853063\n",
      "W1: 10.866469876182865 W2: 1.875212758562437 b -5.701284344375681 Loss: 0.41034052779475405\n",
      "W1: 10.866584605321824 W2: 1.8752251296268054 b -5.7013424386246445 Loss: 0.41034049436654757\n",
      "W1: 10.866699227556904 W2: 1.8752374892938146 b -5.701400478884734 Loss: 0.4103404610005693\n",
      "W1: 10.866813742989601 W2: 1.875249837574043 b -5.701458465206943 Loss: 0.41034042769670265\n",
      "W1: 10.866928151721313 W2: 1.875262174478059 b -5.701516397642214 Loss: 0.41034039445483095\n",
      "W1: 10.867042453853337 W2: 1.8752745000164215 b -5.701574276241442 Loss: 0.4103403612748377\n",
      "W1: 10.867156649486873 W2: 1.875286814199679 b -5.70163210105547 Loss: 0.4103403281566067\n",
      "W1: 10.867270738723018 W2: 1.8752991170383702 b -5.701689872135092 Loss: 0.4103402951000218\n",
      "W1: 10.867384721662773 W2: 1.8753114085430238 b -5.701747589531054 Loss: 0.41034026210496743\n",
      "W1: 10.867498598407037 W2: 1.8753236887241589 b -5.701805253294053 Loss: 0.4103402291713279\n",
      "W1: 10.86761236905661 W2: 1.8753359575922843 b -5.701862863474733 Loss: 0.4103401962989875\n",
      "W1: 10.867726033712195 W2: 1.8753482151578995 b -5.701920420123692 Loss: 0.4103401634878318\n",
      "W1: 10.867839592474393 W2: 1.8753604614314934 b -5.7019779232914765 Loss: 0.4103401307377456\n",
      "W1: 10.86795304544371 W2: 1.8753726964235453 b -5.702035373028586 Loss: 0.41034009804861377\n",
      "W1: 10.868066392720547 W2: 1.875384920144525 b -5.70209276938547 Loss: 0.41034006542032253\n",
      "W1: 10.868179634405212 W2: 1.875397132604892 b -5.702150112412529 Loss: 0.41034003285275705\n",
      "W1: 10.868292770597913 W2: 1.875409333815096 b -5.702207402160113 Loss: 0.4103400003458036\n",
      "W1: 10.868405801398758 W2: 1.875421523785577 b -5.702264638678525 Loss: 0.4103399678993483\n",
      "W1: 10.868518726907757 W2: 1.8754337025267651 b -5.702321822018018 Loss: 0.41033993551327747\n",
      "W1: 10.868631547224824 W2: 1.875445870049081 b -5.702378952228796 Loss: 0.41033990318747793\n",
      "W1: 10.868744262449772 W2: 1.875458026362935 b -5.702436029361014 Loss: 0.41033987092183605\n",
      "W1: 10.868856872682317 W2: 1.8754701714787279 b -5.702493053464779 Loss: 0.41033983871623936\n",
      "W1: 10.868969378022076 W2: 1.8754823054068506 b -5.702550024590149 Loss: 0.4103398065705749\n",
      "W1: 10.86908177856857 W2: 1.8754944281576844 b -5.702606942787132 Loss: 0.41033977448473014\n",
      "W1: 10.86919407442122 W2: 1.8755065397416009 b -5.70266380810569 Loss: 0.4103397424585928\n",
      "W1: 10.869306265679352 W2: 1.8755186401689614 b -5.702720620595733 Loss: 0.4103397104920506\n",
      "W1: 10.869418352442192 W2: 1.875530729450118 b -5.7027773803071256 Loss: 0.41033967858499204\n",
      "W1: 10.869530334808871 W2: 1.8755428075954128 b -5.702834087289681 Loss: 0.41033964673730505\n",
      "W1: 10.86964221287842 W2: 1.8755548746151784 b -5.702890741593167 Loss: 0.4103396149488784\n",
      "W1: 10.869753986749773 W2: 1.8755669305197376 b -5.702947343267302 Loss: 0.41033958321960073\n",
      "W1: 10.869865656521768 W2: 1.8755789753194032 b -5.703003892361753 Loss: 0.4103395515493609\n",
      "W1: 10.869977222293146 W2: 1.8755910090244787 b -5.703060388926143 Loss: 0.41033951993804846\n",
      "W1: 10.870088684162551 W2: 1.8756030316452577 b -5.703116833010044 Loss: 0.41033948838555234\n",
      "W1: 10.870200042228529 W2: 1.8756150431920242 b -5.70317322466298 Loss: 0.41033945689176227\n",
      "W1: 10.870311296589529 W2: 1.8756270436750524 b -5.703229563934429 Loss: 0.4103394254565682\n",
      "W1: 10.870422447343906 W2: 1.8756390331046071 b -5.703285850873819 Loss: 0.41033939407986003\n",
      "W1: 10.870533494589916 W2: 1.875651011490943 b -5.703342085530529 Loss: 0.4103393627615281\n",
      "W1: 10.870644438425717 W2: 1.8756629788443058 b -5.703398267953892 Loss: 0.4103393315014625\n",
      "W1: 10.870755278949376 W2: 1.875674935174931 b -5.703454398193193 Loss: 0.41033930029955434\n",
      "W1: 10.87086601625886 W2: 1.8756868804930447 b -5.703510476297668 Loss: 0.41033926915569413\n",
      "W1: 10.87097665045204 W2: 1.8756988148088634 b -5.703566502316504 Loss: 0.410339238069773\n",
      "W1: 10.87108718162669 W2: 1.8757107381325937 b -5.703622476298844 Loss: 0.4103392070416822\n",
      "W1: 10.87119760988049 W2: 1.8757226504744333 b -5.70367839829378 Loss: 0.4103391760713133\n",
      "W1: 10.871307935311023 W2: 1.8757345518445696 b -5.703734268350357 Loss: 0.4103391451585578\n",
      "W1: 10.871418158015778 W2: 1.8757464422531807 b -5.703790086517572 Loss: 0.4103391143033078\n",
      "W1: 10.871528278092146 W2: 1.8757583217104352 b -5.703845852844376 Loss: 0.41033908350545506\n",
      "W1: 10.871638295637425 W2: 1.875770190226492 b -5.7039015673796705 Loss: 0.41033905276489224\n",
      "W1: 10.871748210748814 W2: 1.8757820478115008 b -5.7039572301723105 Loss: 0.4103390220815115\n",
      "W1: 10.871858023523421 W2: 1.8757938944756012 b -5.704012841271103 Loss: 0.41033899145520575\n",
      "W1: 10.871967734058254 W2: 1.8758057302289235 b -5.7040684007248075 Loss: 0.4103389608858679\n",
      "W1: 10.872077342450229 W2: 1.8758175550815885 b -5.704123908582138 Loss: 0.41033893037339103\n",
      "W1: 10.872186848796167 W2: 1.8758293690437078 b -5.704179364891758 Loss: 0.4103388999176683\n",
      "W1: 10.872296253192792 W2: 1.875841172125383 b -5.7042347697022855 Loss: 0.41033886951859344\n",
      "W1: 10.872405555736734 W2: 1.8758529643367061 b -5.704290123062291 Loss: 0.41033883917605996\n",
      "W1: 10.872514756524529 W2: 1.8758647456877604 b -5.7043454250203 Loss: 0.4103388088899619\n",
      "W1: 10.872623855652618 W2: 1.875876516188619 b -5.704400675624786 Loss: 0.41033877866019336\n",
      "W1: 10.872732853217347 W2: 1.8758882758493458 b -5.70445587492418 Loss: 0.4103387484866486\n",
      "W1: 10.872841749314968 W2: 1.8759000246799953 b -5.704511022966863 Loss: 0.41033871836922214\n",
      "W1: 10.87295054404164 W2: 1.8759117626906123 b -5.7045661198011715 Loss: 0.4103386883078089\n",
      "W1: 10.873059237493424 W2: 1.8759234898912323 b -5.704621165475393 Loss: 0.4103386583023036\n",
      "W1: 10.873167829766288 W2: 1.8759352062918815 b -5.704676160037768 Loss: 0.4103386283526013\n",
      "W1: 10.873276320956109 W2: 1.8759469119025765 b -5.704731103536492 Loss: 0.4103385984585975\n",
      "W1: 10.873384711158666 W2: 1.8759586067333247 b -5.704785996019712 Loss: 0.4103385686201875\n",
      "W1: 10.873493000469649 W2: 1.8759702907941238 b -5.70484083753553 Loss: 0.4103385388372674\n",
      "W1: 10.87360118898465 W2: 1.8759819640949622 b -5.7048956281319985 Loss: 0.4103385091097328\n",
      "W1: 10.873709276799167 W2: 1.875993626645819 b -5.704950367857125 Loss: 0.41033847943747975\n",
      "W1: 10.873817264008606 W2: 1.876005278456664 b -5.705005056758872 Loss: 0.4103384498204049\n",
      "W1: 10.87392515070828 W2: 1.8760169195374576 b -5.705059694885153 Loss: 0.41033842025840433\n",
      "W1: 10.874032936993409 W2: 1.8760285498981504 b -5.705114282283836 Loss: 0.41033839075137524\n",
      "W1: 10.874140622959118 W2: 1.8760401695486841 b -5.7051688190027425 Loss: 0.41033836129921397\n",
      "W1: 10.874248208700438 W2: 1.8760517784989912 b -5.705223305089647 Loss: 0.41033833190181795\n",
      "W1: 10.87435569431231 W2: 1.8760633767589945 b -5.705277740592278 Loss: 0.41033830255908454\n",
      "W1: 10.874463079889582 W2: 1.8760749643386074 b -5.705332125558318 Loss: 0.4103382732709111\n",
      "W1: 10.874570365527005 W2: 1.8760865412477346 b -5.705386460035403 Loss: 0.4103382440371952\n",
      "W1: 10.87467755131924 W2: 1.8760981074962708 b -5.705440744071123 Loss: 0.4103382148578349\n",
      "W1: 10.874784637360854 W2: 1.8761096630941017 b -5.7054949777130215 Loss: 0.4103381857327282\n",
      "W1: 10.874891623746324 W2: 1.8761212080511038 b -5.705549161008595 Loss: 0.41033815666177326\n",
      "W1: 10.874998510570032 W2: 1.8761327423771441 b -5.705603294005296 Loss: 0.41033812764486866\n",
      "W1: 10.87510529792627 W2: 1.8761442660820806 b -5.705657376750528 Loss: 0.4103380986819131\n",
      "W1: 10.875211985909234 W2: 1.876155779175762 b -5.705711409291652 Loss: 0.4103380697728051\n",
      "W1: 10.875318574613031 W2: 1.8761672816680273 b -5.705765391675981 Loss: 0.4103380409174442\n",
      "W1: 10.875425064131674 W2: 1.8761787735687065 b -5.705819323950783 Loss: 0.41033801211572923\n",
      "W1: 10.875531454559084 W2: 1.876190254887621 b -5.705873206163278 Loss: 0.41033798336755983\n",
      "W1: 10.875637745989092 W2: 1.876201725634582 b -5.705927038360643 Loss: 0.4103379546728354\n",
      "W1: 10.875743938515434 W2: 1.876213185819392 b -5.705980820590007 Loss: 0.41033792603145597\n",
      "W1: 10.875850032231758 W2: 1.8762246354518444 b -5.706034552898455 Loss: 0.4103378974433213\n",
      "W1: 10.875956027231618 W2: 1.876236074541723 b -5.706088235333025 Loss: 0.4103378689083316\n",
      "W1: 10.876061923608475 W2: 1.8762475030988028 b -5.706141867940712 Loss: 0.4103378404263874\n",
      "W1: 10.876167721455703 W2: 1.8762589211328493 b -5.706195450768461 Loss: 0.41033781199738917\n",
      "W1: 10.87627342086658 W2: 1.876270328653619 b -5.7062489838631745 Loss: 0.41033778362123763\n",
      "W1: 10.876379021934294 W2: 1.8762817256708593 b -5.706302467271709 Loss: 0.4103377552978337\n",
      "W1: 10.876484524751945 W2: 1.876293112194308 b -5.706355901040877 Loss: 0.41033772702707866\n",
      "W1: 10.876589929412537 W2: 1.8763044882336946 b -5.706409285217442 Loss: 0.4103376988088734\n",
      "W1: 10.876695236008986 W2: 1.8763158537987386 b -5.706462619848126 Loss: 0.4103376706431198\n",
      "W1: 10.876800444634117 W2: 1.876327208899151 b -5.706515904979602 Loss: 0.4103376425297196\n",
      "W1: 10.876905555380663 W2: 1.876338553544633 b -5.706569140658501 Loss: 0.41033761446857453\n",
      "W1: 10.877010568341268 W2: 1.8763498877448777 b -5.706622326931408 Loss: 0.4103375864595865\n",
      "W1: 10.877115483608483 W2: 1.876361211509568 b -5.706675463844861 Loss: 0.41033755850265796\n",
      "W1: 10.87722030127477 W2: 1.8763725248483785 b -5.706728551445355 Loss: 0.4103375305976911\n",
      "W1: 10.877325021432501 W2: 1.8763838277709741 b -5.7067815897793395 Loss: 0.41033750274458886\n",
      "W1: 10.877429644173956 W2: 1.8763951202870113 b -5.7068345788932175 Loss: 0.4103374749432538\n",
      "W1: 10.877534169591328 W2: 1.876406402406137 b -5.70688751883335 Loss: 0.41033744719358883\n",
      "W1: 10.877638597776716 W2: 1.8764176741379894 b -5.706940409646049 Loss: 0.4103374194954974\n",
      "W1: 10.87774292882213 W2: 1.8764289354921972 b -5.706993251377586 Loss: 0.4103373918488826\n",
      "W1: 10.87784716281949 W2: 1.8764401864783806 b -5.707046044074184 Loss: 0.41033736425364825\n",
      "W1: 10.877951299860628 W2: 1.8764514271061503 b -5.707098787782024 Loss: 0.4103373367096978\n",
      "W1: 10.878055340037285 W2: 1.8764626573851082 b -5.70715148254724 Loss: 0.41033730921693523\n",
      "W1: 10.878159283441112 W2: 1.8764738773248473 b -5.707204128415923 Loss: 0.41033728177526463\n",
      "W1: 10.87826313016367 W2: 1.8764850869349512 b -5.707256725434118 Loss: 0.41033725438459023\n",
      "W1: 10.878366880296433 W2: 1.876496286224995 b -5.7073092736478275 Loss: 0.41033722704481657\n",
      "W1: 10.878470533930782 W2: 1.8765074752045445 b -5.707361773103006 Loss: 0.410337199755848\n",
      "W1: 10.878574091158011 W2: 1.8765186538831564 b -5.707414223845567 Loss: 0.41033717251758967\n",
      "W1: 10.878677552069323 W2: 1.8765298222703788 b -5.707466625921377 Loss: 0.41033714532994653\n",
      "W1: 10.878780916755835 W2: 1.8765409803757507 b -5.70751897937626 Loss: 0.41033711819282354\n",
      "W1: 10.878884185308571 W2: 1.876552128208802 b -5.7075712842559945 Loss: 0.41033709110612615\n",
      "W1: 10.87898735781847 W2: 1.8765632657790539 b -5.707623540606314 Loss: 0.41033706406975995\n",
      "W1: 10.879090434376378 W2: 1.8765743930960181 b -5.70767574847291 Loss: 0.4103370370836305\n",
      "W1: 10.879193415073056 W2: 1.8765855101691982 b -5.707727907901428 Loss: 0.41033701014764373\n",
      "W1: 10.879296299999174 W2: 1.8765966170080883 b -5.707780018937469 Loss: 0.4103369832617058\n",
      "W1: 10.879399089245316 W2: 1.876607713622174 b -5.707832081626591 Loss: 0.410336956425723\n",
      "W1: 10.879501782901974 W2: 1.8766188000209312 b -5.707884096014307 Loss: 0.41033692963960156\n",
      "W1: 10.879604381059554 W2: 1.8766298762138278 b -5.707936062146087 Loss: 0.410336902903248\n",
      "W1: 10.879706883808373 W2: 1.8766409422103225 b -5.707987980067355 Loss: 0.4103368762165694\n",
      "W1: 10.879809291238658 W2: 1.876651998019865 b -5.708039849823494 Loss: 0.41033684957947253\n",
      "W1: 10.879911603440553 W2: 1.8766630436518965 b -5.70809167145984 Loss: 0.4103368229918645\n",
      "W1: 10.880013820504107 W2: 1.8766740791158487 b -5.708143445021688 Loss: 0.41033679645365273\n",
      "W1: 10.880115942519287 W2: 1.876685104421145 b -5.708195170554286 Loss: 0.4103367699647446\n",
      "W1: 10.88021796957597 W2: 1.8766961195771996 b -5.708246848102841 Loss: 0.41033674352504773\n",
      "W1: 10.880319901763944 W2: 1.8767071245934182 b -5.708298477712515 Loss: 0.41033671713447006\n",
      "W1: 10.880421739172911 W2: 1.8767181194791973 b -5.708350059428426 Loss: 0.4103366907929194\n",
      "W1: 10.880523481892485 W2: 1.876729104243925 b -5.708401593295649 Loss: 0.4103366645003042\n",
      "W1: 10.880625130012193 W2: 1.8767400788969801 b -5.708453079359216 Loss: 0.41033663825653266\n",
      "W1: 10.880726683621473 W2: 1.8767510434477332 b -5.708504517664113 Loss: 0.4103366120615133\n",
      "W1: 10.880828142809676 W2: 1.8767619979055457 b -5.708555908255285 Loss: 0.4103365859151548\n",
      "W1: 10.880929507666067 W2: 1.87677294227977 b -5.708607251177632 Loss: 0.41033655981736616\n",
      "W1: 10.881030778279825 W2: 1.8767838765797504 b -5.708658546476012 Loss: 0.41033653376805623\n",
      "W1: 10.88113195474004 W2: 1.8767948008148219 b -5.708709794195238 Loss: 0.4103365077671343\n",
      "W1: 10.881233037135713 W2: 1.8768057149943107 b -5.708760994380081 Loss: 0.41033648181450993\n",
      "W1: 10.881334025555763 W2: 1.8768166191275348 b -5.708812147075268 Loss: 0.4103364559100925\n",
      "W1: 10.881434920089017 W2: 1.876827513223803 b -5.708863252325483 Loss: 0.41033643005379156\n",
      "W1: 10.881535720824221 W2: 1.8768383972924154 b -5.708914310175365 Loss: 0.4103364042455176\n",
      "W1: 10.881636427850031 W2: 1.8768492713426634 b -5.708965320669513 Loss: 0.41033637848517995\n",
      "W1: 10.881737041255017 W2: 1.8768601353838297 b -5.709016283852481 Loss: 0.4103363527726895\n",
      "W1: 10.88183756112766 W2: 1.8768709894251883 b -5.70906719976878 Loss: 0.4103363271079562\n",
      "W1: 10.88193798755636 W2: 1.8768818334760045 b -5.709118068462879 Loss: 0.410336301490891\n",
      "W1: 10.882038320629428 W2: 1.876892667545535 b -5.709168889979202 Loss: 0.41033627592140437\n",
      "W1: 10.882138560435088 W2: 1.8769034916430278 b -5.7092196643621325 Loss: 0.41033625039940724\n",
      "W1: 10.882238707061479 W2: 1.8769143057777222 b -5.709270391656008 Loss: 0.41033622492481103\n",
      "W1: 10.882338760596653 W2: 1.8769251099588486 b -5.709321071905126 Loss: 0.4103361994975266\n",
      "W1: 10.88243872112858 W2: 1.8769359041956293 b -5.709371705153741 Loss: 0.4103361741174656\n",
      "W1: 10.882538588745138 W2: 1.8769466884972772 b -5.709422291446062 Loss: 0.4103361487845397\n",
      "W1: 10.882638363534124 W2: 1.876957462872997 b -5.709472830826258 Loss: 0.4103361234986603\n",
      "W1: 10.882738045583247 W2: 1.876968227331985 b -5.709523323338455 Loss: 0.4103360982597397\n",
      "W1: 10.882837634980133 W2: 1.8769789818834282 b -5.709573769026734 Loss: 0.41033607306768993\n",
      "W1: 10.882937131812321 W2: 1.8769897265365056 b -5.709624167935136 Loss: 0.41033604792242306\n",
      "W1: 10.883036536167264 W2: 1.8770004613003872 b -5.709674520107659 Loss: 0.4103360228238515\n",
      "W1: 10.88313584813233 W2: 1.8770111861842347 b -5.709724825588258 Loss: 0.4103359977718883\n",
      "W1: 10.883235067794804 W2: 1.8770219011972011 b -5.709775084420845 Loss: 0.41033597276644573\n",
      "W1: 10.883334195241881 W2: 1.8770326063484306 b -5.709825296649291 Loss: 0.41033594780743693\n",
      "W1: 10.883433230560678 W2: 1.8770433016470591 b -5.709875462317424 Loss: 0.41033592289477505\n",
      "W1: 10.883532173838221 W2: 1.877053987102214 b -5.709925581469028 Loss: 0.4103358980283731\n",
      "W1: 10.883631025161455 W2: 1.8770646627230139 b -5.709975654147847 Loss: 0.41033587320814463\n",
      "W1: 10.883729784617236 W2: 1.8770753285185686 b -5.710025680397582 Loss: 0.41033584843400345\n",
      "W1: 10.88382845229234 W2: 1.8770859844979801 b -5.71007566026189 Loss: 0.41033582370586286\n",
      "W1: 10.883927028273456 W2: 1.8770966306703414 b -5.710125593784389 Loss: 0.410335799023637\n",
      "W1: 10.884025512647192 W2: 1.8771072670447366 b -5.710175481008654 Loss: 0.41033577438724006\n",
      "W1: 10.884123905500065 W2: 1.8771178936302422 b -5.710225321978215 Loss: 0.41033574979658627\n",
      "W1: 10.884222206918512 W2: 1.8771285104359254 b -5.710275116736564 Loss: 0.4103357252515897\n",
      "W1: 10.884320416988887 W2: 1.8771391174708454 b -5.710324865327148 Loss: 0.4103357007521653\n",
      "W1: 10.884418535797456 W2: 1.8771497147440526 b -5.710374567793374 Loss: 0.4103356762982274\n",
      "W1: 10.884516563430406 W2: 1.8771603022645889 b -5.710424224178606 Loss: 0.41033565188969146\n",
      "W1: 10.884614499973834 W2: 1.877170880041488 b -5.710473834526167 Loss: 0.41033562752647196\n",
      "W1: 10.884712345513758 W2: 1.8771814480837747 b -5.710523398879336 Loss: 0.41033560320848445\n",
      "W1: 10.88481010013611 W2: 1.877192006400466 b -5.710572917281353 Loss: 0.4103355789356439\n",
      "W1: 10.88490776392674 W2: 1.8772025550005695 b -5.7106223897754145 Loss: 0.41033555470786637\n",
      "W1: 10.885005336971412 W2: 1.8772130938930853 b -5.710671816404676 Loss: 0.41033553052506716\n",
      "W1: 10.885102819355808 W2: 1.8772236230870047 b -5.710721197212251 Loss: 0.41033550638716226\n",
      "W1: 10.885200211165525 W2: 1.8772341425913104 b -5.710770532241212 Loss: 0.41033548229406763\n",
      "W1: 10.88529751248608 W2: 1.8772446524149768 b -5.71081982153459 Loss: 0.4103354582456992\n",
      "W1: 10.885394723402904 W2: 1.87725515256697 b -5.7108690651353715 Loss: 0.41033543424197405\n",
      "W1: 10.885491844001345 W2: 1.8772656430562475 b -5.710918263086506 Loss: 0.41033541028280784\n",
      "W1: 10.88558887436667 W2: 1.8772761238917586 b -5.710967415430899 Loss: 0.4103353863681175\n",
      "W1: 10.88568581458406 W2: 1.877286595082444 b -5.711016522211414 Loss: 0.4103353624978201\n",
      "W1: 10.885782664738615 W2: 1.877297056637236 b -5.711065583470876 Loss: 0.41033533867183214\n",
      "W1: 10.885879424915352 W2: 1.877307508565059 b -5.711114599252065 Loss: 0.4103353148900709\n",
      "W1: 10.885976095199204 W2: 1.8773179508748283 b -5.711163569597723 Loss: 0.4103352911524538\n",
      "W1: 10.886072675675024 W2: 1.8773283835754515 b -5.711212494550549 Loss: 0.4103352674588981\n",
      "W1: 10.88616916642758 W2: 1.8773388066758276 b -5.7112613741532 Loss: 0.4103352438093214\n",
      "W1: 10.886265567541558 W2: 1.8773492201848472 b -5.711310208448294 Loss: 0.4103352202036415\n",
      "W1: 10.886361879101562 W2: 1.8773596241113923 b -5.711358997478407 Loss: 0.4103351966417763\n",
      "W1: 10.886458101192114 W2: 1.8773700184643374 b -5.711407741286073 Loss: 0.41033517312364365\n",
      "W1: 10.886554233897652 W2: 1.8773804032525478 b -5.7114564399137855 Loss: 0.4103351496491621\n",
      "W1: 10.886650277302534 W2: 1.8773907784848811 b -5.711505093403998 Loss: 0.41033512621824964\n",
      "W1: 10.886746231491035 W2: 1.877401144170186 b -5.711553701799122 Loss: 0.4103351028308252\n",
      "W1: 10.88684209654735 W2: 1.8774115003173037 b -5.711602265141528 Loss: 0.41033507948680703\n",
      "W1: 10.886937872555587 W2: 1.8774218469350663 b -5.711650783473547 Loss: 0.4103350561861141\n",
      "W1: 10.887033559599777 W2: 1.8774321840322983 b -5.711699256837467 Loss: 0.4103350329286654\n",
      "W1: 10.887129157763868 W2: 1.8774425116178155 b -5.711747685275537 Loss: 0.4103350097143801\n",
      "W1: 10.887224667131726 W2: 1.8774528297004256 b -5.711796068829964 Loss: 0.4103349865431774\n",
      "W1: 10.887320087787135 W2: 1.877463138288928 b -5.711844407542915 Loss: 0.41033496341497694\n",
      "W1: 10.887415419813799 W2: 1.8774734373921138 b -5.711892701456517 Loss: 0.4103349403296979\n",
      "W1: 10.887510663295338 W2: 1.8774837270187659 b -5.7119409506128545 Loss: 0.4103349172872603\n",
      "W1: 10.887605818315294 W2: 1.8774940071776591 b -5.711989155053973 Loss: 0.41033489428758413\n",
      "W1: 10.887700884957125 W2: 1.87750427787756 b -5.7120373148218775 Loss: 0.41033487133058916\n",
      "W1: 10.88779586330421 W2: 1.8775145391272265 b -5.712085429958531 Loss: 0.4103348484161958\n",
      "W1: 10.887890753439844 W2: 1.8775247909354091 b -5.712133500505858 Loss: 0.4103348255443242\n",
      "W1: 10.887985555447246 W2: 1.8775350333108496 b -5.7121815265057405 Loss: 0.41033480271489503\n",
      "W1: 10.888080269409548 W2: 1.8775452662622814 b -5.712229508000022 Loss: 0.4103347799278287\n",
      "W1: 10.888174895409806 W2: 1.8775554897984301 b -5.712277445030505 Loss: 0.4103347571830463\n",
      "W1: 10.888269433530994 W2: 1.8775657039280131 b -5.712325337638951 Loss: 0.4103347344804686\n",
      "W1: 10.888363883856002 W2: 1.8775759086597394 b -5.712373185867083 Loss: 0.41033471182001674\n",
      "W1: 10.888458246467644 W2: 1.8775861040023103 b -5.712420989756581 Loss: 0.4103346892016119\n",
      "W1: 10.888552521448654 W2: 1.8775962899644183 b -5.712468749349088 Loss: 0.4103346666251754\n",
      "W1: 10.88864670888168 W2: 1.8776064665547483 b -5.712516464686204 Loss: 0.4103346440906291\n",
      "W1: 10.888740808849295 W2: 1.8776166337819766 b -5.712564135809491 Loss: 0.4103346215978943\n",
      "W1: 10.88883482143399 W2: 1.877626791654772 b -5.712611762760471 Loss: 0.41033459914689313\n",
      "W1: 10.888928746718175 W2: 1.8776369401817945 b -5.712659345580623 Loss: 0.4103345767375474\n",
      "W1: 10.889022584784183 W2: 1.8776470793716966 b -5.712706884311389 Loss: 0.4103345543697794\n",
      "W1: 10.889116335714261 W2: 1.877657209233122 b -5.7127543789941715 Loss: 0.41033453204351117\n",
      "W1: 10.889209999590582 W2: 1.877667329774707 b -5.7128018296703305 Loss: 0.4103345097586653\n",
      "W1: 10.889303576495237 W2: 1.8776774410050796 b -5.712849236381188 Loss: 0.4103344875151643\n",
      "W1: 10.889397066510236 W2: 1.8776875429328592 b -5.712896599168026 Loss: 0.410334465312931\n",
      "W1: 10.889490469717513 W2: 1.877697635566658 b -5.712943918072086 Loss: 0.41033444315188805\n",
      "W1: 10.889583786198918 W2: 1.8777077189150793 b -5.71299119313457 Loss: 0.4103344210319588\n",
      "W1: 10.889677016036224 W2: 1.877717792986719 b -5.7130384243966414 Loss: 0.4103343989530659\n",
      "W1: 10.889770159311125 W2: 1.8777278577901646 b -5.713085611899422 Loss: 0.4103343769151332\n",
      "W1: 10.889863216105233 W2: 1.8777379133339955 b -5.713132755683996 Loss: 0.4103343549180838\n",
      "W1: 10.889956186500084 W2: 1.8777479596267834 b -5.713179855791407 Loss: 0.41033433296184135\n",
      "W1: 10.890049070577133 W2: 1.8777579966770916 b -5.713226912262658 Loss: 0.4103343110463296\n",
      "W1: 10.890141868417755 W2: 1.8777680244934758 b -5.713273925138715 Loss: 0.41033428917147247\n",
      "W1: 10.89023458010325 W2: 1.8777780430844833 b -5.7133208944605025 Loss: 0.41033426733719386\n",
      "W1: 10.890327205714835 W2: 1.8777880524586534 b -5.713367820268907 Loss: 0.4103342455434181\n",
      "W1: 10.890419745333649 W2: 1.8777980526245177 b -5.713414702604775 Loss: 0.4103342237900694\n",
      "W1: 10.890512199040753 W2: 1.8778080435905995 b -5.713461541508912 Loss: 0.4103342020770724\n",
      "W1: 10.89060456691713 W2: 1.8778180253654144 b -5.713508337022088 Loss: 0.41033418040435127\n",
      "W1: 10.890696849043684 W2: 1.87782799795747 b -5.7135550891850295 Loss: 0.4103341587718312\n",
      "W1: 10.890789045501238 W2: 1.8778379613752656 b -5.713601798038427 Loss: 0.41033413717943695\n",
      "W1: 10.89088115637054 W2: 1.877847915627293 b -5.713648463622931 Loss: 0.4103341156270934\n",
      "W1: 10.890973181732258 W2: 1.8778578607220355 b -5.713695085979152 Loss: 0.4103340941147255\n",
      "W1: 10.891065121666982 W2: 1.877867796667969 b -5.713741665147663 Loss: 0.41033407264225913\n",
      "W1: 10.891156976255223 W2: 1.8778777234735613 b -5.713788201168995 Loss: 0.41033405120961935\n",
      "W1: 10.891248745577414 W2: 1.877887641147272 b -5.713834694083643 Loss: 0.4103340298167319\n",
      "W1: 10.891340429713912 W2: 1.8778975496975532 b -5.7138811439320625 Loss: 0.4103340084635223\n",
      "W1: 10.891432028744994 W2: 1.8779074491328487 b -5.7139275507546685 Loss: 0.41033398714991665\n",
      "W1: 10.89152354275086 W2: 1.8779173394615947 b -5.713973914591839 Loss: 0.410333965875841\n",
      "W1: 10.891614971811633 W2: 1.877927220692219 b -5.714020235483911 Loss: 0.4103339446412212\n",
      "W1: 10.891706316007355 W2: 1.8779370928331425 b -5.714066513471185 Loss: 0.4103339234459837\n",
      "W1: 10.891797575417993 W2: 1.8779469558927773 b -5.714112748593921 Loss: 0.4103339022900549\n",
      "W1: 10.891888750123437 W2: 1.8779568098795278 b -5.714158940892341 Loss: 0.41033388117336145\n",
      "W1: 10.891979840203497 W2: 1.8779666548017908 b -5.714205090406629 Loss: 0.4103338600958301\n",
      "W1: 10.892070845737909 W2: 1.877976490667955 b -5.714251197176928 Loss: 0.41033383905738746\n",
      "W1: 10.892161766806328 W2: 1.8779863174864015 b -5.714297261243345 Loss: 0.41033381805796054\n",
      "W1: 10.892252603488336 W2: 1.8779961352655032 b -5.714343282645948 Loss: 0.4103337970974767\n",
      "W1: 10.892343355863431 W2: 1.8780059440136256 b -5.714389261424764 Loss: 0.4103337761758631\n",
      "W1: 10.892434024011044 W2: 1.878015743739126 b -5.714435197619785 Loss: 0.4103337552930468\n",
      "W1: 10.892524608010518 W2: 1.878025534450354 b -5.7144810912709625 Loss: 0.4103337344489557\n",
      "W1: 10.892615107941127 W2: 1.8780353161556516 b -5.714526942418209 Loss: 0.41033371364351745\n",
      "W1: 10.892705523882066 W2: 1.8780450888633524 b -5.714572751101399 Loss: 0.41033369287665983\n",
      "W1: 10.892795855912452 W2: 1.8780548525817828 b -5.714618517360371 Loss: 0.4103336721483107\n",
      "W1: 10.892886104111327 W2: 1.8780646073192613 b -5.714664241234922 Loss: 0.4103336514583981\n",
      "W1: 10.892976268557653 W2: 1.8780743530840982 b -5.714709922764812 Loss: 0.41033363080685026\n",
      "W1: 10.89306634933032 W2: 1.8780840898845965 b -5.714755561989764 Loss: 0.41033361019359554\n",
      "W1: 10.893156346508139 W2: 1.8780938177290514 b -5.714801158949461 Loss: 0.41033358961856253\n",
      "W1: 10.893246260169844 W2: 1.87810353662575 b -5.714846713683548 Loss: 0.41033356908167984\n",
      "W1: 10.893336090394095 W2: 1.8781132465829717 b -5.714892226231633 Loss: 0.41033354858287613\n",
      "W1: 10.893425837259475 W2: 1.8781229476089887 b -5.714937696633285 Loss: 0.41033352812208024\n",
      "W1: 10.893515500844488 W2: 1.8781326397120648 b -5.714983124928035 Loss: 0.4103335076992211\n",
      "W1: 10.893605081227568 W2: 1.8781423229004564 b -5.715028511155377 Loss: 0.41033348731422825\n",
      "W1: 10.893694578487066 W2: 1.8781519971824119 b -5.715073855354766 Loss: 0.4103334669670307\n",
      "W1: 10.89378399270126 W2: 1.8781616625661723 b -5.715119157565619 Loss: 0.4103334466575577\n",
      "W1: 10.893873323948355 W2: 1.8781713190599707 b -5.7151644178273155 Loss: 0.4103334263857393\n",
      "W1: 10.893962572306478 W2: 1.8781809666720326 b -5.715209636179197 Loss: 0.4103334061515046\n",
      "W1: 10.894051737853678 W2: 1.878190605410576 b -5.715254812660567 Loss: 0.41033338595478397\n",
      "W1: 10.894140820667932 W2: 1.8782002352838105 b -5.715299947310692 Loss: 0.4103333657955071\n",
      "W1: 10.894229820827139 W2: 1.8782098562999388 b -5.715345040168801 Loss: 0.41033334567360397\n",
      "W1: 10.894318738409124 W2: 1.8782194684671554 b -5.715390091274083 Loss: 0.41033332558900515\n",
      "W1: 10.894407573491637 W2: 1.8782290717936476 b -5.715435100665691 Loss: 0.4103333055416405\n",
      "W1: 10.894496326152352 W2: 1.8782386662875947 b -5.715480068382742 Loss: 0.4103332855314408\n",
      "W1: 10.894584996468865 W2: 1.8782482519571684 b -5.715524994464312 Loss: 0.4103332655583367\n",
      "W1: 10.894673584518703 W2: 1.8782578288105327 b -5.7155698789494425 Loss: 0.4103332456222587\n",
      "W1: 10.894762090379311 W2: 1.878267396855844 b -5.715614721877135 Loss: 0.41033322572313796\n",
      "W1: 10.894850514128066 W2: 1.8782769561012513 b -5.715659523286355 Loss: 0.4103332058609054\n",
      "W1: 10.894938855842264 W2: 1.8782865065548957 b -5.715704283216031 Loss: 0.410333186035492\n",
      "W1: 10.895027115599131 W2: 1.878296048224911 b -5.715749001705052 Loss: 0.41033316624682925\n",
      "W1: 10.895115293475813 W2: 1.8783055811194227 b -5.715793678792271 Loss: 0.41033314649484826\n",
      "W1: 10.895203389549387 W2: 1.8783151052465494 b -5.715838314516504 Loss: 0.4103331267794808\n",
      "W1: 10.89529140389685 W2: 1.878324620614402 b -5.71588290891653 Loss: 0.41033310710065846\n",
      "W1: 10.895379336595129 W2: 1.8783341272310836 b -5.71592746203109 Loss: 0.4103330874583129\n",
      "W1: 10.895467187721074 W2: 1.8783436251046899 b -5.715971973898887 Loss: 0.41033306785237617\n",
      "W1: 10.895554957351463 W2: 1.8783531142433088 b -5.716016444558588 Loss: 0.4103330482827803\n",
      "W1: 10.895642645562996 W2: 1.8783625946550206 b -5.716060874048823 Loss: 0.4103330287494573\n",
      "W1: 10.8957302524323 W2: 1.8783720663478984 b -5.716105262408185 Loss: 0.4103330092523397\n",
      "W1: 10.89581777803593 W2: 1.8783815293300077 b -5.716149609675228 Loss: 0.4103329897913598\n",
      "W1: 10.895905222450365 W2: 1.8783909836094062 b -5.716193915888472 Loss: 0.4103329703664501\n",
      "W1: 10.895992585752012 W2: 1.878400429194144 b -5.716238181086398 Loss: 0.41033295097754324\n",
      "W1: 10.896079868017202 W2: 1.8784098660922641 b -5.7162824053074495 Loss: 0.4103329316245722\n",
      "W1: 10.89616706932219 W2: 1.8784192943118017 b -5.716326588590035 Loss: 0.41033291230746977\n",
      "W1: 10.896254189743164 W2: 1.8784287138607842 b -5.716370730972525 Loss: 0.4103328930261691\n",
      "W1: 10.896341229356231 W2: 1.8784381247472322 b -5.716414832493252 Loss: 0.41033287378060324\n",
      "W1: 10.89642818823743 W2: 1.8784475269791583 b -5.716458893190516 Loss: 0.41033285457070573\n",
      "W1: 10.896515066462722 W2: 1.8784569205645676 b -5.716502913102574 Loss: 0.41033283539640986\n",
      "W1: 10.896601864108 W2: 1.8784663055114579 b -5.716546892267652 Loss: 0.410332816257649\n",
      "W1: 10.896688581249077 W2: 1.8784756818278194 b -5.716590830723935 Loss: 0.4103327971543571\n",
      "W1: 10.896775217961697 W2: 1.8784850495216348 b -5.716634728509574 Loss: 0.41033277808646795\n",
      "W1: 10.896861774321529 W2: 1.8784944086008795 b -5.716678585662684 Loss: 0.41033275905391525\n",
      "W1: 10.89694825040417 W2: 1.8785037590735212 b -5.71672240222134 Loss: 0.41033274005663345\n",
      "W1: 10.897034646285144 W2: 1.8785131009475204 b -5.716766178223582 Loss: 0.4103327210945562\n",
      "W1: 10.8971209620399 W2: 1.8785224342308302 b -5.716809913707417 Loss: 0.41033270216761847\n",
      "W1: 10.897207197743816 W2: 1.878531758931396 b -5.716853608710809 Loss: 0.4103326832757542\n",
      "W1: 10.897293353472197 W2: 1.8785410750571556 b -5.716897263271692 Loss: 0.41033266441889804\n",
      "W1: 10.897379429300274 W2: 1.8785503826160401 b -5.716940877427959 Loss: 0.41033264559698474\n",
      "W1: 10.897465425303206 W2: 1.8785596816159726 b -5.716984451217469 Loss: 0.4103326268099492\n",
      "W1: 10.89755134155608 W2: 1.8785689720648688 b -5.717027984678043 Loss: 0.4103326080577259\n",
      "W1: 10.897637178133907 W2: 1.8785782539706373 b -5.717071477847467 Loss: 0.4103325893402504\n",
      "W1: 10.897722935111632 W2: 1.878587527341179 b -5.717114930763492 Loss: 0.4103325706574577\n",
      "W1: 10.897808612564122 W2: 1.8785967921843876 b -5.7171583434638285 Loss: 0.41033255200928304\n",
      "W1: 10.897894210566173 W2: 1.8786060485081495 b -5.717201715986156 Loss: 0.410332533395662\n",
      "W1: 10.89797972919251 W2: 1.8786152963203435 b -5.717245048368114 Loss: 0.4103325148165297\n",
      "W1: 10.898065168517784 W2: 1.8786245356288411 b -5.717288340647308 Loss: 0.4103324962718223\n",
      "W1: 10.898150528616574 W2: 1.8786337664415067 b -5.7173315928613055 Loss: 0.4103324777614752\n",
      "W1: 10.89823580956339 W2: 1.8786429887661968 b -5.717374805047641 Loss: 0.4103324592854245\n",
      "W1: 10.898321011432666 W2: 1.878652202610761 b -5.7174179772438105 Loss: 0.4103324408436062\n",
      "W1: 10.898406134298765 W2: 1.8786614079830417 b -5.7174611094872745 Loss: 0.4103324224359564\n",
      "W1: 10.898491178235982 W2: 1.8786706048908735 b -5.717504201815458 Loss: 0.4103324040624114\n",
      "W1: 10.898576143318534 W2: 1.8786797933420838 b -5.717547254265749 Loss: 0.41033238572290737\n",
      "W1: 10.898661029620571 W2: 1.878688973344493 b -5.717590266875502 Loss: 0.41033236741738116\n",
      "W1: 10.89874583721617 W2: 1.8786981449059135 b -5.717633239682033 Loss: 0.4103323491457692\n",
      "W1: 10.898830566179335 W2: 1.8787073080341512 b -5.717676172722624 Loss: 0.4103323309080082\n",
      "W1: 10.898915216584 W2: 1.8787164627370045 b -5.717719066034521 Loss: 0.41033231270403514\n",
      "W1: 10.898999788504028 W2: 1.8787256090222642 b -5.717761919654934 Loss: 0.41033229453378683\n",
      "W1: 10.89908428201321 W2: 1.878734746897714 b -5.717804733621037 Loss: 0.41033227639720044\n",
      "W1: 10.899168697185264 W2: 1.8787438763711304 b -5.717847507969968 Loss: 0.41033225829421344\n",
      "W1: 10.89925303409384 W2: 1.8787529974502823 b -5.717890242738831 Loss: 0.4103322402247627\n",
      "W1: 10.899337292812517 W2: 1.878762110142932 b -5.717932937964695 Loss: 0.41033222218878596\n",
      "W1: 10.899421473414797 W2: 1.8787712144568336 b -5.717975593684589 Loss: 0.4103322041862207\n",
      "W1: 10.89950557597412 W2: 1.878780310399735 b -5.718018209935511 Loss: 0.4103321862170047\n",
      "W1: 10.899589600563848 W2: 1.878789397979376 b -5.718060786754422 Loss: 0.41033216828107566\n",
      "W1: 10.899673547257276 W2: 1.8787984772034896 b -5.718103324178247 Loss: 0.4103321503783715\n",
      "W1: 10.899757416127624 W2: 1.8788075480798014 b -5.718145822243877 Loss: 0.41033213250883044\n",
      "W1: 10.899841207248047 W2: 1.87881661061603 b -5.7181882809881674 Loss: 0.4103321146723905\n",
      "W1: 10.899924920691625 W2: 1.8788256648198867 b -5.718230700447936 Loss: 0.4103320968689897\n",
      "W1: 10.90000855653137 W2: 1.8788347106990753 b -5.718273080659968 Loss: 0.41033207909856684\n",
      "W1: 10.900092114840222 W2: 1.8788437482612927 b -5.718315421661013 Loss: 0.41033206136106026\n",
      "W1: 10.900175595691051 W2: 1.878852777514229 b -5.7183577234877845 Loss: 0.4103320436564086\n",
      "W1: 10.900258999156657 W2: 1.8788617984655662 b -5.71839998617696 Loss: 0.41033202598455054\n",
      "W1: 10.900342325309769 W2: 1.8788708111229797 b -5.718442209765184 Loss: 0.4103320083454248\n",
      "W1: 10.900425574223046 W2: 1.8788798154941375 b -5.718484394289065 Loss: 0.4103319907389707\n",
      "W1: 10.900508745969079 W2: 1.8788888115867008 b -5.7185265397851754 Loss: 0.41033197316512715\n",
      "W1: 10.900591840620384 W2: 1.8788977994083234 b -5.718568646290054 Loss: 0.41033195562383323\n",
      "W1: 10.900674858249413 W2: 1.8789067789666516 b -5.718610713840204 Loss: 0.4103319381150283\n",
      "W1: 10.900757798928545 W2: 1.878915750269325 b -5.718652742472094 Loss: 0.4103319206386518\n",
      "W1: 10.900840662730088 W2: 1.8789247133239761 b -5.718694732222157 Loss: 0.4103319031946435\n",
      "W1: 10.900923449726283 W2: 1.8789336681382303 b -5.718736683126791 Loss: 0.4103318857829427\n",
      "W1: 10.901006159989299 W2: 1.8789426147197053 b -5.7187785952223615 Loss: 0.41033186840348945\n",
      "W1: 10.901088793591237 W2: 1.8789515530760124 b -5.7188204685451955 Loss: 0.4103318510562234\n",
      "W1: 10.901171350604127 W2: 1.8789604832147553 b -5.718862303131587 Loss: 0.4103318337410846\n",
      "W1: 10.90125383109993 W2: 1.8789694051435308 b -5.718904099017796 Loss: 0.4103318164580132\n",
      "W1: 10.90133623515054 W2: 1.8789783188699287 b -5.718945856240047 Loss: 0.4103317992069494\n",
      "W1: 10.901418562827777 W2: 1.8789872244015313 b -5.718987574834528 Loss: 0.41033178198783365\n",
      "W1: 10.901500814203395 W2: 1.8789961217459143 b -5.719029254837396 Loss: 0.4103317648006061\n",
      "W1: 10.901582989349079 W2: 1.8790050109106462 b -5.719070896284772 Loss: 0.4103317476452075\n",
      "W1: 10.901665088336442 W2: 1.8790138919032882 b -5.7191124992127405 Loss: 0.4103317305215786\n",
      "W1: 10.901747111237032 W2: 1.8790227647313946 b -5.719154063657353 Loss: 0.41033171342966007\n",
      "W1: 10.901829058122326 W2: 1.8790316294025127 b -5.7191955896546265 Loss: 0.4103316963693928\n",
      "W1: 10.90191092906373 W2: 1.8790404859241827 b -5.719237077240544 Loss: 0.4103316793407178\n",
      "W1: 10.901992724132583 W2: 1.8790493343039376 b -5.7192785264510535 Loss: 0.41033166234357626\n",
      "W1: 10.902074443400156 W2: 1.8790581745493036 b -5.7193199373220684 Loss: 0.4103316453779092\n",
      "W1: 10.902156086937651 W2: 1.8790670066678 b -5.719361309889467 Loss: 0.410331628443658\n",
      "W1: 10.902237654816203 W2: 1.8790758306669384 b -5.7194026441890955 Loss: 0.41033161154076436\n",
      "W1: 10.902319147106871 W2: 1.8790846465542241 b -5.719443940256763 Loss: 0.4103315946691696\n",
      "W1: 10.902400563880654 W2: 1.8790934543371551 b -5.719485198128247 Loss: 0.4103315778288154\n",
      "W1: 10.90248190520848 W2: 1.8791022540232225 b -5.719526417839289 Loss: 0.4103315610196436\n",
      "W1: 10.902563171161209 W2: 1.87911104561991 b -5.719567599425596 Loss: 0.410331544241596\n",
      "W1: 10.902644361809628 W2: 1.8791198291346949 b -5.719608742922842 Loss: 0.4103315274946148\n",
      "W1: 10.902725477224463 W2: 1.8791286045750473 b -5.719649848366668 Loss: 0.410331510778642\n",
      "W1: 10.902806517476366 W2: 1.8791373719484301 b -5.719690915792678 Loss: 0.4103314940936196\n",
      "W1: 10.902887482635924 W2: 1.8791461312622997 b -5.719731945236443 Loss: 0.41033147743949\n",
      "W1: 10.902968372773655 W2: 1.879154882524105 b -5.719772936733501 Loss: 0.41033146081619587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.90304918796001 W2: 1.879163625741288 b -5.719813890319355 Loss: 0.41033144422367945\n",
      "W1: 10.90312992826537 W2: 1.8791723609212843 b -5.719854806029474 Loss: 0.41033142766188374\n",
      "W1: 10.903210593760052 W2: 1.879181088071522 b -5.719895683899294 Loss: 0.41033141113075117\n",
      "W1: 10.903291184514302 W2: 1.8791898071994226 b -5.719936523964216 Loss: 0.4103313946302248\n",
      "W1: 10.903371700598298 W2: 1.8791985183124005 b -5.719977326259607 Loss: 0.41033137816024734\n",
      "W1: 10.903452142082152 W2: 1.879207221417863 b -5.720018090820801 Loss: 0.41033136172076207\n",
      "W1: 10.903532509035909 W2: 1.8792159165232107 b -5.720058817683099 Loss: 0.4103313453117122\n",
      "W1: 10.903612801529544 W2: 1.8792246036358375 b -5.720099506881766 Loss: 0.410331328933041\n",
      "W1: 10.903693019632966 W2: 1.87923328276313 b -5.720140158452035 Loss: 0.4103313125846915\n",
      "W1: 10.903773163416018 W2: 1.879241953912468 b -5.720180772429106 Loss: 0.41033129626660786\n",
      "W1: 10.903853232948473 W2: 1.8792506170912247 b -5.720221348848142 Loss: 0.41033127997873325\n",
      "W1: 10.90393322830004 W2: 1.879259272306766 b -5.720261887744275 Loss: 0.41033126372101153\n",
      "W1: 10.90401314954036 W2: 1.8792679195664515 b -5.720302389152604 Loss: 0.4103312474933864\n",
      "W1: 10.904092996739003 W2: 1.879276558877633 b -5.720342853108192 Loss: 0.4103312312958018\n",
      "W1: 10.904172769965475 W2: 1.8792851902476564 b -5.72038327964607 Loss: 0.4103312151282019\n",
      "W1: 10.904252469289219 W2: 1.8792938136838602 b -5.720423668801235 Loss: 0.4103311989905309\n",
      "W1: 10.904332094779603 W2: 1.879302429193576 b -5.7204640206086514 Loss: 0.4103311828827328\n",
      "W1: 10.904411646505936 W2: 1.879311036784129 b -5.72050433510325 Loss: 0.4103311668047519\n",
      "W1: 10.904491124537456 W2: 1.8793196364628373 b -5.720544612319927 Loss: 0.41033115075653287\n",
      "W1: 10.904570528943333 W2: 1.8793282282370118 b -5.720584852293546 Loss: 0.4103311347380204\n",
      "W1: 10.904649859792674 W2: 1.8793368121139573 b -5.720625055058937 Loss: 0.4103311187491585\n",
      "W1: 10.904729117154517 W2: 1.8793453881009714 b -5.720665220650898 Loss: 0.41033110278989293\n",
      "W1: 10.904808301097836 W2: 1.8793539562053447 b -5.720705349104192 Loss: 0.4103310868601676\n",
      "W1: 10.904887411691536 W2: 1.8793625164343615 b -5.72074544045355 Loss: 0.410331070959928\n",
      "W1: 10.904966449004458 W2: 1.8793710687952987 b -5.720785494733669 Loss: 0.4103310550891192\n",
      "W1: 10.905045413105375 W2: 1.8793796132954268 b -5.720825511979213 Loss: 0.41033103924768605\n",
      "W1: 10.905124304062994 W2: 1.8793881499420095 b -5.720865492224814 Loss: 0.4103310234355742\n",
      "W1: 10.905203121945956 W2: 1.8793966787423035 b -5.720905435505068 Loss: 0.41033100765272895\n",
      "W1: 10.905281866822836 W2: 1.879405199703559 b -5.720945341854541 Loss: 0.41033099189909555\n",
      "W1: 10.905360538762144 W2: 1.8794137128330193 b -5.720985211307764 Loss: 0.41033097617461994\n",
      "W1: 10.905439137832323 W2: 1.8794222181379208 b -5.721025043899236 Loss: 0.4103309604792475\n",
      "W1: 10.905517664101751 W2: 1.8794307156254932 b -5.721064839663424 Loss: 0.4103309448129243\n",
      "W1: 10.905596117638739 W2: 1.8794392053029598 b -5.72110459863476 Loss: 0.41033092917559594\n",
      "W1: 10.905674498511532 W2: 1.879447687177537 b -5.721144320847644 Loss: 0.41033091356720863\n",
      "W1: 10.90575280678831 W2: 1.879456161256434 b -5.721184006336443 Loss: 0.4103308979877086\n",
      "W1: 10.90583104253719 W2: 1.8794646275468538 b -5.721223655135492 Loss: 0.4103308824370416\n",
      "W1: 10.90590920582622 W2: 1.8794730860559925 b -5.721263267279091 Loss: 0.4103308669151543\n",
      "W1: 10.905987296723382 W2: 1.8794815367910394 b -5.72130284280151 Loss: 0.41033085142199294\n",
      "W1: 10.906065315296596 W2: 1.8794899797591773 b -5.721342381736984 Loss: 0.41033083595750425\n",
      "W1: 10.906143261613714 W2: 1.8794984149675822 b -5.721381884119717 Loss: 0.41033082052163455\n",
      "W1: 10.906221135742523 W2: 1.8795068424234231 b -5.7214213499838795 Loss: 0.4103308051143307\n",
      "W1: 10.906298937750748 W2: 1.8795152621338629 b -5.72146077936361 Loss: 0.4103307897355393\n",
      "W1: 10.906376667706043 W2: 1.8795236741060575 b -5.7215001722930126 Loss: 0.4103307743852076\n",
      "W1: 10.906454325676004 W2: 1.879532078347156 b -5.721539528806161 Loss: 0.4103307590632825\n",
      "W1: 10.906531911728155 W2: 1.8795404748643012 b -5.721578848937094 Loss: 0.41033074376971085\n",
      "W1: 10.90660942592996 W2: 1.8795488636646287 b -5.721618132719821 Loss: 0.41033072850444\n",
      "W1: 10.906686868348814 W2: 1.8795572447552678 b -5.721657380188317 Loss: 0.4103307132674173\n",
      "W1: 10.906764239052052 W2: 1.879565618143341 b -5.721696591376523 Loss: 0.41033069805859035\n",
      "W1: 10.906841538106942 W2: 1.8795739838359646 b -5.721735766318352 Loss: 0.41033068287790636\n",
      "W1: 10.906918765580686 W2: 1.8795823418402475 b -5.721774905047679 Loss: 0.41033066772531285\n",
      "W1: 10.906995921540423 W2: 1.8795906921632926 b -5.721814007598352 Loss: 0.41033065260075785\n",
      "W1: 10.907073006053226 W2: 1.8795990348121956 b -5.721853074004184 Loss: 0.41033063750418874\n",
      "W1: 10.907150019186107 W2: 1.8796073697940463 b -5.721892104298956 Loss: 0.4103306224355539\n",
      "W1: 10.907226961006009 W2: 1.8796156971159275 b -5.721931098516416 Loss: 0.410330607394801\n",
      "W1: 10.907303831579812 W2: 1.8796240167849152 b -5.721970056690281 Loss: 0.4103305923818781\n",
      "W1: 10.907380630974334 W2: 1.879632328808079 b -5.722008978854235 Loss: 0.4103305773967335\n",
      "W1: 10.907457359256329 W2: 1.879640633192482 b -5.72204786504193 Loss: 0.4103305624393155\n",
      "W1: 10.907534016492482 W2: 1.8796489299451806 b -5.722086715286987 Loss: 0.41033054750957254\n",
      "W1: 10.907610602749418 W2: 1.8796572190732246 b -5.722125529622994 Loss: 0.410330532607453\n",
      "W1: 10.907687118093698 W2: 1.8796655005836571 b -5.722164308083506 Loss: 0.41033051773290546\n",
      "W1: 10.907763562591816 W2: 1.879673774483515 b -5.7222030507020465 Loss: 0.4103305028858786\n",
      "W1: 10.907839936310205 W2: 1.8796820407798285 b -5.7222417575121085 Loss: 0.410330488066321\n",
      "W1: 10.907916239315234 W2: 1.879690299479621 b -5.722280428547152 Loss: 0.41033047327418204\n",
      "W1: 10.907992471673209 W2: 1.8796985505899093 b -5.7223190638406045 Loss: 0.41033045850941\n",
      "W1: 10.908068633450368 W2: 1.8797067941177041 b -5.722357663425862 Loss: 0.41033044377195454\n",
      "W1: 10.908144724712889 W2: 1.8797150300700094 b -5.722396227336289 Loss: 0.4103304290617645\n",
      "W1: 10.908220745526885 W2: 1.8797232584538224 b -5.722434755605218 Loss: 0.4103304143787892\n",
      "W1: 10.908296695958407 W2: 1.879731479276134 b -5.722473248265949 Loss: 0.41033039972297797\n",
      "W1: 10.908372576073441 W2: 1.8797396925439285 b -5.722511705351751 Loss: 0.41033038509428027\n",
      "W1: 10.90844838593791 W2: 1.8797478982641838 b -5.722550126895861 Loss: 0.4103303704926456\n",
      "W1: 10.908524125617676 W2: 1.879756096443871 b -5.722588512931485 Loss: 0.41033035591802364\n",
      "W1: 10.908599795178533 W2: 1.8797642870899554 b -5.722626863491795 Loss: 0.4103303413703639\n",
      "W1: 10.908675394686217 W2: 1.8797724702093948 b -5.722665178609935 Loss: 0.4103303268496164\n",
      "W1: 10.908750924206396 W2: 1.879780645809141 b -5.722703458319014 Loss: 0.4103303123557311\n",
      "W1: 10.90882638380468 W2: 1.8797888138961398 b -5.722741702652111 Loss: 0.4103302978886579\n",
      "W1: 10.90890177354661 W2: 1.8797969744773297 b -5.722779911642274 Loss: 0.41033028344834704\n",
      "W1: 10.908977093497668 W2: 1.8798051275596432 b -5.722818085322517 Loss: 0.4103302690347485\n",
      "W1: 10.909052343723275 W2: 1.8798132731500063 b -5.7228562237258265 Loss: 0.41033025464781264\n",
      "W1: 10.909127524288785 W2: 1.8798214112553384 b -5.722894326885154 Loss: 0.41033024028749004\n",
      "W1: 10.90920263525949 W2: 1.8798295418825526 b -5.72293239483342 Loss: 0.41033022595373086\n",
      "W1: 10.90927767670062 W2: 1.8798376650385553 b -5.722970427603516 Loss: 0.4103302116464858\n",
      "W1: 10.909352648677345 W2: 1.8798457807302467 b -5.723008425228301 Loss: 0.41033019736570536\n",
      "W1: 10.909427551254767 W2: 1.8798538889645204 b -5.7230463877406 Loss: 0.4103301831113406\n",
      "W1: 10.90950238449793 W2: 1.8798619897482638 b -5.723084315173209 Loss: 0.4103301688833424\n",
      "W1: 10.909577148471813 W2: 1.8798700830883577 b -5.7231222075588954 Loss: 0.41033015468166134\n",
      "W1: 10.909651843241335 W2: 1.8798781689916766 b -5.72316006493039 Loss: 0.41033014050624866\n",
      "W1: 10.90972646887135 W2: 1.8798862474650884 b -5.723197887320396 Loss: 0.41033012635705524\n",
      "W1: 10.909801025426653 W2: 1.8798943185154549 b -5.723235674761583 Loss: 0.41033011223403276\n",
      "W1: 10.909875512971974 W2: 1.879902382149631 b -5.7232734272865935 Loss: 0.41033009813713206\n",
      "W1: 10.909949931571981 W2: 1.8799104383744658 b -5.723311144928034 Loss: 0.4103300840663049\n",
      "W1: 10.910024281291282 W2: 1.8799184871968015 b -5.723348827718483 Loss: 0.4103300700215025\n",
      "W1: 10.91009856219442 W2: 1.8799265286234743 b -5.723386475690486 Loss: 0.4103300560026765\n",
      "W1: 10.91017277434588 W2: 1.8799345626613138 b -5.72342408887656 Loss: 0.4103300420097788\n",
      "W1: 10.91024691781008 W2: 1.8799425893171433 b -5.723461667309189 Loss: 0.41033002804276075\n",
      "W1: 10.91032099265138 W2: 1.87995060859778 b -5.723499211020826 Loss: 0.4103300141015746\n",
      "W1: 10.910394998934079 W2: 1.8799586205100343 b -5.723536720043894 Loss: 0.4103300001861719\n",
      "W1: 10.910468936722411 W2: 1.8799666250607103 b -5.7235741944107845 Loss: 0.4103299862965049\n",
      "W1: 10.910542806080551 W2: 1.8799746222566063 b -5.723611634153859 Loss: 0.4103299724325258\n",
      "W1: 10.910616607072612 W2: 1.8799826121045136 b -5.723649039305447 Loss: 0.41032995859418675\n",
      "W1: 10.910690339762644 W2: 1.8799905946112172 b -5.723686409897848 Loss: 0.4103299447814399\n",
      "W1: 10.910764004214634 W2: 1.8799985697834964 b -5.72372374596333 Loss: 0.41032993099423776\n",
      "W1: 10.910837600492513 W2: 1.8800065376281236 b -5.723761047534131 Loss: 0.4103299172325327\n",
      "W1: 10.910911128660148 W2: 1.8800144981518652 b -5.723798314642457 Loss: 0.41032990349627774\n",
      "W1: 10.910984588781345 W2: 1.880022451361481 b -5.723835547320486 Loss: 0.4103298897854249\n",
      "W1: 10.911057980919846 W2: 1.8800303972637247 b -5.723872745600362 Loss: 0.41032987609992727\n",
      "W1: 10.911131305139335 W2: 1.8800383358653436 b -5.723909909514201 Loss: 0.4103298624397375\n",
      "W1: 10.911204561503435 W2: 1.880046267173079 b -5.723947039094086 Loss: 0.41032984880480877\n",
      "W1: 10.911277750075707 W2: 1.8800541911936657 b -5.723984134372072 Loss: 0.410329835195094\n",
      "W1: 10.91135087091965 W2: 1.880062107933832 b -5.724021195380182 Loss: 0.41032982161054615\n",
      "W1: 10.911423924098703 W2: 1.8800700174003002 b -5.724058222150409 Loss: 0.4103298080511184\n",
      "W1: 10.911496909676245 W2: 1.8800779195997863 b -5.724095214714714 Loss: 0.4103297945167644\n",
      "W1: 10.911569827715594 W2: 1.880085814539 b -5.724132173105029 Loss: 0.410329781007437\n",
      "W1: 10.911642678280007 W2: 1.880093702224645 b -5.724169097353257 Loss: 0.41032976752309\n",
      "W1: 10.91171546143268 W2: 1.8801015826634182 b -5.724205987491267 Loss: 0.4103297540636767\n",
      "W1: 10.91178817723675 W2: 1.8801094558620108 b -5.7242428435509005 Loss: 0.410329740629151\n",
      "W1: 10.911860825755289 W2: 1.8801173218271074 b -5.7242796655639685 Loss: 0.4103297272194664\n",
      "W1: 10.911933407051315 W2: 1.8801251805653865 b -5.72431645356225 Loss: 0.41032971383457684\n",
      "W1: 10.912005921187781 W2: 1.8801330320835203 b -5.7243532075774946 Loss: 0.41032970047443595\n",
      "W1: 10.912078368227581 W2: 1.880140876388175 b -5.724389927641423 Loss: 0.41032968713899803\n",
      "W1: 10.912150748233548 W2: 1.8801487134860106 b -5.724426613785723 Loss: 0.41032967382821695\n",
      "W1: 10.912223061268456 W2: 1.8801565433836807 b -5.724463266042054 Loss: 0.410329660542047\n",
      "W1: 10.912295307395018 W2: 1.8801643660878324 b -5.724499884442046 Loss: 0.410329647280442\n",
      "W1: 10.912367486675887 W2: 1.8801721816051074 b -5.724536469017296 Loss: 0.41032963404335676\n",
      "W1: 10.912439599173657 W2: 1.8801799899421403 b -5.724573019799374 Loss: 0.41032962083074553\n",
      "W1: 10.912511644950861 W2: 1.8801877911055602 b -5.724609536819819 Loss: 0.4103296076425627\n",
      "W1: 10.91258362406997 W2: 1.88019558510199 b -5.724646020110138 Loss: 0.4103295944787628\n",
      "W1: 10.912655536593402 W2: 1.880203371938046 b -5.724682469701812 Loss: 0.4103295813393007\n",
      "W1: 10.912727382583506 W2: 1.8802111516203386 b -5.724718885626288 Loss: 0.41032956822413097\n",
      "W1: 10.912799162102578 W2: 1.880218924155472 b -5.7247552679149845 Loss: 0.4103295551332086\n",
      "W1: 10.912870875212851 W2: 1.8802266895500443 b -5.724791616599291 Loss: 0.4103295420664883\n",
      "W1: 10.9129425219765 W2: 1.8802344478106474 b -5.724827931710567 Loss: 0.4103295290239251\n",
      "W1: 10.91301410245564 W2: 1.8802421989438671 b -5.7248642132801395 Loss: 0.41032951600547424\n",
      "W1: 10.913085616712328 W2: 1.880249942956283 b -5.72490046133931 Loss: 0.41032950301109083\n",
      "W1: 10.913157064808557 W2: 1.8802576798544683 b -5.724936675919347 Loss: 0.41032949004073005\n",
      "W1: 10.913228446806265 W2: 1.8802654096449907 b -5.7249728570514895 Loss: 0.41032947709434725\n",
      "W1: 10.913299762767329 W2: 1.8802731323344113 b -5.725009004766949 Loss: 0.410329464171898\n",
      "W1: 10.913371012753567 W2: 1.8802808479292854 b -5.725045119096904 Loss: 0.41032945127333753\n",
      "W1: 10.913442196826738 W2: 1.880288556436162 b -5.7250812000725055 Loss: 0.4103294383986215\n",
      "W1: 10.913513315048542 W2: 1.8802962578615838 b -5.725117247724875 Loss: 0.41032942554770563\n",
      "W1: 10.913584367480619 W2: 1.880303952212088 b -5.7251532620851044 Loss: 0.41032941272054585\n",
      "W1: 10.91365535418455 W2: 1.8803116394942048 b -5.725189243184254 Loss: 0.41032939991709766\n",
      "W1: 10.91372627522186 W2: 1.8803193197144592 b -5.725225191053357 Loss: 0.4103293871373172\n",
      "W1: 10.91379713065401 W2: 1.8803269928793698 b -5.725261105723416 Loss: 0.41032937438116035\n",
      "W1: 10.913867920542405 W2: 1.880334658995449 b -5.725296987225404 Loss: 0.41032936164858336\n",
      "W1: 10.913938644948391 W2: 1.8803423180692034 b -5.7253328355902635 Loss: 0.41032934893954226\n",
      "W1: 10.914009303933257 W2: 1.8803499701071333 b -5.72536865084891 Loss: 0.41032933625399326\n",
      "W1: 10.91407989755823 W2: 1.880357615115733 b -5.725404433032228 Loss: 0.4103293235918927\n",
      "W1: 10.914150425884479 W2: 1.8803652531014907 b -5.725440182171073 Loss: 0.4103293109531972\n",
      "W1: 10.914220888973118 W2: 1.8803728840708889 b -5.72547589829627 Loss: 0.41032929833786297\n",
      "W1: 10.914291286885197 W2: 1.8803805080304035 b -5.725511581438616 Loss: 0.4103292857458467\n",
      "W1: 10.914361619681712 W2: 1.8803881249865046 b -5.72554723162888 Loss: 0.41032927317710494\n",
      "W1: 10.914431887423598 W2: 1.8803957349456566 b -5.725582848897799 Loss: 0.41032926063159486\n",
      "W1: 10.914502090171734 W2: 1.8804033379143175 b -5.725618433276082 Loss: 0.4103292481092726\n",
      "W1: 10.91457222798694 W2: 1.8804109338989392 b -5.725653984794409 Loss: 0.41032923561009566\n",
      "W1: 10.914642300929975 W2: 1.880418522905968 b -5.725689503483429 Loss: 0.4103292231340207\n",
      "W1: 10.914712309061544 W2: 1.880426104941844 b -5.725724989373766 Loss: 0.4103292106810048\n",
      "W1: 10.914782252442292 W2: 1.8804336800130013 b -5.72576044249601 Loss: 0.4103291982510051\n",
      "W1: 10.914852131132804 W2: 1.8804412481258677 b -5.725795862880725 Loss: 0.41032918584397904\n",
      "W1: 10.91492194519361 W2: 1.8804488092868654 b -5.7258312505584446 Loss: 0.41032917345988357\n",
      "W1: 10.914991694685181 W2: 1.8804563635024107 b -5.725866605559674 Loss: 0.4103291610986764\n",
      "W1: 10.91506137966793 W2: 1.8804639107789136 b -5.72590192791489 Loss: 0.4103291487603146\n",
      "W1: 10.915131000202214 W2: 1.8804714511227785 b -5.725937217654539 Loss: 0.4103291364447562\n",
      "W1: 10.915200556348328 W2: 1.8804789845404033 b -5.72597247480904 Loss: 0.4103291241519585\n",
      "W1: 10.915270048166512 W2: 1.8804865110381805 b -5.726007699408781 Loss: 0.4103291118818793\n",
      "W1: 10.91533947571695 W2: 1.8804940306224962 b -5.726042891484122 Loss: 0.4103290996344763\n",
      "W1: 10.915408839059767 W2: 1.880501543299731 b -5.726078051065395 Loss: 0.41032908740970747\n",
      "W1: 10.915478138255029 W2: 1.880509049076259 b -5.726113178182903 Loss: 0.4103290752075306\n",
      "W1: 10.915547373362745 W2: 1.880516547958449 b -5.7261482728669195 Loss: 0.4103290630279037\n",
      "W1: 10.91561654444287 W2: 1.880524039952663 b -5.726183335147689 Loss: 0.4103290508707852\n",
      "W1: 10.915685651555297 W2: 1.8805315250652583 b -5.726218365055428 Loss: 0.4103290387361328\n",
      "W1: 10.915754694759864 W2: 1.8805390033025853 b -5.726253362620324 Loss: 0.410329026623905\n",
      "W1: 10.91582367411635 W2: 1.8805464746709886 b -5.726288327872536 Loss: 0.4103290145340603\n",
      "W1: 10.91589258968448 W2: 1.8805539391768071 b -5.726323260842193 Loss: 0.41032900246655674\n",
      "W1: 10.91596144152392 W2: 1.8805613968263741 b -5.726358161559398 Loss: 0.4103289904213529\n",
      "W1: 10.91603022969428 W2: 1.8805688476260165 b -5.726393030054224 Loss: 0.41032897839840765\n",
      "W1: 10.91609895425511 W2: 1.8805762915820554 b -5.726427866356714 Loss: 0.4103289663976792\n",
      "W1: 10.916167615265907 W2: 1.880583728700806 b -5.7264626704968835 Loss: 0.4103289544191265\n",
      "W1: 10.916236212786108 W2: 1.880591158988578 b -5.726497442504721 Loss: 0.4103289424627084\n",
      "W1: 10.916304746875095 W2: 1.8805985824516749 b -5.7265321824101845 Loss: 0.4103289305283837\n",
      "W1: 10.916373217592193 W2: 1.8806059990963941 b -5.7265668902432045 Loss: 0.4103289186161113\n",
      "W1: 10.916441624996668 W2: 1.8806134089290276 b -5.726601566033683 Loss: 0.41032890672585015\n",
      "W1: 10.916509969147734 W2: 1.8806208119558614 b -5.726636209811493 Loss: 0.4103288948575596\n",
      "W1: 10.916578250104545 W2: 1.8806282081831756 b -5.726670821606479 Loss: 0.4103288830111986\n",
      "W1: 10.916646467926197 W2: 1.8806355976172444 b -5.726705401448459 Loss: 0.4103288711867265\n",
      "W1: 10.916714622671734 W2: 1.8806429802643363 b -5.726739949367221 Loss: 0.41032885938410274\n",
      "W1: 10.916782714400139 W2: 1.8806503561307137 b -5.726774465392523 Loss: 0.4103288476032866\n",
      "W1: 10.916850743170343 W2: 1.8806577252226335 b -5.726808949554099 Loss: 0.41032883584423757\n",
      "W1: 10.916918709041218 W2: 1.8806650875463466 b -5.726843401881651 Loss: 0.4103288241069151\n",
      "W1: 10.916986612071579 W2: 1.8806724431080981 b -5.726877822404855 Loss: 0.41032881239127905\n",
      "W1: 10.917054452320187 W2: 1.8806797919141272 b -5.726912211153358 Loss: 0.4103288006972892\n",
      "W1: 10.917122229845745 W2: 1.8806871339706674 b -5.726946568156779 Loss: 0.4103287890249048\n",
      "W1: 10.917189944706902 W2: 1.8806944692839465 b -5.726980893444709 Loss: 0.41032877737408646\n",
      "W1: 10.917257596962248 W2: 1.8807017978601863 b -5.727015187046709 Loss: 0.41032876574479343\n",
      "W1: 10.91732518667032 W2: 1.880709119705603 b -5.727049448992315 Loss: 0.4103287541369864\n",
      "W1: 10.917392713889596 W2: 1.8807164348264065 b -5.727083679311034 Loss: 0.41032874255062474\n",
      "W1: 10.917460178678501 W2: 1.8807237432288018 b -5.727117878032343 Loss: 0.4103287309856693\n",
      "W1: 10.917527581095404 W2: 1.8807310449189873 b -5.727152045185693 Loss: 0.4103287194420797\n",
      "W1: 10.917594921198617 W2: 1.8807383399031563 b -5.727186180800507 Loss: 0.41032870791981657\n",
      "W1: 10.917662199046395 W2: 1.8807456281874957 b -5.727220284906179 Loss: 0.4103286964188404\n",
      "W1: 10.91772941469694 W2: 1.880752909778187 b -5.727254357532076 Loss: 0.4103286849391116\n",
      "W1: 10.917796568208397 W2: 1.880760184681406 b -5.727288398707537 Loss: 0.41032867348059043\n",
      "W1: 10.917863659638856 W2: 1.8807674529033227 b -5.727322408461872 Loss: 0.41032866204323776\n",
      "W1: 10.91793068904635 W2: 1.8807747144501012 b -5.727356386824366 Loss: 0.41032865062701407\n",
      "W1: 10.917997656488861 W2: 1.8807819693279 b -5.727390333824272 Loss: 0.41032863923188034\n",
      "W1: 10.918064562024309 W2: 1.880789217542872 b -5.727424249490818 Loss: 0.41032862785779733\n",
      "W1: 10.918131405710563 W2: 1.8807964591011639 b -5.7274581338532045 Loss: 0.41032861650472585\n",
      "W1: 10.918198187605435 W2: 1.8808036940089172 b -5.727491986940603 Loss: 0.41032860517262687\n",
      "W1: 10.918264907766686 W2: 1.8808109222722675 b -5.727525808782158 Loss: 0.4103285938614618\n",
      "W1: 10.918331566252016 W2: 1.8808181438973446 b -5.727559599406986 Loss: 0.41032858257119115\n",
      "W1: 10.918398163119072 W2: 1.8808253588902726 b -5.727593358844175 Loss: 0.4103285713017767\n",
      "W1: 10.918464698425447 W2: 1.88083256725717 b -5.727627087122788 Loss: 0.41032856005317925\n",
      "W1: 10.918531172228679 W2: 1.8808397690041496 b -5.727660784271858 Loss: 0.4103285488253604\n",
      "W1: 10.91859758458625 W2: 1.8808469641373184 b -5.727694450320392 Loss: 0.4103285376182814\n",
      "W1: 10.918663935555585 W2: 1.880854152662778 b -5.727728085297368 Loss: 0.4103285264319039\n",
      "W1: 10.91873022519406 W2: 1.880861334586624 b -5.727761689231737 Loss: 0.4103285152661895\n",
      "W1: 10.918796453558992 W2: 1.8808685099149465 b -5.727795262152423 Loss: 0.4103285041210997\n",
      "W1: 10.918862620707642 W2: 1.8808756786538297 b -5.727828804088322 Loss: 0.4103284929965962\n",
      "W1: 10.918928726697223 W2: 1.8808828408093523 b -5.727862315068303 Loss: 0.41032848189264076\n",
      "W1: 10.918994771584885 W2: 1.8808899963875876 b -5.727895795121207 Loss: 0.41032847080919516\n",
      "W1: 10.919060755427727 W2: 1.8808971453946028 b -5.727929244275849 Loss: 0.4103284597462215\n",
      "W1: 10.919126678282797 W2: 1.88090428783646 b -5.727962662561016 Loss: 0.4103284487036817\n",
      "W1: 10.919192540207083 W2: 1.8809114237192148 b -5.727996050005466 Loss: 0.4103284376815377\n",
      "W1: 10.919258341257521 W2: 1.880918553048918 b -5.728029406637932 Loss: 0.41032842667975183\n",
      "W1: 10.919324081490993 W2: 1.8809256758316146 b -5.728062732487118 Loss: 0.4103284156982862\n",
      "W1: 10.919389760964327 W2: 1.8809327920733436 b -5.728096027581702 Loss: 0.41032840473710297\n",
      "W1: 10.919455379734295 W2: 1.8809399017801387 b -5.728129291950335 Loss: 0.4103283937961646\n",
      "W1: 10.919520937857616 W2: 1.8809470049580277 b -5.72816252562164 Loss: 0.41032838287543355\n",
      "W1: 10.919586435390954 W2: 1.8809541016130333 b -5.728195728624212 Loss: 0.41032837197487204\n",
      "W1: 10.919651872390922 W2: 1.8809611917511722 b -5.728228900986621 Loss: 0.4103283610944429\n",
      "W1: 10.919717248914074 W2: 1.8809682753784553 b -5.728262042737408 Loss: 0.4103283502341087\n",
      "W1: 10.919782565016915 W2: 1.8809753525008888 b -5.728295153905089 Loss: 0.410328339393832\n",
      "W1: 10.919847820755892 W2: 1.8809824231244723 b -5.72832823451815 Loss: 0.4103283285735758\n",
      "W1: 10.919913016187401 W2: 1.8809894872552002 b -5.728361284605053 Loss: 0.41032831777330253\n",
      "W1: 10.919978151367783 W2: 1.8809965448990615 b -5.7283943041942305 Loss: 0.4103283069929755\n",
      "W1: 10.920043226353323 W2: 1.8810035960620395 b -5.72842729331409 Loss: 0.4103282962325574\n",
      "W1: 10.920108241200259 W2: 1.8810106407501117 b -5.7284602519930115 Loss: 0.41032828549201156\n",
      "W1: 10.920173195964768 W2: 1.8810176789692505 b -5.728493180259346 Loss: 0.41032827477130085\n",
      "W1: 10.920238090702977 W2: 1.8810247107254223 b -5.728526078141422 Loss: 0.4103282640703884\n",
      "W1: 10.920302925470958 W2: 1.8810317360245883 b -5.728558945667537 Loss: 0.41032825338923756\n",
      "W1: 10.920367700324732 W2: 1.8810387548727039 b -5.728591782865963 Loss: 0.4103282427278117\n",
      "W1: 10.920432415320263 W2: 1.881045767275719 b -5.728624589764946 Loss: 0.4103282320860742\n",
      "W1: 10.920497070513466 W2: 1.8810527732395783 b -5.728657366392706 Loss: 0.4103282214639885\n",
      "W1: 10.920561665960198 W2: 1.8810597727702205 b -5.728690112777432 Loss: 0.41032821086151805\n",
      "W1: 10.920626201716267 W2: 1.8810667658735791 b -5.728722828947291 Loss: 0.41032820027862654\n",
      "W1: 10.920690677837424 W2: 1.8810737525555818 b -5.728755514930421 Loss: 0.4103281897152774\n",
      "W1: 10.92075509437937 W2: 1.881080732822151 b -5.7287881707549335 Loss: 0.4103281791714346\n",
      "W1: 10.92081945139775 W2: 1.8810877066792038 b -5.728820796448914 Loss: 0.4103281686470618\n",
      "W1: 10.920883748948157 W2: 1.881094674132651 b -5.7288533920404205 Loss: 0.41032815814212303\n",
      "W1: 10.920947987086134 W2: 1.881101635188399 b -5.728885957557485 Loss: 0.41032814765658193\n",
      "W1: 10.921012165867166 W2: 1.8811085898523476 b -5.728918493028113 Loss: 0.4103281371904028\n",
      "W1: 10.92107628534669 W2: 1.8811155381303921 b -5.728950998480283 Loss: 0.4103281267435495\n",
      "W1: 10.921140345580085 W2: 1.8811224800284216 b -5.7289834739419465 Loss: 0.4103281163159862\n",
      "W1: 10.92120434662268 W2: 1.8811294155523202 b -5.72901591944103 Loss: 0.41032810590767715\n",
      "W1: 10.921268288529753 W2: 1.881136344707966 b -5.729048335005434 Loss: 0.4103280955185866\n",
      "W1: 10.921332171356525 W2: 1.8811432675012323 b -5.7290807206630285 Loss: 0.41032808514867886\n",
      "W1: 10.921395995158168 W2: 1.8811501839379865 b -5.729113076441662 Loss: 0.4103280747979183\n",
      "W1: 10.9214597599898 W2: 1.8811570940240905 b -5.729145402369153 Loss: 0.4103280644662696\n",
      "W1: 10.921523465906487 W2: 1.881163997765401 b -5.729177698473296 Loss: 0.41032805415369694\n",
      "W1: 10.921587112963243 W2: 1.8811708951677693 b -5.729209964781858 Loss: 0.4103280438601651\n",
      "W1: 10.921650701215027 W2: 1.8811777862370407 b -5.72924220132258 Loss: 0.41032803358563874\n",
      "W1: 10.921714230716747 W2: 1.8811846709790556 b -5.729274408123177 Loss: 0.41032802333008256\n",
      "W1: 10.92177770152326 W2: 1.881191549399649 b -5.7293065852113365 Loss: 0.41032801309346123\n",
      "W1: 10.92184111368937 W2: 1.88119842150465 b -5.729338732614721 Loss: 0.41032800287573995\n",
      "W1: 10.921904467269826 W2: 1.881205287299883 b -5.729370850360967 Loss: 0.4103279926768833\n",
      "W1: 10.92196776231933 W2: 1.8812121467911662 b -5.7294029384776834 Loss: 0.41032798249685665\n",
      "W1: 10.922030998892529 W2: 1.881218999984313 b -5.729434996992453 Loss: 0.4103279723356247\n",
      "W1: 10.922094177044016 W2: 1.881225846885131 b -5.729467025932835 Loss: 0.4103279621931526\n",
      "W1: 10.922157296828336 W2: 1.8812326874994227 b -5.72949902532636 Loss: 0.4103279520694059\n",
      "W1: 10.922220358299981 W2: 1.881239521832985 b -5.729530995200533 Loss: 0.41032794196434935\n",
      "W1: 10.922283361513387 W2: 1.8812463498916092 b -5.729562935582833 Loss: 0.41032793187794864\n",
      "W1: 10.922346306522943 W2: 1.8812531716810819 b -5.729594846500714 Loss: 0.41032792181016897\n",
      "W1: 10.922409193382984 W2: 1.8812599872071836 b -5.729626727981602 Loss: 0.41032791176097577\n",
      "W1: 10.922472022147796 W2: 1.88126679647569 b -5.729658580052899 Loss: 0.41032790173033473\n",
      "W1: 10.922534792871607 W2: 1.8812735994923708 b -5.729690402741979 Loss: 0.4103278917182113\n",
      "W1: 10.9225975056086 W2: 1.881280396262991 b -5.729722196076192 Loss: 0.41032788172457124\n",
      "W1: 10.922660160412903 W2: 1.8812871867933096 b -5.729753960082863 Loss: 0.41032787174937996\n",
      "W1: 10.922722757338594 W2: 1.881293971089081 b -5.729785694789286 Loss: 0.4103278617926035\n",
      "W1: 10.922785296439697 W2: 1.8813007491560536 b -5.729817400222736 Loss: 0.41032785185420767\n",
      "W1: 10.922847777770187 W2: 1.8813075209999706 b -5.7298490764104555 Loss: 0.4103278419341583\n",
      "W1: 10.922910201383987 W2: 1.88131428662657 b -5.729880723379667 Loss: 0.41032783203242135\n",
      "W1: 10.922972567334968 W2: 1.8813210460415846 b -5.729912341157563 Loss: 0.41032782214896296\n",
      "W1: 10.92303487567695 W2: 1.8813277992507413 b -5.729943929771314 Loss: 0.41032781228374904\n",
      "W1: 10.923097126463704 W2: 1.8813345462597626 b -5.72997548924806 Loss: 0.41032780243674566\n",
      "W1: 10.923159319748944 W2: 1.8813412870743647 b -5.73000701961492 Loss: 0.4103277926079194\n",
      "W1: 10.923221455586338 W2: 1.881348021700259 b -5.730038520898984 Loss: 0.4103277827972363\n",
      "W1: 10.923283534029503 W2: 1.8813547501431516 b -5.7300699931273185 Loss: 0.4103277730046628\n",
      "W1: 10.923345555132 W2: 1.881361472408743 b -5.730101436326963 Loss: 0.4103277632301652\n",
      "W1: 10.923407518947345 W2: 1.881368188502729 b -5.7301328505249325 Loss: 0.4103277534737099\n",
      "W1: 10.923469425529 W2: 1.8813748984307994 b -5.730164235748215 Loss: 0.4103277437352636\n",
      "W1: 10.923531274930376 W2: 1.8813816021986391 b -5.730195592023774 Loss: 0.41032773401479283\n",
      "W1: 10.923593067204834 W2: 1.8813882998119278 b -5.730226919378548 Loss: 0.4103277243122643\n",
      "W1: 10.923654802405684 W2: 1.8813949912763395 b -5.730258217839447 Loss: 0.4103277146276447\n",
      "W1: 10.923716480586185 W2: 1.8814016765975432 b -5.73028948743336 Loss: 0.4103277049609008\n",
      "W1: 10.923778101799543 W2: 1.881408355781203 b -5.730320728187148 Loss: 0.41032769531199914\n",
      "W1: 10.92383966609892 W2: 1.8814150288329767 b -5.730351940127646 Loss: 0.4103276856809072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.923901173537418 W2: 1.8814216957585181 b -5.730383123281665 Loss: 0.41032767606759146\n",
      "W1: 10.923962624168098 W2: 1.8814283565634748 b -5.73041427767599 Loss: 0.4103276664720194\n",
      "W1: 10.924024018043964 W2: 1.8814350112534897 b -5.730445403337381 Loss: 0.4103276568941576\n",
      "W1: 10.924085355217972 W2: 1.8814416598342 b -5.730476500292572 Loss: 0.41032764733397364\n",
      "W1: 10.924146635743027 W2: 1.8814483023112383 b -5.730507568568272 Loss: 0.4103276377914343\n",
      "W1: 10.924207859671984 W2: 1.8814549386902313 b -5.730538608191165 Loss: 0.4103276282665073\n",
      "W1: 10.924269027057647 W2: 1.8814615689768006 b -5.73056961918791 Loss: 0.41032761875915963\n",
      "W1: 10.924330137952772 W2: 1.881468193176563 b -5.730600601585139 Loss: 0.410327609269359\n",
      "W1: 10.924391192410061 W2: 1.8814748112951298 b -5.730631555409461 Loss: 0.41032759979707245\n",
      "W1: 10.92445219048217 W2: 1.881481423338107 b -5.730662480687459 Loss: 0.4103275903422679\n",
      "W1: 10.9245131322217 W2: 1.8814880293110954 b -5.73069337744569 Loss: 0.4103275809049128\n",
      "W1: 10.924574017681207 W2: 1.8814946292196906 b -5.730724245710688 Loss: 0.41032757148497473\n",
      "W1: 10.924634846913195 W2: 1.8815012230694832 b -5.730755085508958 Loss: 0.4103275620824214\n",
      "W1: 10.924695619970116 W2: 1.8815078108660586 b -5.730785896866985 Loss: 0.41032755269722043\n",
      "W1: 10.924756336904375 W2: 1.8815143926149966 b -5.730816679811226 Loss: 0.4103275433293399\n",
      "W1: 10.924816997768326 W2: 1.8815209683218723 b -5.730847434368112 Loss: 0.41032753397874766\n",
      "W1: 10.924877602614275 W2: 1.8815275379922554 b -5.7308781605640515 Loss: 0.4103275246454114\n",
      "W1: 10.924938151494475 W2: 1.8815341016317104 b -5.730908858425426 Loss: 0.4103275153292994\n",
      "W1: 10.924998644461128 W2: 1.8815406592457966 b -5.7309395279785935 Loss: 0.41032750603037954\n",
      "W1: 10.925059081566394 W2: 1.8815472108400684 b -5.730970169249886 Loss: 0.41032749674862007\n",
      "W1: 10.925119462862375 W2: 1.8815537564200746 b -5.731000782265611 Loss: 0.410327487483989\n",
      "W1: 10.925179788401127 W2: 1.8815602959913593 b -5.731031367052052 Loss: 0.4103274782364547\n",
      "W1: 10.92524005823466 W2: 1.8815668295594612 b -5.731061923635465 Loss: 0.4103274690059855\n",
      "W1: 10.925300272414928 W2: 1.8815733571299136 b -5.731092452042085 Loss: 0.41032745979254953\n",
      "W1: 10.92536043099384 W2: 1.8815798787082452 b -5.731122952298119 Loss: 0.4103274505961154\n",
      "W1: 10.925420534023251 W2: 1.8815863942999793 b -5.73115342442975 Loss: 0.41032744141665156\n",
      "W1: 10.925480581554973 W2: 1.8815929039106343 b -5.7311838684631375 Loss: 0.4103274322541267\n",
      "W1: 10.925540573640765 W2: 1.881599407545723 b -5.731214284424414 Loss: 0.410327423108509\n",
      "W1: 10.925600510332336 W2: 1.8816059052107532 b -5.73124467233969 Loss: 0.41032741397976746\n",
      "W1: 10.92566039168135 W2: 1.881612396911228 b -5.731275032235049 Loss: 0.4103274048678708\n",
      "W1: 10.925720217739416 W2: 1.881618882652645 b -5.731305364136552 Loss: 0.4103273957727874\n",
      "W1: 10.925779988558098 W2: 1.8816253624404966 b -5.731335668070232 Loss: 0.4103273866944864\n",
      "W1: 10.925839704188911 W2: 1.8816318362802706 b -5.7313659440621 Loss: 0.4103273776329368\n",
      "W1: 10.92589936468332 W2: 1.8816383041774494 b -5.731396192138143 Loss: 0.4103273685881072\n",
      "W1: 10.92595897009274 W2: 1.88164476613751 b -5.731426412324321 Loss: 0.4103273595599669\n",
      "W1: 10.926018520468538 W2: 1.8816512221659247 b -5.731456604646572 Loss: 0.41032735054848485\n",
      "W1: 10.926078015862034 W2: 1.8816576722681608 b -5.7314867691308065 Loss: 0.41032734155363\n",
      "W1: 10.926137456324495 W2: 1.8816641164496803 b -5.731516905802914 Loss: 0.4103273325753717\n",
      "W1: 10.926196841907144 W2: 1.88167055471594 b -5.731547014688756 Loss: 0.4103273236136792\n",
      "W1: 10.926256172661153 W2: 1.881676987072392 b -5.731577095814172 Loss: 0.4103273146685216\n",
      "W1: 10.926315448637645 W2: 1.881683413524483 b -5.731607149204978 Loss: 0.4103273057398685\n",
      "W1: 10.926374669887695 W2: 1.881689834077655 b -5.731637174886961 Loss: 0.4103272968276892\n",
      "W1: 10.926433836462328 W2: 1.8816962487373445 b -5.731667172885889 Loss: 0.41032728793195317\n",
      "W1: 10.926492948412523 W2: 1.8817026575089832 b -5.731697143227501 Loss: 0.4103272790526297\n",
      "W1: 10.92655200578921 W2: 1.8817090603979978 b -5.731727085937515 Loss: 0.4103272701896888\n",
      "W1: 10.92661100864327 W2: 1.8817154574098098 b -5.731757001041624 Loss: 0.41032726134309977\n",
      "W1: 10.926669957025535 W2: 1.881721848549836 b -5.731786888565495 Loss: 0.41032725251283236\n",
      "W1: 10.92672885098679 W2: 1.8817282338234878 b -5.731816748534772 Loss: 0.4103272436988563\n",
      "W1: 10.926787690577768 W2: 1.8817346132361716 b -5.731846580975076 Loss: 0.4103272349011417\n",
      "W1: 10.926846475849162 W2: 1.8817409867932888 b -5.731876385912002 Loss: 0.41032722611965794\n",
      "W1: 10.92690520685161 W2: 1.8817473545002361 b -5.731906163371121 Loss: 0.41032721735437505\n",
      "W1: 10.9269638836357 W2: 1.8817537163624047 b -5.7319359133779795 Loss: 0.4103272086052632\n",
      "W1: 10.92702250625198 W2: 1.8817600723851813 b -5.731965635958102 Loss: 0.41032719987229244\n",
      "W1: 10.927081074750943 W2: 1.8817664225739472 b -5.731995331136987 Loss: 0.41032719115543254\n",
      "W1: 10.927139589183037 W2: 1.881772766934079 b -5.7320249989401075 Loss: 0.41032718245465377\n",
      "W1: 10.927198049598662 W2: 1.8817791054709476 b -5.732054639392916 Loss: 0.4103271737699265\n",
      "W1: 10.92725645604817 W2: 1.8817854381899202 b -5.732084252520839 Loss: 0.41032716510122086\n",
      "W1: 10.927314808581864 W2: 1.8817917650963578 b -5.732113838349279 Loss: 0.41032715644850715\n",
      "W1: 10.92737310725 W2: 1.881798086195617 b -5.732143396903614 Loss: 0.4103271478117556\n",
      "W1: 10.927431352102788 W2: 1.8818044014930493 b -5.732172928209199 Loss: 0.41032713919093683\n",
      "W1: 10.927489543190386 W2: 1.8818107109940012 b -5.7322024322913645 Loss: 0.41032713058602116\n",
      "W1: 10.92754768056291 W2: 1.8818170147038145 b -5.732231909175418 Loss: 0.41032712199697924\n",
      "W1: 10.927605764270423 W2: 1.8818233126278254 b -5.732261358886642 Loss: 0.41032711342378164\n",
      "W1: 10.927663794362944 W2: 1.881829604771366 b -5.732290781450295 Loss: 0.41032710486639884\n",
      "W1: 10.927721770890443 W2: 1.881835891139763 b -5.732320176891611 Loss: 0.41032709632480163\n",
      "W1: 10.927779693902844 W2: 1.881842171738338 b -5.732349545235803 Loss: 0.4103270877989607\n",
      "W1: 10.927837563450021 W2: 1.8818484465724077 b -5.732378886508059 Loss: 0.410327079288847\n",
      "W1: 10.927895379581804 W2: 1.8818547156472842 b -5.73240820073354 Loss: 0.41032707079443126\n",
      "W1: 10.927953142347972 W2: 1.8818609789682745 b -5.732437487937388 Loss: 0.4103270623156845\n",
      "W1: 10.928010851798259 W2: 1.8818672365406803 b -5.732466748144718 Loss: 0.41032705385257756\n",
      "W1: 10.928068507982351 W2: 1.881873488369799 b -5.732495981380623 Loss: 0.41032704540508136\n",
      "W1: 10.928126110949888 W2: 1.8818797344609226 b -5.732525187670171 Loss: 0.4103270369731673\n",
      "W1: 10.928183660750461 W2: 1.8818859748193386 b -5.732554367038407 Loss: 0.4103270285568063\n",
      "W1: 10.928241157433616 W2: 1.8818922094503292 b -5.732583519510353 Loss: 0.41032702015596934\n",
      "W1: 10.92829860104885 W2: 1.881898438359172 b -5.732612645111006 Loss: 0.410327011770628\n",
      "W1: 10.928355991645613 W2: 1.8819046615511394 b -5.73264174386534 Loss: 0.41032700340075334\n",
      "W1: 10.928413329273312 W2: 1.8819108790314991 b -5.732670815798306 Loss: 0.41032699504631687\n",
      "W1: 10.9284706139813 W2: 1.881917090805514 b -5.73269986093483 Loss: 0.41032698670728984\n",
      "W1: 10.928527845818891 W2: 1.8819232968784418 b -5.732728879299817 Loss: 0.41032697838364385\n",
      "W1: 10.928585024835346 W2: 1.8819294972555356 b -5.732757870918145 Loss: 0.41032697007535024\n",
      "W1: 10.928642151079883 W2: 1.8819356919420436 b -5.732786835814672 Loss: 0.41032696178238054\n",
      "W1: 10.92869922460167 W2: 1.881941880943209 b -5.732815774014229 Loss: 0.41032695350470655\n",
      "W1: 10.928756245449833 W2: 1.8819480642642699 b -5.732844685541628 Loss: 0.41032694524229973\n",
      "W1: 10.928813213673445 W2: 1.8819542419104602 b -5.732873570421653 Loss: 0.410326936995132\n",
      "W1: 10.928870129321538 W2: 1.8819604138870085 b -5.732902428679067 Loss: 0.4103269287631749\n",
      "W1: 10.928926992443097 W2: 1.8819665801991385 b -5.732931260338609 Loss: 0.4103269205464004\n",
      "W1: 10.928983803087057 W2: 1.8819727408520692 b -5.7329600654249955 Loss: 0.41032691234478036\n",
      "W1: 10.929040561302308 W2: 1.8819788958510149 b -5.732988843962918 Loss: 0.4103269041582866\n",
      "W1: 10.929097267137696 W2: 1.8819850452011846 b -5.733017595977047 Loss: 0.4103268959868911\n",
      "W1: 10.929153920642017 W2: 1.881991188907783 b -5.733046321492027 Loss: 0.410326887830566\n",
      "W1: 10.929210521864025 W2: 1.8819973269760093 b -5.733075020532482 Loss: 0.41032687968928344\n",
      "W1: 10.929267070852424 W2: 1.8820034594110586 b -5.73310369312301 Loss: 0.4103268715630153\n",
      "W1: 10.92932356765587 W2: 1.882009586218121 b -5.733132339288189 Loss: 0.41032686345173386\n",
      "W1: 10.929380012322982 W2: 1.8820157074023813 b -5.7331609590525705 Loss: 0.41032685535541147\n",
      "W1: 10.929436404902322 W2: 1.88202182296902 b -5.733189552440685 Loss: 0.4103268472740203\n",
      "W1: 10.929492745442412 W2: 1.8820279329232126 b -5.733218119477038 Loss: 0.4103268392075328\n",
      "W1: 10.929549033991727 W2: 1.8820340372701299 b -5.733246660186114 Loss: 0.41032683115592117\n",
      "W1: 10.929605270598694 W2: 1.8820401360149377 b -5.733275174592373 Loss: 0.4103268231191581\n",
      "W1: 10.929661455311697 W2: 1.882046229162797 b -5.733303662720253 Loss: 0.41032681509721575\n",
      "W1: 10.929717588179074 W2: 1.8820523167188645 b -5.733332124594167 Loss: 0.41032680709006686\n",
      "W1: 10.929773669249114 W2: 1.8820583986882915 b -5.7333605602385065 Loss: 0.41032679909768427\n",
      "W1: 10.929829698570062 W2: 1.8820644750762248 b -5.73338896967764 Loss: 0.41032679112004045\n",
      "W1: 10.929885676190118 W2: 1.8820705458878062 b -5.733417352935914 Loss: 0.4103267831571076\n",
      "W1: 10.929941602157436 W2: 1.882076611128173 b -5.733445710037648 Loss: 0.41032677520885924\n",
      "W1: 10.929997476520125 W2: 1.8820826708024578 b -5.733474041007143 Loss: 0.4103267672752677\n",
      "W1: 10.930053299326245 W2: 1.8820887249157883 b -5.733502345868675 Loss: 0.4103267593563059\n",
      "W1: 10.930109070623814 W2: 1.8820947734732874 b -5.733530624646497 Loss: 0.4103267514519469\n",
      "W1: 10.930164790460804 W2: 1.882100816480073 b -5.73355887736484 Loss: 0.41032674356216353\n",
      "W1: 10.930220458885138 W2: 1.8821068539412589 b -5.733587104047912 Loss: 0.41032673568692885\n",
      "W1: 10.930276075944699 W2: 1.8821128858619536 b -5.733615304719896 Loss: 0.41032672782621576\n",
      "W1: 10.93033164168732 W2: 1.882118912247261 b -5.733643479404956 Loss: 0.4103267199799974\n",
      "W1: 10.930387156160794 W2: 1.8821249331022802 b -5.7336716281272295 Loss: 0.4103267121482473\n",
      "W1: 10.930442619412862 W2: 1.8821309484321058 b -5.7336997509108345 Loss: 0.41032670433093815\n",
      "W1: 10.930498031491224 W2: 1.8821369582418277 b -5.733727847779863 Loss: 0.41032669652804343\n",
      "W1: 10.930553392443533 W2: 1.8821429625365305 b -5.733755918758388 Loss: 0.4103266887395364\n",
      "W1: 10.930608702317398 W2: 1.8821489613212947 b -5.733783963870456 Loss: 0.4103266809653906\n",
      "W1: 10.930663961160382 W2: 1.882154954601196 b -5.733811983140093 Loss: 0.41032667320557914\n",
      "W1: 10.930719169020005 W2: 1.882160942381305 b -5.733839976591302 Loss: 0.41032666546007557\n",
      "W1: 10.930774325943737 W2: 1.8821669246666881 b -5.733867944248063 Loss: 0.41032665772885335\n",
      "W1: 10.930829431979008 W2: 1.8821729014624067 b -5.733895886134333 Loss: 0.4103266500118862\n",
      "W1: 10.930884487173202 W2: 1.8821788727735176 b -5.733923802274049 Loss: 0.4103266423091476\n",
      "W1: 10.930939491573657 W2: 1.8821848386050728 b -5.733951692691121 Loss: 0.41032663462061136\n",
      "W1: 10.930994445227666 W2: 1.8821907989621196 b -5.73397955740944 Loss: 0.4103266269462508\n",
      "W1: 10.931049348182478 W2: 1.8821967538497009 b -5.734007396452873 Loss: 0.41032661928604\n",
      "W1: 10.931104200485297 W2: 1.8822027032728545 b -5.734035209845266 Loss: 0.4103266116399526\n",
      "W1: 10.931159002183282 W2: 1.882208647236614 b -5.734062997610439 Loss: 0.4103266040079626\n",
      "W1: 10.931213753323547 W2: 1.882214585746008 b -5.734090759772195 Loss: 0.4103265963900437\n",
      "W1: 10.931268453953162 W2: 1.8822205188060603 b -5.734118496354308 Loss: 0.41032658878617007\n",
      "W1: 10.931323104119153 W2: 1.8822264464217906 b -5.734146207380536 Loss: 0.41032658119631543\n",
      "W1: 10.9313777038685 W2: 1.8822323685982134 b -5.734173892874609 Loss: 0.4103265736204538\n",
      "W1: 10.93143225324814 W2: 1.8822382853403388 b -5.734201552860239 Loss: 0.41032656605855977\n",
      "W1: 10.931486752304963 W2: 1.882244196653172 b -5.734229187361112 Loss: 0.4103265585106069\n",
      "W1: 10.931541201085818 W2: 1.8822501025417138 b -5.734256796400896 Loss: 0.41032655097656967\n",
      "W1: 10.931595599637506 W2: 1.8822560030109603 b -5.734284380003232 Loss: 0.41032654345642217\n",
      "W1: 10.931649948006784 W2: 1.8822618980659032 b -5.734311938191742 Loss: 0.41032653595013885\n",
      "W1: 10.93170424624037 W2: 1.882267787711529 b -5.734339470990024 Loss: 0.41032652845769396\n",
      "W1: 10.931758494384932 W2: 1.8822736719528204 b -5.734366978421655 Loss: 0.41032652097906186\n",
      "W1: 10.931812692487096 W2: 1.8822795507947545 b -5.734394460510189 Loss: 0.4103265135142167\n",
      "W1: 10.931866840593443 W2: 1.8822854242423046 b -5.734421917279158 Loss: 0.41032650606313353\n",
      "W1: 10.93192093875051 W2: 1.882291292300439 b -5.7344493487520705 Loss: 0.41032649862578646\n",
      "W1: 10.931974987004791 W2: 1.8822971549741212 b -5.734476754952415 Loss: 0.41032649120215015\n",
      "W1: 10.932028985402736 W2: 1.8823030122683106 b -5.7345041359036575 Loss: 0.41032648379219927\n",
      "W1: 10.932082933990749 W2: 1.8823088641879617 b -5.734531491629241 Loss: 0.4103264763959084\n",
      "W1: 10.93213683281519 W2: 1.8823147107380243 b -5.734558822152586 Loss: 0.41032646901325215\n",
      "W1: 10.93219068192238 W2: 1.8823205519234438 b -5.734586127497092 Loss: 0.4103264616442057\n",
      "W1: 10.932244481358591 W2: 1.8823263877491612 b -5.734613407686137 Loss: 0.41032645428874326\n",
      "W1: 10.932298231170051 W2: 1.8823322182201125 b -5.734640662743074 Loss: 0.4103264469468401\n",
      "W1: 10.932351931402948 W2: 1.8823380433412293 b -5.734667892691238 Loss: 0.4103264396184709\n",
      "W1: 10.932405582103423 W2: 1.8823438631174387 b -5.7346950975539395 Loss: 0.4103264323036109\n",
      "W1: 10.932459183317572 W2: 1.8823496775536632 b -5.734722277354467 Loss: 0.4103264250022347\n",
      "W1: 10.932512735091453 W2: 1.8823554866548204 b -5.734749432116088 Loss: 0.41032641771431744\n",
      "W1: 10.932566237471077 W2: 1.882361290425824 b -5.734776561862047 Loss: 0.4103264104398345\n",
      "W1: 10.932619690502412 W2: 1.8823670888715827 b -5.734803666615568 Loss: 0.4103264031787608\n",
      "W1: 10.93267309423138 W2: 1.8823728819970005 b -5.734830746399853 Loss: 0.4103263959310713\n",
      "W1: 10.932726448703862 W2: 1.8823786698069773 b -5.73485780123808 Loss: 0.41032638869674154\n",
      "W1: 10.932779753965697 W2: 1.8823844523064082 b -5.7348848311534075 Loss: 0.41032638147574674\n",
      "W1: 10.932833010062676 W2: 1.8823902295001838 b -5.734911836168972 Loss: 0.41032637426806196\n",
      "W1: 10.93288621704055 W2: 1.88239600139319 b -5.734938816307886 Loss: 0.41032636707366293\n",
      "W1: 10.932939374945029 W2: 1.8824017679903084 b -5.7349657715932425 Loss: 0.41032635989252486\n",
      "W1: 10.932992483821772 W2: 1.8824075292964162 b -5.734992702048112 Loss: 0.4103263527246231\n",
      "W1: 10.933045543716403 W2: 1.8824132853163857 b -5.735019607695544 Loss: 0.4103263455699334\n",
      "W1: 10.9330985546745 W2: 1.882419036055085 b -5.735046488558565 Loss: 0.4103263384284311\n",
      "W1: 10.933151516741594 W2: 1.8824247815173774 b -5.735073344660179 Loss: 0.41032633130009194\n",
      "W1: 10.933204429963178 W2: 1.8824305217081216 b -5.735100176023372 Loss: 0.4103263241848914\n",
      "W1: 10.933257294384699 W2: 1.8824362566321724 b -5.735126982671105 Loss: 0.4103263170828052\n",
      "W1: 10.933310110051563 W2: 1.8824419862943795 b -5.735153764626317 Loss: 0.41032630999380904\n",
      "W1: 10.933362877009131 W2: 1.8824477106995885 b -5.735180521911929 Loss: 0.4103263029178789\n",
      "W1: 10.933415595302723 W2: 1.88245342985264 b -5.735207254550837 Loss: 0.4103262958549905\n",
      "W1: 10.933468264977614 W2: 1.8824591437583709 b -5.735233962565918 Loss: 0.4103262888051194\n",
      "W1: 10.93352088607904 W2: 1.8824648524216128 b -5.7352606459800235 Loss: 0.410326281768242\n",
      "W1: 10.933573458652187 W2: 1.8824705558471932 b -5.735287304815988 Loss: 0.4103262747443338\n",
      "W1: 10.933625982742207 W2: 1.8824762540399353 b -5.7353139390966215 Loss: 0.41032626773337105\n",
      "W1: 10.933678458394203 W2: 1.8824819470046574 b -5.7353405488447144 Loss: 0.4103262607353297\n",
      "W1: 10.933730885653238 W2: 1.8824876347461739 b -5.735367134083035 Loss: 0.4103262537501859\n",
      "W1: 10.933783264564331 W2: 1.882493317269294 b -5.735393694834328 Loss: 0.4103262467779157\n",
      "W1: 10.93383559517246 W2: 1.8824989945788229 b -5.735420231121321 Loss: 0.4103262398184955\n",
      "W1: 10.93388787752256 W2: 1.8825046666795613 b -5.735446742966716 Loss: 0.4103262328719012\n",
      "W1: 10.93394011165952 W2: 1.8825103335763056 b -5.735473230393197 Loss: 0.41032622593810913\n",
      "W1: 10.933992297628192 W2: 1.8825159952738475 b -5.7354996934234235 Loss: 0.41032621901709576\n",
      "W1: 10.934044435473384 W2: 1.8825216517769743 b -5.735526132080036 Loss: 0.41032621210883724\n",
      "W1: 10.934096525239859 W2: 1.882527303090469 b -5.7355525463856525 Loss: 0.4103262052133102\n",
      "W1: 10.93414856697234 W2: 1.8825329492191099 b -5.73557893636287 Loss: 0.4103261983304909\n",
      "W1: 10.934200560715507 W2: 1.882538590167671 b -5.735605302034266 Loss: 0.41032619146035587\n",
      "W1: 10.934252506513996 W2: 1.882544225940922 b -5.735631643422392 Loss: 0.4103261846028815\n",
      "W1: 10.934304404412405 W2: 1.882549856543628 b -5.735657960549784 Loss: 0.41032617775804475\n",
      "W1: 10.934356254455286 W2: 1.88255548198055 b -5.735684253438953 Loss: 0.41032617092582196\n",
      "W1: 10.93440805668715 W2: 1.882561102256444 b -5.73571052211239 Loss: 0.41032616410618955\n",
      "W1: 10.934459811152468 W2: 1.882566717376062 b -5.735736766592565 Loss: 0.4103261572991246\n",
      "W1: 10.934511517895665 W2: 1.8825723273441517 b -5.735762986901926 Loss: 0.4103261505046038\n",
      "W1: 10.934563176961126 W2: 1.882577932165456 b -5.7357891830629 Loss: 0.4103261437226037\n",
      "W1: 10.934614788393194 W2: 1.8825835318447142 b -5.735815355097895 Loss: 0.4103261369531015\n",
      "W1: 10.934666352236173 W2: 1.88258912638666 b -5.735841503029294 Loss: 0.41032613019607367\n",
      "W1: 10.93471786853432 W2: 1.8825947157960237 b -5.735867626879464 Loss: 0.4103261234514975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.93476933733185 W2: 1.8826003000775307 b -5.735893726670745 Loss: 0.4103261167193496\n",
      "W1: 10.934820758672942 W2: 1.8826058792359022 b -5.735919802425461 Loss: 0.4103261099996072\n",
      "W1: 10.934872132601727 W2: 1.8826114532758549 b -5.735945854165912 Loss: 0.41032610329224734\n",
      "W1: 10.9349234591623 W2: 1.8826170222021015 b -5.735971881914379 Loss: 0.4103260965972471\n",
      "W1: 10.93497473839871 W2: 1.88262258601935 b -5.735997885693121 Loss: 0.4103260899145836\n",
      "W1: 10.935025970354964 W2: 1.8826281447323039 b -5.736023865524375 Loss: 0.4103260832442338\n",
      "W1: 10.935077155075032 W2: 1.8826336983456629 b -5.73604982143036 Loss: 0.41032607658617515\n",
      "W1: 10.935128292602837 W2: 1.8826392468641215 b -5.73607575343327 Loss: 0.41032606994038495\n",
      "W1: 10.935179382982263 W2: 1.8826447902923709 b -5.736101661555282 Loss: 0.4103260633068405\n",
      "W1: 10.935230426257153 W2: 1.8826503286350968 b -5.73612754581855 Loss: 0.41032605668551886\n",
      "W1: 10.93528142247131 W2: 1.8826558618969815 b -5.736153406245208 Loss: 0.4103260500763976\n",
      "W1: 10.93533237166849 W2: 1.8826613900827025 b -5.736179242857369 Loss: 0.41032604347945417\n",
      "W1: 10.935383273892414 W2: 1.8826669131969331 b -5.736205055677123 Loss: 0.41032603689466607\n",
      "W1: 10.935434129186756 W2: 1.8826724312443424 b -5.736230844726544 Loss: 0.41032603032201076\n",
      "W1: 10.935484937595154 W2: 1.8826779442295947 b -5.736256610027681 Loss: 0.4103260237614659\n",
      "W1: 10.935535699161202 W2: 1.8826834521573503 b -5.736282351602564 Loss: 0.4103260172130089\n",
      "W1: 10.935586413928451 W2: 1.8826889550322654 b -5.736308069473202 Loss: 0.41032601067661734\n",
      "W1: 10.935637081940415 W2: 1.8826944528589915 b -5.736333763661583 Loss: 0.41032600415226894\n",
      "W1: 10.935687703240564 W2: 1.882699945642176 b -5.736359434189675 Loss: 0.4103259976399418\n",
      "W1: 10.935738277872328 W2: 1.882705433386462 b -5.736385081079424 Loss: 0.4103259911396134\n",
      "W1: 10.935788805879097 W2: 1.8827109160964879 b -5.736410704352758 Loss: 0.41032598465126124\n",
      "W1: 10.935839287304217 W2: 1.8827163937768883 b -5.736436304031581 Loss: 0.4103259781748638\n",
      "W1: 10.935889722190995 W2: 1.8827218664322933 b -5.736461880137778 Loss: 0.4103259717103984\n",
      "W1: 10.935940110582695 W2: 1.882727334067329 b -5.736487432693214 Loss: 0.4103259652578433\n",
      "W1: 10.935990452522546 W2: 1.8827327966866165 b -5.736512961719733 Loss: 0.41032595881717615\n",
      "W1: 10.936040748053728 W2: 1.8827382542947735 b -5.736538467239158 Loss: 0.4103259523883755\n",
      "W1: 10.936090997219386 W2: 1.8827437068964126 b -5.736563949273291 Loss: 0.4103259459714188\n",
      "W1: 10.936141200062622 W2: 1.8827491544961428 b -5.736589407843916 Loss: 0.4103259395662846\n",
      "W1: 10.936191356626498 W2: 1.8827545970985684 b -5.736614842972794 Loss: 0.41032593317295074\n",
      "W1: 10.936241466954035 W2: 1.8827600347082896 b -5.736640254681666 Loss: 0.41032592679139535\n",
      "W1: 10.936291531088214 W2: 1.8827654673299024 b -5.736665642992254 Loss: 0.41032592042159693\n",
      "W1: 10.936341549071972 W2: 1.8827708949679982 b -5.736691007926256 Loss: 0.4103259140635334\n",
      "W1: 10.936391520948211 W2: 1.8827763176271648 b -5.736716349505353 Loss: 0.4103259077171833\n",
      "W1: 10.936441446759789 W2: 1.882781735311985 b -5.736741667751206 Loss: 0.4103259013825251\n",
      "W1: 10.936491326549524 W2: 1.8827871480270377 b -5.7367669626854525 Loss: 0.4103258950595368\n",
      "W1: 10.936541160360193 W2: 1.8827925557768979 b -5.736792234329712 Loss: 0.4103258887481971\n",
      "W1: 10.936590948234533 W2: 1.8827979585661356 b -5.736817482705583 Loss: 0.41032588244848417\n",
      "W1: 10.936640690215242 W2: 1.8828033563993172 b -5.7368427078346445 Loss: 0.4103258761603767\n",
      "W1: 10.936690386344976 W2: 1.8828087492810046 b -5.736867909738453 Loss: 0.4103258698838534\n",
      "W1: 10.936740036666352 W2: 1.8828141372157554 b -5.7368930884385465 Loss: 0.4103258636188923\n",
      "W1: 10.936789641221946 W2: 1.8828195202081233 b -5.736918243956444 Loss: 0.4103258573654726\n",
      "W1: 10.936839200054292 W2: 1.8828248982626574 b -5.736943376313641 Loss: 0.4103258511235726\n",
      "W1: 10.936888713205887 W2: 1.882830271383903 b -5.736968485531614 Loss: 0.4103258448931712\n",
      "W1: 10.936938180719187 W2: 1.8828356395764008 b -5.736993571631822 Loss: 0.41032583867424693\n",
      "W1: 10.936987602636606 W2: 1.8828410028446874 b -5.7370186346356995 Loss: 0.4103258324667788\n",
      "W1: 10.937036979000519 W2: 1.8828463611932953 b -5.737043674564664 Loss: 0.4103258262707454\n",
      "W1: 10.937086309853264 W2: 1.8828517146267527 b -5.73706869144011 Loss: 0.41032582008612556\n",
      "W1: 10.937135595237134 W2: 1.8828570631495838 b -5.7370936852834165 Loss: 0.4103258139128984\n",
      "W1: 10.937184835194385 W2: 1.8828624067663082 b -5.737118656115938 Loss: 0.4103258077510427\n",
      "W1: 10.937234029767232 W2: 1.8828677454814418 b -5.7371436039590105 Loss: 0.4103258016005375\n",
      "W1: 10.93728317899785 W2: 1.8828730792994959 b -5.7371685288339505 Loss: 0.4103257954613618\n",
      "W1: 10.937332282928377 W2: 1.8828784082249779 b -5.737193430762053 Loss: 0.4103257893334945\n",
      "W1: 10.937381341600908 W2: 1.8828837322623908 b -5.737218309764595 Loss: 0.41032578321691493\n",
      "W1: 10.937430355057497 W2: 1.8828890514162337 b -5.7372431658628305 Loss: 0.410325777111602\n",
      "W1: 10.937479323340163 W2: 1.8828943656910013 b -5.7372679990779964 Loss: 0.41032577101753503\n",
      "W1: 10.937528246490881 W2: 1.8828996750911842 b -5.73729280943131 Loss: 0.41032576493469297\n",
      "W1: 10.937577124551591 W2: 1.882904979621269 b -5.7373175969439645 Loss: 0.4103257588630554\n",
      "W1: 10.937625957564189 W2: 1.8829102792857377 b -5.737342361637138 Loss: 0.4103257528026015\n",
      "W1: 10.937674745570531 W2: 1.8829155740890688 b -5.737367103531986 Loss: 0.41032574675331046\n",
      "W1: 10.937723488612438 W2: 1.8829208640357362 b -5.737391822649645 Loss: 0.4103257407151617\n",
      "W1: 10.937772186731689 W2: 1.8829261491302096 b -5.737416519011231 Loss: 0.41032573468813477\n",
      "W1: 10.937820839970023 W2: 1.8829314293769548 b -5.737441192637841 Loss: 0.4103257286722087\n",
      "W1: 10.93786944836914 W2: 1.8829367047804335 b -5.7374658435505514 Loss: 0.4103257226673635\n",
      "W1: 10.937918011970702 W2: 1.882941975345103 b -5.737490471770419 Loss: 0.4103257166735782\n",
      "W1: 10.937966530816329 W2: 1.8829472410754169 b -5.7375150773184815 Loss: 0.4103257106908326\n",
      "W1: 10.938015004947603 W2: 1.882952501975824 b -5.737539660215755 Loss: 0.4103257047191064\n",
      "W1: 10.938063434406068 W2: 1.8829577580507695 b -5.737564220483238 Loss: 0.41032569875837877\n",
      "W1: 10.938111819233228 W2: 1.8829630093046943 b -5.737588758141908 Loss: 0.4103256928086299\n",
      "W1: 10.938160159470547 W2: 1.8829682557420353 b -5.737613273212723 Loss: 0.41032568686983917\n",
      "W1: 10.938208455159451 W2: 1.8829734973672254 b -5.737637765716623 Loss: 0.41032568094198657\n",
      "W1: 10.938256706341326 W2: 1.882978734184693 b -5.737662235674525 Loss: 0.41032567502505146\n",
      "W1: 10.938304913057518 W2: 1.8829839661988628 b -5.737686683107328 Loss: 0.410325669119014\n",
      "W1: 10.938353075349337 W2: 1.882989193414155 b -5.737711108035913 Loss: 0.41032566322385394\n",
      "W1: 10.93840119325805 W2: 1.882994415834986 b -5.737735510481138 Loss: 0.4103256573395513\n",
      "W1: 10.93844926682489 W2: 1.8829996334657682 b -5.7377598904638445 Loss: 0.4103256514660858\n",
      "W1: 10.938497296091047 W2: 1.8830048463109095 b -5.737784248004853 Loss: 0.4103256456034375\n",
      "W1: 10.938545281097674 W2: 1.883010054374814 b -5.737808583124964 Loss: 0.41032563975158637\n",
      "W1: 10.938593221885885 W2: 1.883015257661882 b -5.737832895844959 Loss: 0.41032563391051247\n",
      "W1: 10.938641118496754 W2: 1.883020456176509 b -5.737857186185601 Loss: 0.4103256280801959\n",
      "W1: 10.938688970971318 W2: 1.883025649923087 b -5.737881454167632 Loss: 0.4103256222606167\n",
      "W1: 10.938736779350574 W2: 1.883030838906004 b -5.737905699811775 Loss: 0.41032561645175486\n",
      "W1: 10.938784543675482 W2: 1.8830360231296435 b -5.737929923138734 Loss: 0.4103256106535911\n",
      "W1: 10.93883226398696 W2: 1.883041202598385 b -5.737954124169192 Loss: 0.41032560486610525\n",
      "W1: 10.93887994032589 W2: 1.8830463773166042 b -5.737978302923814 Loss: 0.4103255990892775\n",
      "W1: 10.938927572733116 W2: 1.8830515472886726 b -5.738002459423246 Loss: 0.4103255933230884\n",
      "W1: 10.938975161249441 W2: 1.883056712518958 b -5.738026593688113 Loss: 0.4103255875675178\n",
      "W1: 10.939022705915633 W2: 1.8830618730118234 b -5.738050705739022 Loss: 0.41032558182254686\n",
      "W1: 10.939070206772419 W2: 1.8830670287716285 b -5.73807479559656 Loss: 0.4103255760881554\n",
      "W1: 10.939117663860486 W2: 1.8830721798027286 b -5.738098863281295 Loss: 0.4103255703643239\n",
      "W1: 10.939165077220487 W2: 1.8830773261094749 b -5.738122908813776 Loss: 0.4103255646510331\n",
      "W1: 10.939212446893032 W2: 1.8830824676962148 b -5.738146932214531 Loss: 0.4103255589482633\n",
      "W1: 10.939259772918698 W2: 1.8830876045672915 b -5.738170933504071 Loss: 0.41032555325599507\n",
      "W1: 10.939307055338018 W2: 1.8830927367270445 b -5.738194912702886 Loss: 0.41032554757420914\n",
      "W1: 10.93935429419149 W2: 1.8830978641798088 b -5.738218869831447 Loss: 0.410325541902886\n",
      "W1: 10.939401489519575 W2: 1.8831029869299156 b -5.7382428049102066 Loss: 0.41032553624200624\n",
      "W1: 10.939448641362691 W2: 1.8831081049816922 b -5.738266717959598 Loss: 0.41032553059155075\n",
      "W1: 10.939495749761225 W2: 1.8831132183394619 b -5.738290609000035 Loss: 0.41032552495150026\n",
      "W1: 10.939542814755518 W2: 1.8831183270075438 b -5.738314478051913 Loss: 0.41032551932183536\n",
      "W1: 10.93958983638588 W2: 1.8831234309902531 b -5.738338325135605 Loss: 0.4103255137025371\n",
      "W1: 10.939636814692578 W2: 1.883128530291901 b -5.7383621502714695 Loss: 0.4103255080935859\n",
      "W1: 10.939683749715844 W2: 1.8831336249167947 b -5.738385953479843 Loss: 0.4103255024949629\n",
      "W1: 10.93973064149587 W2: 1.8831387148692376 b -5.738409734781043 Loss: 0.4103254969066492\n",
      "W1: 10.939777490072812 W2: 1.8831438001535286 b -5.73843349419537 Loss: 0.4103254913286255\n",
      "W1: 10.939824295486787 W2: 1.8831488807739631 b -5.738457231743102 Loss: 0.41032548576087263\n",
      "W1: 10.939871057777873 W2: 1.8831539567348325 b -5.7384809474445015 Loss: 0.41032548020337206\n",
      "W1: 10.939917776986114 W2: 1.883159028040424 b -5.7385046413198095 Loss: 0.4103254746561045\n",
      "W1: 10.939964453151513 W2: 1.883164094695021 b -5.738528313389249 Loss: 0.41032546911905105\n",
      "W1: 10.940011086314033 W2: 1.8831691567029027 b -5.738551963673025 Loss: 0.41032546359219296\n",
      "W1: 10.940057676513607 W2: 1.8831742140683447 b -5.738575592191321 Loss: 0.4103254580755113\n",
      "W1: 10.940104223790124 W2: 1.8831792667956184 b -5.7385991989643035 Loss: 0.4103254525689874\n",
      "W1: 10.940150728183436 W2: 1.8831843148889913 b -5.73862278401212 Loss: 0.41032544707260227\n",
      "W1: 10.940197189733361 W2: 1.8831893583527268 b -5.738646347354898 Loss: 0.4103254415863372\n",
      "W1: 10.940243608479676 W2: 1.8831943971910847 b -5.738669889012747 Loss: 0.41032543611017386\n",
      "W1: 10.94028998446212 W2: 1.8831994314083207 b -5.738693409005757 Loss: 0.41032543064409305\n",
      "W1: 10.9403363177204 W2: 1.8832044610086862 b -5.738716907354 Loss: 0.41032542518807646\n",
      "W1: 10.940382608294177 W2: 1.8832094859964292 b -5.738740384077529 Loss: 0.4103254197421054\n",
      "W1: 10.940428856223082 W2: 1.8832145063757937 b -5.738763839196377 Loss: 0.41032541430616126\n",
      "W1: 10.940475061546707 W2: 1.8832195221510193 b -5.738787272730559 Loss: 0.41032540888022556\n",
      "W1: 10.940521224304602 W2: 1.883224533326342 b -5.738810684700073 Loss: 0.41032540346427987\n",
      "W1: 10.940567344536285 W2: 1.883229539905994 b -5.738834075124894 Loss: 0.4103253980583055\n",
      "W1: 10.940613422281237 W2: 1.8832345418942034 b -5.7388574440249815 Loss: 0.4103253926622843\n",
      "W1: 10.940659457578898 W2: 1.8832395392951946 b -5.738880791420277 Loss: 0.4103253872761979\n",
      "W1: 10.940705450468673 W2: 1.8832445321131879 b -5.7389041173307 Loss: 0.4103253819000276\n",
      "W1: 10.94075140098993 W2: 1.8832495203523993 b -5.738927421776154 Loss: 0.4103253765337555\n",
      "W1: 10.940797309181999 W2: 1.8832545040170419 b -5.7389507047765225 Loss: 0.41032537117736273\n",
      "W1: 10.940843175084174 W2: 1.8832594831113239 b -5.73897396635167 Loss: 0.4103253658308315\n",
      "W1: 10.940888998735712 W2: 1.8832644576394502 b -5.738997206521445 Loss: 0.41032536049414364\n",
      "W1: 10.940934780175832 W2: 1.8832694276056214 b -5.739020425305674 Loss: 0.4103253551672806\n",
      "W1: 10.940980519443714 W2: 1.8832743930140348 b -5.739043622724167 Loss: 0.41032534985022456\n",
      "W1: 10.941026216578507 W2: 1.8832793538688832 b -5.739066798796714 Loss: 0.41032534454295727\n",
      "W1: 10.941071871619318 W2: 1.8832843101743557 b -5.739089953543089 Loss: 0.4103253392454605\n",
      "W1: 10.941117484605218 W2: 1.8832892619346377 b -5.739113086983044 Loss: 0.4103253339577165\n",
      "W1: 10.941163055575245 W2: 1.8832942091539109 b -5.739136199136314 Loss: 0.4103253286797069\n",
      "W1: 10.941208584568395 W2: 1.8832991518363524 b -5.7391592900226165 Loss: 0.41032532341141387\n",
      "W1: 10.941254071623629 W2: 1.8833040899861362 b -5.739182359661649 Loss: 0.41032531815281975\n",
      "W1: 10.941299516779873 W2: 1.883309023607432 b -5.739205408073092 Loss: 0.4103253129039061\n",
      "W1: 10.941344920076014 W2: 1.8833139527044054 b -5.739228435276606 Loss: 0.4103253076646554\n",
      "W1: 10.941390281550905 W2: 1.883318877281219 b -5.739251441291834 Loss: 0.41032530243504955\n",
      "W1: 10.94143560124336 W2: 1.883323797342031 b -5.739274426138399 Loss: 0.41032529721507094\n",
      "W1: 10.941480879192156 W2: 1.8833287128909955 b -5.739297389835909 Loss: 0.41032529200470175\n",
      "W1: 10.941526115436037 W2: 1.8833336239322633 b -5.73932033240395 Loss: 0.41032528680392405\n",
      "W1: 10.941571310013709 W2: 1.8833385304699812 b -5.739343253862092 Loss: 0.41032528161272025\n",
      "W1: 10.941616462963838 W2: 1.8833434325082918 b -5.739366154229885 Loss: 0.4103252764310728\n",
      "W1: 10.941661574325057 W2: 1.8833483300513343 b -5.739389033526862 Loss: 0.4103252712589636\n",
      "W1: 10.941706644135962 W2: 1.883353223103244 b -5.739411891772537 Loss: 0.4103252660963756\n",
      "W1: 10.941751672435116 W2: 1.8833581116681521 b -5.739434728986406 Loss: 0.4103252609432907\n",
      "W1: 10.941796659261037 W2: 1.8833629957501863 b -5.739457545187944 Loss: 0.41032525579969176\n",
      "W1: 10.941841604652216 W2: 1.8833678753534702 b -5.7394803403966135 Loss: 0.4103252506655611\n",
      "W1: 10.941886508647103 W2: 1.8833727504821236 b -5.739503114631854 Loss: 0.41032524554088107\n",
      "W1: 10.941931371284111 W2: 1.8833776211402629 b -5.7395258679130885 Loss: 0.41032524042563434\n",
      "W1: 10.94197619260162 W2: 1.8833824873320002 b -5.739548600259722 Loss: 0.4103252353198034\n",
      "W1: 10.942020972637973 W2: 1.8833873490614443 b -5.73957131169114 Loss: 0.410325230223371\n",
      "W1: 10.942065711431475 W2: 1.8833922063326995 b -5.739594002226711 Loss: 0.4103252251363198\n",
      "W1: 10.942110409020396 W2: 1.883397059149867 b -5.739616671885784 Loss: 0.41032522005863237\n",
      "W1: 10.94215506544297 W2: 1.8834019075170436 b -5.739639320687693 Loss: 0.41032521499029123\n",
      "W1: 10.942199680737396 W2: 1.8834067514383228 b -5.73966194865175 Loss: 0.4103252099312794\n",
      "W1: 10.942244254941835 W2: 1.8834115909177942 b -5.7396845557972505 Loss: 0.41032520488157975\n",
      "W1: 10.942288788094414 W2: 1.8834164259595434 b -5.739707142143473 Loss: 0.41032519984117466\n",
      "W1: 10.942333280233223 W2: 1.8834212565676522 b -5.739729707709676 Loss: 0.41032519481004726\n",
      "W1: 10.942377731396316 W2: 1.883426082746199 b -5.7397522525151015 Loss: 0.41032518978818017\n",
      "W1: 10.942422141621712 W2: 1.8834309044992583 b -5.739774776578972 Loss: 0.41032518477555674\n",
      "W1: 10.942466510947394 W2: 1.8834357218309006 b -5.739797279920494 Loss: 0.4103251797721594\n",
      "W1: 10.942510839411309 W2: 1.8834405347451926 b -5.739819762558854 Loss: 0.4103251747779712\n",
      "W1: 10.942555127051369 W2: 1.8834453432461975 b -5.739842224513222 Loss: 0.41032516979297534\n",
      "W1: 10.942599373905448 W2: 1.8834501473379748 b -5.739864665802748 Loss: 0.4103251648171548\n",
      "W1: 10.942643580011389 W2: 1.8834549470245798 b -5.739887086446566 Loss: 0.4103251598504926\n",
      "W1: 10.942687745406992 W2: 1.8834597423100645 b -5.739909486463792 Loss: 0.41032515489297167\n",
      "W1: 10.942731870130029 W2: 1.883464533198477 b -5.7399318658735226 Loss: 0.41032514994457525\n",
      "W1: 10.942775954218233 W2: 1.8834693196938617 b -5.739954224694838 Loss: 0.4103251450052865\n",
      "W1: 10.9428199977093 W2: 1.883474101800259 b -5.7399765629468 Loss: 0.4103251400750887\n",
      "W1: 10.942864000640894 W2: 1.883478879521706 b -5.739998880648452 Loss: 0.41032513515396474\n",
      "W1: 10.94290796305064 W2: 1.8834836528622354 b -5.74002117781882 Loss: 0.4103251302418981\n",
      "W1: 10.94295188497613 W2: 1.883488421825877 b -5.740043454476911 Loss: 0.41032512533887205\n",
      "W1: 10.942995766454922 W2: 1.8834931864166562 b -5.7400657106417174 Loss: 0.41032512044486985\n",
      "W1: 10.943039607524534 W2: 1.8834979466385953 b -5.740087946332211 Loss: 0.4103251155598749\n",
      "W1: 10.943083408222453 W2: 1.883502702495712 b -5.740110161567346 Loss: 0.4103251106838703\n",
      "W1: 10.943127168586129 W2: 1.8835074539920214 b -5.740132356366059 Loss: 0.4103251058168397\n",
      "W1: 10.943170888652975 W2: 1.8835122011315337 b -5.7401545307472714 Loss: 0.4103251009587666\n",
      "W1: 10.943214568460373 W2: 1.8835169439182564 b -5.7401766847298825 Loss: 0.41032509610963414\n",
      "W1: 10.943258208045666 W2: 1.8835216823561927 b -5.740198818332777 Loss: 0.41032509126942607\n",
      "W1: 10.943301807446163 W2: 1.8835264164493422 b -5.740220931574821 Loss: 0.4103250864381259\n",
      "W1: 10.94334536669914 W2: 1.8835311462017008 b -5.740243024474863 Loss: 0.41032508161571696\n",
      "W1: 10.943388885841834 W2: 1.883535871617261 b -5.740265097051732 Loss: 0.4103250768021829\n",
      "W1: 10.943432364911452 W2: 1.883540592700011 b -5.740287149324243 Loss: 0.41032507199750773\n",
      "W1: 10.94347580394516 W2: 1.883545309453936 b -5.740309181311191 Loss: 0.4103250672016745\n",
      "W1: 10.943519202980093 W2: 1.8835500218830172 b -5.740331193031354 Loss: 0.41032506241466726\n",
      "W1: 10.943562562053351 W2: 1.883554729991232 b -5.740353184503491 Loss: 0.41032505763646937\n",
      "W1: 10.943605881201998 W2: 1.8835594337825543 b -5.740375155746347 Loss: 0.410325052867065\n",
      "W1: 10.943649160463062 W2: 1.883564133260954 b -5.740397106778644 Loss: 0.4103250481064375\n",
      "W1: 10.94369239987354 W2: 1.883568828430398 b -5.740419037619093 Loss: 0.4103250433545711\n",
      "W1: 10.943735599470388 W2: 1.8835735192948488 b -5.740440948286381 Loss: 0.4103250386114492\n",
      "W1: 10.943778759290534 W2: 1.8835782058582657 b -5.740462838799182 Loss: 0.41032503387705593\n",
      "W1: 10.94382187937087 W2: 1.8835828881246042 b -5.740484709176151 Loss: 0.4103250291513749\n",
      "W1: 10.943864959748247 W2: 1.8835875660978159 b -5.740506559435925 Loss: 0.4103250244343904\n",
      "W1: 10.943908000459489 W2: 1.883592239781849 b -5.740528389597124 Loss: 0.4103250197260861\n",
      "W1: 10.943951001541382 W2: 1.8835969091806481 b -5.740550199678351 Loss: 0.4103250150264459\n",
      "W1: 10.943993963030676 W2: 1.8836015742981542 b -5.740571989698191 Loss: 0.41032501033545404\n",
      "W1: 10.94403688496409 W2: 1.8836062351383045 b -5.740593759675212 Loss: 0.4103250056530945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.944079767378305 W2: 1.8836108917050325 b -5.740615509627964 Loss: 0.41032500097935115\n",
      "W1: 10.944122610309972 W2: 1.8836155440022682 b -5.74063723957498 Loss: 0.41032499631420816\n",
      "W1: 10.9441654137957 W2: 1.8836201920339377 b -5.740658949534775 Loss: 0.41032499165764996\n",
      "W1: 10.944208177872072 W2: 1.8836248358039638 b -5.7406806395258485 Loss: 0.41032498700966025\n",
      "W1: 10.94425090257563 W2: 1.8836294753162655 b -5.740702309566681 Loss: 0.41032498237022336\n",
      "W1: 10.944293587942887 W2: 1.8836341105747583 b -5.740723959675736 Loss: 0.41032497773932347\n",
      "W1: 10.944336234010319 W2: 1.883638741583354 b -5.7407455898714606 Loss: 0.41032497311694516\n",
      "W1: 10.944378840814364 W2: 1.8836433683459608 b -5.740767200172283 Loss: 0.4103249685030722\n",
      "W1: 10.944421408391433 W2: 1.8836479908664832 b -5.740788790596615 Loss: 0.4103249638976891\n",
      "W1: 10.944463936777899 W2: 1.8836526091488222 b -5.740810361162851 Loss: 0.4103249593007802\n",
      "W1: 10.944506426010099 W2: 1.8836572231968751 b -5.740831911889369 Loss: 0.41032495471232977\n",
      "W1: 10.94454887612434 W2: 1.8836618330145356 b -5.7408534427945295 Loss: 0.41032495013232234\n",
      "W1: 10.944591287156893 W2: 1.8836664386056938 b -5.7408749538966735 Loss: 0.41032494556074234\n",
      "W1: 10.944633659143992 W2: 1.8836710399742365 b -5.740896445214128 Loss: 0.41032494099757405\n",
      "W1: 10.944675992121843 W2: 1.8836756371240464 b -5.740917916765202 Loss: 0.4103249364428018\n",
      "W1: 10.94471828612661 W2: 1.883680230059003 b -5.740939368568187 Loss: 0.4103249318964105\n",
      "W1: 10.944760541194432 W2: 1.883684818782982 b -5.740960800641355 Loss: 0.41032492735838433\n",
      "W1: 10.944802757361408 W2: 1.8836894032998557 b -5.740982213002966 Loss: 0.410324922828708\n",
      "W1: 10.944844934663605 W2: 1.8836939836134925 b -5.741003605671259 Loss: 0.4103249183073662\n",
      "W1: 10.944887073137055 W2: 1.8836985597277576 b -5.7410249786644565 Loss: 0.4103249137943434\n",
      "W1: 10.944929172817757 W2: 1.8837031316465123 b -5.7410463320007645 Loss: 0.41032490928962423\n",
      "W1: 10.944971233741676 W2: 1.8837076993736144 b -5.741067665698372 Loss: 0.4103249047931932\n",
      "W1: 10.945013255944742 W2: 1.8837122629129184 b -5.741088979775451 Loss: 0.4103249003050353\n",
      "W1: 10.945055239462855 W2: 1.883716822268275 b -5.741110274250158 Loss: 0.41032489582513526\n",
      "W1: 10.945097184331877 W2: 1.8837213774435315 b -5.741131549140627 Loss: 0.41032489135347755\n",
      "W1: 10.945139090587638 W2: 1.8837259284425314 b -5.741152804464982 Loss: 0.41032488689004726\n",
      "W1: 10.945180958265935 W2: 1.8837304752691149 b -5.741174040241326 Loss: 0.4103248824348291\n",
      "W1: 10.94522278740253 W2: 1.8837350179271182 b -5.741195256487745 Loss: 0.41032487798780776\n",
      "W1: 10.945264578033152 W2: 1.8837395564203745 b -5.741216453222311 Loss: 0.4103248735489684\n",
      "W1: 10.945306330193498 W2: 1.8837440907527134 b -5.7412376304630754 Loss: 0.4103248691182955\n",
      "W1: 10.945348043919228 W2: 1.8837486209279606 b -5.741258788228075 Loss: 0.41032486469577445\n",
      "W1: 10.945389719245972 W2: 1.8837531469499385 b -5.741279926535328 Loss: 0.4103248602813897\n",
      "W1: 10.945431356209323 W2: 1.8837576688224658 b -5.741301045402838 Loss: 0.4103248558751266\n",
      "W1: 10.945472954844844 W2: 1.8837621865493577 b -5.74132214484859 Loss: 0.4103248514769703\n",
      "W1: 10.945514515188062 W2: 1.8837667001344263 b -5.741343224890554 Loss: 0.4103248470869056\n",
      "W1: 10.945556037274473 W2: 1.8837712095814796 b -5.7413642855466795 Loss: 0.4103248427049172\n",
      "W1: 10.945597521139538 W2: 1.8837757148943224 b -5.741385326834903 Loss: 0.4103248383309907\n",
      "W1: 10.945638966818684 W2: 1.8837802160767558 b -5.741406348773143 Loss: 0.41032483396511127\n",
      "W1: 10.945680374347306 W2: 1.8837847131325776 b -5.7414273513793015 Loss: 0.4103248296072636\n",
      "W1: 10.945721743760766 W2: 1.8837892060655816 b -5.741448334671262 Loss: 0.41032482525743325\n",
      "W1: 10.945763075094392 W2: 1.883793694879559 b -5.741469298666893 Loss: 0.4103248209156052\n",
      "W1: 10.94580436838348 W2: 1.8837981795782968 b -5.741490243384046 Loss: 0.410324816581765\n",
      "W1: 10.945845623663288 W2: 1.8838026601655784 b -5.741511168840555 Loss: 0.4103248122558974\n",
      "W1: 10.94588684096905 W2: 1.883807136645184 b -5.741532075054239 Loss: 0.41032480793798826\n",
      "W1: 10.945928020335959 W2: 1.8838116090208905 b -5.741552962042897 Loss: 0.41032480362802237\n",
      "W1: 10.945969161799178 W2: 1.883816077296471 b -5.741573829824317 Loss: 0.4103247993259854\n",
      "W1: 10.946010265393836 W2: 1.883820541475695 b -5.741594678416264 Loss: 0.4103247950318625\n",
      "W1: 10.94605133115503 W2: 1.8838250015623288 b -5.74161550783649 Loss: 0.4103247907456392\n",
      "W1: 10.946092359117824 W2: 1.883829457560135 b -5.74163631810273 Loss: 0.410324786467301\n",
      "W1: 10.946133349317247 W2: 1.883833909472873 b -5.741657109232702 Loss: 0.4103247821968331\n",
      "W1: 10.946174301788298 W2: 1.8838383573042987 b -5.741677881244108 Loss: 0.410324777934221\n",
      "W1: 10.946215216565943 W2: 1.883842801058164 b -5.741698634154632 Loss: 0.4103247736794506\n",
      "W1: 10.946256093685111 W2: 1.883847240738218 b -5.741719367981943 Loss: 0.410324769432507\n",
      "W1: 10.946296933180705 W2: 1.883851676348206 b -5.741740082743693 Loss: 0.4103247651933758\n",
      "W1: 10.946337735087587 W2: 1.8838561078918699 b -5.741760778457516 Loss: 0.4103247609620427\n",
      "W1: 10.946378499440595 W2: 1.883860535372948 b -5.741781455141032 Loss: 0.41032475673849333\n",
      "W1: 10.946419226274527 W2: 1.8838649587951755 b -5.741802112811843 Loss: 0.4103247525227134\n",
      "W1: 10.946459915624153 W2: 1.8838693781622835 b -5.741822751487535 Loss: 0.4103247483146882\n",
      "W1: 10.946500567524208 W2: 1.8838737934780003 b -5.741843371185677 Loss: 0.41032474411440367\n",
      "W1: 10.946541182009394 W2: 1.8838782047460505 b -5.741863971923823 Loss: 0.4103247399218457\n",
      "W1: 10.946581759114382 W2: 1.8838826119701555 b -5.741884553719507 Loss: 0.4103247357369995\n",
      "W1: 10.94662229887381 W2: 1.8838870151540328 b -5.741905116590252 Loss: 0.41032473155985144\n",
      "W1: 10.946662801322285 W2: 1.8838914143013967 b -5.7419256605535605 Loss: 0.4103247273903872\n",
      "W1: 10.946703266494378 W2: 1.8838958094159581 b -5.7419461856269205 Loss: 0.4103247232285923\n",
      "W1: 10.94674369442463 W2: 1.8839002005014245 b -5.741966691827802 Loss: 0.4103247190744527\n",
      "W1: 10.946784085147547 W2: 1.8839045875614997 b -5.74198717917366 Loss: 0.4103247149279543\n",
      "W1: 10.946824438697607 W2: 1.8839089705998846 b -5.742007647681933 Loss: 0.41032471078908306\n",
      "W1: 10.946864755109253 W2: 1.883913349620276 b -5.742028097370043 Loss: 0.41032470665782483\n",
      "W1: 10.946905034416895 W2: 1.883917724626368 b -5.7420485282553955 Loss: 0.4103247025341656\n",
      "W1: 10.946945276654912 W2: 1.8839220956218508 b -5.74206894035538 Loss: 0.41032469841809144\n",
      "W1: 10.946985481857649 W2: 1.883926462610411 b -5.74208933368737 Loss: 0.41032469430958807\n",
      "W1: 10.94702565005942 W2: 1.8839308255957328 b -5.742109708268722 Loss: 0.4103246902086418\n",
      "W1: 10.947065781294508 W2: 1.8839351845814958 b -5.742130064116777 Loss: 0.4103246861152385\n",
      "W1: 10.947105875597163 W2: 1.8839395395713767 b -5.74215040124886 Loss: 0.41032468202936445\n",
      "W1: 10.947145933001602 W2: 1.883943890569049 b -5.742170719682277 Loss: 0.41032467795100547\n",
      "W1: 10.947185953542009 W2: 1.8839482375781826 b -5.742191019434323 Loss: 0.41032467388014804\n",
      "W1: 10.947225937252538 W2: 1.883952580602444 b -5.742211300522271 Loss: 0.41032466981677795\n",
      "W1: 10.947265884167312 W2: 1.8839569196454964 b -5.742231562963383 Loss: 0.4103246657608817\n",
      "W1: 10.947305794320418 W2: 1.8839612547109994 b -5.7422518067749015 Loss: 0.4103246617124452\n",
      "W1: 10.947345667745912 W2: 1.8839655858026094 b -5.742272031974054 Loss: 0.41032465767145504\n",
      "W1: 10.947385504477822 W2: 1.8839699129239795 b -5.742292238578052 Loss: 0.41032465363789733\n",
      "W1: 10.947425304550139 W2: 1.8839742360787592 b -5.742312426604091 Loss: 0.4103246496117581\n",
      "W1: 10.947465067996825 W2: 1.8839785552705948 b -5.74233259606935 Loss: 0.410324645593024\n",
      "W1: 10.947504794851811 W2: 1.883982870503129 b -5.742352746990991 Loss: 0.4103246415816813\n",
      "W1: 10.947544485148994 W2: 1.8839871817800014 b -5.742372879386163 Loss: 0.41032463757771626\n",
      "W1: 10.947584138922236 W2: 1.8839914891048481 b -5.742392993271995 Loss: 0.4103246335811153\n",
      "W1: 10.947623756205376 W2: 1.883995792481302 b -5.742413088665604 Loss: 0.41032462959186494\n",
      "W1: 10.947663337032214 W2: 1.8840000919129924 b -5.742433165584087 Loss: 0.41032462560995137\n",
      "W1: 10.947702881436522 W2: 1.8840043874035455 b -5.742453224044528 Loss: 0.4103246216353613\n",
      "W1: 10.947742389452037 W2: 1.8840086789565837 b -5.742473264063994 Loss: 0.41032461766808104\n",
      "W1: 10.947781861112466 W2: 1.8840129665757268 b -5.7424932856595365 Loss: 0.4103246137080973\n",
      "W1: 10.947821296451485 W2: 1.8840172502645904 b -5.74251328884819 Loss: 0.41032460975539653\n",
      "W1: 10.947860695502738 W2: 1.8840215300267875 b -5.7425332736469725 Loss: 0.4103246058099652\n",
      "W1: 10.947900058299838 W2: 1.8840258058659274 b -5.74255324007289 Loss: 0.41032460187178993\n",
      "W1: 10.947939384876367 W2: 1.8840300777856158 b -5.742573188142927 Loss: 0.4103245979408575\n",
      "W1: 10.947978675265873 W2: 1.8840343457894557 b -5.7425931178740575 Loss: 0.4103245940171542\n",
      "W1: 10.948017929501871 W2: 1.8840386098810462 b -5.742613029283236 Loss: 0.41032459010066713\n",
      "W1: 10.94805714761785 W2: 1.8840428700639835 b -5.7426329223874015 Loss: 0.4103245861913827\n",
      "W1: 10.948096329647267 W2: 1.8840471263418603 b -5.742652797203479 Loss: 0.41032458228928764\n",
      "W1: 10.948135475623543 W2: 1.8840513787182658 b -5.742672653748376 Loss: 0.41032457839436876\n",
      "W1: 10.948174585580071 W2: 1.884055627196786 b -5.742692492038985 Loss: 0.4103245745066127\n",
      "W1: 10.94821365955021 W2: 1.884059871781004 b -5.742712312092182 Loss: 0.41032457062600647\n",
      "W1: 10.948252697567293 W2: 1.884064112474499 b -5.742732113924829 Loss: 0.41032456675253653\n",
      "W1: 10.948291699664615 W2: 1.884068349280847 b -5.74275189755377 Loss: 0.4103245628861902\n",
      "W1: 10.948330665875446 W2: 1.884072582203621 b -5.7427716629958345 Loss: 0.4103245590269538\n",
      "W1: 10.94836959623302 W2: 1.8840768112463906 b -5.742791410267835 Loss: 0.41032455517481453\n",
      "W1: 10.948408490770543 W2: 1.8840810364127216 b -5.742811139386571 Loss: 0.4103245513297594\n",
      "W1: 10.948447349521187 W2: 1.8840852577061773 b -5.742830850368824 Loss: 0.41032454749177505\n",
      "W1: 10.948486172518095 W2: 1.8840894751303172 b -5.742850543231359 Loss: 0.4103245436608487\n",
      "W1: 10.948524959794378 W2: 1.8840936886886976 b -5.742870217990928 Loss: 0.41032453983696693\n",
      "W1: 10.948563711383118 W2: 1.8840978983848717 b -5.742889874664266 Loss: 0.41032453602011726\n",
      "W1: 10.948602427317363 W2: 1.884102104222389 b -5.742909513268093 Loss: 0.4103245322102864\n",
      "W1: 10.94864110763013 W2: 1.8841063062047965 b -5.7429291338191115 Loss: 0.41032452840746153\n",
      "W1: 10.94867975235441 W2: 1.8841105043356368 b -5.74294873633401 Loss: 0.41032452461162944\n",
      "W1: 10.948718361523156 W2: 1.8841146986184503 b -5.742968320829461 Loss: 0.41032452082277776\n",
      "W1: 10.948756935169294 W2: 1.8841188890567735 b -5.742987887322122 Loss: 0.41032451704089323\n",
      "W1: 10.948795473325719 W2: 1.8841230756541396 b -5.743007435828634 Loss: 0.41032451326596303\n",
      "W1: 10.948833976025295 W2: 1.8841272584140791 b -5.7430269663656235 Loss: 0.4103245094979744\n",
      "W1: 10.948872443300854 W2: 1.8841314373401188 b -5.7430464789497 Loss: 0.41032450573691454\n",
      "W1: 10.948910875185199 W2: 1.884135612435782 b -5.743065973597458 Loss: 0.41032450198277065\n",
      "W1: 10.9489492717111 W2: 1.8841397837045895 b -5.743085450325478 Loss: 0.41032449823552997\n",
      "W1: 10.948987632911301 W2: 1.884143951150058 b -5.743104909150323 Loss: 0.4103244944951798\n",
      "W1: 10.949025958818508 W2: 1.8841481147757015 b -5.743124350088541 Loss: 0.4103244907617073\n",
      "W1: 10.949064249465401 W2: 1.8841522745850308 b -5.743143773156666 Loss: 0.4103244870351\n",
      "W1: 10.94910250488463 W2: 1.884156430581553 b -5.743163178371215 Loss: 0.410324483315345\n",
      "W1: 10.949140725108812 W2: 1.8841605827687726 b -5.743182565748689 Loss: 0.41032447960242985\n",
      "W1: 10.949178910170536 W2: 1.8841647311501901 b -5.743201935305575 Loss: 0.41032447589634197\n",
      "W1: 10.949217060102358 W2: 1.8841688757293034 b -5.743221287058345 Loss: 0.4103244721970684\n",
      "W1: 10.949255174936802 W2: 1.8841730165096067 b -5.743240621023454 Loss: 0.410324468504597\n",
      "W1: 10.949293254706367 W2: 1.8841771534945915 b -5.743259937217343 Loss: 0.41032446481891505\n",
      "W1: 10.949331299443516 W2: 1.8841812866877454 b -5.743279235656436 Loss: 0.4103244611400102\n",
      "W1: 10.949369309180685 W2: 1.8841854160925535 b -5.743298516357144 Loss: 0.4103244574678696\n",
      "W1: 10.94940728395028 W2: 1.8841895417124972 b -5.74331777933586 Loss: 0.410324453802481\n",
      "W1: 10.949445223784672 W2: 1.8841936635510548 b -5.743337024608964 Loss: 0.41032445014383184\n",
      "W1: 10.949483128716206 W2: 1.8841977816117015 b -5.743356252192819 Loss: 0.41032444649190974\n",
      "W1: 10.949520998777198 W2: 1.884201895897909 b -5.743375462103774 Loss: 0.41032444284670233\n",
      "W1: 10.949558833999927 W2: 1.884206006413146 b -5.743394654358162 Loss: 0.4103244392081974\n",
      "W1: 10.949596634416649 W2: 1.8842101131608782 b -5.7434138289723 Loss: 0.4103244355763822\n",
      "W1: 10.949634400059585 W2: 1.8842142161445676 b -5.743432985962492 Loss: 0.41032443195124463\n",
      "W1: 10.949672130960929 W2: 1.8842183153676735 b -5.7434521253450255 Loss: 0.4103244283327722\n",
      "W1: 10.94970982715284 W2: 1.8842224108336516 b -5.7434712471361715 Loss: 0.4103244247209531\n",
      "W1: 10.949747488667455 W2: 1.8842265025459548 b -5.743490351352188 Loss: 0.41032442111577444\n",
      "W1: 10.949785115536873 W2: 1.8842305905080325 b -5.743509438009316 Loss: 0.41032441751722426\n",
      "W1: 10.949822707793166 W2: 1.8842346747233312 b -5.743528507123783 Loss: 0.4103244139252904\n",
      "W1: 10.949860265468375 W2: 1.8842387551952937 b -5.7435475587118 Loss: 0.41032441033996053\n",
      "W1: 10.949897788594514 W2: 1.88424283192736 b -5.743566592789564 Loss: 0.4103244067612225\n",
      "W1: 10.949935277203563 W2: 1.884246904922967 b -5.7435856093732545 Loss: 0.4103244031890641\n",
      "W1: 10.949972731327476 W2: 1.8842509741855484 b -5.743604608479039 Loss: 0.41032439962347345\n",
      "W1: 10.950010150998173 W2: 1.8842550397185345 b -5.743623590123069 Loss: 0.4103243960644382\n",
      "W1: 10.950047536247547 W2: 1.8842591015253525 b -5.74364255432148 Loss: 0.41032439251194625\n",
      "W1: 10.95008488710746 W2: 1.8842631596094266 b -5.743661501090392 Loss: 0.4103243889659856\n",
      "W1: 10.950122203609743 W2: 1.8842672139741776 b -5.743680430445911 Loss: 0.4103243854265443\n",
      "W1: 10.9501594857862 W2: 1.8842712646230235 b -5.7436993424041285 Loss: 0.4103243818936102\n",
      "W1: 10.950196733668603 W2: 1.8842753115593787 b -5.7437182369811195 Loss: 0.41032437836717117\n",
      "W1: 10.950233947288696 W2: 1.8842793547866545 b -5.743737114192945 Loss: 0.4103243748472156\n",
      "W1: 10.95027112667819 W2: 1.8842833943082598 b -5.743755974055651 Loss: 0.41032437133373123\n",
      "W1: 10.95030827186877 W2: 1.8842874301275991 b -5.743774816585269 Loss: 0.41032436782670634\n",
      "W1: 10.95034538289209 W2: 1.8842914622480749 b -5.743793641797813 Loss: 0.4103243643261289\n",
      "W1: 10.950382459779773 W2: 1.8842954906730858 b -5.743812449709285 Loss: 0.410324360831987\n",
      "W1: 10.950419502563413 W2: 1.8842995154060278 b -5.743831240335671 Loss: 0.4103243573442686\n",
      "W1: 10.950456511274576 W2: 1.8843035364502934 b -5.74385001369294 Loss: 0.4103243538629622\n",
      "W1: 10.950493485944795 W2: 1.8843075538092717 b -5.74386876979705 Loss: 0.4103243503880558\n",
      "W1: 10.950530426605578 W2: 1.8843115674863495 b -5.743887508663942 Loss: 0.4103243469195377\n",
      "W1: 10.9505673332884 W2: 1.8843155774849099 b -5.743906230309541 Loss: 0.41032434345739616\n",
      "W1: 10.95060420602471 W2: 1.8843195838083329 b -5.74392493474976 Loss: 0.41032434000161905\n",
      "W1: 10.950641044845923 W2: 1.8843235864599954 b -5.7439436220004945 Loss: 0.41032433655219513\n",
      "W1: 10.950677849783428 W2: 1.8843275854432715 b -5.743962292077626 Loss: 0.41032433310911237\n",
      "W1: 10.950714620868583 W2: 1.8843315807615317 b -5.743980944997022 Loss: 0.4103243296723591\n",
      "W1: 10.950751358132715 W2: 1.8843355724181436 b -5.743999580774534 Loss: 0.4103243262419238\n",
      "W1: 10.950788061607126 W2: 1.8843395604164719 b -5.744018199426 Loss: 0.4103243228177947\n",
      "W1: 10.950824731323086 W2: 1.884343544759878 b -5.744036800967241 Loss: 0.4103243193999601\n",
      "W1: 10.950861367311836 W2: 1.88434752545172 b -5.744055385414066 Loss: 0.41032431598840874\n",
      "W1: 10.950897969604586 W2: 1.884351502495353 b -5.7440739527822675 Loss: 0.41032431258312857\n",
      "W1: 10.950934538232522 W2: 1.8843554758941294 b -5.744092503087623 Loss: 0.41032430918410845\n",
      "W1: 10.950971073226794 W2: 1.8843594456513981 b -5.744111036345897 Loss: 0.4103243057913364\n",
      "W1: 10.95100757461853 W2: 1.884363411770505 b -5.744129552572838 Loss: 0.4103243024048013\n",
      "W1: 10.951044042438822 W2: 1.8843673742547928 b -5.7441480517841805 Loss: 0.4103242990244915\n",
      "W1: 10.951080476718737 W2: 1.8843713331076015 b -5.744166533995642 Loss: 0.4103242956503955\n",
      "W1: 10.95111687748931 W2: 1.8843752883322675 b -5.744184999222929 Loss: 0.41032429228250183\n",
      "W1: 10.951153244781551 W2: 1.8843792399321244 b -5.7442034474817305 Loss: 0.4103242889207991\n",
      "W1: 10.951189578626439 W2: 1.8843831879105026 b -5.744221878787722 Loss: 0.4103242855652759\n",
      "W1: 10.951225879054922 W2: 1.8843871322707297 b -5.744240293156565 Loss: 0.4103242822159208\n",
      "W1: 10.951262146097921 W2: 1.88439107301613 b -5.744258690603905 Loss: 0.41032427887272244\n",
      "W1: 10.951298379786328 W2: 1.8843950101500246 b -5.7442770711453734 Loss: 0.4103242755356694\n",
      "W1: 10.951334580151007 W2: 1.884398943675732 b -5.744295434796587 Loss: 0.41032427220475043\n",
      "W1: 10.951370747222791 W2: 1.8844028735965672 b -5.744313781573149 Loss: 0.4103242688799543\n",
      "W1: 10.951406881032485 W2: 1.8844067999158423 b -5.744332111490646 Loss: 0.41032426556126966\n",
      "W1: 10.951442981610864 W2: 1.884410722636866 b -5.744350424564652 Loss: 0.4103242622486852\n",
      "W1: 10.951479048988677 W2: 1.8844146417629448 b -5.7443687208107255 Loss: 0.41032425894218966\n",
      "W1: 10.951515083196643 W2: 1.8844185572973813 b -5.74438700024441 Loss: 0.41032425564177183\n",
      "W1: 10.95155108426545 W2: 1.8844224692434752 b -5.744405262881236 Loss: 0.4103242523474206\n",
      "W1: 10.95158705222576 W2: 1.8844263776045238 b -5.744423508736719 Loss: 0.4103242490591246\n",
      "W1: 10.951622987108205 W2: 1.8844302823838204 b -5.744441737826358 Loss: 0.41032424577687293\n",
      "W1: 10.95165888894339 W2: 1.8844341835846559 b -5.744459950165641 Loss: 0.4103242425006543\n",
      "W1: 10.95169475776189 W2: 1.884438081210318 b -5.74447814577004 Loss: 0.41032423923045747\n",
      "W1: 10.95173059359425 W2: 1.8844419752640915 b -5.74449632465501 Loss: 0.4103242359662716\n",
      "W1: 10.95176639647099 W2: 1.8844458657492578 b -5.744514486835997 Loss: 0.41032423270808527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.951802166422597 W2: 1.8844497526690955 b -5.744532632328427 Loss: 0.41032422945588765\n",
      "W1: 10.951837903479532 W2: 1.8844536360268804 b -5.744550761147716 Loss: 0.4103242262096678\n",
      "W1: 10.951873607672228 W2: 1.884457515825885 b -5.7445688733092615 Loss: 0.4103242229694144\n",
      "W1: 10.951909279031089 W2: 1.8844613920693785 b -5.74458696882845 Loss: 0.4103242197351167\n",
      "W1: 10.95194491758649 W2: 1.8844652647606277 b -5.744605047720653 Loss: 0.41032421650676376\n",
      "W1: 10.951980523368777 W2: 1.884469133902896 b -5.744623110001227 Loss: 0.41032421328434426\n",
      "W1: 10.952016096408268 W2: 1.8844729994994438 b -5.744641155685514 Loss: 0.41032421006784775\n",
      "W1: 10.952051636735256 W2: 1.8844768615535288 b -5.7446591847888415 Loss: 0.41032420685726284\n",
      "W1: 10.95208714438 W2: 1.884480720068405 b -5.744677197326524 Loss: 0.410324203652579\n",
      "W1: 10.952122619372735 W2: 1.8844845750473243 b -5.744695193313861 Loss: 0.4103242004537852\n",
      "W1: 10.952158061743665 W2: 1.8844884264935349 b -5.744713172766137 Loss: 0.41032419726087055\n",
      "W1: 10.952193471522968 W2: 1.8844922744102823 b -5.744731135698624 Loss: 0.4103241940738243\n",
      "W1: 10.952228848740791 W2: 1.8844961188008091 b -5.744749082126577 Loss: 0.41032419089263555\n",
      "W1: 10.952264193427256 W2: 1.8844999596683547 b -5.74476701206524 Loss: 0.4103241877172936\n",
      "W1: 10.952299505612453 W2: 1.8845037970161556 b -5.7447849255298395 Loss: 0.41032418454778763\n",
      "W1: 10.952334785326448 W2: 1.884507630847445 b -5.744802822535591 Loss: 0.4103241813841069\n",
      "W1: 10.952370032599276 W2: 1.8845114611654536 b -5.744820703097694 Loss: 0.4103241782262405\n",
      "W1: 10.952405247460945 W2: 1.884515287973409 b -5.744838567231334 Loss: 0.410324175074178\n",
      "W1: 10.952440429941435 W2: 1.8845191112745356 b -5.744856414951681 Loss: 0.41032417192790843\n",
      "W1: 10.952475580070695 W2: 1.884522931072055 b -5.744874246273895 Loss: 0.4103241687874213\n",
      "W1: 10.952510697878653 W2: 1.8845267473691858 b -5.744892061213117 Loss: 0.4103241656527059\n",
      "W1: 10.952545783395202 W2: 1.8845305601691436 b -5.744909859784477 Loss: 0.41032416252375176\n",
      "W1: 10.95258083665021 W2: 1.884534369475141 b -5.74492764200309 Loss: 0.41032415940054784\n",
      "W1: 10.952615857673516 W2: 1.8845381752903878 b -5.744945407884057 Loss: 0.4103241562830839\n",
      "W1: 10.952650846494933 W2: 1.8845419776180907 b -5.744963157442463 Loss: 0.4103241531713492\n",
      "W1: 10.952685803144243 W2: 1.8845457764614533 b -5.744980890693382 Loss: 0.4103241500653333\n",
      "W1: 10.952720727651204 W2: 1.8845495718236764 b -5.744998607651873 Loss: 0.41032414696502556\n",
      "W1: 10.952755620045544 W2: 1.8845533637079581 b -5.745016308332979 Loss: 0.4103241438704156\n",
      "W1: 10.952790480356962 W2: 1.884557152117493 b -5.745033992751733 Loss: 0.4103241407814927\n",
      "W1: 10.95282530861513 W2: 1.8845609370554735 b -5.745051660923149 Loss: 0.4103241376982465\n",
      "W1: 10.952860104849696 W2: 1.884564718525088 b -5.745069312862231 Loss: 0.4103241346206665\n",
      "W1: 10.952894869090274 W2: 1.8845684965295229 b -5.7450869485839675 Loss: 0.41032413154874237\n",
      "W1: 10.952929601366455 W2: 1.8845722710719612 b -5.745104568103333 Loss: 0.4103241284824634\n",
      "W1: 10.9529643017078 W2: 1.8845760421555833 b -5.745122171435288 Loss: 0.41032412542181973\n",
      "W1: 10.952998970143843 W2: 1.8845798097835662 b -5.745139758594778 Loss: 0.41032412236680044\n",
      "W1: 10.953033606704091 W2: 1.8845835739590844 b -5.745157329596737 Loss: 0.4103241193173954\n",
      "W1: 10.953068211418021 W2: 1.884587334685309 b -5.745174884456083 Loss: 0.4103241162735943\n",
      "W1: 10.953102784315087 W2: 1.8845910919654087 b -5.745192423187722 Loss: 0.4103241132353865\n",
      "W1: 10.953137325424711 W2: 1.884594845802549 b -5.745209945806542 Loss: 0.4103241102027622\n",
      "W1: 10.953171834776288 W2: 1.8845985961998923 b -5.745227452327424 Loss: 0.4103241071757107\n",
      "W1: 10.953206312399189 W2: 1.8846023431605987 b -5.745244942765229 Loss: 0.4103241041542219\n",
      "W1: 10.953240758322753 W2: 1.8846060866878247 b -5.745262417134806 Loss: 0.4103241011382855\n",
      "W1: 10.953275172576296 W2: 1.884609826784724 b -5.745279875450992 Loss: 0.4103240981278912\n",
      "W1: 10.953309555189103 W2: 1.8846135634544479 b -5.745297317728607 Loss: 0.4103240951230289\n",
      "W1: 10.953343906190431 W2: 1.884617296700144 b -5.74531474398246 Loss: 0.4103240921236884\n",
      "W1: 10.953378225609516 W2: 1.8846210265249579 b -5.745332154227345 Loss: 0.41032408912985957\n",
      "W1: 10.953412513475559 W2: 1.8846247529320315 b -5.745349548478042 Loss: 0.41032408614153226\n",
      "W1: 10.953446769817738 W2: 1.8846284759245042 b -5.745366926749316 Loss: 0.41032408315869623\n",
      "W1: 10.9534809946652 W2: 1.8846321955055125 b -5.745384289055922 Loss: 0.41032408018134137\n",
      "W1: 10.953515188047072 W2: 1.88463591167819 b -5.745401635412597 Loss: 0.41032407720945757\n",
      "W1: 10.953549349992446 W2: 1.8846396244456671 b -5.745418965834069 Loss: 0.4103240742430346\n",
      "W1: 10.95358348053039 W2: 1.8846433338110717 b -5.745436280335046 Loss: 0.4103240712820629\n",
      "W1: 10.953617579689947 W2: 1.8846470397775288 b -5.745453578930228 Loss: 0.41032406832653207\n",
      "W1: 10.953651647500127 W2: 1.8846507423481602 b -5.745470861634298 Loss: 0.41032406537643185\n",
      "W1: 10.953685683989919 W2: 1.884654441526085 b -5.745488128461927 Loss: 0.41032406243175257\n",
      "W1: 10.953719689188281 W2: 1.8846581373144198 b -5.7455053794277715 Loss: 0.4103240594924843\n",
      "W1: 10.953753663124147 W2: 1.8846618297162776 b -5.745522614546474 Loss: 0.4103240565586168\n",
      "W1: 10.95378760582642 W2: 1.884665518734769 b -5.745539833832665 Loss: 0.4103240536301405\n",
      "W1: 10.95382151732398 W2: 1.8846692043730013 b -5.745557037300959 Loss: 0.4103240507070451\n",
      "W1: 10.953855397645677 W2: 1.8846728866340796 b -5.745574224965958 Loss: 0.41032404778932074\n",
      "W1: 10.953889246820337 W2: 1.8846765655211057 b -5.745591396842252 Loss: 0.4103240448769578\n",
      "W1: 10.953923064876754 W2: 1.8846802410371786 b -5.7456085529444145 Loss: 0.41032404196994593\n",
      "W1: 10.953956851843701 W2: 1.8846839131853943 b -5.745625693287008 Loss: 0.41032403906827586\n",
      "W1: 10.95399060774992 W2: 1.8846875819688462 b -5.745642817884579 Loss: 0.4103240361719371\n",
      "W1: 10.95402433262413 W2: 1.8846912473906248 b -5.745659926751662 Loss: 0.4103240332809203\n",
      "W1: 10.954058026495018 W2: 1.8846949094538177 b -5.745677019902778 Loss: 0.41032403039521553\n",
      "W1: 10.954091689391246 W2: 1.8846985681615096 b -5.745694097352434 Loss: 0.410324027514813\n",
      "W1: 10.954125321341454 W2: 1.8847022235167823 b -5.745711159115124 Loss: 0.41032402463970286\n",
      "W1: 10.95415892237425 W2: 1.8847058755227148 b -5.745728205205327 Loss: 0.4103240217698754\n",
      "W1: 10.954192492518214 W2: 1.8847095241823837 b -5.745745235637511 Loss: 0.410324018905321\n",
      "W1: 10.954226031801904 W2: 1.884713169498862 b -5.745762250426128 Loss: 0.41032401604602975\n",
      "W1: 10.954259540253847 W2: 1.8847168114752204 b -5.745779249585618 Loss: 0.41032401319199197\n",
      "W1: 10.954293017902549 W2: 1.8847204501145265 b -5.745796233130406 Loss: 0.41032401034319826\n",
      "W1: 10.954326464776484 W2: 1.8847240854198453 b -5.745813201074906 Loss: 0.4103240074996387\n",
      "W1: 10.954359880904102 W2: 1.8847277173942387 b -5.745830153433518 Loss: 0.4103240046613037\n",
      "W1: 10.954393266313824 W2: 1.884731346040766 b -5.745847090220627 Loss: 0.41032400182818357\n",
      "W1: 10.954426621034047 W2: 1.8847349713624835 b -5.745864011450605 Loss: 0.410323999000269\n",
      "W1: 10.954459945093141 W2: 1.884738593362445 b -5.745880917137812 Loss: 0.41032399617755\n",
      "W1: 10.954493238519449 W2: 1.884742212043701 b -5.7458978072965925 Loss: 0.4103239933600173\n",
      "W1: 10.954526501341286 W2: 1.8847458274092996 b -5.745914681941279 Loss: 0.41032399054766117\n",
      "W1: 10.954559733586944 W2: 1.884749439462286 b -5.745931541086192 Loss: 0.41032398774047213\n",
      "W1: 10.954592935284685 W2: 1.8847530482057022 b -5.7459483847456365 Loss: 0.41032398493844063\n",
      "W1: 10.954626106462747 W2: 1.8847566536425882 b -5.745965212933903 Loss: 0.4103239821415572\n",
      "W1: 10.954659247149342 W2: 1.8847602557759804 b -5.745982025665273 Loss: 0.4103239793498123\n",
      "W1: 10.954692357372654 W2: 1.8847638546089127 b -5.745998822954011 Loss: 0.4103239765631966\n",
      "W1: 10.954725437160839 W2: 1.8847674501444163 b -5.746015604814369 Loss: 0.41032397378170055\n",
      "W1: 10.95475848654203 W2: 1.8847710423855193 b -5.746032371260587 Loss: 0.41032397100531487\n",
      "W1: 10.954791505544334 W2: 1.8847746313352474 b -5.74604912230689 Loss: 0.4103239682340298\n",
      "W1: 10.954824494195828 W2: 1.8847782169966234 b -5.7460658579674915 Loss: 0.41032396546783617\n",
      "W1: 10.954857452524566 W2: 1.8847817993726672 b -5.7460825782565905 Loss: 0.41032396270672467\n",
      "W1: 10.954890380558576 W2: 1.884785378466396 b -5.746099283188372 Loss: 0.4103239599506858\n",
      "W1: 10.954923278325856 W2: 1.8847889542808238 b -5.746115972777011 Loss: 0.41032395719971027\n",
      "W1: 10.954956145854382 W2: 1.8847925268189625 b -5.746132647036665 Loss: 0.4103239544537889\n",
      "W1: 10.954988983172102 W2: 1.8847960960838208 b -5.746149305981483 Loss: 0.410323951712912\n",
      "W1: 10.955021790306938 W2: 1.8847996620784049 b -5.746165949625596 Loss: 0.4103239489770708\n",
      "W1: 10.955054567286787 W2: 1.884803224805718 b -5.7461825779831255 Loss: 0.4103239462462555\n",
      "W1: 10.955087314139519 W2: 1.8848067842687606 b -5.746199191068178 Loss: 0.410323943520457\n",
      "W1: 10.955120030892976 W2: 1.8848103404705303 b -5.7462157888948475 Loss: 0.4103239407996663\n",
      "W1: 10.955152717574979 W2: 1.8848138934140222 b -5.746232371477214 Loss: 0.4103239380838741\n",
      "W1: 10.955185374213318 W2: 1.8848174431022284 b -5.746248938829346 Loss: 0.41032393537307105\n",
      "W1: 10.95521800083576 W2: 1.8848209895381385 b -5.746265490965299 Loss: 0.4103239326672478\n",
      "W1: 10.955250597470044 W2: 1.884824532724739 b -5.746282027899112 Loss: 0.41032392996639583\n",
      "W1: 10.955283164143886 W2: 1.884828072665014 b -5.746298549644815 Loss: 0.41032392727050515\n",
      "W1: 10.955315700884972 W2: 1.8848316093619444 b -5.746315056216424 Loss: 0.410323924579567\n",
      "W1: 10.955348207720967 W2: 1.8848351428185088 b -5.746331547627939 Loss: 0.4103239218935725\n",
      "W1: 10.955380684679504 W2: 1.884838673037683 b -5.746348023893351 Loss: 0.41032391921251216\n",
      "W1: 10.955413131788196 W2: 1.8848422000224394 b -5.746364485026635 Loss: 0.4103239165363771\n",
      "W1: 10.955445549074629 W2: 1.8848457237757488 b -5.746380931041754 Loss: 0.41032391386515826\n",
      "W1: 10.95547793656636 W2: 1.8848492443005782 b -5.74639736195266 Loss: 0.41032391119884654\n",
      "W1: 10.955510294290924 W2: 1.8848527615998927 b -5.746413777773288 Loss: 0.41032390853743284\n",
      "W1: 10.955542622275829 W2: 1.884856275676654 b -5.7464301785175635 Loss: 0.4103239058809081\n",
      "W1: 10.955574920548555 W2: 1.8848597865338215 b -5.746446564199397 Loss: 0.4103239032292635\n",
      "W1: 10.955607189136561 W2: 1.8848632941743515 b -5.746462934832687 Loss: 0.41032390058248985\n",
      "W1: 10.955639428067277 W2: 1.884866798601198 b -5.746479290431319 Loss: 0.4103238979405784\n",
      "W1: 10.955671637368107 W2: 1.884870299817312 b -5.746495631009165 Loss: 0.41032389530352015\n",
      "W1: 10.955703817066432 W2: 1.8848737978256416 b -5.746511956580085 Loss: 0.410323892671306\n",
      "W1: 10.955735967189606 W2: 1.8848772926291326 b -5.746528267157926 Loss: 0.41032389004392705\n",
      "W1: 10.955768087764955 W2: 1.884880784230728 b -5.74654456275652 Loss: 0.4103238874213744\n",
      "W1: 10.955800178819784 W2: 1.8848842726333679 b -5.746560843389688 Loss: 0.41032388480363924\n",
      "W1: 10.955832240381369 W2: 1.8848877578399896 b -5.746577109071239 Loss: 0.4103238821907128\n",
      "W1: 10.955864272476964 W2: 1.8848912398535282 b -5.746593359814968 Loss: 0.4103238795825861\n",
      "W1: 10.955896275133794 W2: 1.8848947186769156 b -5.746609595634657 Loss: 0.41032387697925027\n",
      "W1: 10.95592824837906 W2: 1.8848981943130811 b -5.746625816544074 Loss: 0.41032387438069634\n",
      "W1: 10.955960192239937 W2: 1.8849016667649514 b -5.746642022556977 Loss: 0.41032387178691593\n",
      "W1: 10.955992106743578 W2: 1.8849051360354505 b -5.74665821368711 Loss: 0.4103238691979\n",
      "W1: 10.956023991917105 W2: 1.8849086021274997 b -5.746674389948202 Loss: 0.41032386661363957\n",
      "W1: 10.956055847787619 W2: 1.8849120650440172 b -5.746690551353973 Loss: 0.41032386403412624\n",
      "W1: 10.956087674382193 W2: 1.8849155247879192 b -5.746706697918128 Loss: 0.410323861459351\n",
      "W1: 10.956119471727877 W2: 1.884918981362119 b -5.7467228296543595 Loss: 0.4103238588893054\n",
      "W1: 10.956151239851696 W2: 1.8849224347695268 b -5.746738946576348 Loss: 0.41032385632398044\n",
      "W1: 10.956182978780648 W2: 1.8849258850130506 b -5.746755048697759 Loss: 0.41032385376336755\n",
      "W1: 10.956214688541705 W2: 1.8849293320955953 b -5.746771136032248 Loss: 0.41032385120745823\n",
      "W1: 10.956246369161814 W2: 1.8849327760200636 b -5.7467872085934575 Loss: 0.41032384865624344\n",
      "W1: 10.9562780206679 W2: 1.884936216789355 b -5.746803266395015 Loss: 0.4103238461097148\n",
      "W1: 10.956309643086861 W2: 1.884939654406367 b -5.7468193094505375 Loss: 0.4103238435678637\n",
      "W1: 10.95634123644557 W2: 1.8849430888739938 b -5.7468353377736285 Loss: 0.41032384103068137\n",
      "W1: 10.956372800770874 W2: 1.884946520195127 b -5.746851351377879 Loss: 0.4103238384981593\n",
      "W1: 10.956404336089594 W2: 1.884949948372656 b -5.746867350276867 Loss: 0.41032383597028904\n",
      "W1: 10.956435842428531 W2: 1.884953373409467 b -5.746883334484159 Loss: 0.4103238334470616\n",
      "W1: 10.956467319814454 W2: 1.8849567953084438 b -5.746899304013307 Loss: 0.4103238309284689\n",
      "W1: 10.956498768274113 W2: 1.8849602140724677 b -5.746915258877852 Loss: 0.41032382841450216\n",
      "W1: 10.956530187834229 W2: 1.884963629704417 b -5.746931199091322 Loss: 0.41032382590515293\n",
      "W1: 10.9565615785215 W2: 1.8849670422071674 b -5.746947124667233 Loss: 0.4103238234004128\n",
      "W1: 10.956592940362599 W2: 1.884970451583592 b -5.7469630356190855 Loss: 0.4103238209002729\n",
      "W1: 10.956624273384174 W2: 1.8849738578365616 b -5.7469789319603715 Loss: 0.41032381840472526\n",
      "W1: 10.956655577612846 W2: 1.8849772609689437 b -5.746994813704568 Loss: 0.4103238159137612\n",
      "W1: 10.956686853075215 W2: 1.8849806609836037 b -5.747010680865139 Loss: 0.41032381342737223\n",
      "W1: 10.956718099797856 W2: 1.884984057883404 b -5.747026533455538 Loss: 0.41032381094555015\n",
      "W1: 10.956749317807313 W2: 1.8849874516712046 b -5.747042371489205 Loss: 0.41032380846828614\n",
      "W1: 10.956780507130112 W2: 1.884990842349863 b -5.747058194979568 Loss: 0.4103238059955721\n",
      "W1: 10.956811667792753 W2: 1.8849942299222335 b -5.74707400394004 Loss: 0.4103238035273995\n",
      "W1: 10.95684279982171 W2: 1.8849976143911684 b -5.747089798384025 Loss: 0.4103238010637604\n",
      "W1: 10.95687390324343 W2: 1.8850009957595169 b -5.747105578324912 Loss: 0.41032379860464585\n",
      "W1: 10.956904978084339 W2: 1.8850043740301257 b -5.7471213437760795 Loss: 0.4103237961500479\n",
      "W1: 10.956936024370837 W2: 1.885007749205839 b -5.747137094750892 Loss: 0.41032379369995814\n",
      "W1: 10.9569670421293 W2: 1.8850111212894984 b -5.747152831262702 Loss: 0.4103237912543683\n",
      "W1: 10.956998031386078 W2: 1.8850144902839427 b -5.74716855332485 Loss: 0.41032378881326986\n",
      "W1: 10.9570289921675 W2: 1.8850178561920081 b -5.7471842609506645 Loss: 0.4103237863766548\n",
      "W1: 10.957059924499864 W2: 1.8850212190165285 b -5.7471999541534595 Loss: 0.41032378394451485\n",
      "W1: 10.95709082840945 W2: 1.8850245787603348 b -5.7472156329465385 Loss: 0.41032378151684185\n",
      "W1: 10.957121703922509 W2: 1.8850279354262554 b -5.747231297343193 Loss: 0.41032377909362727\n",
      "W1: 10.957152551065269 W2: 1.8850312890171161 b -5.7472469473567 Loss: 0.41032377667486325\n",
      "W1: 10.957183369863934 W2: 1.8850346395357402 b -5.747262583000326 Loss: 0.41032377426054134\n",
      "W1: 10.957214160344684 W2: 1.8850379869849483 b -5.7472782042873245 Loss: 0.41032377185065344\n",
      "W1: 10.957244922533674 W2: 1.8850413313675585 b -5.747293811230937 Loss: 0.41032376944519144\n",
      "W1: 10.957275656457032 W2: 1.8850446726863859 b -5.747309403844391 Loss: 0.41032376704414714\n",
      "W1: 10.957306362140868 W2: 1.8850480109442436 b -5.7473249821409045 Loss: 0.4103237646475124\n",
      "W1: 10.957337039611259 W2: 1.8850513461439418 b -5.747340546133682 Loss: 0.4103237622552793\n",
      "W1: 10.957367688894266 W2: 1.885054678288288 b -5.747356095835914 Loss: 0.4103237598674392\n",
      "W1: 10.95739831001592 W2: 1.8850580073800876 b -5.747371631260782 Loss: 0.41032375748398464\n",
      "W1: 10.957428903002231 W2: 1.8850613334221427 b -5.747387152421451 Loss: 0.41032375510490715\n",
      "W1: 10.957459467879183 W2: 1.8850646564172533 b -5.747402659331079 Loss: 0.4103237527301989\n",
      "W1: 10.957490004672735 W2: 1.8850679763682165 b -5.747418152002807 Loss: 0.41032375035985164\n",
      "W1: 10.957520513408824 W2: 1.8850712932778273 b -5.747433630449767 Loss: 0.41032374799385757\n",
      "W1: 10.957550994113362 W2: 1.8850746071488778 b -5.747449094685077 Loss: 0.41032374563220836\n",
      "W1: 10.957581446812236 W2: 1.8850779179841575 b -5.7474645447218435 Loss: 0.4103237432748964\n",
      "W1: 10.957611871531311 W2: 1.8850812257864533 b -5.747479980573161 Loss: 0.4103237409219132\n",
      "W1: 10.957642268296425 W2: 1.8850845305585497 b -5.74749540225211 Loss: 0.41032373857325144\n",
      "W1: 10.957672637133392 W2: 1.8850878323032285 b -5.747510809771761 Loss: 0.41032373622890267\n",
      "W1: 10.957702978068005 W2: 1.8850911310232692 b -5.747526203145172 Loss: 0.410323733888859\n",
      "W1: 10.95773329112603 W2: 1.8850944267214484 b -5.747541582385389 Loss: 0.4103237315531128\n",
      "W1: 10.95776357633321 W2: 1.8850977194005403 b -5.747556947505444 Loss: 0.41032372922165583\n",
      "W1: 10.957793833715266 W2: 1.8851010090633165 b -5.747572298518359 Loss: 0.4103237268944804\n",
      "W1: 10.957824063297892 W2: 1.885104295712546 b -5.747587635437144 Loss: 0.4103237245715785\n",
      "W1: 10.957854265106759 W2: 1.8851075793509953 b -5.747602958274794 Loss: 0.4103237222529424\n",
      "W1: 10.957884439167513 W2: 1.8851108599814284 b -5.747618267044295 Loss: 0.4103237199385641\n",
      "W1: 10.957914585505778 W2: 1.8851141376066067 b -5.7476335617586205 Loss: 0.4103237176284358\n",
      "W1: 10.957944704147154 W2: 1.885117412229289 b -5.74764884243073 Loss: 0.4103237153225497\n",
      "W1: 10.957974795117217 W2: 1.8851206838522319 b -5.747664109073574 Loss: 0.4103237130208981\n",
      "W1: 10.958004858441516 W2: 1.8851239524781889 b -5.7476793617000865 Loss: 0.4103237107234729\n",
      "W1: 10.95803489414558 W2: 1.8851272181099112 b -5.747694600323194 Loss: 0.4103237084302666\n",
      "W1: 10.958064902254915 W2: 1.8851304807501479 b -5.747709824955808 Loss: 0.41032370614127145\n",
      "W1: 10.958094882794999 W2: 1.8851337404016448 b -5.747725035610831 Loss: 0.41032370385647954\n",
      "W1: 10.958124835791288 W2: 1.8851369970671457 b -5.747740232301149 Loss: 0.4103237015758831\n",
      "W1: 10.958154761269217 W2: 1.8851402507493915 b -5.747755415039641 Loss: 0.4103236992994747\n",
      "W1: 10.958184659254194 W2: 1.8851435014511209 b -5.74777058383917 Loss: 0.41032369702724625\n",
      "W1: 10.958214529771602 W2: 1.88514674917507 b -5.747785738712589 Loss: 0.4103236947591903\n",
      "W1: 10.958244372846805 W2: 1.8851499939239722 b -5.74780087967274 Loss: 0.4103236924952991\n",
      "W1: 10.95827418850514 W2: 1.8851532357005587 b -5.74781600673245 Loss: 0.41032369023556503\n",
      "W1: 10.958303976771921 W2: 1.885156474507558 b -5.7478311199045375 Loss: 0.41032368797998037\n",
      "W1: 10.95833373767244 W2: 1.8851597103476958 b -5.747846219201807 Loss: 0.41032368572853745\n",
      "W1: 10.958363471231964 W2: 1.8851629432236958 b -5.747861304637051 Loss: 0.4103236834812288\n",
      "W1: 10.958393177475735 W2: 1.885166173138279 b -5.747876376223051 Loss: 0.4103236812380466\n",
      "W1: 10.958422856428975 W2: 1.8851694000941637 b -5.747891433972575 Loss: 0.4103236789989835\n",
      "W1: 10.958452508116878 W2: 1.885172624094066 b -5.747906477898383 Loss: 0.4103236767640318\n",
      "W1: 10.958482132564619 W2: 1.8851758451406992 b -5.747921508013218 Loss: 0.4103236745331838\n",
      "W1: 10.958511729797348 W2: 1.8851790632367744 b -5.747936524329814 Loss: 0.41032367230643224\n",
      "W1: 10.958541299840189 W2: 1.8851822783849999 b -5.747951526860894 Loss: 0.41032367008376924\n",
      "W1: 10.958570842718245 W2: 1.8851854905880816 b -5.747966515619168 Loss: 0.4103236678651875\n",
      "W1: 10.958600358456598 W2: 1.8851886998487233 b -5.747981490617333 Loss: 0.41032366565067946\n",
      "W1: 10.958629847080301 W2: 1.8851919061696256 b -5.747996451868076 Loss: 0.4103236634402375\n",
      "W1: 10.958659308614388 W2: 1.8851951095534871 b -5.748011399384072 Loss: 0.41032366123385433\n",
      "W1: 10.958688743083869 W2: 1.8851983100030036 b -5.748026333177982 Loss: 0.4103236590315225\n",
      "W1: 10.958718150513727 W2: 1.8852015075208688 b -5.74804125326246 Loss: 0.4103236568332345\n",
      "W1: 10.958747530928926 W2: 1.8852047021097738 b -5.748056159650142 Loss: 0.4103236546389825\n",
      "W1: 10.958776884354407 W2: 1.8852078937724068 b -5.748071052353658 Loss: 0.4103236524487597\n",
      "W1: 10.958806210815084 W2: 1.885211082511454 b -5.7480859313856225 Loss: 0.4103236502625584\n",
      "W1: 10.958835510335849 W2: 1.8852142683295992 b -5.74810079675864 Loss: 0.41032364808037103\n",
      "W1: 10.958864782941573 W2: 1.8852174512295232 b -5.748115648485303 Loss: 0.41032364590219056\n",
      "W1: 10.958894028657102 W2: 1.885220631213905 b -5.748130486578192 Loss: 0.4103236437280092\n",
      "W1: 10.958923247507261 W2: 1.8852238082854205 b -5.748145311049875 Loss: 0.41032364155782\n",
      "W1: 10.958952439516848 W2: 1.8852269824467434 b -5.74816012191291 Loss: 0.41032363939161526\n",
      "W1: 10.95898160471064 W2: 1.8852301537005451 b -5.748174919179843 Loss: 0.4103236372293878\n",
      "W1: 10.959010743113394 W2: 1.8852333220494943 b -5.748189702863207 Loss: 0.41032363507113045\n",
      "W1: 10.959039854749838 W2: 1.8852364874962573 b -5.748204472975525 Loss: 0.4103236329168359\n",
      "W1: 10.95906893964468 W2: 1.885239650043498 b -5.748219229529306 Loss: 0.4103236307664964\n",
      "W1: 10.959097997822607 W2: 1.8852428096938778 b -5.748233972537052 Loss: 0.41032362862010524\n",
      "W1: 10.959127029308277 W2: 1.8852459664500556 b -5.748248702011248 Loss: 0.41032362647765463\n",
      "W1: 10.959156034126332 W2: 1.885249120314688 b -5.7482634179643695 Loss: 0.41032362433913777\n",
      "W1: 10.959185012301386 W2: 1.8852522712904287 b -5.748278120408882 Loss: 0.4103236222045474\n",
      "W1: 10.959213963858033 W2: 1.8852554193799298 b -5.748292809357237 Loss: 0.41032362007387585\n",
      "W1: 10.959242888820842 W2: 1.8852585645858402 b -5.7483074848218765 Loss: 0.41032361794711636\n",
      "W1: 10.95927178721436 W2: 1.8852617069108066 b -5.748322146815228 Loss: 0.41032361582426147\n",
      "W1: 10.959300659063112 W2: 1.8852648463574735 b -5.7483367953497115 Loss: 0.4103236137053042\n",
      "W1: 10.959329504391599 W2: 1.8852679829284824 b -5.748351430437732 Loss: 0.4103236115902373\n",
      "W1: 10.9593583232243 W2: 1.8852711166264728 b -5.7483660520916855 Loss: 0.4103236094790534\n",
      "W1: 10.95938711558567 W2: 1.885274247454082 b -5.748380660323955 Loss: 0.41032360737174545\n",
      "W1: 10.959415881500144 W2: 1.8852773754139442 b -5.748395255146911 Loss: 0.41032360526830663\n",
      "W1: 10.959444620992128 W2: 1.8852805005086917 b -5.748409836572915 Loss: 0.41032360316872957\n",
      "W1: 10.959473334086013 W2: 1.8852836227409542 b -5.7484244046143145 Loss: 0.4103236010730072\n",
      "W1: 10.959502020806163 W2: 1.8852867421133588 b -5.748438959283448 Loss: 0.4103235989811323\n",
      "W1: 10.959530681176918 W2: 1.8852898586285305 b -5.748453500592642 Loss: 0.410323596893098\n",
      "W1: 10.9595593152226 W2: 1.8852929722890919 b -5.748468028554209 Loss: 0.4103235948088971\n",
      "W1: 10.959587922967504 W2: 1.8852960830976626 b -5.748482543180453 Loss: 0.4103235927285226\n",
      "W1: 10.959616504435903 W2: 1.8852991910568606 b -5.748497044483665 Loss: 0.4103235906519675\n",
      "W1: 10.95964505965205 W2: 1.885302296169301 b -5.748511532476126 Loss: 0.41032358857922446\n",
      "W1: 10.959673588640175 W2: 1.8853053984375963 b -5.748526007170104 Loss: 0.41032358651028694\n",
      "W1: 10.959702091424482 W2: 1.885308497864357 b -5.748540468577856 Loss: 0.41032358444514755\n",
      "W1: 10.959730568029155 W2: 1.8853115944521912 b -5.748554916711629 Loss: 0.4103235823837997\n",
      "W1: 10.959759018478355 W2: 1.8853146882037044 b -5.748569351583656 Loss: 0.4103235803262359\n",
      "W1: 10.959787442796221 W2: 1.8853177791215 b -5.748583773206161 Loss: 0.41032357827244964\n",
      "W1: 10.95981584100687 W2: 1.8853208672081783 b -5.748598181591356 Loss: 0.4103235762224339\n",
      "W1: 10.959844213134394 W2: 1.8853239524663379 b -5.74861257675144 Loss: 0.4103235741761813\n",
      "W1: 10.959872559202866 W2: 1.885327034898575 b -5.748626958698604 Loss: 0.4103235721336855\n",
      "W1: 10.959900879236333 W2: 1.8853301145074828 b -5.748641327445024 Loss: 0.4103235700949392\n",
      "W1: 10.959929173258823 W2: 1.8853331912956526 b -5.748655683002868 Loss: 0.4103235680599358\n",
      "W1: 10.959957441294339 W2: 1.8853362652656733 b -5.74867002538429 Loss: 0.41032356602866804\n",
      "W1: 10.959985683366863 W2: 1.8853393364201314 b -5.748684354601434 Loss: 0.4103235640011295\n",
      "W1: 10.960013899500353 W2: 1.8853424047616107 b -5.748698670666434 Loss: 0.41032356197731273\n",
      "W1: 10.960042089718748 W2: 1.885345470292693 b -5.748712973591409 Loss: 0.4103235599572114\n",
      "W1: 10.960070254045961 W2: 1.8853485330159576 b -5.748727263388471 Loss: 0.4103235579408187\n",
      "W1: 10.960098392505886 W2: 1.8853515929339812 b -5.748741540069717 Loss: 0.41032355592812736\n",
      "W1: 10.96012650512239 W2: 1.8853546500493386 b -5.748755803647236 Loss: 0.410323553919131\n",
      "W1: 10.960154591919325 W2: 1.8853577043646017 b -5.748770054133104 Loss: 0.4103235519138226\n",
      "W1: 10.960182652920516 W2: 1.8853607558823404 b -5.748784291539385 Loss: 0.4103235499121952\n",
      "W1: 10.960210688149765 W2: 1.8853638046051222 b -5.748798515878135 Loss: 0.41032354791424247\n",
      "W1: 10.960238697630853 W2: 1.8853668505355121 b -5.748812727161394 Loss: 0.4103235459199574\n",
      "W1: 10.960266681387541 W2: 1.8853698936760728 b -5.748826925401196 Loss: 0.4103235439293332\n",
      "W1: 10.960294639443564 W2: 1.8853729340293646 b -5.748841110609559 Loss: 0.410323541942363\n",
      "W1: 10.960322571822639 W2: 1.8853759715979452 b -5.748855282798495 Loss: 0.41032353995904053\n",
      "W1: 10.960350478548456 W2: 1.8853790063843707 b -5.748869441979999 Loss: 0.41032353797935883\n",
      "W1: 10.96037835964469 W2: 1.8853820383911941 b -5.74888358816606 Loss: 0.41032353600331106\n",
      "W1: 10.960406215134986 W2: 1.8853850676209662 b -5.748897721368652 Loss: 0.4103235340308908\n",
      "W1: 10.960434045042973 W2: 1.8853880940762358 b -5.748911841599742 Loss: 0.4103235320620912\n",
      "W1: 10.960461849392255 W2: 1.885391117759549 b -5.74892594887128 Loss: 0.41032353009690553\n",
      "W1: 10.960489628206414 W2: 1.8853941386734496 b -5.748940043195211 Loss: 0.4103235281353273\n",
      "W1: 10.960517381509012 W2: 1.8853971568204793 b -5.748954124583466 Loss: 0.41032352617734985\n",
      "W1: 10.960545109323586 W2: 1.885400172203177 b -5.748968193047964 Loss: 0.41032352422296653\n",
      "W1: 10.960572811673655 W2: 1.8854031848240798 b -5.7489822486006155 Loss: 0.4103235222721708\n",
      "W1: 10.960600488582713 W2: 1.885406194685722 b -5.7489962912533175 Loss: 0.41032352032495595\n",
      "W1: 10.960628140074235 W2: 1.8854092017906356 b -5.749010321017957 Loss: 0.4103235183813154\n",
      "W1: 10.96065576617167 W2: 1.885412206141351 b -5.749024337906412 Loss: 0.4103235164412426\n",
      "W1: 10.960683366898447 W2: 1.8854152077403952 b -5.749038341930544 Loss: 0.4103235145047309\n",
      "W1: 10.960710942277975 W2: 1.8854182065902936 b -5.74905233310221 Loss: 0.41032351257177396\n",
      "W1: 10.96073849233364 W2: 1.885421202693569 b -5.749066311433251 Loss: 0.41032351064236505\n",
      "W1: 10.960766017088806 W2: 1.885424196052742 b -5.7490802769355 Loss: 0.41032350871649786\n",
      "W1: 10.960793516566815 W2: 1.8854271866703307 b -5.749094229620777 Loss: 0.41032350679416557\n",
      "W1: 10.960820990790987 W2: 1.885430174548851 b -5.749108169500892 Loss: 0.4103235048753619\n",
      "W1: 10.960848439784622 W2: 1.8854331596908165 b -5.749122096587644 Loss: 0.4103235029600802\n",
      "W1: 10.960875863570996 W2: 1.8854361420987384 b -5.749136010892823 Loss: 0.410323501048314\n",
      "W1: 10.960903262173366 W2: 1.8854391217751256 b -5.749149912428203 Loss: 0.4103234991400572\n",
      "W1: 10.960930635614965 W2: 1.885442098722485 b -5.749163801205552 Loss: 0.4103234972353029\n",
      "W1: 10.960957983919005 W2: 1.8854450729433203 b -5.7491776772366245 Loss: 0.41032349533404483\n",
      "W1: 10.960985307108677 W2: 1.885448044440134 b -5.7491915405331655 Loss: 0.41032349343627667\n",
      "W1: 10.96101260520715 W2: 1.8854510132154259 b -5.749205391106908 Loss: 0.4103234915419916\n",
      "W1: 10.961039878237573 W2: 1.8854539792716931 b -5.749219228969574 Loss: 0.41032348965118376\n",
      "W1: 10.96106712622307 W2: 1.8854569426114307 b -5.749233054132875 Loss: 0.4103234877638462\n",
      "W1: 10.961094349186745 W2: 1.8854599032371318 b -5.749246866608513 Loss: 0.410323485879973\n",
      "W1: 10.96112154715168 W2: 1.8854628611512865 b -5.749260666408177 Loss: 0.4103234839995576\n",
      "W1: 10.96114872014094 W2: 1.8854658163563833 b -5.749274453543546 Loss: 0.41032348212259345\n",
      "W1: 10.961175868177563 W2: 1.8854687688549079 b -5.749288228026288 Loss: 0.41032348024907467\n",
      "W1: 10.961202991284566 W2: 1.8854717186493442 b -5.74930198986806 Loss: 0.4103234783789946\n",
      "W1: 10.961230089484948 W2: 1.8854746657421733 b -5.74931573908051 Loss: 0.41032347651234696\n",
      "W1: 10.961257162801685 W2: 1.8854776101358743 b -5.749329475675272 Loss: 0.4103234746491254\n",
      "W1: 10.961284211257729 W2: 1.885480551832924 b -5.749343199663971 Loss: 0.4103234727893236\n",
      "W1: 10.961311234876014 W2: 1.8854834908357971 b -5.749356911058222 Loss: 0.4103234709329353\n",
      "W1: 10.961338233679452 W2: 1.8854864271469656 b -5.7493706098696284 Loss: 0.4103234690799544\n",
      "W1: 10.961365207690934 W2: 1.8854893607688994 b -5.749384296109782 Loss: 0.4103234672303744\n",
      "W1: 10.961392156933327 W2: 1.8854922917040662 b -5.749397969790265 Loss: 0.410323465384189\n",
      "W1: 10.96141908142948 W2: 1.8854952199549315 b -5.749411630922649 Loss: 0.4103234635413921\n",
      "W1: 10.96144598120222 W2: 1.8854981455239583 b -5.749425279518492 Loss: 0.4103234617019776\n",
      "W1: 10.96147285627435 W2: 1.8855010684136075 b -5.749438915589346 Loss: 0.41032345986593904\n",
      "W1: 10.961499706668654 W2: 1.8855039886263376 b -5.749452539146748 Loss: 0.41032345803327036\n",
      "W1: 10.961526532407897 W2: 1.885506906164605 b -5.7494661502022275 Loss: 0.4103234562039651\n",
      "W1: 10.961553333514818 W2: 1.8855098210308636 b -5.7494797487673015 Loss: 0.41032345437801737\n",
      "W1: 10.96158011001214 W2: 1.8855127332275654 b -5.749493334853476 Loss: 0.410323452555421\n",
      "W1: 10.96160686192256 W2: 1.8855156427571598 b -5.749506908472248 Loss: 0.4103234507361696\n",
      "W1: 10.961633589268757 W2: 1.885518549622094 b -5.749520469635102 Loss: 0.4103234489202572\n",
      "W1: 10.961660292073388 W2: 1.8855214538248135 b -5.749534018353513 Loss: 0.4103234471076776\n",
      "W1: 10.961686970359088 W2: 1.8855243553677605 b -5.749547554638945 Loss: 0.41032344529842457\n",
      "W1: 10.961713624148473 W2: 1.8855272542533759 b -5.749561078502852 Loss: 0.410323443492492\n",
      "W1: 10.961740253464136 W2: 1.8855301504840978 b -5.749574589956676 Loss: 0.41032344168987406\n",
      "W1: 10.96176685832865 W2: 1.885533044062362 b -5.74958808901185 Loss: 0.41032343989056436\n",
      "W1: 10.961793438764566 W2: 1.885535934990603 b -5.749601575679794 Loss: 0.4103234380945571\n",
      "W1: 10.961819994794416 W2: 1.8855388232712516 b -5.74961504997192 Loss: 0.41032343630184587\n",
      "W1: 10.96184652644071 W2: 1.8855417089067374 b -5.749628511899629 Loss: 0.4103234345124248\n",
      "W1: 10.961873033725935 W2: 1.8855445918994875 b -5.7496419614743095 Loss: 0.4103234327262877\n",
      "W1: 10.96189951667256 W2: 1.8855474722519268 b -5.749655398707341 Loss: 0.4103234309434287\n",
      "W1: 10.961925975303032 W2: 1.8855503499664776 b -5.749668823610092 Loss: 0.41032342916384174\n",
      "W1: 10.961952409639778 W2: 1.8855532250455607 b -5.74968223619392 Loss: 0.4103234273875206\n",
      "W1: 10.961978819705203 W2: 1.885556097491594 b -5.749695636470174 Loss: 0.4103234256144596\n",
      "W1: 10.962005205521692 W2: 1.8855589673069932 b -5.7497090244501905 Loss: 0.41032342384465254\n",
      "W1: 10.962031567111605 W2: 1.8855618344941723 b -5.749722400145296 Loss: 0.4103234220780936\n",
      "W1: 10.96205790449729 W2: 1.8855646990555426 b -5.749735763566806 Loss: 0.41032342031477637\n",
      "W1: 10.962084217701065 W2: 1.8855675609935134 b -5.749749114726026 Loss: 0.4103234185546954\n",
      "W1: 10.962110506745233 W2: 1.885570420310492 b -5.749762453634251 Loss: 0.4103234167978446\n",
      "W1: 10.962136771652075 W2: 1.8855732770088827 b -5.749775780302765 Loss: 0.4103234150442178\n",
      "W1: 10.962163012443849 W2: 1.8855761310910883 b -5.749789094742844 Loss: 0.41032341329380934\n",
      "W1: 10.962189229142796 W2: 1.8855789825595095 b -5.749802396965749 Loss: 0.4103234115466133\n",
      "W1: 10.962215421771132 W2: 1.885581831416544 b -5.749815686982735 Loss: 0.4103234098026236\n",
      "W1: 10.962241590351057 W2: 1.8855846776645881 b -5.749828964805043 Loss: 0.41032340806183415\n",
      "W1: 10.962267734904747 W2: 1.8855875213060354 b -5.749842230443907 Loss: 0.4103234063242395\n",
      "W1: 10.962293855454359 W2: 1.8855903623432775 b -5.749855483910547 Loss: 0.4103234045898338\n",
      "W1: 10.962319952022026 W2: 1.8855932007787037 b -5.749868725216176 Loss: 0.4103234028586108\n",
      "W1: 10.962346024629868 W2: 1.8855960366147013 b -5.749881954371994 Loss: 0.4103234011305648\n",
      "W1: 10.962372073299976 W2: 1.8855988698536552 b -5.749895171389191 Loss: 0.41032339940569\n",
      "W1: 10.962398098054425 W2: 1.885601700497948 b -5.749908376278949 Loss: 0.4103233976839808\n",
      "W1: 10.962424098915271 W2: 1.8856045285499603 b -5.749921569052436 Loss: 0.4103233959654309\n",
      "W1: 10.962450075904544 W2: 1.8856073540120706 b -5.749934749720812 Loss: 0.4103233942500348\n",
      "W1: 10.962476029044257 W2: 1.8856101768866549 b -5.749947918295227 Loss: 0.4103233925377865\n",
      "W1: 10.962501958356404 W2: 1.8856129971760873 b -5.749961074786818 Loss: 0.41032339082868047\n",
      "W1: 10.962527863862954 W2: 1.8856158148827398 b -5.749974219206716 Loss: 0.4103233891227109\n",
      "W1: 10.96255374558586 W2: 1.8856186300089817 b -5.749987351566037 Loss: 0.4103233874198717\n",
      "W1: 10.962579603547052 W2: 1.8856214425571807 b -5.750000471875889 Loss: 0.4103233857201573\n",
      "W1: 10.96260543776844 W2: 1.8856242525297018 b -5.750013580147369 Loss: 0.4103233840235622\n",
      "W1: 10.962631248271915 W2: 1.8856270599289082 b -5.750026676391566 Loss: 0.4103233823300804\n",
      "W1: 10.962657035079348 W2: 1.885629864757161 b -5.750039760619555 Loss: 0.4103233806397062\n",
      "W1: 10.962682798212585 W2: 1.8856326670168186 b -5.750052832842404 Loss: 0.4103233789524339\n",
      "W1: 10.962708537693457 W2: 1.8856354667102377 b -5.750065893071168 Loss: 0.41032337726825785\n",
      "W1: 10.962734253543772 W2: 1.8856382638397728 b -5.750078941316895 Loss: 0.4103233755871722\n",
      "W1: 10.962759945785319 W2: 1.885641058407776 b -5.7500919775906185 Loss: 0.41032337390917156\n",
      "W1: 10.962785614439866 W2: 1.8856438504165975 b -5.750105001903365 Loss: 0.41032337223425003\n",
      "W1: 10.962811259529161 W2: 1.885646639868585 b -5.7501180142661505 Loss: 0.41032337056240203\n",
      "W1: 10.962836881074931 W2: 1.8856494267660842 b -5.75013101468998 Loss: 0.4103233688936218\n",
      "W1: 10.962862479098884 W2: 1.8856522111114389 b -5.750144003185848 Loss: 0.41032336722790386\n",
      "W1: 10.962888053622708 W2: 1.8856549929069903 b -5.750156979764739 Loss: 0.4103233655652423\n",
      "W1: 10.962913604668069 W2: 1.8856577721550778 b -5.750169944437628 Loss: 0.4103233639056319\n",
      "W1: 10.962939132256613 W2: 1.8856605488580385 b -5.750182897215479 Loss: 0.4103233622490667\n",
      "W1: 10.96296463640997 W2: 1.8856633230182072 b -5.7501958381092475 Loss: 0.4103233605955413\n",
      "W1: 10.962990117149744 W2: 1.885666094637917 b -5.750208767129876 Loss: 0.41032335894505007\n",
      "W1: 10.963015574497522 W2: 1.8856688637194983 b -5.750221684288299 Loss: 0.41032335729758757\n",
      "W1: 10.963041008474871 W2: 1.8856716302652796 b -5.750234589595439 Loss: 0.4103233556531478\n",
      "W1: 10.963066419103338 W2: 1.8856743942775875 b -5.7502474830622115 Loss: 0.41032335401172565\n",
      "W1: 10.96309180640445 W2: 1.885677155758746 b -5.7502603646995185 Loss: 0.41032335237331535\n",
      "W1: 10.96311717039971 W2: 1.8856799147110772 b -5.750273234518255 Loss: 0.4103233507379114\n",
      "W1: 10.96314251111061 W2: 1.8856826711369012 b -5.750286092529302 Loss: 0.4103233491055084\n",
      "W1: 10.963167828558612 W2: 1.8856854250385358 b -5.7502989387435335 Loss: 0.41032334747610066\n",
      "W1: 10.963193122765166 W2: 1.8856881764182964 b -5.750311773171814 Loss: 0.41032334584968255\n",
      "W1: 10.963218393751696 W2: 1.8856909252784968 b -5.750324595824995 Loss: 0.4103233442262489\n",
      "W1: 10.96324364153961 W2: 1.8856936716214483 b -5.7503374067139195 Loss: 0.41032334260579406\n",
      "W1: 10.963268866150292 W2: 1.8856964154494602 b -5.750350205849421 Loss: 0.41032334098831263\n",
      "W1: 10.963294067605112 W2: 1.8856991567648396 b -5.750362993242322 Loss: 0.41032333937379906\n",
      "W1: 10.963319245925417 W2: 1.8857018955698917 b -5.750375768903436 Loss: 0.4103233377622477\n",
      "W1: 10.963344401132533 W2: 1.8857046318669193 b -5.750388532843565 Loss: 0.4103233361536536\n",
      "W1: 10.963369533247768 W2: 1.8857073656582233 b -5.750401285073502 Loss: 0.410323334548011\n",
      "W1: 10.963394642292409 W2: 1.8857100969461023 b -5.750414025604029 Loss: 0.41032333294531453\n",
      "W1: 10.963419728287723 W2: 1.8857128257328528 b -5.75042675444592 Loss: 0.4103233313455585\n",
      "W1: 10.963444791254961 W2: 1.8857155520207693 b -5.750439471609936 Loss: 0.410323329748738\n",
      "W1: 10.963469831215349 W2: 1.8857182758121442 b -5.7504521771068315 Loss: 0.4103233281548473\n",
      "W1: 10.963494848190095 W2: 1.8857209971092679 b -5.750464870947348 Loss: 0.41032332656388115\n",
      "W1: 10.96351984220039 W2: 1.885723715914428 b -5.750477553142219 Loss: 0.4103233249758341\n",
      "W1: 10.963544813267399 W2: 1.885726432229911 b -5.750490223702167 Loss: 0.4103233233907009\n",
      "W1: 10.963569761412275 W2: 1.8857291460580006 b -5.750502882637905 Loss: 0.4103233218084759\n",
      "W1: 10.963594686656148 W2: 1.8857318574009785 b -5.750515529960136 Loss: 0.41032332022915424\n",
      "W1: 10.963619589020126 W2: 1.8857345662611245 b -5.750528165679554 Loss: 0.41032331865273003\n",
      "W1: 10.9636444685253 W2: 1.8857372726407162 b -5.75054078980684 Loss: 0.4103233170791984\n",
      "W1: 10.963669325192743 W2: 1.885739976542029 b -5.750553402352669 Loss: 0.4103233155085537\n",
      "W1: 10.963694159043504 W2: 1.8857426779673367 b -5.750566003327704 Loss: 0.4103233139407909\n",
      "W1: 10.963718970098615 W2: 1.8857453769189103 b -5.750578592742599 Loss: 0.4103233123759045\n",
      "W1: 10.963743758379088 W2: 1.885748073399019 b -5.750591170607996 Loss: 0.41032331081388945\n",
      "W1: 10.963768523905918 W2: 1.88575076740993 b -5.75060373693453 Loss: 0.4103233092547401\n",
      "W1: 10.963793266700076 W2: 1.8857534589539084 b -5.7506162917328245 Loss: 0.41032330769845154\n",
      "W1: 10.963817986782518 W2: 1.8857561480332172 b -5.750628835013493 Loss: 0.4103233061450181\n",
      "W1: 10.963842684174175 W2: 1.885758834650117 b -5.75064136678714 Loss: 0.410323304594435\n",
      "W1: 10.963867358895962 W2: 1.885761518806867 b -5.75065388706436 Loss: 0.4103233030466967\n",
      "W1: 10.963892010968777 W2: 1.8857642005057238 b -5.750666395855737 Loss: 0.4103233015017981\n",
      "W1: 10.963916640413494 W2: 1.885766879748942 b -5.750678893171846 Loss: 0.4103232999597339\n",
      "W1: 10.96394124725097 W2: 1.885769556538774 b -5.750691379023253 Loss: 0.41032329842049914\n",
      "W1: 10.963965831502042 W2: 1.8857722308774705 b -5.750703853420511 Loss: 0.41032329688408814\n",
      "W1: 10.963990393187528 W2: 1.8857749027672799 b -5.750716316374166 Loss: 0.41032329535049605\n",
      "W1: 10.964014932328226 W2: 1.8857775722104486 b -5.750728767894754 Loss: 0.41032329381971766\n",
      "W1: 10.964039448944916 W2: 1.8857802392092207 b -5.7507412079928 Loss: 0.41032329229174774\n",
      "W1: 10.964063943058358 W2: 1.8857829037658387 b -5.750753636678821 Loss: 0.4103232907665809\n",
      "W1: 10.96408841468929 W2: 1.8857855658825424 b -5.750766053963323 Loss: 0.4103232892442125\n",
      "W1: 10.964112863858434 W2: 1.8857882255615703 b -5.750778459856802 Loss: 0.410323287724637\n",
      "W1: 10.964137290586493 W2: 1.8857908828051582 b -5.750790854369744 Loss: 0.41032328620784947\n",
      "W1: 10.96416169489415 W2: 1.8857935376155401 b -5.750803237512628 Loss: 0.41032328469384455\n",
      "W1: 10.964186076802068 W2: 1.885796189994948 b -5.75081560929592 Loss: 0.4103232831826174\n",
      "W1: 10.964210436330891 W2: 1.8857988399456116 b -5.750827969730078 Loss: 0.41032328167416277\n",
      "W1: 10.964234773501245 W2: 1.8858014874697588 b -5.750840318825549 Loss: 0.4103232801684756\n",
      "W1: 10.964259088333735 W2: 1.8858041325696155 b -5.750852656592773 Loss: 0.4103232786655507\n",
      "W1: 10.964283380848949 W2: 1.8858067752474055 b -5.750864983042177 Loss: 0.41032327716538314\n",
      "W1: 10.964307651067452 W2: 1.88580941550535 b -5.750877298184181 Loss: 0.4103232756679678\n",
      "W1: 10.964331899009796 W2: 1.885812053345669 b -5.7508896020291935 Loss: 0.4103232741732995\n",
      "W1: 10.964356124696508 W2: 1.88581468877058 b -5.7509018945876145 Loss: 0.4103232726813734\n",
      "W1: 10.9643803281481 W2: 1.8858173217822984 b -5.750914175869833 Loss: 0.41032327119218426\n",
      "W1: 10.96440450938506 W2: 1.885819952383038 b -5.750926445886231 Loss: 0.41032326970572724\n",
      "W1: 10.964428668427866 W2: 1.88582258057501 b -5.750938704647178 Loss: 0.4103232682219973\n",
      "W1: 10.964452805296967 W2: 1.885825206360424 b -5.750950952163035 Loss: 0.41032326674098923\n",
      "W1: 10.964476920012798 W2: 1.8858278297414872 b -5.750963188444154 Loss: 0.4103232652626982\n",
      "W1: 10.964501012595775 W2: 1.8858304507204051 b -5.750975413500877 Loss: 0.41032326378711903\n",
      "W1: 10.964525083066295 W2: 1.885833069299381 b -5.750987627343536 Loss: 0.41032326231424693\n",
      "W1: 10.964549131444734 W2: 1.8858356854806164 b -5.750999829982453 Loss: 0.41032326084407694\n",
      "W1: 10.96457315775145 W2: 1.8858382992663103 b -5.751012021427942 Loss: 0.41032325937660397\n",
      "W1: 10.964597162006786 W2: 1.8858409106586602 b -5.751024201690307 Loss: 0.4103232579118232\n",
      "W1: 10.96462114423106 W2: 1.885843519659861 b -5.7510363707798415 Loss: 0.4103232564497294\n",
      "W1: 10.964645104444573 W2: 1.8858461262721062 b -5.751048528706829 Loss: 0.4103232549903179\n",
      "W1: 10.964669042667609 W2: 1.885848730497587 b -5.751060675481547 Loss: 0.4103232535335837\n",
      "W1: 10.964692958920432 W2: 1.8858513323384924 b -5.751072811114258 Loss: 0.4103232520795219\n",
      "W1: 10.964716853223289 W2: 1.8858539317970098 b -5.75108493561522 Loss: 0.4103232506281275\n",
      "W1: 10.964740725596403 W2: 1.8858565288753242 b -5.751097048994678 Loss: 0.41032324917939583\n",
      "W1: 10.964764576059984 W2: 1.8858591235756186 b -5.75110915126287 Loss: 0.4103232477333216\n",
      "W1: 10.964788404634222 W2: 1.8858617159000743 b -5.751121242430024 Loss: 0.4103232462899003\n",
      "W1: 10.964812211339284 W2: 1.8858643058508706 b -5.751133322506356 Loss: 0.41032324484912674\n",
      "W1: 10.964835996195324 W2: 1.8858668934301843 b -5.751145391502076 Loss: 0.4103232434109963\n",
      "W1: 10.964859759222474 W2: 1.8858694786401906 b -5.7511574494273825 Loss: 0.4103232419755041\n",
      "W1: 10.964883500440846 W2: 1.8858720614830629 b -5.751169496292465 Loss: 0.4103232405426452\n",
      "W1: 10.964907219870538 W2: 1.885874641960972 b -5.751181532107504 Loss: 0.4103232391124147\n",
      "W1: 10.964930917531627 W2: 1.885877220076087 b -5.7511935568826695 Loss: 0.4103232376848079\n",
      "W1: 10.964954593444169 W2: 1.885879795830575 b -5.751205570628123 Loss: 0.41032323625981987\n",
      "W1: 10.964978247628204 W2: 1.8858823692266014 b -5.751217573354017 Loss: 0.410323234837446\n",
      "W1: 10.965001880103754 W2: 1.8858849402663291 b -5.751229565070494 Loss: 0.4103232334176811\n",
      "W1: 10.96502549089082 W2: 1.8858875089519194 b -5.751241545787686 Loss: 0.41032323200052095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.965049080009384 W2: 1.8858900752855314 b -5.751253515515717 Loss: 0.41032323058596026\n",
      "W1: 10.965072647479415 W2: 1.8858926392693223 b -5.751265474264702 Loss: 0.41032322917399444\n",
      "W1: 10.965096193320857 W2: 1.885895200905447 b -5.751277422044746 Loss: 0.4103232277646187\n",
      "W1: 10.965119717553637 W2: 1.8858977601960591 b -5.751289358865943 Loss: 0.41032322635782825\n",
      "W1: 10.965143220197668 W2: 1.8859003171433097 b -5.75130128473838 Loss: 0.41032322495361845\n",
      "W1: 10.965166701272837 W2: 1.8859028717493478 b -5.7513131996721345 Loss: 0.41032322355198436\n",
      "W1: 10.965190160799018 W2: 1.8859054240163209 b -5.7513251036772735 Loss: 0.4103232221529216\n",
      "W1: 10.965213598796065 W2: 1.8859079739463742 b -5.751336996763855 Loss: 0.410323220756425\n",
      "W1: 10.965237015283815 W2: 1.8859105215416512 b -5.751348878941927 Loss: 0.4103232193624899\n",
      "W1: 10.965260410282085 W2: 1.885913066804293 b -5.751360750221531 Loss: 0.4103232179711121\n",
      "W1: 10.965283783810673 W2: 1.885915609736439 b -5.751372610612696 Loss: 0.4103232165822864\n",
      "W1: 10.965307135889358 W2: 1.8859181503402265 b -5.751384460125444 Loss: 0.41032321519600834\n",
      "W1: 10.965330466537905 W2: 1.8859206886177913 b -5.7513962987697855 Loss: 0.4103232138122731\n",
      "W1: 10.965353775776055 W2: 1.8859232245712665 b -5.751408126555723 Loss: 0.41032321243107606\n",
      "W1: 10.965377063623535 W2: 1.8859257582027837 b -5.75141994349325 Loss: 0.4103232110524125\n",
      "W1: 10.965400330100053 W2: 1.8859282895144727 b -5.75143174959235 Loss: 0.4103232096762777\n",
      "W1: 10.965423575225296 W2: 1.885930818508461 b -5.751443544862998 Loss: 0.4103232083026674\n",
      "W1: 10.965446799018935 W2: 1.8859333451868738 b -5.75145532931516 Loss: 0.41032320693157653\n",
      "W1: 10.965470001500622 W2: 1.8859358695518353 b -5.751467102958791 Loss: 0.4103232055630007\n",
      "W1: 10.965493182689992 W2: 1.885938391605467 b -5.751478865803838 Loss: 0.41032320419693524\n",
      "W1: 10.965516342606659 W2: 1.8859409113498886 b -5.751490617860239 Loss: 0.41032320283337537\n",
      "W1: 10.965539481270222 W2: 1.885943428787218 b -5.751502359137922 Loss: 0.4103232014723168\n",
      "W1: 10.96556259870026 W2: 1.8859459439195712 b -5.7515140896468075 Loss: 0.41032320011375467\n",
      "W1: 10.965585694916333 W2: 1.8859484567490616 b -5.751525809396805 Loss: 0.4103231987576844\n",
      "W1: 10.965608769937987 W2: 1.8859509672778019 b -5.751537518397814 Loss: 0.4103231974041016\n",
      "W1: 10.965631823784744 W2: 1.8859534755079015 b -5.751549216659729 Loss: 0.41032319605300155\n",
      "W1: 10.965654856476112 W2: 1.8859559814414688 b -5.751560904192431 Loss: 0.41032319470437967\n",
      "W1: 10.96567786803158 W2: 1.88595848508061 b -5.751572581005792 Loss: 0.4103231933582316\n",
      "W1: 10.965700858470617 W2: 1.8859609864274292 b -5.751584247109679 Loss: 0.41032319201455264\n",
      "W1: 10.965723827812678 W2: 1.8859634854840286 b -5.751595902513945 Loss: 0.41032319067333806\n",
      "W1: 10.965746776077195 W2: 1.8859659822525086 b -5.7516075472284385 Loss: 0.4103231893345839\n",
      "W1: 10.965769703283584 W2: 1.8859684767349676 b -5.751619181262994 Loss: 0.410323187998285\n",
      "W1: 10.965792609451245 W2: 1.8859709689335022 b -5.75163080462744 Loss: 0.4103231866644373\n",
      "W1: 10.965815494599559 W2: 1.8859734588502068 b -5.751642417331595 Loss: 0.41032318533303597\n",
      "W1: 10.965838358747886 W2: 1.8859759464871741 b -5.75165401938527 Loss: 0.41032318400407664\n",
      "W1: 10.965861201915573 W2: 1.885978431846495 b -5.7516656107982636 Loss: 0.4103231826775549\n",
      "W1: 10.965884024121944 W2: 1.8859809149302578 b -5.751677191580368 Loss: 0.4103231813534663\n",
      "W1: 10.965906825386309 W2: 1.8859833957405496 b -5.751688761741367 Loss: 0.4103231800318063\n",
      "W1: 10.965929605727958 W2: 1.8859858742794555 b -5.751700321291032 Loss: 0.4103231787125704\n",
      "W1: 10.965952365166164 W2: 1.8859883505490584 b -5.751711870239127 Loss: 0.4103231773957541\n",
      "W1: 10.965975103720181 W2: 1.8859908245514394 b -5.751723408595408 Loss: 0.41032317608135305\n",
      "W1: 10.965997821409248 W2: 1.8859932962886776 b -5.751734936369622 Loss: 0.41032317476936275\n",
      "W1: 10.966020518252583 W2: 1.8859957657628503 b -5.751746453571505 Loss: 0.4103231734597789\n",
      "W1: 10.966043194269385 W2: 1.8859982329760328 b -5.751757960210785 Loss: 0.410323172152597\n",
      "W1: 10.96606584947884 W2: 1.8860006979302986 b -5.751769456297182 Loss: 0.41032317084781256\n",
      "W1: 10.966088483900112 W2: 1.8860031606277192 b -5.751780941840405 Loss: 0.41032316954542125\n",
      "W1: 10.96611109755235 W2: 1.8860056210703644 b -5.751792416850155 Loss: 0.41032316824541853\n",
      "W1: 10.966133690454685 W2: 1.8860080792603018 b -5.751803881336126 Loss: 0.4103231669478004\n",
      "W1: 10.966156262626226 W2: 1.8860105351995973 b -5.751815335307999 Loss: 0.4103231656525621\n",
      "W1: 10.96617881408607 W2: 1.8860129888903148 b -5.75182677877545 Loss: 0.41032316435969923\n",
      "W1: 10.966201344853294 W2: 1.8860154403345162 b -5.751838211748143 Loss: 0.4103231630692079\n",
      "W1: 10.966223854946955 W2: 1.8860178895342619 b -5.751849634235734 Loss: 0.41032316178108313\n",
      "W1: 10.966246344386096 W2: 1.88602033649161 b -5.751861046247872 Loss: 0.410323160495321\n",
      "W1: 10.966268813189743 W2: 1.8860227812086168 b -5.751872447794194 Loss: 0.4103231592119171\n",
      "W1: 10.966291261376897 W2: 1.8860252236873367 b -5.75188383888433 Loss: 0.4103231579308668\n",
      "W1: 10.966313688966551 W2: 1.8860276639298226 b -5.7518952195279 Loss: 0.41032315665216623\n",
      "W1: 10.966336095977672 W2: 1.8860301019381247 b -5.751906589734516 Loss: 0.4103231553758108\n",
      "W1: 10.966358482429216 W2: 1.8860325377142921 b -5.751917949513781 Loss: 0.41032315410179626\n",
      "W1: 10.966380848340119 W2: 1.8860349712603717 b -5.751929298875289 Loss: 0.4103231528301183\n",
      "W1: 10.966403193729297 W2: 1.8860374025784084 b -5.751940637828624 Loss: 0.4103231515607724\n",
      "W1: 10.966425518615653 W2: 1.8860398316704454 b -5.751951966383363 Loss: 0.4103231502937548\n",
      "W1: 10.966447823018067 W2: 1.886042258538524 b -5.751963284549072 Loss: 0.41032314902906086\n",
      "W1: 10.966470106955406 W2: 1.8860446831846833 b -5.751974592335311 Loss: 0.41032314776668616\n",
      "W1: 10.966492370446518 W2: 1.8860471056109613 b -5.751985889751628 Loss: 0.4103231465066269\n",
      "W1: 10.966514613510235 W2: 1.8860495258193932 b -5.751997176807565 Loss: 0.4103231452488785\n",
      "W1: 10.966536836165368 W2: 1.8860519438120131 b -5.752008453512653 Loss: 0.4103231439934368\n",
      "W1: 10.966559038430713 W2: 1.8860543595908528 b -5.752019719876415 Loss: 0.4103231427402976\n",
      "W1: 10.966581220325049 W2: 1.886056773157942 b -5.752030975908366 Loss: 0.41032314148945653\n",
      "W1: 10.966603381867134 W2: 1.8860591845153092 b -5.7520422216180105 Loss: 0.41032314024090955\n",
      "W1: 10.966625523075715 W2: 1.8860615936649805 b -5.752053457014846 Loss: 0.4103231389946522\n",
      "W1: 10.966647643969514 W2: 1.8860640006089804 b -5.752064682108359 Loss: 0.4103231377506807\n",
      "W1: 10.966669744567243 W2: 1.8860664053493315 b -5.752075896908029 Loss: 0.4103231365089904\n",
      "W1: 10.966691824887592 W2: 1.8860688078880543 b -5.752087101423327 Loss: 0.4103231352695774\n",
      "W1: 10.966713884949234 W2: 1.886071208227168 b -5.752098295663714 Loss: 0.4103231340324372\n",
      "W1: 10.966735924770827 W2: 1.8860736063686894 b -5.7521094796386425 Loss: 0.410323132797566\n",
      "W1: 10.966757944371007 W2: 1.8860760023146335 b -5.752120653357556 Loss: 0.4103231315649594\n",
      "W1: 10.9667799437684 W2: 1.8860783960670138 b -5.752131816829891 Loss: 0.4103231303346133\n",
      "W1: 10.966801922981608 W2: 1.8860807876278416 b -5.752142970065073 Loss: 0.4103231291065235\n",
      "W1: 10.96682388202922 W2: 1.8860831769991266 b -5.752154113072519 Loss: 0.410323127880686\n",
      "W1: 10.966845820929803 W2: 1.8860855641828764 b -5.75216524586164 Loss: 0.4103231266570967\n",
      "W1: 10.966867739701915 W2: 1.886087949181097 b -5.752176368441835 Loss: 0.41032312543575106\n",
      "W1: 10.966889638364087 W2: 1.8860903319957922 b -5.752187480822496 Loss: 0.4103231242166453\n",
      "W1: 10.966911516934841 W2: 1.8860927126289644 b -5.752198583013006 Loss: 0.4103231229997753\n",
      "W1: 10.966933375432676 W2: 1.886095091082614 b -5.752209675022739 Loss: 0.41032312178513697\n",
      "W1: 10.966955213876078 W2: 1.8860974673587394 b -5.7522207568610595 Loss: 0.41032312057272596\n",
      "W1: 10.966977032283513 W2: 1.886099841459337 b -5.752231828537326 Loss: 0.41032311936253835\n",
      "W1: 10.96699883067343 W2: 1.886102213386402 b -5.752242890060886 Loss: 0.4103231181545702\n",
      "W1: 10.967020609064264 W2: 1.8861045831419274 b -5.752253941441079 Loss: 0.41032311694881723\n",
      "W1: 10.967042367474429 W2: 1.8861069507279042 b -5.752264982687237 Loss: 0.41032311574527536\n",
      "W1: 10.967064105922324 W2: 1.8861093161463218 b -5.752276013808681 Loss: 0.4103231145439406\n",
      "W1: 10.96708582442633 W2: 1.8861116793991677 b -5.752287034814725 Loss: 0.4103231133448089\n",
      "W1: 10.967107523004813 W2: 1.8861140404884276 b -5.752298045714674 Loss: 0.41032311214787637\n",
      "W1: 10.96712920167612 W2: 1.8861163994160852 b -5.7523090465178255 Loss: 0.41032311095313856\n",
      "W1: 10.96715086045858 W2: 1.8861187561841228 b -5.752320037233466 Loss: 0.4103231097605919\n",
      "W1: 10.967172499370506 W2: 1.8861211107945206 b -5.752331017870875 Loss: 0.41032310857023196\n",
      "W1: 10.967194118430196 W2: 1.8861234632492567 b -5.752341988439324 Loss: 0.410323107382055\n",
      "W1: 10.96721571765593 W2: 1.8861258135503078 b -5.752352948948073 Loss: 0.41032310619605694\n",
      "W1: 10.967237297065969 W2: 1.8861281616996488 b -5.752363899406377 Loss: 0.4103231050122336\n",
      "W1: 10.96725885667856 W2: 1.8861305076992525 b -5.752374839823481 Loss: 0.4103231038305813\n",
      "W1: 10.967280396511931 W2: 1.88613285155109 b -5.75238577020862 Loss: 0.41032310265109595\n",
      "W1: 10.967301916584294 W2: 1.8861351932571306 b -5.7523966905710235 Loss: 0.41032310147377343\n",
      "W1: 10.967323416913842 W2: 1.886137532819342 b -5.75240760091991 Loss: 0.4103231002986098\n",
      "W1: 10.967344897518755 W2: 1.8861398702396894 b -5.75241850126449 Loss: 0.4103230991256011\n",
      "W1: 10.967366358417195 W2: 1.8861422055201371 b -5.752429391613966 Loss: 0.4103230979547435\n",
      "W1: 10.967387799627303 W2: 1.886144538662647 b -5.752440271977532 Loss: 0.4103230967860329\n",
      "W1: 10.96740922116721 W2: 1.8861468696691794 b -5.7524511423643725 Loss: 0.4103230956194656\n",
      "W1: 10.967430623055025 W2: 1.8861491985416927 b -5.752462002783664 Loss: 0.41032309445503734\n",
      "W1: 10.967452005308841 W2: 1.8861515252821437 b -5.7524728532445755 Loss: 0.41032309329274425\n",
      "W1: 10.967473367946736 W2: 1.8861538498924872 b -5.7524836937562664 Loss: 0.4103230921325826\n",
      "W1: 10.967494710986772 W2: 1.8861561723746763 b -5.752494524327888 Loss: 0.41032309097454844\n",
      "W1: 10.96751603444699 W2: 1.886158492730662 b -5.752505344968583 Loss: 0.4103230898186377\n",
      "W1: 10.96753733834542 W2: 1.8861608109623942 b -5.752516155687485 Loss: 0.4103230886648465\n",
      "W1: 10.967558622700068 W2: 1.8861631270718202 b -5.752526956493721 Loss: 0.41032308751317115\n",
      "W1: 10.96757988752893 W2: 1.8861654410608861 b -5.752537747396408 Loss: 0.4103230863636075\n",
      "W1: 10.967601132849982 W2: 1.886167752931536 b -5.752548528404654 Loss: 0.41032308521615185\n",
      "W1: 10.967622358681185 W2: 1.886170062685712 b -5.752559299527561 Loss: 0.41032308407080026\n",
      "W1: 10.96764356504048 W2: 1.8861723703253548 b -5.75257006077422 Loss: 0.41032308292754904\n",
      "W1: 10.967664751945797 W2: 1.8861746758524032 b -5.752580812153715 Loss: 0.410323081786394\n",
      "W1: 10.967685919415045 W2: 1.886176979268794 b -5.7525915536751215 Loss: 0.4103230806473314\n",
      "W1: 10.967707067466117 W2: 1.8861792805764623 b -5.752602285347506 Loss: 0.41032307951035757\n",
      "W1: 10.967728196116889 W2: 1.8861815797773418 b -5.752613007179928 Loss: 0.4103230783754687\n",
      "W1: 10.967749305385224 W2: 1.8861838768733639 b -5.752623719181436 Loss: 0.4103230772426606\n",
      "W1: 10.967770395288964 W2: 1.8861861718664585 b -5.752634421361073 Loss: 0.41032307611192975\n",
      "W1: 10.967791465845936 W2: 1.8861884647585536 b -5.752645113727872 Loss: 0.41032307498327236\n",
      "W1: 10.967812517073952 W2: 1.8861907555515758 b -5.752655796290858 Loss: 0.4103230738566843\n",
      "W1: 10.967833548990805 W2: 1.8861930442474493 b -5.752666469059047 Loss: 0.4103230727321621\n",
      "W1: 10.967854561614274 W2: 1.8861953308480968 b -5.752677132041449 Loss: 0.41032307160970183\n",
      "W1: 10.96787555496212 W2: 1.8861976153554396 b -5.752687785247063 Loss: 0.4103230704892998\n",
      "W1: 10.967896529052089 W2: 1.8861998977713967 b -5.75269842868488 Loss: 0.41032306937095187\n",
      "W1: 10.967917483901907 W2: 1.8862021780978857 b -5.752709062363884 Loss: 0.41032306825465487\n",
      "W1: 10.967938419529286 W2: 1.886204456336822 b -5.75271968629305 Loss: 0.41032306714040473\n",
      "W1: 10.967959335951925 W2: 1.88620673249012 b -5.752730300481344 Loss: 0.41032306602819735\n",
      "W1: 10.967980233187498 W2: 1.8862090065596913 b -5.752740904937726 Loss: 0.41032306491802956\n",
      "W1: 10.968001111253672 W2: 1.8862112785474465 b -5.752751499671144 Loss: 0.41032306380989747\n",
      "W1: 10.968021970168092 W2: 1.8862135484552944 b -5.752762084690542 Loss: 0.41032306270379704\n",
      "W1: 10.968042809948386 W2: 1.886215816285142 b -5.752772660004853 Loss: 0.4103230615997246\n",
      "W1: 10.96806363061217 W2: 1.886218082038894 b -5.752783225623001 Loss: 0.41032306049767675\n",
      "W1: 10.96808443217704 W2: 1.8862203457184543 b -5.752793781553905 Loss: 0.4103230593976497\n",
      "W1: 10.968105214660579 W2: 1.8862226073257244 b -5.752804327806472 Loss: 0.4103230582996393\n",
      "W1: 10.96812597808035 W2: 1.886224866862604 b -5.752814864389603 Loss: 0.4103230572036423\n",
      "W1: 10.9681467224539 W2: 1.8862271243309914 b -5.752825391312192 Loss: 0.4103230561096547\n",
      "W1: 10.968167447798765 W2: 1.886229379732783 b -5.752835908583121 Loss: 0.41032305501767324\n",
      "W1: 10.968188154132458 W2: 1.8862316330698734 b -5.752846416211267 Loss: 0.4103230539276938\n",
      "W1: 10.968208841472478 W2: 1.8862338843441557 b -5.7528569142054975 Loss: 0.4103230528397129\n",
      "W1: 10.968229509836311 W2: 1.8862361335575208 b -5.7528674025746716 Loss: 0.41032305175372685\n",
      "W1: 10.968250159241423 W2: 1.8862383807118583 b -5.752877881327641 Loss: 0.4103230506697319\n",
      "W1: 10.968270789705265 W2: 1.886240625809056 b -5.752888350473248 Loss: 0.41032304958772453\n",
      "W1: 10.968291401245272 W2: 1.8862428688509998 b -5.752898810020328 Loss: 0.4103230485077011\n",
      "W1: 10.968311993878864 W2: 1.8862451098395736 b -5.7529092599777085 Loss: 0.41032304742965775\n",
      "W1: 10.968332567623442 W2: 1.8862473487766602 b -5.752919700354207 Loss: 0.4103230463535911\n",
      "W1: 10.968353122496392 W2: 1.8862495856641404 b -5.752930131158634 Loss: 0.4103230452794973\n",
      "W1: 10.968373658515086 W2: 1.8862518205038932 b -5.752940552399792 Loss: 0.41032304420737287\n",
      "W1: 10.968394175696877 W2: 1.8862540532977958 b -5.752950964086476 Loss: 0.4103230431372143\n",
      "W1: 10.968414674059105 W2: 1.886256284047724 b -5.752961366227471 Loss: 0.4103230420690176\n",
      "W1: 10.96843515361909 W2: 1.8862585127555513 b -5.752971758831554 Loss: 0.4103230410027796\n",
      "W1: 10.96845561439414 W2: 1.8862607394231503 b -5.752982141907496 Loss: 0.4103230399384963\n",
      "W1: 10.968476056401542 W2: 1.8862629640523911 b -5.752992515464058 Loss: 0.4103230388761645\n",
      "W1: 10.968496479658572 W2: 1.8862651866451423 b -5.753002879509994 Loss: 0.4103230378157802\n",
      "W1: 10.968516884182488 W2: 1.886267407203271 b -5.75301323405405 Loss: 0.4103230367573403\n",
      "W1: 10.968537269990533 W2: 1.8862696257286427 b -5.753023579104962 Loss: 0.4103230357008409\n",
      "W1: 10.96855763709993 W2: 1.8862718422231206 b -5.75303391467146 Loss: 0.4103230346462785\n",
      "W1: 10.968577985527892 W2: 1.8862740566885667 b -5.753044240762265 Loss: 0.4103230335936496\n",
      "W1: 10.968598315291612 W2: 1.886276269126841 b -5.753054557386091 Loss: 0.4103230325429505\n",
      "W1: 10.968618626408267 W2: 1.8862784795398022 b -5.753064864551641 Loss: 0.41032303149417787\n",
      "W1: 10.96863891889502 W2: 1.8862806879293068 b -5.7530751622676135 Loss: 0.41032303044732804\n",
      "W1: 10.96865919276902 W2: 1.8862828942972099 b -5.753085450542697 Loss: 0.4103230294023976\n",
      "W1: 10.968679448047393 W2: 1.8862850986453645 b -5.7530957293855725 Loss: 0.4103230283593827\n",
      "W1: 10.968699684747255 W2: 1.8862873009756225 b -5.753105998804913 Loss: 0.41032302731828024\n",
      "W1: 10.968719902885706 W2: 1.8862895012898335 b -5.753116258809384 Loss: 0.4103230262790865\n",
      "W1: 10.968740102479828 W2: 1.886291699589846 b -5.753126509407641 Loss: 0.41032302524179803\n",
      "W1: 10.968760283546688 W2: 1.8862938958775064 b -5.753136750608334 Loss: 0.41032302420641126\n",
      "W1: 10.968780446103338 W2: 1.8862960901546595 b -5.753146982420103 Loss: 0.41032302317292263\n",
      "W1: 10.968800590166813 W2: 1.8862982824231482 b -5.753157204851581 Loss: 0.4103230221413288\n",
      "W1: 10.968820715754132 W2: 1.886300472684814 b -5.753167417911393 Loss: 0.4103230211116264\n",
      "W1: 10.9688408228823 W2: 1.8863026609414968 b -5.753177621608156 Loss: 0.4103230200838117\n",
      "W1: 10.968860911568303 W2: 1.8863048471950343 b -5.753187815950479 Loss: 0.4103230190578813\n",
      "W1: 10.968880981829116 W2: 1.886307031447263 b -5.753198000946963 Loss: 0.410323018033832\n",
      "W1: 10.968901033681695 W2: 1.8863092137000175 b -5.753208176606201 Loss: 0.4103230170116598\n",
      "W1: 10.968921067142979 W2: 1.8863113939551306 b -5.753218342936777 Loss: 0.41032301599136184\n",
      "W1: 10.968941082229895 W2: 1.8863135722144337 b -5.753228499947269 Loss: 0.41032301497293433\n",
      "W1: 10.968961078959353 W2: 1.8863157484797566 b -5.753238647646247 Loss: 0.4103230139563739\n",
      "W1: 10.968981057348246 W2: 1.8863179227529268 b -5.753248786042271 Loss: 0.4103230129416771\n",
      "W1: 10.969001017413452 W2: 1.8863200950357708 b -5.7532589151438955 Loss: 0.41032301192884063\n",
      "W1: 10.969020959171836 W2: 1.886322265330113 b -5.753269034959665 Loss: 0.41032301091786105\n",
      "W1: 10.969040882640241 W2: 1.8863244336377762 b -5.753279145498118 Loss: 0.4103230099087348\n",
      "W1: 10.969060787835502 W2: 1.8863265999605818 b -5.753289246767782 Loss: 0.4103230089014586\n",
      "W1: 10.969080674774434 W2: 1.8863287643003492 b -5.753299338777181 Loss: 0.41032300789602894\n",
      "W1: 10.969100543473836 W2: 1.8863309266588961 b -5.753309421534827 Loss: 0.41032300689244267\n",
      "W1: 10.969120393950492 W2: 1.8863330870380388 b -5.753319495049229 Loss: 0.41032300589069615\n",
      "W1: 10.969140226221173 W2: 1.8863352454395919 b -5.753329559328882 Loss: 0.4103230048907862\n",
      "W1: 10.969160040302631 W2: 1.886337401865368 b -5.753339614382278 Loss: 0.41032300389270926\n",
      "W1: 10.969179836211605 W2: 1.8863395563171785 b -5.753349660217899 Loss: 0.4103230028964621\n",
      "W1: 10.969199613964818 W2: 1.8863417087968328 b -5.753359696844219 Loss: 0.41032300190204124\n",
      "W1: 10.969219373578976 W2: 1.8863438593061388 b -5.753369724269706 Loss: 0.41032300090944357\n",
      "W1: 10.969239115070772 W2: 1.8863460078469025 b -5.753379742502817 Loss: 0.4103229999186654\n",
      "W1: 10.969258838456883 W2: 1.8863481544209284 b -5.753389751552005 Loss: 0.4103229989297036\n",
      "W1: 10.969278543753965 W2: 1.8863502990300194 b -5.753399751425713 Loss: 0.4103229979425549\n",
      "W1: 10.969298230978668 W2: 1.8863524416759767 b -5.7534097421323755 Loss: 0.4103229969572157\n",
      "W1: 10.969317900147619 W2: 1.8863545823606 b -5.753419723680421 Loss: 0.4103229959736831\n",
      "W1: 10.969337551277434 W2: 1.886356721085687 b -5.753429696078269 Loss: 0.41032299499195335\n",
      "W1: 10.96935718438471 W2: 1.8863588578530341 b -5.753439659334332 Loss: 0.41032299401202327\n",
      "W1: 10.969376799486033 W2: 1.8863609926644358 b -5.753449613457014 Loss: 0.41032299303388964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.969396396597972 W2: 1.886363125521685 b -5.753459558454711 Loss: 0.4103229920575491\n",
      "W1: 10.969415975737077 W2: 1.8863652564265732 b -5.753469494335813 Loss: 0.41032299108299847\n",
      "W1: 10.969435536919887 W2: 1.8863673853808898 b -5.7534794211087 Loss: 0.4103229901102343\n",
      "W1: 10.969455080162925 W2: 1.8863695123864228 b -5.753489338781747 Loss: 0.4103229891392534\n",
      "W1: 10.969474605482697 W2: 1.8863716374449586 b -5.753499247363317 Loss: 0.41032298817005264\n",
      "W1: 10.969494112895696 W2: 1.8863737605582818 b -5.75350914686177 Loss: 0.41032298720262833\n",
      "W1: 10.969513602418395 W2: 1.8863758817281755 b -5.7535190372854546 Loss: 0.4103229862369776\n",
      "W1: 10.96953307406726 W2: 1.8863780009564213 b -5.753528918642714 Loss: 0.41032298527309713\n",
      "W1: 10.969552527858733 W2: 1.8863801182447988 b -5.7535387909418825 Loss: 0.4103229843109835\n",
      "W1: 10.969571963809246 W2: 1.8863822335950864 b -5.753548654191287 Loss: 0.4103229833506337\n",
      "W1: 10.969591381935215 W2: 1.8863843470090604 b -5.753558508399247 Loss: 0.4103229823920442\n",
      "W1: 10.96961078225304 W2: 1.886386458488496 b -5.7535683535740745 Loss: 0.41032298143521206\n",
      "W1: 10.969630164779108 W2: 1.886388568035166 b -5.753578189724072 Loss: 0.4103229804801337\n",
      "W1: 10.969649529529786 W2: 1.8863906756508422 b -5.753588016857537 Loss: 0.41032297952680635\n",
      "W1: 10.96966887652143 W2: 1.8863927813372947 b -5.753597834982758 Loss: 0.4103229785752266\n",
      "W1: 10.96968820577038 W2: 1.886394885096292 b -5.753607644108015 Loss: 0.41032297762539116\n",
      "W1: 10.96970751729296 W2: 1.8863969869296005 b -5.7536174442415815 Loss: 0.4103229766772968\n",
      "W1: 10.96972681110548 W2: 1.8863990868389855 b -5.753627235391724 Loss: 0.4103229757309404\n",
      "W1: 10.969746087224232 W2: 1.8864011848262106 b -5.753637017566699 Loss: 0.41032297478631885\n",
      "W1: 10.969765345665497 W2: 1.8864032808930373 b -5.7536467907747575 Loss: 0.4103229738434288\n",
      "W1: 10.96978458644554 W2: 1.8864053750412262 b -5.753656555024142 Loss: 0.4103229729022674\n",
      "W1: 10.969803809580608 W2: 1.886407467272536 b -5.753666310323087 Loss: 0.4103229719628308\n",
      "W1: 10.969823015086936 W2: 1.8864095575887234 b -5.753676056679821 Loss: 0.41032297102511656\n",
      "W1: 10.969842202980743 W2: 1.886411645991544 b -5.753685794102564 Loss: 0.4103229700891211\n",
      "W1: 10.969861373278233 W2: 1.8864137324827517 b -5.753695522599528 Loss: 0.41032296915484157\n",
      "W1: 10.969880525995595 W2: 1.8864158170640986 b -5.753705242178916 Loss: 0.41032296822227443\n",
      "W1: 10.969899661149004 W2: 1.886417899737335 b -5.753714952848927 Loss: 0.41032296729141693\n",
      "W1: 10.969918778754616 W2: 1.8864199805042103 b -5.75372465461775 Loss: 0.41032296636226556\n",
      "W1: 10.969937878828578 W2: 1.8864220593664718 b -5.753734347493567 Loss: 0.4103229654348175\n",
      "W1: 10.969956961387018 W2: 1.886424136325865 b -5.753744031484552 Loss: 0.41032296450906947\n",
      "W1: 10.96997602644605 W2: 1.8864262113841341 b -5.7537537065988715 Loss: 0.41032296358501835\n",
      "W1: 10.969995074021773 W2: 1.8864282845430218 b -5.753763372844685 Loss: 0.41032296266266105\n",
      "W1: 10.970014104130271 W2: 1.886430355804269 b -5.753773030230145 Loss: 0.4103229617419944\n",
      "W1: 10.970033116787615 W2: 1.886432425169615 b -5.753782678763395 Loss: 0.41032296082301545\n",
      "W1: 10.970052112009858 W2: 1.8864344926407974 b -5.753792318452572 Loss: 0.410322959905721\n",
      "W1: 10.97007108981304 W2: 1.8864365582195528 b -5.753801949305804 Loss: 0.41032295899010784\n",
      "W1: 10.970090050213186 W2: 1.8864386219076155 b -5.753811571331213 Loss: 0.41032295807617314\n",
      "W1: 10.970108993226306 W2: 1.8864406837067182 b -5.753821184536915 Loss: 0.4103229571639137\n",
      "W1: 10.970127918868396 W2: 1.8864427436185927 b -5.7538307889310145 Loss: 0.4103229562533263\n",
      "W1: 10.970146827155435 W2: 1.8864448016449684 b -5.753840384521611 Loss: 0.4103229553444082\n",
      "W1: 10.97016571810339 W2: 1.8864468577875737 b -5.7538499713167965 Loss: 0.410322954437156\n",
      "W1: 10.97018459172821 W2: 1.8864489120481351 b -5.753859549324655 Loss: 0.41032295353156684\n",
      "W1: 10.970203448045831 W2: 1.8864509644283778 b -5.753869118553263 Loss: 0.41032295262763757\n",
      "W1: 10.970222287072177 W2: 1.886453014930025 b -5.753878679010691 Loss: 0.4103229517253651\n",
      "W1: 10.970241108823153 W2: 1.8864550635547985 b -5.753888230704998 Loss: 0.4103229508247466\n",
      "W1: 10.97025991331465 W2: 1.8864571103044188 b -5.7538977736442405 Loss: 0.41032294992577883\n",
      "W1: 10.970278700562545 W2: 1.8864591551806045 b -5.753907307836465 Loss: 0.410322949028459\n",
      "W1: 10.970297470582702 W2: 1.8864611981850725 b -5.75391683328971 Loss: 0.41032294813278364\n",
      "W1: 10.970316223390967 W2: 1.8864632393195386 b -5.7539263500120095 Loss: 0.4103229472387502\n",
      "W1: 10.970334959003173 W2: 1.8864652785857166 b -5.753935858011387 Loss: 0.4103229463463553\n",
      "W1: 10.97035367743514 W2: 1.886467315985319 b -5.7539453572958585 Loss: 0.4103229454555963\n",
      "W1: 10.970372378702672 W2: 1.8864693515200563 b -5.753954847873436 Loss: 0.41032294456646984\n",
      "W1: 10.970391062821557 W2: 1.8864713851916382 b -5.75396432975212 Loss: 0.4103229436789732\n",
      "W1: 10.97040972980757 W2: 1.8864734170017718 b -5.753973802939906 Loss: 0.41032294279310305\n",
      "W1: 10.970428379676468 W2: 1.8864754469521636 b -5.753983267444782 Loss: 0.41032294190885693\n",
      "W1: 10.970447012444 W2: 1.886477475044518 b -5.753992723274727 Loss: 0.4103229410262315\n",
      "W1: 10.970465628125895 W2: 1.8864795012805378 b -5.754002170437715 Loss: 0.41032294014522375\n",
      "W1: 10.97048422673787 W2: 1.8864815256619245 b -5.7540116089417115 Loss: 0.4103229392658307\n",
      "W1: 10.970502808295628 W2: 1.886483548190378 b -5.754021038794674 Loss: 0.41032293838804973\n",
      "W1: 10.970521372814853 W2: 1.8864855688675963 b -5.754030460004553 Loss: 0.4103229375118774\n",
      "W1: 10.97053992031122 W2: 1.8864875876952765 b -5.754039872579292 Loss: 0.410322936637311\n",
      "W1: 10.970558450800386 W2: 1.8864896046751134 b -5.754049276526827 Loss: 0.4103229357643477\n",
      "W1: 10.970576964297994 W2: 1.8864916198088006 b -5.754058671855089 Loss: 0.41032293489298455\n",
      "W1: 10.970595460819673 W2: 1.8864936330980302 b -5.754068058571995 Loss: 0.41032293402321823\n",
      "W1: 10.97061394038104 W2: 1.8864956445444927 b -5.7540774366854635 Loss: 0.41032293315504625\n",
      "W1: 10.970632402997694 W2: 1.886497654149877 b -5.754086806203398 Loss: 0.41032293228846545\n",
      "W1: 10.97065084868522 W2: 1.8864996619158705 b -5.7540961671337 Loss: 0.410322931423473\n",
      "W1: 10.97066927745919 W2: 1.8865016678441588 b -5.754105519484261 Loss: 0.41032293056006586\n",
      "W1: 10.970687689335161 W2: 1.8865036719364265 b -5.7541148632629655 Loss: 0.4103229296982413\n",
      "W1: 10.970706084328675 W2: 1.8865056741943562 b -5.754124198477691 Loss: 0.4103229288379964\n",
      "W1: 10.97072446245526 W2: 1.886507674619629 b -5.754133525136309 Loss: 0.41032292797932796\n",
      "W1: 10.970742823730431 W2: 1.8865096732139244 b -5.754142843246681 Loss: 0.41032292712223345\n",
      "W1: 10.970761168169686 W2: 1.8865116699789206 b -5.754152152816664 Loss: 0.41032292626670996\n",
      "W1: 10.97077949578851 W2: 1.8865136649162944 b -5.754161453854105 Loss: 0.4103229254127543\n",
      "W1: 10.970797806602373 W2: 1.8865156580277205 b -5.754170746366847 Loss: 0.4103229245603639\n",
      "W1: 10.970816100626735 W2: 1.8865176493148723 b -5.754180030362723 Loss: 0.41032292370953577\n",
      "W1: 10.970834377877035 W2: 1.8865196387794219 b -5.75418930584956 Loss: 0.410322922860267\n",
      "W1: 10.9708526383687 W2: 1.8865216264230396 b -5.754198572835177 Loss: 0.4103229220125547\n",
      "W1: 10.970870882117147 W2: 1.8865236122473943 b -5.7542078313273874 Loss: 0.4103229211663963\n",
      "W1: 10.970889109137772 W2: 1.8865255962541534 b -5.754217081333996 Loss: 0.4103229203217884\n",
      "W1: 10.970907319445963 W2: 1.8865275784449826 b -5.754226322862801 Loss: 0.41032291947872873\n",
      "W1: 10.97092551305709 W2: 1.8865295588215463 b -5.754235555921591 Loss: 0.4103229186372141\n",
      "W1: 10.970943689986507 W2: 1.886531537385507 b -5.754244780518151 Loss: 0.4103229177972418\n",
      "W1: 10.970961850249559 W2: 1.886533514138526 b -5.754253996660259 Loss: 0.410322916958809\n",
      "W1: 10.970979993861572 W2: 1.886535489082263 b -5.754263204355681 Loss: 0.41032291612191296\n",
      "W1: 10.970998120837862 W2: 1.8865374622183761 b -5.75427240361218 Loss: 0.4103229152865506\n",
      "W1: 10.97101623119373 W2: 1.886539433548522 b -5.754281594437512 Loss: 0.41032291445271923\n",
      "W1: 10.971034324944458 W2: 1.8865414030743555 b -5.754290776839424 Loss: 0.4103229136204163\n",
      "W1: 10.97105240210532 W2: 1.8865433707975305 b -5.754299950825656 Loss: 0.41032291278963856\n",
      "W1: 10.971070462691573 W2: 1.8865453367196992 b -5.754309116403941 Loss: 0.41032291196038345\n",
      "W1: 10.97108850671846 W2: 1.8865473008425118 b -5.7543182735820055 Loss: 0.41032291113264796\n",
      "W1: 10.971106534201208 W2: 1.8865492631676173 b -5.754327422367569 Loss: 0.41032291030642987\n",
      "W1: 10.971124545155037 W2: 1.8865512236966635 b -5.754336562768343 Loss: 0.41032290948172573\n",
      "W1: 10.971142539595144 W2: 1.8865531824312962 b -5.754345694792033 Loss: 0.41032290865853316\n",
      "W1: 10.971160517536717 W2: 1.88655513937316 b -5.754354818446335 Loss: 0.4103229078368491\n",
      "W1: 10.97117847899493 W2: 1.8865570945238979 b -5.754363933738941 Loss: 0.4103229070166712\n",
      "W1: 10.971196423984939 W2: 1.8865590478851513 b -5.7543730406775335 Loss: 0.41032290619799644\n",
      "W1: 10.971214352521892 W2: 1.8865609994585602 b -5.754382139269789 Loss: 0.4103229053808219\n",
      "W1: 10.97123226462092 W2: 1.8865629492457627 b -5.754391229523378 Loss: 0.410322904565145\n",
      "W1: 10.971250160297137 W2: 1.8865648972483962 b -5.754400311445961 Loss: 0.41032290375096303\n",
      "W1: 10.971268039565647 W2: 1.886566843468096 b -5.754409385045194 Loss: 0.4103229029382733\n",
      "W1: 10.971285902441538 W2: 1.886568787906496 b -5.754418450328725 Loss: 0.41032290212707284\n",
      "W1: 10.971303748939887 W2: 1.8865707305652288 b -5.754427507304194 Loss: 0.41032290131735893\n",
      "W1: 10.971321579075754 W2: 1.8865726714459252 b -5.754436555979236 Loss: 0.4103229005091292\n",
      "W1: 10.971339392864186 W2: 1.8865746105502146 b -5.754445596361478 Loss: 0.41032289970238056\n",
      "W1: 10.971357190320216 W2: 1.886576547879725 b -5.7544546284585385 Loss: 0.41032289889711054\n",
      "W1: 10.971374971458863 W2: 1.8865784834360826 b -5.754463652278032 Loss: 0.4103228980933162\n",
      "W1: 10.971392736295131 W2: 1.8865804172209126 b -5.754472667827563 Loss: 0.41032289729099497\n",
      "W1: 10.971410484844014 W2: 1.8865823492358387 b -5.75448167511473 Loss: 0.41032289649014414\n",
      "W1: 10.971428217120488 W2: 1.8865842794824825 b -5.754490674147125 Loss: 0.41032289569076075\n",
      "W1: 10.971445933139517 W2: 1.8865862079624647 b -5.754499664932333 Loss: 0.41032289489284257\n",
      "W1: 10.97146363291605 W2: 1.886588134677404 b -5.754508647477932 Loss: 0.4103228940963868\n",
      "W1: 10.971481316465026 W2: 1.8865900596289182 b -5.754517621791492 Loss: 0.41032289330139027\n",
      "W1: 10.971498983801364 W2: 1.8865919828186233 b -5.7545265878805765 Loss: 0.4103228925078509\n",
      "W1: 10.971516634939974 W2: 1.8865939042481337 b -5.754535545752743 Loss: 0.4103228917157658\n",
      "W1: 10.97153426989575 W2: 1.8865958239190623 b -5.754544495415541 Loss: 0.4103228909251323\n",
      "W1: 10.971551888683573 W2: 1.8865977418330209 b -5.754553436876512 Loss: 0.4103228901359476\n",
      "W1: 10.97156949131831 W2: 1.8865996579916195 b -5.754562370143194 Loss: 0.41032288934820915\n",
      "W1: 10.971587077814814 W2: 1.8866015723964669 b -5.754571295223115 Loss: 0.4103228885619145\n",
      "W1: 10.971604648187924 W2: 1.88660348504917 b -5.754580212123796 Loss: 0.4103228877770608\n",
      "W1: 10.971622202452467 W2: 1.8866053959513345 b -5.754589120852752 Loss: 0.4103228869936453\n",
      "W1: 10.971639740623257 W2: 1.8866073051045646 b -5.754598021417491 Loss: 0.41032288621166535\n",
      "W1: 10.97165726271509 W2: 1.8866092125104632 b -5.754606913825516 Loss: 0.41032288543111856\n",
      "W1: 10.97167476874275 W2: 1.8866111181706313 b -5.754615798084318 Loss: 0.41032288465200234\n",
      "W1: 10.971692258721008 W2: 1.8866130220866686 b -5.754624674201386 Loss: 0.41032288387431365\n",
      "W1: 10.971709732664623 W2: 1.8866149242601735 b -5.754633542184201 Loss: 0.4103228830980503\n",
      "W1: 10.97172719058834 W2: 1.8866168246927428 b -5.7546424020402345 Loss: 0.4103228823232095\n",
      "W1: 10.971744632506885 W2: 1.886618723385972 b -5.754651253776954 Loss: 0.4103228815497885\n",
      "W1: 10.971762058434978 W2: 1.8866206203414546 b -5.754660097401819 Loss: 0.41032288077778495\n",
      "W1: 10.971779468387322 W2: 1.8866225155607834 b -5.754668932922283 Loss: 0.410322880007196\n",
      "W1: 10.971796862378604 W2: 1.8866244090455493 b -5.754677760345791 Loss: 0.4103228792380193\n",
      "W1: 10.9718142404235 W2: 1.8866263007973416 b -5.754686579679782 Loss: 0.410322878470252\n",
      "W1: 10.971831602536675 W2: 1.8866281908177487 b -5.754695390931688 Loss: 0.4103228777038918\n",
      "W1: 10.971848948732774 W2: 1.8866300791083568 b -5.754704194108934 Loss: 0.41032287693893593\n",
      "W1: 10.971866279026434 W2: 1.8866319656707513 b -5.754712989218938 Loss: 0.41032287617538193\n",
      "W1: 10.971883593432276 W2: 1.8866338505065157 b -5.754721776269113 Loss: 0.41032287541322715\n",
      "W1: 10.971900891964909 W2: 1.8866357336172321 b -5.754730555266863 Loss: 0.4103228746524689\n",
      "W1: 10.971918174638926 W2: 1.8866376150044817 b -5.754739326219585 Loss: 0.4103228738931049\n",
      "W1: 10.971935441468908 W2: 1.8866394946698435 b -5.754748089134671 Loss: 0.41032287313513227\n",
      "W1: 10.971952692469422 W2: 1.8866413726148954 b -5.754756844019505 Loss: 0.4103228723785488\n",
      "W1: 10.971969927655024 W2: 1.886643248841214 b -5.7547655908814646 Loss: 0.4103228716233515\n",
      "W1: 10.971987147040254 W2: 1.8866451233503738 b -5.754774329727919 Loss: 0.4103228708695385\n",
      "W1: 10.972004350639638 W2: 1.8866469961439487 b -5.754783060566233 Loss: 0.4103228701171066\n",
      "W1: 10.972021538467692 W2: 1.8866488672235107 b -5.754791783403763 Loss: 0.4103228693660536\n",
      "W1: 10.972038710538913 W2: 1.8866507365906302 b -5.75480049824786 Loss: 0.4103228686163767\n",
      "W1: 10.97205586686779 W2: 1.8866526042468768 b -5.754809205105867 Loss: 0.4103228678680738\n",
      "W1: 10.972073007468795 W2: 1.886654470193818 b -5.754817903985121 Loss: 0.41032286712114185\n",
      "W1: 10.972090132356389 W2: 1.8866563344330198 b -5.75482659489295 Loss: 0.4103228663755788\n",
      "W1: 10.972107241545018 W2: 1.8866581969660476 b -5.754835277836678 Loss: 0.41032286563138193\n",
      "W1: 10.972124335049116 W2: 1.8866600577944646 b -5.754843952823622 Loss: 0.410322864888549\n",
      "W1: 10.972141412883104 W2: 1.8866619169198326 b -5.754852619861091 Loss: 0.41032286414707697\n",
      "W1: 10.972158475061388 W2: 1.8866637743437125 b -5.754861278956388 Loss: 0.4103228634069636\n",
      "W1: 10.97217552159836 W2: 1.8866656300676632 b -5.754869930116809 Loss: 0.4103228626682067\n",
      "W1: 10.9721925525084 W2: 1.8866674840932425 b -5.754878573349643 Loss: 0.41032286193080336\n",
      "W1: 10.972209567805876 W2: 1.8866693364220066 b -5.754887208662173 Loss: 0.4103228611947513\n",
      "W1: 10.972226567505142 W2: 1.8866711870555104 b -5.754895836061674 Loss: 0.4103228604600481\n",
      "W1: 10.972243551620538 W2: 1.886673035995307 b -5.754904455555416 Loss: 0.41032285972669097\n",
      "W1: 10.97226052016639 W2: 1.8866748832429485 b -5.754913067150662 Loss: 0.41032285899467785\n",
      "W1: 10.972277473157012 W2: 1.8866767287999857 b -5.754921670854666 Loss: 0.410322858264006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.972294410606704 W2: 1.8866785726679676 b -5.754930266674679 Loss: 0.410322857534673\n",
      "W1: 10.972311332529753 W2: 1.8866804148484417 b -5.754938854617941 Loss: 0.41032285680667646\n",
      "W1: 10.972328238940433 W2: 1.8866822553429545 b -5.754947434691689 Loss: 0.41032285608001384\n",
      "W1: 10.972345129853005 W2: 1.886684094153051 b -5.754956006903153 Loss: 0.41032285535468277\n",
      "W1: 10.972362005281719 W2: 1.8866859312802742 b -5.754964571259553 Loss: 0.41032285463068074\n",
      "W1: 10.972378865240806 W2: 1.8866877667261663 b -5.754973127768105 Loss: 0.4103228539080055\n",
      "W1: 10.97239570974449 W2: 1.8866896004922682 b -5.75498167643602 Loss: 0.41032285318665446\n",
      "W1: 10.972412538806976 W2: 1.8866914325801187 b -5.754990217270499 Loss: 0.4103228524666252\n",
      "W1: 10.972429352442463 W2: 1.8866932629912558 b -5.7549987502787365 Loss: 0.4103228517479153\n",
      "W1: 10.97244615066513 W2: 1.8866950917272158 b -5.755007275467923 Loss: 0.4103228510305222\n",
      "W1: 10.972462933489146 W2: 1.8866969187895337 b -5.75501579284524 Loss: 0.4103228503144438\n",
      "W1: 10.972479700928668 W2: 1.886698744179743 b -5.755024302417865 Loss: 0.41032284959967724\n",
      "W1: 10.972496452997836 W2: 1.8867005678993756 b -5.755032804192965 Loss: 0.41032284888622067\n",
      "W1: 10.972513189710783 W2: 1.8867023899499624 b -5.755041298177703 Loss: 0.4103228481740712\n",
      "W1: 10.972529911081624 W2: 1.886704210333033 b -5.755049784379236 Loss: 0.4103228474632268\n",
      "W1: 10.972546617124461 W2: 1.8867060290501148 b -5.755058262804712 Loss: 0.41032284675368474\n",
      "W1: 10.972563307853386 W2: 1.8867078461027347 b -5.755066733461275 Loss: 0.410322846045443\n",
      "W1: 10.972579983282476 W2: 1.8867096614924177 b -5.75507519635606 Loss: 0.41032284533849883\n",
      "W1: 10.972596643425794 W2: 1.8867114752206875 b -5.755083651496197 Loss: 0.41032284463284996\n",
      "W1: 10.972613288297394 W2: 1.8867132872890664 b -5.7550920988888095 Loss: 0.4103228439284942\n",
      "W1: 10.972629917911313 W2: 1.8867150976990754 b -5.755100538541012 Loss: 0.4103228432254289\n",
      "W1: 10.972646532281576 W2: 1.886716906452234 b -5.755108970459917 Loss: 0.4103228425236521\n",
      "W1: 10.972663131422197 W2: 1.8867187135500603 b -5.755117394652625 Loss: 0.41032284182316076\n",
      "W1: 10.972679715347171 W2: 1.886720518994071 b -5.755125811126233 Loss: 0.41032284112395323\n",
      "W1: 10.972696284070489 W2: 1.8867223227857814 b -5.755134219887833 Loss: 0.4103228404260268\n",
      "W1: 10.972712837606123 W2: 1.8867241249267055 b -5.755142620944508 Loss: 0.4103228397293792\n",
      "W1: 10.972729375968035 W2: 1.8867259254183557 b -5.755151014303334 Loss: 0.41032283903400796\n",
      "W1: 10.972745899170171 W2: 1.8867277242622433 b -5.755159399971382 Loss: 0.4103228383399109\n",
      "W1: 10.972762407226465 W2: 1.8867295214598783 b -5.755167777955717 Loss: 0.4103228376470856\n",
      "W1: 10.972778900150843 W2: 1.8867313170127686 b -5.755176148263395 Loss: 0.4103228369555298\n",
      "W1: 10.97279537795721 W2: 1.8867331109224217 b -5.755184510901468 Loss: 0.41032283626524096\n",
      "W1: 10.972811840659464 W2: 1.8867349031903429 b -5.755192865876979 Loss: 0.410322835576217\n",
      "W1: 10.972828288271488 W2: 1.8867366938180363 b -5.755201213196967 Loss: 0.4103228348884555\n",
      "W1: 10.972844720807153 W2: 1.886738482807005 b -5.755209552868464 Loss: 0.41032283420195415\n",
      "W1: 10.972861138280317 W2: 1.8867402701587506 b -5.755217884898494 Loss: 0.4103228335167106\n",
      "W1: 10.972877540704824 W2: 1.886742055874773 b -5.755226209294076 Loss: 0.41032283283272264\n",
      "W1: 10.972893928094507 W2: 1.8867438399565708 b -5.755234526062221 Loss: 0.41032283214998794\n",
      "W1: 10.972910300463186 W2: 1.8867456224056416 b -5.755242835209936 Loss: 0.41032283146850435\n",
      "W1: 10.972926657824665 W2: 1.8867474032234812 b -5.755251136744219 Loss: 0.4103228307882691\n",
      "W1: 10.97294300019274 W2: 1.8867491824115843 b -5.755259430672063 Loss: 0.4103228301092802\n",
      "W1: 10.972959327581194 W2: 1.886750959971444 b -5.7552677170004545 Loss: 0.41032282943153553\n",
      "W1: 10.97297564000379 W2: 1.8867527359045522 b -5.755275995736373 Loss: 0.4103228287550325\n",
      "W1: 10.972991937474289 W2: 1.8867545102123993 b -5.755284266886791 Loss: 0.41032282807976905\n",
      "W1: 10.97300822000643 W2: 1.8867562828964746 b -5.755292530458677 Loss: 0.41032282740574283\n",
      "W1: 10.973024487613944 W2: 1.8867580539582658 b -5.75530078645899 Loss: 0.41032282673295145\n",
      "W1: 10.973040740310552 W2: 1.886759823399259 b -5.755309034894683 Loss: 0.41032282606139286\n",
      "W1: 10.973056978109954 W2: 1.8867615912209397 b -5.755317275772706 Loss: 0.4103228253910647\n",
      "W1: 10.973073201025844 W2: 1.886763357424791 b -5.755325509099999 Loss: 0.4103228247219646\n",
      "W1: 10.973089409071903 W2: 1.8867651220122956 b -5.7553337348834965 Loss: 0.41032282405409054\n",
      "W1: 10.973105602261796 W2: 1.8867668849849342 b -5.755341953130127 Loss: 0.4103228233874401\n",
      "W1: 10.97312178060918 W2: 1.8867686463441864 b -5.7553501638468125 Loss: 0.41032282272201104\n",
      "W1: 10.973137944127693 W2: 1.8867704060915305 b -5.755358367040468 Loss: 0.41032282205780124\n",
      "W1: 10.973154092830967 W2: 1.8867721642284432 b -5.755366562718004 Loss: 0.4103228213948084\n",
      "W1: 10.973170226732616 W2: 1.8867739207564 b -5.755374750886323 Loss: 0.41032282073303017\n",
      "W1: 10.973186345846246 W2: 1.8867756756768754 b -5.755382931552321 Loss: 0.4103228200724645\n",
      "W1: 10.973202450185447 W2: 1.8867774289913417 b -5.755391104722888 Loss: 0.410322819413109\n",
      "W1: 10.9732185397638 W2: 1.8867791807012706 b -5.755399270404907 Loss: 0.41032281875496146\n",
      "W1: 10.973234614594867 W2: 1.886780930808132 b -5.755407428605257 Loss: 0.41032281809802007\n",
      "W1: 10.973250674692204 W2: 1.8867826793133948 b -5.755415579330808 Loss: 0.41032281744228205\n",
      "W1: 10.973266720069354 W2: 1.8867844262185263 b -5.755423722588425 Loss: 0.4103228167877454\n",
      "W1: 10.973282750739843 W2: 1.8867861715249925 b -5.755431858384966 Loss: 0.4103228161344081\n",
      "W1: 10.973298766717187 W2: 1.8867879152342582 b -5.755439986727284 Loss: 0.41032281548226757\n",
      "W1: 10.973314768014891 W2: 1.8867896573477865 b -5.7554481076222235 Loss: 0.4103228148313221\n",
      "W1: 10.973330754646446 W2: 1.8867913978670396 b -5.755456221076624 Loss: 0.4103228141815692\n",
      "W1: 10.97334672662533 W2: 1.8867931367934783 b -5.75546432709732 Loss: 0.41032281353300654\n",
      "W1: 10.973362683965009 W2: 1.8867948741285616 b -5.755472425691137 Loss: 0.41032281288563227\n",
      "W1: 10.973378626678938 W2: 1.8867966098737476 b -5.755480516864895 Loss: 0.41032281223944406\n",
      "W1: 10.973394554780558 W2: 1.886798344030493 b -5.75548860062541 Loss: 0.4103228115944397\n",
      "W1: 10.973410468283298 W2: 1.8868000766002528 b -5.7554966769794875 Loss: 0.4103228109506171\n",
      "W1: 10.973426367200574 W2: 1.8868018075844815 b -5.755504745933931 Loss: 0.41032281030797396\n",
      "W1: 10.97344225154579 W2: 1.8868035369846312 b -5.755512807495535 Loss: 0.41032280966650814\n",
      "W1: 10.973458121332339 W2: 1.8868052648021534 b -5.755520861671089 Loss: 0.41032280902621765\n",
      "W1: 10.9734739765736 W2: 1.8868069910384981 b -5.755528908467375 Loss: 0.41032280838710017\n",
      "W1: 10.973489817282937 W2: 1.8868087156951139 b -5.75553694789117 Loss: 0.4103228077491537\n",
      "W1: 10.97350564347371 W2: 1.8868104387734481 b -5.755544979949245 Loss: 0.4103228071123759\n",
      "W1: 10.973521455159256 W2: 1.8868121602749466 b -5.755553004648363 Loss: 0.4103228064767647\n",
      "W1: 10.973537252352909 W2: 1.8868138802010541 b -5.755561021995283 Loss: 0.41032280584231806\n",
      "W1: 10.973553035067985 W2: 1.886815598553214 b -5.755569031996756 Loss: 0.41032280520903375\n",
      "W1: 10.97356880331779 W2: 1.8868173153328682 b -5.7555770346595265 Loss: 0.41032280457690967\n",
      "W1: 10.973584557115617 W2: 1.8868190305414574 b -5.755585029990335 Loss: 0.4103228039459435\n",
      "W1: 10.973600296474745 W2: 1.8868207441804208 b -5.7555930179959125 Loss: 0.41032280331613363\n",
      "W1: 10.973616021408445 W2: 1.8868224562511966 b -5.755600998682987 Loss: 0.41032280268747723\n",
      "W1: 10.973631731929972 W2: 1.8868241667552215 b -5.75560897205828 Loss: 0.41032280205997274\n",
      "W1: 10.97364742805257 W2: 1.8868258756939307 b -5.755616938128504 Loss: 0.41032280143361793\n",
      "W1: 10.973663109789474 W2: 1.8868275830687582 b -5.755624896900367 Loss: 0.4103228008084105\n",
      "W1: 10.973678777153898 W2: 1.886829288881137 b -5.755632848380573 Loss: 0.41032280018434847\n",
      "W1: 10.973694430159053 W2: 1.8868309931324987 b -5.755640792575816 Loss: 0.4103227995614296\n",
      "W1: 10.973710068818134 W2: 1.886832695824273 b -5.755648729492786 Loss: 0.41032279893965223\n",
      "W1: 10.973725693144322 W2: 1.8868343969578887 b -5.755656659138166 Loss: 0.41032279831901364\n",
      "W1: 10.97374130315079 W2: 1.8868360965347735 b -5.7556645815186345 Loss: 0.41032279769951246\n",
      "W1: 10.973756898850695 W2: 1.8868377945563535 b -5.755672496640861 Loss: 0.4103227970811459\n",
      "W1: 10.973772480257185 W2: 1.8868394910240538 b -5.75568040451151 Loss: 0.41032279646391223\n",
      "W1: 10.973788047383394 W2: 1.8868411859392977 b -5.755688305137243 Loss: 0.4103227958478094\n",
      "W1: 10.973803600242443 W2: 1.8868428793035075 b -5.75569619852471 Loss: 0.4103227952328352\n",
      "W1: 10.973819138847443 W2: 1.886844571118104 b -5.755704084680558 Loss: 0.4103227946189877\n",
      "W1: 10.973834663211491 W2: 1.8868462613845074 b -5.755711963611429 Loss: 0.4103227940062647\n",
      "W1: 10.973850173347675 W2: 1.8868479501041355 b -5.755719835323955 Loss: 0.4103227933946641\n",
      "W1: 10.973865669269067 W2: 1.8868496372784056 b -5.755727699824765 Loss: 0.41032279278418415\n",
      "W1: 10.97388115098873 W2: 1.8868513229087331 b -5.755735557120481 Loss: 0.4103227921748224\n",
      "W1: 10.973896618519712 W2: 1.8868530069965328 b -5.755743407217719 Loss: 0.4103227915665771\n",
      "W1: 10.973912071875052 W2: 1.8868546895432177 b -5.7557512501230885 Loss: 0.4103227909594459\n",
      "W1: 10.973927511067776 W2: 1.8868563705501997 b -5.755759085843193 Loss: 0.4103227903534272\n",
      "W1: 10.973942936110896 W2: 1.8868580500188894 b -5.7557669143846315 Loss: 0.41032278974851855\n",
      "W1: 10.973958347017415 W2: 1.8868597279506958 b -5.7557747357539935 Loss: 0.41032278914471815\n",
      "W1: 10.973973743800322 W2: 1.886861404347027 b -5.755782549957866 Loss: 0.4103227885420237\n",
      "W1: 10.973989126472594 W2: 1.8868630792092898 b -5.7557903570028275 Loss: 0.4103227879404336\n",
      "W1: 10.974004495047195 W2: 1.8868647525388893 b -5.755798156895452 Loss: 0.41032278733994526\n",
      "W1: 10.97401984953708 W2: 1.8868664243372297 b -5.755805949642305 Loss: 0.41032278674055706\n",
      "W1: 10.974035189955194 W2: 1.886868094605714 b -5.75581373524995 Loss: 0.4103227861422671\n",
      "W1: 10.974050516314461 W2: 1.8868697633457434 b -5.75582151372494 Loss: 0.41032278554507295\n",
      "W1: 10.974065828627802 W2: 1.8868714305587182 b -5.755829285073825 Loss: 0.4103227849489729\n",
      "W1: 10.974081126908121 W2: 1.8868730962460374 b -5.755837049303149 Loss: 0.4103227843539649\n",
      "W1: 10.974096411168313 W2: 1.8868747604090987 b -5.755844806419447 Loss: 0.4103227837600467\n",
      "W1: 10.97411168142126 W2: 1.8868764230492985 b -5.755852556429252 Loss: 0.41032278316721665\n",
      "W1: 10.97412693767983 W2: 1.8868780841680317 b -5.755860299339088 Loss: 0.4103227825754727\n",
      "W1: 10.974142179956884 W2: 1.8868797437666922 b -5.755868035155474 Loss: 0.4103227819848127\n",
      "W1: 10.974157408265267 W2: 1.8868814018466724 b -5.755875763884922 Loss: 0.41032278139523465\n",
      "W1: 10.974172622617813 W2: 1.8868830584093637 b -5.75588348553394 Loss: 0.4103227808067368\n",
      "W1: 10.974187823027345 W2: 1.886884713456156 b -5.755891200109029 Loss: 0.4103227802193168\n",
      "W1: 10.974203009506674 W2: 1.886886366988438 b -5.755898907616683 Loss: 0.410322779632973\n",
      "W1: 10.974218182068599 W2: 1.8868880190075972 b -5.755906608063392 Loss: 0.41032277904770337\n",
      "W1: 10.974233340725906 W2: 1.8868896695150197 b -5.755914301455638 Loss: 0.41032277846350573\n",
      "W1: 10.97424848549137 W2: 1.8868913185120901 b -5.755921987799899 Loss: 0.4103227778803784\n",
      "W1: 10.974263616377756 W2: 1.8868929660001925 b -5.755929667102644 Loss: 0.4103227772983191\n",
      "W1: 10.974278733397815 W2: 1.8868946119807088 b -5.75593733937034 Loss: 0.4103227767173262\n",
      "W1: 10.974293836564287 W2: 1.8868962564550205 b -5.755945004609446 Loss: 0.4103227761373974\n",
      "W1: 10.9743089258899 W2: 1.886897899424507 b -5.755952662826414 Loss: 0.4103227755585312\n",
      "W1: 10.974324001387371 W2: 1.886899540890547 b -5.755960314027692 Loss: 0.41032277498072534\n",
      "W1: 10.974339063069404 W2: 1.8869011808545175 b -5.7559679582197205 Loss: 0.4103227744039778\n",
      "W1: 10.974354110948692 W2: 1.8869028193177948 b -5.755975595408935 Loss: 0.41032277382828686\n",
      "W1: 10.974369145037915 W2: 1.8869044562817534 b -5.755983225601765 Loss: 0.41032277325365046\n",
      "W1: 10.974384165349745 W2: 1.8869060917477671 b -5.755990848804634 Loss: 0.41032277268006667\n",
      "W1: 10.974399171896838 W2: 1.8869077257172078 b -5.75599846502396 Loss: 0.4103227721075337\n",
      "W1: 10.97441416469184 W2: 1.8869093581914467 b -5.7560060742661525 Loss: 0.41032277153604946\n",
      "W1: 10.974429143747386 W2: 1.8869109891718532 b -5.756013676537619 Loss: 0.41032277096561204\n",
      "W1: 10.9744441090761 W2: 1.886912618659796 b -5.756021271844759 Loss: 0.4103227703962195\n",
      "W1: 10.97445906069059 W2: 1.886914246656642 b -5.7560288601939655 Loss: 0.41032276982787014\n",
      "W1: 10.974473998603457 W2: 1.8869158731637574 b -5.756036441591628 Loss: 0.4103227692605617\n",
      "W1: 10.97448892282729 W2: 1.8869174981825068 b -5.756044016044127 Loss: 0.4103227686942926\n",
      "W1: 10.974503833374662 W2: 1.8869191217142534 b -5.75605158355784 Loss: 0.4103227681290607\n",
      "W1: 10.974518730258142 W2: 1.8869207437603597 b -5.756059144139136 Loss: 0.4103227675648643\n",
      "W1: 10.97453361349028 W2: 1.8869223643221864 b -5.75606669779438 Loss: 0.4103227670017013\n",
      "W1: 10.974548483083618 W2: 1.8869239834010931 b -5.75607424452993 Loss: 0.41032276643956983\n",
      "W1: 10.974563339050686 W2: 1.8869256009984383 b -5.756081784352141 Loss: 0.4103227658784681\n",
      "W1: 10.974578181404002 W2: 1.8869272171155793 b -5.756089317267357 Loss: 0.41032276531839434\n",
      "W1: 10.974593010156074 W2: 1.886928831753872 b -5.756096843281919 Loss: 0.4103227647593463\n",
      "W1: 10.974607825319394 W2: 1.8869304449146709 b -5.756104362402165 Loss: 0.41032276420132247\n",
      "W1: 10.974622626906449 W2: 1.8869320565993295 b -5.7561118746344215 Loss: 0.4103227636443208\n",
      "W1: 10.974637414929708 W2: 1.8869336668092 b -5.756119379985013 Loss: 0.4103227630883392\n",
      "W1: 10.974652189401635 W2: 1.8869352755456335 b -5.7561268784602575 Loss: 0.4103227625333762\n",
      "W1: 10.974666950334676 W2: 1.8869368828099795 b -5.756134370066466 Loss: 0.4103227619794298\n",
      "W1: 10.97468169774127 W2: 1.8869384886035867 b -5.756141854809944 Loss: 0.41032276142649804\n",
      "W1: 10.974696431633843 W2: 1.8869400929278022 b -5.756149332696993 Loss: 0.41032276087457914\n",
      "W1: 10.97471115202481 W2: 1.8869416957839718 b -5.756156803733908 Loss: 0.4103227603236712\n",
      "W1: 10.974725858926572 W2: 1.8869432971734406 b -5.756164267926975 Loss: 0.4103227597737723\n",
      "W1: 10.974740552351523 W2: 1.886944897097552 b -5.756171725282479 Loss: 0.4103227592248807\n",
      "W1: 10.974755232312043 W2: 1.8869464955576483 b -5.756179175806696 Loss: 0.4103227586769945\n",
      "W1: 10.974769898820501 W2: 1.8869480925550703 b -5.756186619505897 Loss: 0.410322758130112\n",
      "W1: 10.974784551889252 W2: 1.8869496880911583 b -5.756194056386348 Loss: 0.4103227575842311\n",
      "W1: 10.974799191530645 W2: 1.8869512821672505 b -5.756201486454308 Loss: 0.41032275703935017\n",
      "W1: 10.974813817757012 W2: 1.8869528747846844 b -5.756208909716031 Loss: 0.41032275649546723\n",
      "W1: 10.974828430580677 W2: 1.8869544659447963 b -5.756216326177766 Loss: 0.41032275595258055\n",
      "W1: 10.974843030013954 W2: 1.886956055648921 b -5.7562237358457535 Loss: 0.41032275541068836\n",
      "W1: 10.97485761606914 W2: 1.8869576438983924 b -5.756231138726232 Loss: 0.4103227548697886\n",
      "W1: 10.974872188758528 W2: 1.8869592306945426 b -5.756238534825431 Loss: 0.4103227543298797\n",
      "W1: 10.974886748094393 W2: 1.886960816038703 b -5.756245924149576 Loss: 0.41032275379095967\n",
      "W1: 10.974901294089003 W2: 1.8869623999322038 b -5.756253306704886 Loss: 0.4103227532530271\n",
      "W1: 10.974915826754613 W2: 1.8869639823763735 b -5.756260682497576 Loss: 0.4103227527160795\n",
      "W1: 10.974930346103465 W2: 1.88696556337254 b -5.756268051533852 Loss: 0.4103227521801156\n",
      "W1: 10.974944852147793 W2: 1.8869671429220294 b -5.7562754138199175 Loss: 0.4103227516451333\n",
      "W1: 10.974959344899817 W2: 1.8869687210261668 b -5.7562827693619685 Loss: 0.410322751111131\n",
      "W1: 10.974973824371748 W2: 1.8869702976862763 b -5.756290118166195 Loss: 0.4103227505781067\n",
      "W1: 10.974988290575785 W2: 1.8869718729036806 b -5.756297460238783 Loss: 0.4103227500460587\n",
      "W1: 10.975002743524115 W2: 1.8869734466797012 b -5.756304795585912 Loss: 0.41032274951498526\n",
      "W1: 10.975017183228914 W2: 1.8869750190156585 b -5.756312124213754 Loss: 0.41032274898488463\n",
      "W1: 10.975031609702347 W2: 1.8869765899128712 b -5.7563194461284795 Loss: 0.41032274845575506\n",
      "W1: 10.975046022956567 W2: 1.8869781593726576 b -5.756326761336249 Loss: 0.41032274792759454\n",
      "W1: 10.975060423003717 W2: 1.886979727396334 b -5.756334069843219 Loss: 0.41032274740040137\n",
      "W1: 10.975074809855927 W2: 1.8869812939852162 b -5.756341371655541 Loss: 0.41032274687417397\n",
      "W1: 10.97508918352532 W2: 1.8869828591406181 b -5.75634866677936 Loss: 0.4103227463489103\n",
      "W1: 10.975103544024003 W2: 1.886984422863853 b -5.756355955220815 Loss: 0.41032274582460887\n",
      "W1: 10.975117891364075 W2: 1.8869859851562327 b -5.75636323698604 Loss: 0.41032274530126767\n",
      "W1: 10.975132225557621 W2: 1.8869875460190677 b -5.756370512081165 Loss: 0.41032274477888486\n",
      "W1: 10.975146546616717 W2: 1.8869891054536676 b -5.7563777805123095 Loss: 0.410322744257459\n",
      "W1: 10.975160854553426 W2: 1.8869906634613405 b -5.756385042285594 Loss: 0.4103227437369883\n",
      "W1: 10.975175149379803 W2: 1.8869922200433933 b -5.756392297407126 Loss: 0.41032274321747075\n",
      "W1: 10.97518943110789 W2: 1.8869937752011319 b -5.756399545883014 Loss: 0.41032274269890495\n",
      "W1: 10.975203699749715 W2: 1.886995328935861 b -5.756406787719358 Loss: 0.4103227421812889\n",
      "W1: 10.9752179553173 W2: 1.886996881248884 b -5.756414022922251 Loss: 0.41032274166462074\n",
      "W1: 10.975232197822654 W2: 1.886998432141503 b -5.756421251497783 Loss: 0.41032274114889894\n",
      "W1: 10.975246427277774 W2: 1.8869999816150191 b -5.756428473452036 Loss: 0.4103227406341219\n",
      "W1: 10.975260643694646 W2: 1.8870015296707323 b -5.756435688791089 Loss: 0.41032274012028763\n",
      "W1: 10.975274847085247 W2: 1.8870030763099412 b -5.756442897521013 Loss: 0.4103227396073945\n",
      "W1: 10.97528903746154 W2: 1.887004621533943 b -5.756450099647874 Loss: 0.4103227390954407\n",
      "W1: 10.975303214835478 W2: 1.8870061653440344 b -5.756457295177734 Loss: 0.41032273858442475\n",
      "W1: 10.975317379219005 W2: 1.8870077077415102 b -5.7564644841166475 Loss: 0.4103227380743446\n",
      "W1: 10.975331530624052 W2: 1.8870092487276642 b -5.756471666470664 Loss: 0.41032273756519894\n",
      "W1: 10.975345669062538 W2: 1.8870107883037892 b -5.756478842245828 Loss: 0.4103227370569853\n",
      "W1: 10.975359794546373 W2: 1.8870123264711767 b -5.756486011448178 Loss: 0.4103227365497029\n",
      "W1: 10.975373907087455 W2: 1.887013863231117 b -5.756493174083747 Loss: 0.41032273604334973\n",
      "W1: 10.975388006697672 W2: 1.8870153985848994 b -5.756500330158562 Loss: 0.4103227355379237\n",
      "W1: 10.9754020933889 W2: 1.8870169325338118 b -5.756507479678644 Loss: 0.41032273503342337\n",
      "W1: 10.975416167173004 W2: 1.8870184650791406 b -5.756514622650012 Loss: 0.41032273452984713\n",
      "W1: 10.975430228061839 W2: 1.8870199962221719 b -5.756521759078674 Loss: 0.4103227340271933\n",
      "W1: 10.975444276067249 W2: 1.8870215259641898 b -5.756528888970636 Loss: 0.4103227335254601\n",
      "W1: 10.975458311201065 W2: 1.8870230543064777 b -5.756536012331898 Loss: 0.41032273302464567\n",
      "W1: 10.975472333475109 W2: 1.8870245812503177 b -5.7565431291684535 Loss: 0.41032273252474866\n",
      "W1: 10.975486342901192 W2: 1.8870261067969905 b -5.756550239486291 Loss: 0.41032273202576713\n",
      "W1: 10.975500339491115 W2: 1.8870276309477758 b -5.756557343291394 Loss: 0.41032273152769955\n",
      "W1: 10.975514323256666 W2: 1.8870291537039523 b -5.756564440589741 Loss: 0.41032273103054406\n",
      "W1: 10.975528294209623 W2: 1.8870306750667973 b -5.756571531387302 Loss: 0.41032273053429935\n",
      "W1: 10.975542252361754 W2: 1.887032195037587 b -5.756578615690046 Loss: 0.41032273003896336\n",
      "W1: 10.975556197724814 W2: 1.8870337136175963 b -5.756585693503932 Loss: 0.41032272954453464\n",
      "W1: 10.97557013031055 W2: 1.8870352308080993 b -5.756592764834916 Loss: 0.41032272905101147\n",
      "W1: 10.975584050130694 W2: 1.8870367466103684 b -5.756599829688948 Loss: 0.41032272855839214\n",
      "W1: 10.975597957196973 W2: 1.8870382610256753 b -5.756606888071974 Loss: 0.4103227280666751\n",
      "W1: 10.975611851521098 W2: 1.8870397740552902 b -5.756613939989931 Loss: 0.41032272757585864\n",
      "W1: 10.975625733114773 W2: 1.8870412857004824 b -5.7566209854487544 Loss: 0.41032272708594103\n",
      "W1: 10.97563960198969 W2: 1.8870427959625198 b -5.756628024454371 Loss: 0.41032272659692076\n",
      "W1: 10.975653458157526 W2: 1.8870443048426693 b -5.756635057012704 Loss: 0.410322726108796\n",
      "W1: 10.975667301629953 W2: 1.8870458123421965 b -5.756642083129671 Loss: 0.4103227256215656\n",
      "W1: 10.97568113241863 W2: 1.887047318462366 b -5.756649102811184 Loss: 0.41032272513522705\n",
      "W1: 10.975694950535207 W2: 1.8870488232044411 b -5.756656116063148 Loss: 0.4103227246497795\n",
      "W1: 10.975708755991318 W2: 1.887050326569684 b -5.7566631228914655 Loss: 0.410322724165221\n",
      "W1: 10.975722548798593 W2: 1.887051828559356 b -5.7566701233020305 Loss: 0.4103227236815497\n",
      "W1: 10.975736328968647 W2: 1.8870533291747167 b -5.756677117300734 Loss: 0.41032272319876456\n",
      "W1: 10.975750096513085 W2: 1.887054828417025 b -5.756684104893461 Loss: 0.4103227227168635\n",
      "W1: 10.975763851443501 W2: 1.8870563262875384 b -5.756691086086089 Loss: 0.41032272223584515\n",
      "W1: 10.97577759377148 W2: 1.8870578227875132 b -5.756698060884494 Loss: 0.41032272175570755\n",
      "W1: 10.975791323508597 W2: 1.887059317918205 b -5.756705029294542 Loss: 0.4103227212764493\n",
      "W1: 10.975805040666412 W2: 1.8870608116808676 b -5.756711991322097 Loss: 0.4103227207980689\n",
      "W1: 10.975818745256477 W2: 1.887062304076754 b -5.756718946973018 Loss: 0.41032272032056466\n",
      "W1: 10.975832437290334 W2: 1.887063795107116 b -5.756725896253155 Loss: 0.41032271984393476\n",
      "W1: 10.975846116779515 W2: 1.8870652847732046 b -5.756732839168355 Loss: 0.4103227193681779\n",
      "W1: 10.975859783735538 W2: 1.887066773076269 b -5.75673977572446 Loss: 0.41032271889329236\n",
      "W1: 10.975873438169915 W2: 1.8870682600175577 b -5.7567467059273065 Loss: 0.4103227184192765\n",
      "W1: 10.975887080094141 W2: 1.8870697455983179 b -5.7567536297827235 Loss: 0.41032271794612873\n",
      "W1: 10.975900709519708 W2: 1.8870712298197956 b -5.756760547296538 Loss: 0.41032271747384746\n",
      "W1: 10.97591432645809 W2: 1.8870727126832358 b -5.7567674584745685 Loss: 0.41032271700243134\n",
      "W1: 10.975927930920758 W2: 1.8870741941898823 b -5.75677436332263 Loss: 0.41032271653187846\n",
      "W1: 10.975941522919165 W2: 1.8870756743409778 b -5.756781261846531 Loss: 0.41032271606218734\n",
      "W1: 10.975955102464757 W2: 1.8870771531377637 b -5.756788154052077 Loss: 0.41032271559335637\n",
      "W1: 10.975968669568973 W2: 1.8870786305814804 b -5.756795039945065 Loss: 0.41032271512538404\n",
      "W1: 10.975982224243234 W2: 1.8870801066733671 b -5.75680191953129 Loss: 0.41032271465826864\n",
      "W1: 10.975995766498954 W2: 1.887081581414662 b -5.756808792816536 Loss: 0.41032271419200883\n",
      "W1: 10.97600929634754 W2: 1.887083054806602 b -5.756815659806589 Loss: 0.410322713726603\n",
      "W1: 10.976022813800382 W2: 1.887084526850423 b -5.756822520507225 Loss: 0.4103227132620493\n",
      "W1: 10.976036318868864 W2: 1.8870859975473597 b -5.756829374924216 Loss: 0.4103227127983465\n",
      "W1: 10.976049811564359 W2: 1.8870874668986457 b -5.756836223063328 Loss: 0.41032271233549283\n",
      "W1: 10.976063291898225 W2: 1.8870889349055133 b -5.7568430649303215 Loss: 0.41032271187348696\n",
      "W1: 10.976076759881817 W2: 1.8870904015691938 b -5.756849900530953 Loss: 0.41032271141232707\n",
      "W1: 10.976090215526474 W2: 1.8870918668909176 b -5.756856729870973 Loss: 0.41032271095201184\n",
      "W1: 10.976103658843527 W2: 1.8870933308719133 b -5.756863552956128 Loss: 0.41032271049253954\n",
      "W1: 10.976117089844296 W2: 1.8870947935134093 b -5.756870369792156 Loss: 0.41032271003390863\n",
      "W1: 10.976130508540088 W2: 1.8870962548166321 b -5.756877180384793 Loss: 0.4103227095761178\n",
      "W1: 10.976143914942204 W2: 1.8870977147828074 b -5.756883984739767 Loss: 0.4103227091191652\n",
      "W1: 10.976157309061932 W2: 1.8870991734131597 b -5.756890782862803 Loss: 0.41032270866304954\n",
      "W1: 10.97617069091055 W2: 1.8871006307089124 b -5.756897574759621 Loss: 0.41032270820776906\n",
      "W1: 10.976184060499326 W2: 1.887102086671288 b -5.756904360435932 Loss: 0.41032270775332247\n",
      "W1: 10.976197417839519 W2: 1.8871035413015076 b -5.756911139897446 Loss: 0.41032270729970804\n",
      "W1: 10.976210762942372 W2: 1.887104994600791 b -5.7569179131498665 Loss: 0.4103227068469243\n",
      "W1: 10.976224095819125 W2: 1.8871064465703573 b -5.75692468019889 Loss: 0.41032270639496987\n",
      "W1: 10.976237416481002 W2: 1.8871078972114244 b -5.7569314410502095 Loss: 0.4103227059438431\n",
      "W1: 10.97625072493922 W2: 1.887109346525209 b -5.7569381957095125 Loss: 0.41032270549354233\n",
      "W1: 10.976264021204983 W2: 1.8871107945129264 b -5.7569449441824805 Loss: 0.4103227050440665\n",
      "W1: 10.976277305289488 W2: 1.8871122411757912 b -5.756951686474791 Loss: 0.41032270459541353\n",
      "W1: 10.976290577203917 W2: 1.8871136865150169 b -5.756958422592115 Loss: 0.4103227041475824\n",
      "W1: 10.976303836959447 W2: 1.8871151305318157 b -5.756965152540119 Loss: 0.4103227037005711\n",
      "W1: 10.976317084567242 W2: 1.8871165732273985 b -5.756971876324465 Loss: 0.41032270325437853\n",
      "W1: 10.976330320038455 W2: 1.8871180146029753 b -5.756978593950808 Loss: 0.4103227028090032\n",
      "W1: 10.976343543384232 W2: 1.8871194546597554 b -5.756985305424799 Loss: 0.4103227023644433\n",
      "W1: 10.976356754615702 W2: 1.8871208933989463 b -5.756992010752083 Loss: 0.41032270192069764\n",
      "W1: 10.976369953743992 W2: 1.8871223308217546 b -5.756998709938301 Loss: 0.41032270147776456\n",
      "W1: 10.976383140780213 W2: 1.887123766929386 b -5.757005402989088 Loss: 0.41032270103564267\n",
      "W1: 10.976396315735467 W2: 1.887125201723045 b -5.757012089910074 Loss: 0.41032270059433035\n",
      "W1: 10.976409478620848 W2: 1.887126635203935 b -5.757018770706883 Loss: 0.41032270015382616\n",
      "W1: 10.976422629447436 W2: 1.8871280673732582 b -5.7570254453851355 Loss: 0.41032269971412877\n",
      "W1: 10.976435768226304 W2: 1.8871294982322155 b -5.757032113950445 Loss: 0.4103226992752365\n",
      "W1: 10.976448894968515 W2: 1.8871309277820074 b -5.757038776408422 Loss: 0.41032269883714806\n",
      "W1: 10.976462009685118 W2: 1.8871323560238324 b -5.757045432764669 Loss: 0.4103226983998617\n",
      "W1: 10.976475112387156 W2: 1.8871337829588888 b -5.757052083024786 Loss: 0.4103226979633762\n",
      "W1: 10.976488203085658 W2: 1.887135208588373 b -5.757058727194367 Loss: 0.4103226975276901\n",
      "W1: 10.976501281791647 W2: 1.8871366329134809 b -5.757065365278999 Loss: 0.41032269709280184\n",
      "W1: 10.976514348516133 W2: 1.887138055935407 b -5.7570719972842666 Loss: 0.4103226966587098\n",
      "W1: 10.976527403270117 W2: 1.8871394776553445 b -5.757078623215748 Loss: 0.41032269622541295\n",
      "W1: 10.976540446064588 W2: 1.8871408980744862 b -5.7570852430790165 Loss: 0.41032269579290936\n",
      "W1: 10.976553476910528 W2: 1.887142317194023 b -5.75709185687964 Loss: 0.4103226953611978\n",
      "W1: 10.976566495818906 W2: 1.8871437350151452 b -5.757098464623181 Loss: 0.4103226949302768\n",
      "W1: 10.976579502800684 W2: 1.887145151539042 b -5.757105066315198 Loss: 0.4103226945001449\n",
      "W1: 10.97659249786681 W2: 1.8871465667669014 b -5.757111661961242 Loss: 0.41032269407080085\n",
      "W1: 10.976605481028223 W2: 1.88714798069991 b -5.757118251566863 Loss: 0.410322693642243\n",
      "W1: 10.976618452295854 W2: 1.887149393339254 b -5.757124835137601 Loss: 0.41032269321446985\n",
      "W1: 10.976631411680625 W2: 1.887150804686118 b -5.757131412678995 Loss: 0.4103226927874799\n",
      "W1: 10.976644359193443 W2: 1.8871522147416857 b -5.757137984196577 Loss: 0.410322692361272\n",
      "W1: 10.976657294845207 W2: 1.8871536235071393 b -5.757144549695873 Loss: 0.41032269193584453\n",
      "W1: 10.976670218646808 W2: 1.8871550309836607 b -5.757151109182407 Loss: 0.4103226915111961\n",
      "W1: 10.976683130609125 W2: 1.88715643717243 b -5.757157662661694 Loss: 0.4103226910873254\n",
      "W1: 10.976696030743026 W2: 1.887157842074627 b -5.757164210139246 Loss: 0.4103226906642309\n",
      "W1: 10.976708919059373 W2: 1.8871592456914292 b -5.757170751620571 Loss: 0.410322690241911\n",
      "W1: 10.976721795569015 W2: 1.8871606480240142 b -5.75717728711117 Loss: 0.41032268982036446\n",
      "W1: 10.976734660282789 W2: 1.887162049073558 b -5.75718381661654 Loss: 0.41032268939958993\n",
      "W1: 10.976747513211526 W2: 1.8871634488412354 b -5.757190340142173 Loss: 0.41032268897958607\n",
      "W1: 10.976760354366046 W2: 1.8871648473282208 b -5.757196857693554 Loss: 0.41032268856035103\n",
      "W1: 10.976773183757158 W2: 1.8871662445356865 b -5.757203369276166 Loss: 0.41032268814188383\n",
      "W1: 10.976786001395663 W2: 1.8871676404648046 b -5.757209874895484 Loss: 0.41032268772418284\n",
      "W1: 10.976798807292347 W2: 1.8871690351167454 b -5.75721637455698 Loss: 0.4103226873072467\n",
      "W1: 10.976811601457992 W2: 1.8871704284926787 b -5.757222868266121 Loss: 0.41032268689107415\n",
      "W1: 10.976824383903368 W2: 1.887171820593773 b -5.757229356028367 Loss: 0.41032268647566367\n",
      "W1: 10.976837154639233 W2: 1.8871732114211959 b -5.757235837849176 Loss: 0.41032268606101385\n",
      "W1: 10.976849913676338 W2: 1.8871746009761137 b -5.7572423137339985 Loss: 0.41032268564712326\n",
      "W1: 10.976862661025422 W2: 1.8871759892596915 b -5.75724878368828 Loss: 0.4103226852339906\n",
      "W1: 10.976875396697215 W2: 1.887177376273094 b -5.757255247717463 Loss: 0.4103226848216146\n",
      "W1: 10.976888120702439 W2: 1.887178762017484 b -5.757261705826983 Loss: 0.4103226844099935\n",
      "W1: 10.9769008330518 W2: 1.8871801464940239 b -5.7572681580222715 Loss: 0.4103226839991263\n",
      "W1: 10.976913533756003 W2: 1.8871815297038745 b -5.757274604308754 Loss: 0.41032268358901125\n",
      "W1: 10.976926222825735 W2: 1.887182911648196 b -5.757281044691852 Loss: 0.41032268317964726\n",
      "W1: 10.97693890027168 W2: 1.887184292328147 b -5.7572874791769815 Loss: 0.41032268277103295\n",
      "W1: 10.976951566104505 W2: 1.8871856717448856 b -5.757293907769554 Loss: 0.41032268236316677\n",
      "W1: 10.976964220334873 W2: 1.8871870498995684 b -5.757300330474977 Loss: 0.41032268195604754\n",
      "W1: 10.976976862973435 W2: 1.8871884267933514 b -5.75730674729865 Loss: 0.41032268154967366\n",
      "W1: 10.976989494030832 W2: 1.8871898024273892 b -5.75731315824597 Loss: 0.4103226811440441\n",
      "W1: 10.977002113517695 W2: 1.8871911768028353 b -5.757319563322328 Loss: 0.4103226807391571\n",
      "W1: 10.977014721444647 W2: 1.8871925499208422 b -5.757325962533111 Loss: 0.4103226803350115\n",
      "W1: 10.977027317822298 W2: 1.8871939217825615 b -5.757332355883699 Loss: 0.41032267993160604\n",
      "W1: 10.977039902661252 W2: 1.8871952923891437 b -5.757338743379471 Loss: 0.41032267952893914\n",
      "W1: 10.9770524759721 W2: 1.8871966617417382 b -5.757345125025796 Loss: 0.41032267912700965\n",
      "W1: 10.977065037765424 W2: 1.887198029841493 b -5.757351500828041 Loss: 0.4103226787258162\n",
      "W1: 10.977077588051799 W2: 1.8871993966895557 b -5.7573578707915685 Loss: 0.4103226783253573\n",
      "W1: 10.977090126841787 W2: 1.8872007622870726 b -5.757364234921734 Loss: 0.41032267792563154\n",
      "W1: 10.977102654145941 W2: 1.8872021266351886 b -5.757370593223891 Loss: 0.4103226775266378\n",
      "W1: 10.977115169974805 W2: 1.8872034897350478 b -5.757376945703386 Loss: 0.4103226771283747\n",
      "W1: 10.977127674338913 W2: 1.8872048515877935 b -5.757383292365559 Loss: 0.41032267673084083\n",
      "W1: 10.977140167248788 W2: 1.8872062121945676 b -5.757389633215749 Loss: 0.4103226763340349\n",
      "W1: 10.977152648714943 W2: 1.887207571556511 b -5.757395968259287 Loss: 0.41032267593795557\n",
      "W1: 10.977165118747887 W2: 1.8872089296747638 b -5.7574022975015 Loss: 0.41032267554260143\n",
      "W1: 10.977177577358113 W2: 1.8872102865504647 b -5.757408620947711 Loss: 0.4103226751479712\n",
      "W1: 10.977190024556105 W2: 1.8872116421847518 b -5.757414938603237 Loss: 0.4103226747540635\n",
      "W1: 10.977202460352341 W2: 1.8872129965787616 b -5.7574212504733895 Loss: 0.4103226743608772\n",
      "W1: 10.977214884757286 W2: 1.88721434973363 b -5.757427556563478 Loss: 0.4103226739684109\n",
      "W1: 10.977227297781397 W2: 1.8872157016504918 b -5.757433856878803 Loss: 0.41032267357666297\n",
      "W1: 10.977239699435119 W2: 1.8872170523304805 b -5.757440151424664 Loss: 0.4103226731856326\n",
      "W1: 10.977252089728891 W2: 1.8872184017747289 b -5.757446440206353 Loss: 0.410322672795318\n",
      "W1: 10.97726446867314 W2: 1.8872197499843684 b -5.757452723229159 Loss: 0.4103226724057183\n",
      "W1: 10.977276836278284 W2: 1.8872210969605296 b -5.757459000498364 Loss: 0.41032267201683187\n",
      "W1: 10.97728919255473 W2: 1.8872224427043423 b -5.757465272019247 Loss: 0.4103226716286575\n",
      "W1: 10.97730153751288 W2: 1.8872237872169344 b -5.757471537797081 Loss: 0.41032267124119387\n",
      "W1: 10.977313871163119 W2: 1.8872251304994339 b -5.757477797837135 Loss: 0.41032267085443963\n",
      "W1: 10.977326193515829 W2: 1.8872264725529668 b -5.757484052144672 Loss: 0.4103226704683937\n",
      "W1: 10.97733850458138 W2: 1.8872278133786589 b -5.757490300724952 Loss: 0.4103226700830546\n",
      "W1: 10.977350804370133 W2: 1.8872291529776342 b -5.757496543583229 Loss: 0.41032266969842085\n",
      "W1: 10.977363092892437 W2: 1.887230491351016 b -5.75750278072475 Loss: 0.41032266931449163\n",
      "W1: 10.977375370158635 W2: 1.8872318284999268 b -5.757509012154762 Loss: 0.4103226689312653\n",
      "W1: 10.977387636179058 W2: 1.8872331644254876 b -5.757515237878504 Loss: 0.41032266854874067\n",
      "W1: 10.977399890964028 W2: 1.8872344991288188 b -5.75752145790121 Loss: 0.4103226681669165\n",
      "W1: 10.977412134523858 W2: 1.8872358326110397 b -5.75752767222811 Loss: 0.4103226677857913\n",
      "W1: 10.977424366868851 W2: 1.8872371648732682 b -5.757533880864429 Loss: 0.4103226674053641\n",
      "W1: 10.977436588009303 W2: 1.8872384959166217 b -5.757540083815388 Loss: 0.41032266702563336\n",
      "W1: 10.977448797955494 W2: 1.8872398257422163 b -5.757546281086202 Loss: 0.41032266664659783\n",
      "W1: 10.977460996717703 W2: 1.887241154351167 b -5.7575524726820815 Loss: 0.41032266626825636\n",
      "W1: 10.977473184306193 W2: 1.8872424817445876 b -5.757558658608232 Loss: 0.4103226658906076\n",
      "W1: 10.977485360731222 W2: 1.8872438079235916 b -5.757564838869857 Loss: 0.4103226655136506\n",
      "W1: 10.977497526003035 W2: 1.8872451328892907 b -5.757571013472149 Loss: 0.41032266513738347\n",
      "W1: 10.977509680131869 W2: 1.887246456642796 b -5.757577182420302 Loss: 0.4103226647618054\n",
      "W1: 10.977521823127951 W2: 1.8872477791852176 b -5.757583345719503 Loss: 0.41032266438691495\n",
      "W1: 10.9775339550015 W2: 1.8872491005176644 b -5.757589503374933 Loss: 0.410322664012711\n",
      "W1: 10.977546075762724 W2: 1.8872504206412444 b -5.7575956553917695 Loss: 0.4103226636391921\n",
      "W1: 10.977558185421824 W2: 1.8872517395570645 b -5.757601801775184 Loss: 0.4103226632663571\n",
      "W1: 10.977570283988987 W2: 1.8872530572662305 b -5.7576079425303455 Loss: 0.41032266289420477\n",
      "W1: 10.977582371474396 W2: 1.8872543737698475 b -5.757614077662416 Loss: 0.41032266252273375\n",
      "W1: 10.97759444788822 W2: 1.8872556890690193 b -5.757620207176554 Loss: 0.41032266215194296\n",
      "W1: 10.977606513240623 W2: 1.8872570031648488 b -5.757626331077914 Loss: 0.4103226617818312\n",
      "W1: 10.977618567541757 W2: 1.887258316058438 b -5.757632449371642 Loss: 0.4103226614123969\n",
      "W1: 10.977630610801764 W2: 1.8872596277508875 b -5.757638562062884 Loss: 0.41032266104363924\n",
      "W1: 10.977642643030778 W2: 1.8872609382432972 b -5.757644669156779 Loss: 0.4103226606755564\n",
      "W1: 10.977654664238925 W2: 1.8872622475367662 b -5.7576507706584605 Loss: 0.4103226603081479\n",
      "W1: 10.977666674436318 W2: 1.887263555632392 b -5.757656866573059 Loss: 0.41032265994141165\n",
      "W1: 10.977678673633063 W2: 1.8872648625312718 b -5.7576629569057 Loss: 0.41032265957534725\n",
      "W1: 10.977690661839256 W2: 1.887266168234501 b -5.757669041661503 Loss: 0.4103226592099529\n",
      "W1: 10.977702639064985 W2: 1.8872674727431749 b -5.757675120845583 Loss: 0.4103226588452276\n",
      "W1: 10.977714605320328 W2: 1.8872687760583868 b -5.757681194463052 Loss: 0.41032265848116994\n",
      "W1: 10.977726560615352 W2: 1.8872700781812297 b -5.757687262519015 Loss: 0.4103226581177792\n",
      "W1: 10.977738504960119 W2: 1.8872713791127955 b -5.757693325018575 Loss: 0.4103226577550535\n",
      "W1: 10.977750438364676 W2: 1.887272678854175 b -5.757699381966828 Loss: 0.41032265739299195\n",
      "W1: 10.977762360839066 W2: 1.8872739774064577 b -5.757705433368866 Loss: 0.4103226570315934\n",
      "W1: 10.977774272393319 W2: 1.8872752747707329 b -5.757711479229775 Loss: 0.4103226566708564\n",
      "W1: 10.977786173037456 W2: 1.887276570948088 b -5.757717519554641 Loss: 0.41032265631078\n",
      "W1: 10.977798062781494 W2: 1.8872778659396103 b -5.757723554348539 Loss: 0.4103226559513628\n",
      "W1: 10.977809941635433 W2: 1.8872791597463852 b -5.757729583616544 Loss: 0.41032265559260356\n",
      "W1: 10.977821809609269 W2: 1.8872804523694975 b -5.757735607363724 Loss: 0.41032265523450134\n",
      "W1: 10.977833666712987 W2: 1.887281743810031 b -5.757741625595143 Loss: 0.4103226548770547\n",
      "W1: 10.977845512956563 W2: 1.887283034069069 b -5.757747638315861 Loss: 0.4103226545202625\n",
      "W1: 10.977857348349964 W2: 1.8872843231476926 b -5.757753645530932 Loss: 0.4103226541641234\n",
      "W1: 10.977869172903148 W2: 1.8872856110469831 b -5.757759647245406 Loss: 0.41032265380863664\n",
      "W1: 10.977880986626063 W2: 1.8872868977680204 b -5.757765643464328 Loss: 0.4103226534538006\n",
      "W1: 10.97789278952865 W2: 1.887288183311883 b -5.75777163419274 Loss: 0.410322653099614\n",
      "W1: 10.977904581620837 W2: 1.8872894676796492 b -5.757777619435678 Loss: 0.4103226527460762\n",
      "W1: 10.977916362912547 W2: 1.8872907508723955 b -5.757783599198173 Loss: 0.4103226523931855\n",
      "W1: 10.977928133413691 W2: 1.8872920328911982 b -5.757789573485251 Loss: 0.4103226520409409\n",
      "W1: 10.977939893134172 W2: 1.8872933137371317 b -5.757795542301936 Loss: 0.4103226516893411\n",
      "W1: 10.977951642083884 W2: 1.8872945934112704 b -5.7578015056532434 Loss: 0.41032265133838525\n",
      "W1: 10.97796338027271 W2: 1.8872958719146868 b -5.7578074635441885 Loss: 0.41032265098807197\n",
      "W1: 10.977975107710527 W2: 1.8872971492484532 b -5.757813415979778 Loss: 0.4103226506383999\n",
      "W1: 10.977986824407202 W2: 1.8872984254136405 b -5.757819362965017 Loss: 0.410322650289368\n",
      "W1: 10.97799853037259 W2: 1.8872997004113186 b -5.7578253045049035 Loss: 0.41032264994097517\n",
      "W1: 10.97801022561654 W2: 1.8873009742425564 b -5.757831240604433 Loss: 0.41032264959322035\n",
      "W1: 10.978021910148893 W2: 1.8873022469084222 b -5.757837171268594 Loss: 0.410322649246102\n",
      "W1: 10.978033583979478 W2: 1.887303518409983 b -5.7578430965023735 Loss: 0.4103226488996193\n",
      "W1: 10.978045247118114 W2: 1.8873047887483045 b -5.757849016310751 Loss: 0.4103226485537706\n",
      "W1: 10.978056899574616 W2: 1.8873060579244523 b -5.757854930698704 Loss: 0.4103226482085555\n",
      "W1: 10.978068541358786 W2: 1.8873073259394901 b -5.757860839671203 Loss: 0.4103226478639723\n",
      "W1: 10.978080172480416 W2: 1.8873085927944813 b -5.757866743233215 Loss: 0.41032264752001985\n",
      "W1: 10.978091792949293 W2: 1.887309858490488 b -5.757872641389704 Loss: 0.4103226471766973\n",
      "W1: 10.978103402775192 W2: 1.887311123028571 b -5.757878534145626 Loss: 0.4103226468340033\n",
      "W1: 10.978115001967879 W2: 1.8873123864097912 b -5.757884421505936 Loss: 0.4103226464919366\n",
      "W1: 10.978126590537114 W2: 1.8873136486352073 b -5.75789030347558 Loss: 0.4103226461504962\n",
      "W1: 10.978138168492643 W2: 1.887314909705878 b -5.757896180059506 Loss: 0.4103226458096809\n",
      "W1: 10.978149735844209 W2: 1.8873161696228602 b -5.757902051262651 Loss: 0.4103226454694896\n",
      "W1: 10.978161292601541 W2: 1.8873174283872105 b -5.75790791708995 Loss: 0.41032264512992106\n",
      "W1: 10.978172838774363 W2: 1.887318685999984 b -5.757913777546335 Loss: 0.4103226447909741\n",
      "W1: 10.978184374372384 W2: 1.8873199424622353 b -5.757919632636732 Loss: 0.4103226444526479\n",
      "W1: 10.978195899405312 W2: 1.8873211977750177 b -5.757925482366061 Loss: 0.410322644114941\n",
      "W1: 10.97820741388284 W2: 1.8873224519393839 b -5.757931326739241 Loss: 0.41032264377785227\n",
      "W1: 10.978218917814655 W2: 1.8873237049563851 b -5.7579371657611835 Loss: 0.4103226434413809\n",
      "W1: 10.978230411210433 W2: 1.887324956827072 b -5.757942999436796 Loss: 0.41032264310552535\n",
      "W1: 10.978241894079844 W2: 1.8873262075524941 b -5.757948827770983 Loss: 0.4103226427702848\n",
      "W1: 10.978253366432545 W2: 1.8873274571337 b -5.757954650768642 Loss: 0.4103226424356578\n",
      "W1: 10.978264828278189 W2: 1.8873287055717374 b -5.757960468434669 Loss: 0.41032264210164365\n",
      "W1: 10.978276279626416 W2: 1.8873299528676528 b -5.757966280773952 Loss: 0.4103226417682409\n",
      "W1: 10.97828772048686 W2: 1.8873311990224921 b -5.757972087791378 Loss: 0.41032264143544855\n",
      "W1: 10.978299150869145 W2: 1.8873324440373 b -5.757977889491827 Loss: 0.41032264110326544\n",
      "W1: 10.978310570782885 W2: 1.8873336879131204 b -5.757983685880176 Loss: 0.4103226407716905\n",
      "W1: 10.978321980237686 W2: 1.887334930650996 b -5.757989476961297 Loss: 0.41032264044072253\n",
      "W1: 10.978333379243146 W2: 1.8873361722519686 b -5.7579952627400575 Loss: 0.4103226401103605\n",
      "W1: 10.978344767808853 W2: 1.8873374127170794 b -5.75800104322132 Loss: 0.41032263978060324\n",
      "W1: 10.978356145944387 W2: 1.8873386520473685 b -5.758006818409942 Loss: 0.41032263945144964\n",
      "W1: 10.978367513659318 W2: 1.8873398902438745 b -5.75801258831078 Loss: 0.41032263912289896\n",
      "W1: 10.97837887096321 W2: 1.8873411273076357 b -5.758018352928681 Loss: 0.41032263879494946\n",
      "W1: 10.978390217865615 W2: 1.8873423632396893 b -5.758024112268491 Loss: 0.4103226384676005\n",
      "W1: 10.978401554376076 W2: 1.8873435980410713 b -5.758029866335052 Loss: 0.41032263814085074\n",
      "W1: 10.97841288050413 W2: 1.887344831712817 b -5.758035615133199 Loss: 0.4103226378146991\n",
      "W1: 10.978424196259304 W2: 1.8873460642559605 b -5.7580413586677635 Loss: 0.41032263748914466\n",
      "W1: 10.978435501651116 W2: 1.8873472956715354 b -5.758047096943573 Loss: 0.4103226371641862\n",
      "W1: 10.978446796689076 W2: 1.887348525960574 b -5.75805282996545 Loss: 0.4103226368398225\n",
      "W1: 10.978458081382682 W2: 1.8873497551241076 b -5.758058557738214 Loss: 0.4103226365160529\n",
      "W1: 10.978469355741426 W2: 1.8873509831631667 b -5.7580642802666775 Loss: 0.4103226361928757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.978480619774793 W2: 1.887352210078781 b -5.758069997555651 Loss: 0.41032263587029044\n",
      "W1: 10.978491873492256 W2: 1.887353435871979 b -5.75807570960994 Loss: 0.4103226355482957\n",
      "W1: 10.978503116903282 W2: 1.8873546605437883 b -5.758081416434345 Loss: 0.4103226352268903\n",
      "W1: 10.978514350017326 W2: 1.8873558840952358 b -5.758087118033661 Loss: 0.41032263490607335\n",
      "W1: 10.978525572843838 W2: 1.8873571065273471 b -5.758092814412681 Loss: 0.41032263458584367\n",
      "W1: 10.978536785392256 W2: 1.887358327841147 b -5.758098505576192 Loss: 0.41032263426620025\n",
      "W1: 10.97854798767201 W2: 1.8873595480376593 b -5.758104191528977 Loss: 0.4103226339471421\n",
      "W1: 10.978559179692525 W2: 1.8873607671179071 b -5.758109872275815 Loss: 0.410322633628668\n",
      "W1: 10.97857036146321 W2: 1.8873619850829124 b -5.758115547821481 Loss: 0.41032263331077684\n",
      "W1: 10.978581532993475 W2: 1.8873632019336963 b -5.758121218170743 Loss: 0.4103226329934678\n",
      "W1: 10.978592694292713 W2: 1.887364417671279 b -5.758126883328368 Loss: 0.41032263267673946\n",
      "W1: 10.97860384537031 W2: 1.8873656322966792 b -5.758132543299117 Loss: 0.41032263236059113\n",
      "W1: 10.978614986235648 W2: 1.8873668458109156 b -5.758138198087745 Loss: 0.41032263204502134\n",
      "W1: 10.978626116898095 W2: 1.8873680582150056 b -5.758143847699007 Loss: 0.41032263173002936\n",
      "W1: 10.978637237367012 W2: 1.8873692695099655 b -5.758149492137648 Loss: 0.4103226314156141\n",
      "W1: 10.978648347651754 W2: 1.8873704796968107 b -5.758155131408414 Loss: 0.4103226311017743\n",
      "W1: 10.978659447761663 W2: 1.8873716887765557 b -5.758160765516044 Loss: 0.4103226307885091\n",
      "W1: 10.978670537706076 W2: 1.8873728967502141 b -5.758166394465271 Loss: 0.4103226304758174\n",
      "W1: 10.97868161749432 W2: 1.8873741036187988 b -5.758172018260828 Loss: 0.410322630163698\n",
      "W1: 10.978692687135712 W2: 1.8873753093833212 b -5.758177636907439 Loss: 0.41032262985215023\n",
      "W1: 10.978703746639564 W2: 1.8873765140447925 b -5.758183250409827 Loss: 0.4103226295411725\n",
      "W1: 10.978714796015176 W2: 1.8873777176042223 b -5.7581888587727095 Loss: 0.41032262923076424\n",
      "W1: 10.97872583527184 W2: 1.8873789200626199 b -5.758194462000799 Loss: 0.41032262892092414\n",
      "W1: 10.978736864418842 W2: 1.887380121420993 b -5.758200060098805 Loss: 0.4103226286116513\n",
      "W1: 10.978747883465456 W2: 1.887381321680349 b -5.758205653071431 Loss: 0.41032262830294464\n",
      "W1: 10.97875889242095 W2: 1.8873825208416937 b -5.758211240923377 Loss: 0.4103226279948032\n",
      "W1: 10.978769891294583 W2: 1.8873837189060325 b -5.758216823659341 Loss: 0.4103226276872256\n",
      "W1: 10.978780880095604 W2: 1.88738491587437 b -5.758222401284012 Loss: 0.41032262738021125\n",
      "W1: 10.978791858833254 W2: 1.8873861117477095 b -5.758227973802079 Loss: 0.4103226270737588\n",
      "W1: 10.978802827516768 W2: 1.8873873065270534 b -5.758233541218223 Loss: 0.4103226267678676\n",
      "W1: 10.978813786155369 W2: 1.8873885002134034 b -5.758239103537123 Loss: 0.4103226264625361\n",
      "W1: 10.978824734758273 W2: 1.88738969280776 b -5.758244660763455 Loss: 0.41032262615776366\n",
      "W1: 10.978835673334688 W2: 1.8873908843111231 b -5.758250212901887 Loss: 0.41032262585354906\n",
      "W1: 10.978846601893812 W2: 1.8873920747244917 b -5.758255759957085 Loss: 0.4103226255498914\n",
      "W1: 10.978857520444837 W2: 1.8873932640488633 b -5.758261301933711 Loss: 0.4103226252467897\n",
      "W1: 10.978868428996943 W2: 1.8873944522852353 b -5.7582668388364215 Loss: 0.41032262494424265\n",
      "W1: 10.978879327559307 W2: 1.8873956394346034 b -5.75827237066987 Loss: 0.41032262464224956\n",
      "W1: 10.97889021614109 W2: 1.8873968254979632 b -5.758277897438704 Loss: 0.4103226243408095\n",
      "W1: 10.978901094751453 W2: 1.8873980104763086 b -5.75828341914757 Loss: 0.41032262403992087\n",
      "W1: 10.978911963399542 W2: 1.8873991943706332 b -5.7582889358011045 Loss: 0.4103226237395834\n",
      "W1: 10.978922822094496 W2: 1.8874003771819292 b -5.758294447403945 Loss: 0.4103226234397954\n",
      "W1: 10.978933670845448 W2: 1.8874015589111883 b -5.758299953960724 Loss: 0.41032262314055645\n",
      "W1: 10.97894450966152 W2: 1.8874027395594013 b -5.758305455476067 Loss: 0.4103226228418651\n",
      "W1: 10.978955338551827 W2: 1.8874039191275576 b -5.758310951954597 Loss: 0.41032262254372065\n",
      "W1: 10.978966157525477 W2: 1.887405097616646 b -5.758316443400933 Loss: 0.41032262224612187\n",
      "W1: 10.978976966591565 W2: 1.8874062750276548 b -5.758321929819689 Loss: 0.41032262194906804\n",
      "W1: 10.978987765759182 W2: 1.8874074513615706 b -5.758327411215476 Loss: 0.41032262165255773\n",
      "W1: 10.97899855503741 W2: 1.8874086266193797 b -5.7583328875929 Loss: 0.41032262135659037\n",
      "W1: 10.979009334435322 W2: 1.887409800802067 b -5.758338358956562 Loss: 0.41032262106116485\n",
      "W1: 10.979020103961979 W2: 1.887410973910617 b -5.75834382531106 Loss: 0.41032262076628\n",
      "W1: 10.97903086362644 W2: 1.8874121459460131 b -5.758349286660987 Loss: 0.41032262047193496\n",
      "W1: 10.979041613437753 W2: 1.8874133169092377 b -5.758354743010932 Loss: 0.4103226201781288\n",
      "W1: 10.979052353404956 W2: 1.8874144868012726 b -5.758360194365479 Loss: 0.4103226198848603\n",
      "W1: 10.979063083537081 W2: 1.887415655623098 b -5.75836564072921 Loss: 0.4103226195921288\n",
      "W1: 10.97907380384315 W2: 1.887416823375694 b -5.7583710821067 Loss: 0.4103226192999333\n",
      "W1: 10.979084514332177 W2: 1.8874179900600396 b -5.758376518502521 Loss: 0.41032261900827244\n",
      "W1: 10.979095215013169 W2: 1.8874191556771125 b -5.758381949921243 Loss: 0.4103226187171455\n",
      "W1: 10.979105905895125 W2: 1.8874203202278899 b -5.758387376367428 Loss: 0.41032261842655154\n",
      "W1: 10.979116586987033 W2: 1.887421483713348 b -5.7583927978456355 Loss: 0.4103226181364894\n",
      "W1: 10.979127258297874 W2: 1.887422646134462 b -5.7583982143604215 Loss: 0.4103226178469584\n",
      "W1: 10.979137919836623 W2: 1.8874238074922065 b -5.758403625916337 Loss: 0.4103226175579573\n",
      "W1: 10.979148571612242 W2: 1.8874249677875548 b -5.758409032517928 Loss: 0.41032261726948516\n",
      "W1: 10.97915921363369 W2: 1.8874261270214796 b -5.7584144341697385 Loss: 0.4103226169815411\n",
      "W1: 10.979169845909913 W2: 1.8874272851949527 b -5.758419830876307 Loss: 0.4103226166941243\n",
      "W1: 10.979180468449854 W2: 1.887428442308945 b -5.758425222642168 Loss: 0.4103226164072335\n",
      "W1: 10.979191081262442 W2: 1.887429598364426 b -5.7584306094718505 Loss: 0.4103226161208679\n",
      "W1: 10.979201684356603 W2: 1.887430753362365 b -5.758435991369882 Loss: 0.4103226158350264\n",
      "W1: 10.97921227774125 W2: 1.8874319073037304 b -5.758441368340783 Loss: 0.410322615549708\n",
      "W1: 10.979222861425292 W2: 1.887433060189489 b -5.758446740389073 Loss: 0.41032261526491226\n",
      "W1: 10.979233435417626 W2: 1.8874342120206078 b -5.758452107519265 Loss: 0.4103226149806376\n",
      "W1: 10.979243999727146 W2: 1.8874353627980518 b -5.758457469735868 Loss: 0.4103226146968834\n",
      "W1: 10.979254554362731 W2: 1.8874365125227857 b -5.758462827043387 Loss: 0.4103226144136485\n",
      "W1: 10.979265099333258 W2: 1.8874376611957733 b -5.758468179446324 Loss: 0.41032261413093196\n",
      "W1: 10.97927563464759 W2: 1.8874388088179774 b -5.758473526949176 Loss: 0.4103226138487333\n",
      "W1: 10.97928616031459 W2: 1.8874399553903602 b -5.758478869556436 Loss: 0.4103226135670509\n",
      "W1: 10.979296676343104 W2: 1.8874411009138827 b -5.758484207272592 Loss: 0.41032261328588415\n",
      "W1: 10.979307182741975 W2: 1.887442245389505 b -5.758489540102129 Loss: 0.4103226130052322\n",
      "W1: 10.979317679520037 W2: 1.8874433888181863 b -5.758494868049528 Loss: 0.41032261272509385\n",
      "W1: 10.979328166686114 W2: 1.8874445312008852 b -5.758500191119264 Loss: 0.41032261244546847\n",
      "W1: 10.979338644249026 W2: 1.8874456725385593 b -5.75850550931581 Loss: 0.4103226121663546\n",
      "W1: 10.97934911221758 W2: 1.887446812832165 b -5.758510822643635 Loss: 0.41032261188775193\n",
      "W1: 10.979359570600579 W2: 1.8874479520826586 b -5.758516131107203 Loss: 0.410322611609659\n",
      "W1: 10.979370019406813 W2: 1.8874490902909946 b -5.758521434710972 Loss: 0.4103226113320753\n",
      "W1: 10.97938045864507 W2: 1.8874502274581273 b -5.7585267334594 Loss: 0.41032261105499956\n",
      "W1: 10.979390888324126 W2: 1.8874513635850099 b -5.758532027356938 Loss: 0.41032261077843124\n",
      "W1: 10.979401308452749 W2: 1.8874524986725945 b -5.758537316408034 Loss: 0.4103226105023689\n",
      "W1: 10.9794117190397 W2: 1.8874536327218325 b -5.75854260061713 Loss: 0.41032261022681205\n",
      "W1: 10.979422120093732 W2: 1.8874547657336749 b -5.758547879988667 Loss: 0.4103226099517595\n",
      "W1: 10.97943251162359 W2: 1.887455897709071 b -5.75855315452708 Loss: 0.4103226096772104\n",
      "W1: 10.97944289363801 W2: 1.8874570286489698 b -5.7585584242368 Loss: 0.4103226094031639\n",
      "W1: 10.979453266145722 W2: 1.887458158554319 b -5.758563689122255 Loss: 0.410322609129619\n",
      "W1: 10.979463629155443 W2: 1.887459287426066 b -5.758568949187867 Loss: 0.41032260885657496\n",
      "W1: 10.979473982675888 W2: 1.8874604152651568 b -5.758574204438057 Loss: 0.4103226085840305\n",
      "W1: 10.979484326715761 W2: 1.887461542072537 b -5.758579454877238 Loss: 0.41032260831198497\n",
      "W1: 10.97949466128376 W2: 1.8874626678491506 b -5.7585847005098225 Loss: 0.4103226080404374\n",
      "W1: 10.97950498638857 W2: 1.8874637925959417 b -5.758589941340216 Loss: 0.4103226077693869\n",
      "W1: 10.979515302038873 W2: 1.8874649163138528 b -5.758595177372822 Loss: 0.4103226074988325\n",
      "W1: 10.97952560824334 W2: 1.8874660390038258 b -5.75860040861204 Loss: 0.4103226072287734\n",
      "W1: 10.97953590501064 W2: 1.8874671606668019 b -5.758605635062263 Loss: 0.4103226069592086\n",
      "W1: 10.979546192349424 W2: 1.887468281303721 b -5.758610856727884 Loss: 0.4103226066901371\n",
      "W1: 10.979556470268344 W2: 1.8874694009155224 b -5.758616073613288 Loss: 0.41032260642155816\n",
      "W1: 10.97956673877604 W2: 1.8874705195031447 b -5.7586212857228585 Loss: 0.41032260615347094\n",
      "W1: 10.979576997881143 W2: 1.8874716370675255 b -5.758626493060974 Loss: 0.4103226058858743\n",
      "W1: 10.979587247592278 W2: 1.8874727536096014 b -5.758631695632008 Loss: 0.4103226056187675\n",
      "W1: 10.979597487918063 W2: 1.8874738691303083 b -5.7586368934403325 Loss: 0.41032260535214976\n",
      "W1: 10.979607718867106 W2: 1.8874749836305813 b -5.758642086490314 Loss: 0.41032260508601986\n",
      "W1: 10.979617940448009 W2: 1.8874760971113542 b -5.7586472747863136 Loss: 0.4103226048203771\n",
      "W1: 10.979628152669362 W2: 1.8874772095735606 b -5.7586524583326915 Loss: 0.4103226045552207\n",
      "W1: 10.979638355539752 W2: 1.8874783210181327 b -5.758657637133801 Loss: 0.4103226042905495\n",
      "W1: 10.979648549067756 W2: 1.8874794314460024 b -5.758662811193994 Loss: 0.41032260402636267\n",
      "W1: 10.979658733261944 W2: 1.8874805408581001 b -5.7586679805176155 Loss: 0.4103226037626595\n",
      "W1: 10.979668908130876 W2: 1.8874816492553559 b -5.758673145109009 Loss: 0.4103226034994391\n",
      "W1: 10.979679073683105 W2: 1.8874827566386987 b -5.758678304972513 Loss: 0.4103226032367005\n",
      "W1: 10.979689229927178 W2: 1.8874838630090567 b -5.7586834601124615 Loss: 0.41032260297444273\n",
      "W1: 10.979699376871633 W2: 1.8874849683673571 b -5.758688610533185 Loss: 0.4103226027126649\n",
      "W1: 10.979709514524998 W2: 1.8874860727145266 b -5.758693756239011 Loss: 0.4103226024513665\n",
      "W1: 10.979719642895798 W2: 1.8874871760514906 b -5.758698897234262 Loss: 0.41032260219054617\n",
      "W1: 10.979729761992544 W2: 1.887488278379174 b -5.758704033523255 Loss: 0.41032260193020315\n",
      "W1: 10.979739871823744 W2: 1.8874893796985006 b -5.758709165110306 Loss: 0.41032260167033674\n",
      "W1: 10.979749972397896 W2: 1.8874904800103935 b -5.758714291999726 Loss: 0.410322601410946\n",
      "W1: 10.97976006372349 W2: 1.887491579315775 b -5.758719414195821 Loss: 0.41032260115203\n",
      "W1: 10.97977014580901 W2: 1.8874926776155663 b -5.758724531702894 Loss: 0.4103226008935881\n",
      "W1: 10.979780218662931 W2: 1.8874937749106881 b -5.758729644525244 Loss: 0.41032260063561893\n",
      "W1: 10.97979028229372 W2: 1.88749487120206 b -5.758734752667165 Loss: 0.4103226003781222\n",
      "W1: 10.979800336709836 W2: 1.8874959664906008 b -5.758739856132948 Loss: 0.4103226001210966\n",
      "W1: 10.979810381919732 W2: 1.8874970607772286 b -5.758744954926881 Loss: 0.4103225998645415\n",
      "W1: 10.97982041793185 W2: 1.8874981540628606 b -5.758750049053246 Loss: 0.410322599608456\n",
      "W1: 10.979830444754626 W2: 1.887499246348413 b -5.758755138516323 Loss: 0.41032259935283905\n",
      "W1: 10.97984046239649 W2: 1.8875003376348014 b -5.758760223320387 Loss: 0.4103225990976902\n",
      "W1: 10.979850470865863 W2: 1.8875014279229403 b -5.758765303469708 Loss: 0.41032259884300826\n",
      "W1: 10.979860470171156 W2: 1.8875025172137436 b -5.758770378968555 Loss: 0.41032259858879255\n",
      "W1: 10.979870460320775 W2: 1.8875036055081245 b -5.75877544982119 Loss: 0.410322598335042\n",
      "W1: 10.979880441323118 W2: 1.8875046928069947 b -5.758780516031873 Loss: 0.41032259808175603\n",
      "W1: 10.979890413186574 W2: 1.8875057791112657 b -5.7587855776048595 Loss: 0.41032259782893343\n",
      "W1: 10.979900375919526 W2: 1.8875068644218478 b -5.758790634544401 Loss: 0.41032259757657386\n",
      "W1: 10.979910329530345 W2: 1.8875079487396509 b -5.758795686854746 Loss: 0.410322597324676\n",
      "W1: 10.9799202740274 W2: 1.8875090320655836 b -5.758800734540136 Loss: 0.4103225970732392\n",
      "W1: 10.97993020941905 W2: 1.887510114400554 b -5.758805777604814 Loss: 0.41032259682226263\n",
      "W1: 10.979940135713646 W2: 1.8875111957454689 b -5.758810816053014 Loss: 0.4103225965717456\n",
      "W1: 10.97995005291953 W2: 1.8875122761012348 b -5.758815849888968 Loss: 0.4103225963216868\n",
      "W1: 10.97995996104504 W2: 1.8875133554687573 b -5.7588208791169055 Loss: 0.41032259607208593\n",
      "W1: 10.979969860098503 W2: 1.887514433848941 b -5.75882590374105 Loss: 0.4103225958229417\n",
      "W1: 10.979979750088239 W2: 1.8875155112426893 b -5.758830923765622 Loss: 0.4103225955742537\n",
      "W1: 10.97998963102256 W2: 1.8875165876509057 b -5.758835939194838 Loss: 0.41032259532602056\n",
      "W1: 10.979999502909774 W2: 1.887517663074492 b -5.75884095003291 Loss: 0.4103225950782422\n",
      "W1: 10.980009365758175 W2: 1.8875187375143498 b -5.758845956284048 Loss: 0.410322594830917\n",
      "W1: 10.980019219576056 W2: 1.8875198109713793 b -5.758850957952457 Loss: 0.4103225945840446\n",
      "W1: 10.980029064371696 W2: 1.8875208834464803 b -5.758855955042337 Loss: 0.4103225943376239\n",
      "W1: 10.980038900153371 W2: 1.8875219549405517 b -5.758860947557886 Loss: 0.41032259409165434\n",
      "W1: 10.980048726929349 W2: 1.8875230254544915 b -5.758865935503297 Loss: 0.410322593846135\n",
      "W1: 10.98005854470789 W2: 1.8875240949891967 b -5.75887091888276 Loss: 0.41032259360106504\n",
      "W1: 10.980068353497243 W2: 1.8875251635455639 b -5.75887589770046 Loss: 0.4103225933564435\n",
      "W1: 10.980078153305655 W2: 1.8875262311244885 b -5.75888087196058 Loss: 0.41032259311226976\n",
      "W1: 10.98008794414136 W2: 1.8875272977268653 b -5.758885841667296 Loss: 0.41032259286854295\n",
      "W1: 10.980097726012588 W2: 1.8875283633535884 b -5.758890806824783 Loss: 0.41032259262526216\n",
      "W1: 10.98010749892756 W2: 1.8875294280055506 b -5.758895767437211 Loss: 0.4103225923824267\n",
      "W1: 10.980117262894492 W2: 1.8875304916836442 b -5.758900723508748 Loss: 0.4103225921400356\n",
      "W1: 10.980127017921587 W2: 1.8875315543887607 b -5.758905675043555 Loss: 0.41032259189808823\n",
      "W1: 10.980136764017047 W2: 1.887532616121791 b -5.758910622045791 Loss: 0.41032259165658364\n",
      "W1: 10.980146501189061 W2: 1.8875336768836244 b -5.7589155645196115 Loss: 0.410322591415521\n",
      "W1: 10.980156229445814 W2: 1.8875347366751503 b -5.758920502469167 Loss: 0.41032259117489966\n",
      "W1: 10.980165948795483 W2: 1.8875357954972567 b -5.758925435898606 Loss: 0.4103225909347188\n",
      "W1: 10.980175659246234 W2: 1.887536853350831 b -5.758930364812071 Loss: 0.4103225906949774\n",
      "W1: 10.98018536080623 W2: 1.88753791023676 b -5.758935289213701 Loss: 0.41032259045567476\n",
      "W1: 10.980195053483623 W2: 1.8875389661559292 b -5.758940209107633 Loss: 0.41032259021681006\n",
      "W1: 10.980204737286561 W2: 1.8875400211092235 b -5.758945124498 Loss: 0.41032258997838267\n",
      "W1: 10.980214412223182 W2: 1.887541075097527 b -5.758950035388929 Loss: 0.41032258974039165\n",
      "W1: 10.980224078301616 W2: 1.8875421281217233 b -5.758954941784544 Loss: 0.4103225895028361\n",
      "W1: 10.980233735529987 W2: 1.8875431801826947 b -5.758959843688967 Loss: 0.4103225892657154\n",
      "W1: 10.980243383916413 W2: 1.8875442312813229 b -5.758964741106314 Loss: 0.41032258902902874\n",
      "W1: 10.980253023469 W2: 1.8875452814184888 b -5.758969634040699 Loss: 0.4103225887927752\n",
      "W1: 10.980262654195851 W2: 1.8875463305950726 b -5.75897452249623 Loss: 0.41032258855695414\n",
      "W1: 10.98027227610506 W2: 1.8875473788119534 b -5.758979406477014 Loss: 0.4103225883215645\n",
      "W1: 10.980281889204711 W2: 1.88754842607001 b -5.758984285987152 Loss: 0.41032258808660593\n",
      "W1: 10.980291493502886 W2: 1.8875494723701196 b -5.758989161030742 Loss: 0.41032258785207715\n",
      "W1: 10.980301089007655 W2: 1.8875505177131593 b -5.758994031611879 Loss: 0.41032258761797774\n",
      "W1: 10.980310675727083 W2: 1.8875515621000052 b -5.758998897734653 Loss: 0.4103225873843066\n",
      "W1: 10.980320253669223 W2: 1.8875526055315324 b -5.759003759403151 Loss: 0.4103225871510633\n",
      "W1: 10.980329822842128 W2: 1.8875536480086155 b -5.759008616621456 Loss: 0.41032258691824686\n",
      "W1: 10.980339383253838 W2: 1.887554689532128 b -5.759013469393646 Loss: 0.4103225866858564\n",
      "W1: 10.98034893491239 W2: 1.8875557301029429 b -5.759018317723798 Loss: 0.41032258645389147\n",
      "W1: 10.980358477825808 W2: 1.887556769721932 b -5.759023161615983 Loss: 0.4103225862223509\n",
      "W1: 10.980368012002113 W2: 1.887557808389967 b -5.759028001074269 Loss: 0.4103225859912341\n",
      "W1: 10.980377537449318 W2: 1.8875588461079178 b -5.759032836102722 Loss: 0.41032258576054037\n",
      "W1: 10.980387054175425 W2: 1.8875598828766544 b -5.7590376667053995 Loss: 0.4103225855302688\n",
      "W1: 10.980396562188435 W2: 1.8875609186970457 b -5.75904249288636 Loss: 0.4103225853004187\n",
      "W1: 10.980406061496335 W2: 1.8875619535699595 b -5.759047314649656 Loss: 0.41032258507098923\n",
      "W1: 10.980415552107111 W2: 1.8875629874962632 b -5.759052131999338 Loss: 0.4103225848419797\n",
      "W1: 10.980425034028736 W2: 1.8875640204768234 b -5.75905694493945 Loss: 0.4103225846133892\n",
      "W1: 10.980434507269178 W2: 1.8875650525125056 b -5.759061753474036 Loss: 0.41032258438521724\n",
      "W1: 10.9804439718364 W2: 1.8875660836041748 b -5.759066557607132 Loss: 0.4103225841574627\n",
      "W1: 10.980453427738356 W2: 1.8875671137526948 b -5.759071357342774 Loss: 0.4103225839301251\n",
      "W1: 10.980462874982988 W2: 1.8875681429589293 b -5.759076152684991 Loss: 0.4103225837032035\n",
      "W1: 10.980472313578238 W2: 1.8875691712237406 b -5.759080943637812 Loss: 0.4103225834766972\n",
      "W1: 10.980481743532037 W2: 1.8875701985479902 b -5.75908573020526 Loss: 0.4103225832506055\n",
      "W1: 10.980491164852308 W2: 1.8875712249325394 b -5.759090512391353 Loss: 0.4103225830249276\n",
      "W1: 10.98050057754697 W2: 1.8875722503782482 b -5.759095290200109 Loss: 0.4103225827996626\n",
      "W1: 10.98050998162393 W2: 1.887573274885976 b -5.759100063635539 Loss: 0.4103225825748101\n",
      "W1: 10.980519377091094 W2: 1.887574298456581 b -5.759104832701652 Loss: 0.4103225823503689\n",
      "W1: 10.980528763956354 W2: 1.8875753210909214 b -5.759109597402453 Loss: 0.41032258212633843\n",
      "W1: 10.9805381422276 W2: 1.887576342789854 b -5.759114357741944 Loss: 0.41032258190271803\n",
      "W1: 10.980547511912711 W2: 1.887577363554235 b -5.759119113724121 Loss: 0.41032258167950686\n",
      "W1: 10.98055687301956 W2: 1.88757838338492 b -5.759123865352978 Loss: 0.41032258145670436\n",
      "W1: 10.980566225556016 W2: 1.8875794022827634 b -5.759128612632507 Loss: 0.4103225812343095\n",
      "W1: 10.980575569529936 W2: 1.8875804202486193 b -5.759133355566693 Loss: 0.4103225810123215\n",
      "W1: 10.980584904949172 W2: 1.8875814372833406 b -5.7591380941595185 Loss: 0.41032258079074\n",
      "W1: 10.980594231821568 W2: 1.8875824533877794 b -5.759142828414963 Loss: 0.410322580569564\n",
      "W1: 10.98060355015496 W2: 1.8875834685627875 b -5.759147558337003 Loss: 0.41032258034879265\n",
      "W1: 10.98061285995718 W2: 1.8875844828092154 b -5.759152283929609 Loss: 0.4103225801284255\n",
      "W1: 10.98062216123605 W2: 1.8875854961279133 b -5.759157005196751 Loss: 0.41032257990846155\n",
      "W1: 10.980631453999386 W2: 1.88758650851973 b -5.759161722142392 Loss: 0.4103225796889001\n",
      "W1: 10.980640738254996 W2: 1.8875875199855143 b -5.759166434770494 Loss: 0.41032257946974054\n",
      "W1: 10.980650014010681 W2: 1.8875885305261135 b -5.759171143085013 Loss: 0.41032257925098214\n",
      "W1: 10.980659281274237 W2: 1.8875895401423746 b -5.759175847089905 Loss: 0.41032257903262404\n",
      "W1: 10.980668540053449 W2: 1.8875905488351434 b -5.759180546789118 Loss: 0.41032257881466544\n",
      "W1: 10.980677790356095 W2: 1.8875915566052655 b -5.759185242186598 Loss: 0.41032257859710575\n",
      "W1: 10.980687032189952 W2: 1.8875925634535853 b -5.75918993328629 Loss: 0.4103225783799443\n",
      "W1: 10.980696265562782 W2: 1.8875935693809465 b -5.759194620092131 Loss: 0.4103225781631803\n",
      "W1: 10.980705490482345 W2: 1.887594574388192 b -5.759199302608058 Loss: 0.410322577946813\n",
      "W1: 10.980714706956391 W2: 1.887595578476164 b -5.759203980838003 Loss: 0.4103225777308417\n",
      "W1: 10.980723914992664 W2: 1.887596581645704 b -5.759208654785893 Loss: 0.4103225775152655\n",
      "W1: 10.980733114598902 W2: 1.8875975838976526 b -5.759213324455653 Loss: 0.4103225773000838\n",
      "W1: 10.980742305782833 W2: 1.8875985852328496 b -5.759217989851205 Loss: 0.41032257708529607\n",
      "W1: 10.980751488552182 W2: 1.8875995856521341 b -5.759222650976466 Loss: 0.41032257687090135\n",
      "W1: 10.980760662914662 W2: 1.8876005851563447 b -5.75922730783535 Loss: 0.410322576656899\n",
      "W1: 10.980769828877984 W2: 1.8876015837463187 b -5.759231960431767 Loss: 0.4103225764432883\n",
      "W1: 10.980778986449847 W2: 1.887602581422893 b -5.759236608769624 Loss: 0.4103225762300686\n",
      "W1: 10.980788135637948 W2: 1.8876035781869034 b -5.759241252852823 Loss: 0.41032257601723887\n",
      "W1: 10.980797276449971 W2: 1.8876045740391856 b -5.759245892685266 Loss: 0.41032257580479886\n",
      "W1: 10.9808064088936 W2: 1.8876055689805737 b -5.759250528270847 Loss: 0.4103225755927475\n",
      "W1: 10.980815532976505 W2: 1.8876065630119017 b -5.759255159613459 Loss: 0.41032257538108413\n",
      "W1: 10.980824648706355 W2: 1.8876075561340024 b -5.75925978671699 Loss: 0.41032257516980836\n",
      "W1: 10.980833756090805 W2: 1.887608548347708 b -5.7592644095853265 Loss: 0.41032257495891905\n",
      "W1: 10.980842855137508 W2: 1.8876095396538501 b -5.759269028222349 Loss: 0.41032257474841577\n",
      "W1: 10.980851945854111 W2: 1.8876105300532593 b -5.7592736426319355 Loss: 0.41032257453829774\n",
      "W1: 10.98086102824825 W2: 1.8876115195467653 b -5.759278252817961 Loss: 0.41032257432856417\n",
      "W1: 10.980870102327557 W2: 1.8876125081351975 b -5.759282858784297 Loss: 0.41032257411921447\n",
      "W1: 10.980879168099657 W2: 1.8876134958193842 b -5.75928746053481 Loss: 0.4103225739102479\n",
      "W1: 10.980888225572164 W2: 1.887614482600153 b -5.759292058073364 Loss: 0.4103225737016636\n",
      "W1: 10.980897274752689 W2: 1.887615468478331 b -5.75929665140382 Loss: 0.4103225734934613\n",
      "W1: 10.980906315648834 W2: 1.8876164534547442 b -5.759301240530034 Loss: 0.41032257328563976\n",
      "W1: 10.980915348268196 W2: 1.887617437530218 b -5.75930582545586 Loss: 0.4103225730781986\n",
      "W1: 10.980924372618363 W2: 1.8876184207055768 b -5.759310406185146 Loss: 0.4103225728711372\n",
      "W1: 10.980933388706918 W2: 1.8876194029816449 b -5.759314982721739 Loss: 0.41032257266445443\n",
      "W1: 10.980942396541433 W2: 1.887620384359245 b -5.7593195550694825 Loss: 0.41032257245815024\n",
      "W1: 10.98095139612948 W2: 1.8876213648391995 b -5.759324123232215 Loss: 0.4103225722522233\n",
      "W1: 10.980960387478618 W2: 1.8876223444223301 b -5.759328687213771 Loss: 0.4103225720466734\n",
      "W1: 10.9809693705964 W2: 1.8876233231094575 b -5.759333247017984 Loss: 0.4103225718414997\n",
      "W1: 10.980978345490374 W2: 1.8876243009014018 b -5.759337802648681 Loss: 0.4103225716367013\n",
      "W1: 10.98098731216808 W2: 1.8876252777989824 b -5.759342354109688 Loss: 0.41032257143227774\n",
      "W1: 10.980996270637052 W2: 1.887626253803018 b -5.759346901404827 Loss: 0.41032257122822835\n",
      "W1: 10.981005220904814 W2: 1.8876272289143263 b -5.759351444537915 Loss: 0.41032257102455233\n",
      "W1: 10.981014162978887 W2: 1.8876282031337246 b -5.759355983512766 Loss: 0.41032257082124896\n",
      "W1: 10.981023096866785 W2: 1.887629176462029 b -5.7593605183331915 Loss: 0.4103225706183178\n",
      "W1: 10.981032022576011 W2: 1.887630148900055 b -5.759365049002999 Loss: 0.41032257041575804\n",
      "W1: 10.981040940114065 W2: 1.8876311204486178 b -5.759369575525993 Loss: 0.4103225702135687\n",
      "W1: 10.981049849488437 W2: 1.8876320911085311 b -5.759374097905972 Loss: 0.4103225700117496\n",
      "W1: 10.981058750706614 W2: 1.8876330608806084 b -5.759378616146735 Loss: 0.41032256981029963\n",
      "W1: 10.981067643776072 W2: 1.8876340297656624 b -5.759383130252075 Loss: 0.4103225696092185\n",
      "W1: 10.981076528704282 W2: 1.8876349977645048 b -5.75938764022578 Loss: 0.41032256940850526\n",
      "W1: 10.98108540549871 W2: 1.8876359648779468 b -5.759392146071639 Loss: 0.41032256920815935\n",
      "W1: 10.981094274166812 W2: 1.8876369311067989 b -5.759396647793434 Loss: 0.41032256900818004\n",
      "W1: 10.98110313471604 W2: 1.8876378964518703 b -5.7594011453949445 Loss: 0.4103225688085667\n",
      "W1: 10.981111987153835 W2: 1.8876388609139703 b -5.759405638879946 Loss: 0.41032256860931854\n",
      "W1: 10.981120831487635 W2: 1.8876398244939068 b -5.759410128252212 Loss: 0.4103225684104352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: 10.98112966772487 W2: 1.8876407871924874 b -5.759414613515512 Loss: 0.41032256821191576\n",
      "W1: 10.981138495872964 W2: 1.8876417490105186 b -5.759419094673611 Loss: 0.4103225680137595\n",
      "W1: 10.981147315939332 W2: 1.8876427099488065 b -5.75942357173027 Loss: 0.41032256781596604\n",
      "W1: 10.981156127931383 W2: 1.887643670008156 b -5.759428044689249 Loss: 0.4103225676185344\n",
      "W1: 10.981164931856522 W2: 1.8876446291893718 b -5.759432513554304 Loss: 0.4103225674214641\n",
      "W1: 10.981173727722144 W2: 1.8876455874932576 b -5.759436978329186 Loss: 0.4103225672247543\n",
      "W1: 10.981182515535636 W2: 1.8876465449206163 b -5.7594414390176425 Loss: 0.4103225670284046\n",
      "W1: 10.981191295304383 W2: 1.88764750147225 b -5.759445895623419 Loss: 0.41032256683241425\n",
      "W1: 10.981200067035758 W2: 1.8876484571489605 b -5.759450348150258 Loss: 0.4103225666367825\n",
      "W1: 10.981208830737131 W2: 1.8876494119515483 b -5.759454796601897 Loss: 0.41032256644150866\n",
      "W1: 10.981217586415864 W2: 1.8876503658808137 b -5.75945924098207 Loss: 0.41032256624659236\n",
      "W1: 10.981226334079311 W2: 1.8876513189375557 b -5.759463681294509 Loss: 0.4103225660520327\n",
      "W1: 10.98123507373482 W2: 1.887652271122573 b -5.759468117542942 Loss: 0.41032256585782906\n",
      "W1: 10.981243805389736 W2: 1.8876532224366633 b -5.7594725497310915 Loss: 0.4103225656639806\n",
      "W1: 10.98125252905139 W2: 1.887654172880624 b -5.75947697786268 Loss: 0.4103225654704871\n",
      "W1: 10.981261244727113 W2: 1.8876551224552514 b -5.759481401941425 Loss: 0.4103225652773475\n",
      "W1: 10.981269952424224 W2: 1.887656071161341 b -5.75948582197104 Loss: 0.41032256508456144\n",
      "W1: 10.981278652150039 W2: 1.8876570189996877 b -5.759490237955236 Loss: 0.41032256489212815\n",
      "W1: 10.981287343911864 W2: 1.887657965971086 b -5.759494649897721 Loss: 0.41032256470004697\n",
      "W1: 10.981296027717004 W2: 1.887658912076329 b -5.759499057802197 Loss: 0.41032256450831744\n",
      "W1: 10.98130470357275 W2: 1.8876598573162096 b -5.759503461672366 Loss: 0.41032256431693864\n",
      "W1: 10.981313371486392 W2: 1.8876608016915197 b -5.759507861511924 Loss: 0.4103225641259101\n",
      "W1: 10.98132203146521 W2: 1.8876617452030509 b -5.759512257324565 Loss: 0.41032256393523103\n",
      "W1: 10.981330683516477 W2: 1.8876626878515932 b -5.75951664911398 Loss: 0.41032256374490106\n",
      "W1: 10.981339327647463 W2: 1.8876636296379368 b -5.759521036883855 Loss: 0.41032256355491925\n",
      "W1: 10.981347963865428 W2: 1.8876645705628707 b -5.759525420637875 Loss: 0.410322563365285\n",
      "W1: 10.981356592177626 W2: 1.8876655106271836 b -5.759529800379718 Loss: 0.41032256317599797\n",
      "W1: 10.981365212591305 W2: 1.8876664498316627 b -5.759534176113061 Loss: 0.4103225629870572\n",
      "W1: 10.981373825113707 W2: 1.8876673881770951 b -5.759538547841579 Loss: 0.41032256279846224\n",
      "W1: 10.981382429752065 W2: 1.8876683256642672 b -5.759542915568941 Loss: 0.4103225626102123\n",
      "W1: 10.981391026513608 W2: 1.8876692622939644 b -5.759547279298814 Loss: 0.4103225624223068\n",
      "W1: 10.981399615405556 W2: 1.8876701980669712 b -5.75955163903486 Loss: 0.4103225622347454\n",
      "W1: 10.981408196435122 W2: 1.887671132984072 b -5.759555994780739 Loss: 0.41032256204752693\n",
      "W1: 10.981416769609517 W2: 1.88767206704605 b -5.759560346540109 Loss: 0.41032256186065125\n",
      "W1: 10.98142533493594 W2: 1.887673000253688 b -5.759564694316622 Loss: 0.4103225616741174\n",
      "W1: 10.981433892421586 W2: 1.8876739326077674 b -5.759569038113929 Loss: 0.410322561487925\n",
      "W1: 10.981442442073643 W2: 1.88767486410907 b -5.759573377935674 Loss: 0.4103225613020733\n",
      "W1: 10.981450983899292 W2: 1.8876757947583758 b -5.759577713785503 Loss: 0.4103225611165616\n",
      "W1: 10.981459517905707 W2: 1.8876767245564647 b -5.759582045667054 Loss: 0.41032256093138936\n",
      "W1: 10.981468044100058 W2: 1.887677653504116 b -5.759586373583963 Loss: 0.4103225607465561\n",
      "W1: 10.981476562489506 W2: 1.8876785816021078 b -5.759590697539865 Loss: 0.41032256056206096\n",
      "W1: 10.981485073081204 W2: 1.8876795088512177 b -5.759595017538388 Loss: 0.41032256037790343\n",
      "W1: 10.981493575882302 W2: 1.8876804352522227 b -5.759599333583158 Loss: 0.410322560194083\n",
      "W1: 10.981502070899943 W2: 1.887681360805899 b -5.7596036456777995 Loss: 0.4103225600105988\n",
      "W1: 10.98151055814126 W2: 1.8876822855130222 b -5.759607953825932 Loss: 0.41032255982745036\n",
      "W1: 10.981519037613381 W2: 1.8876832093743667 b -5.759612258031171 Loss: 0.41032255964463715\n",
      "W1: 10.981527509323431 W2: 1.8876841323907068 b -5.759616558297131 Loss: 0.4103225594621584\n",
      "W1: 10.981535973278524 W2: 1.8876850545628159 b -5.75962085462742 Loss: 0.4103225592800135\n"
     ]
    }
   ],
   "source": [
    "cofficients = gradient_descent(X_train['age'], X_train['affordibility'], y_true= y_train, alpha=0.5, epochs=7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41ddb640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.398554492221438, 1.8258712762262244, -5.465560947094428)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cofficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f76e1250",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediciton = prediction_fun(cofficients,X_test['age'], X_test['affordibility'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "662d7fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediciton = categorical_output(prediciton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44def5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(prediciton != y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc77cb",
   "metadata": {},
   "source": [
    "## Tensorflow implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64be304d",
   "metadata": {},
   "source": [
    "#### Checking the cofficients of model form tensorflow implementation to compare it from our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f22f478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24eccd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=(2,), activation='sigmoid', kernel_initializer='ones', bias_initializer='zeros')\n",
    "])\n",
    "\n",
    "# kernel_initializer='ones' means weights = 1\n",
    "# bias_initializer='zeros' means bias = 0\n",
    "# so we are starting from same position as w1=w2=1 and bias = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7346478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.4344 - accuracy: 0.9091\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4344 - accuracy: 0.9091\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4344 - accuracy: 0.9091\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.9091\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.9091\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.9091\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.9091\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.9091\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.9091\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4342 - accuracy: 0.9091\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4342 - accuracy: 0.9091\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4342 - accuracy: 0.9091\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4342 - accuracy: 0.9091\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4342 - accuracy: 0.9091\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4342 - accuracy: 0.9091\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4342 - accuracy: 0.9091\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.9091\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.9091\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.9091\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.9091\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.9091\n",
      "Epoch 22/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.9091\n",
      "Epoch 23/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.9091\n",
      "Epoch 24/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.9091\n",
      "Epoch 25/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.9091\n",
      "Epoch 26/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.9091\n",
      "Epoch 27/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.9091\n",
      "Epoch 28/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.9091\n",
      "Epoch 29/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.9091\n",
      "Epoch 30/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.9091\n",
      "Epoch 31/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.9091\n",
      "Epoch 32/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.9091\n",
      "Epoch 33/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.9091\n",
      "Epoch 34/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4339 - accuracy: 0.9091\n",
      "Epoch 35/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4339 - accuracy: 0.9091\n",
      "Epoch 36/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4339 - accuracy: 0.9091\n",
      "Epoch 37/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4339 - accuracy: 0.9091\n",
      "Epoch 38/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.9091\n",
      "Epoch 39/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4338 - accuracy: 0.9091\n",
      "Epoch 40/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.9091\n",
      "Epoch 41/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.9091\n",
      "Epoch 42/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.9091\n",
      "Epoch 43/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.9091\n",
      "Epoch 44/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.9091\n",
      "Epoch 45/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4338 - accuracy: 0.9091\n",
      "Epoch 46/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.9091\n",
      "Epoch 47/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.9091\n",
      "Epoch 48/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.9091\n",
      "Epoch 49/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.9091\n",
      "Epoch 50/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4337 - accuracy: 0.9091\n",
      "Epoch 51/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4337 - accuracy: 0.9091\n",
      "Epoch 52/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4337 - accuracy: 0.9091\n",
      "Epoch 53/10000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.9091\n",
      "Epoch 54/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4336 - accuracy: 0.9091\n",
      "Epoch 55/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.9091\n",
      "Epoch 56/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4336 - accuracy: 0.9091\n",
      "Epoch 57/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4336 - accuracy: 0.9091\n",
      "Epoch 58/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.9091\n",
      "Epoch 59/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.9091\n",
      "Epoch 60/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.9091\n",
      "Epoch 61/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.9091\n",
      "Epoch 62/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.9091\n",
      "Epoch 63/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.9091\n",
      "Epoch 64/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.9091\n",
      "Epoch 65/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.9091\n",
      "Epoch 66/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.9091\n",
      "Epoch 67/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.9091\n",
      "Epoch 68/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4334 - accuracy: 0.9091\n",
      "Epoch 69/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.9091\n",
      "Epoch 70/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.9091\n",
      "Epoch 71/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4334 - accuracy: 0.9091\n",
      "Epoch 72/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4334 - accuracy: 0.9091\n",
      "Epoch 73/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4334 - accuracy: 0.9091\n",
      "Epoch 74/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4334 - accuracy: 0.9091\n",
      "Epoch 75/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.9091\n",
      "Epoch 76/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.9091\n",
      "Epoch 77/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.9091\n",
      "Epoch 78/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.9091\n",
      "Epoch 79/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.9091\n",
      "Epoch 80/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.9091\n",
      "Epoch 81/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.9091\n",
      "Epoch 82/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.9091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.9091\n",
      "Epoch 84/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.9091\n",
      "Epoch 85/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.9091\n",
      "Epoch 86/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.9091\n",
      "Epoch 87/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.9091\n",
      "Epoch 88/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.9091\n",
      "Epoch 89/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.9091\n",
      "Epoch 90/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.9091\n",
      "Epoch 91/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.9091\n",
      "Epoch 92/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.9091\n",
      "Epoch 93/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.9091\n",
      "Epoch 94/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.9091\n",
      "Epoch 95/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.9091\n",
      "Epoch 96/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.9091\n",
      "Epoch 97/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.9091\n",
      "Epoch 98/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.9091\n",
      "Epoch 99/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.9091\n",
      "Epoch 100/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.9091\n",
      "Epoch 101/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.9091\n",
      "Epoch 102/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.9091\n",
      "Epoch 103/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.9091\n",
      "Epoch 104/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4330 - accuracy: 0.9091\n",
      "Epoch 105/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.9091\n",
      "Epoch 106/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.9091\n",
      "Epoch 107/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.9091\n",
      "Epoch 108/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.9091\n",
      "Epoch 109/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.9091\n",
      "Epoch 110/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.9091\n",
      "Epoch 111/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.9091\n",
      "Epoch 112/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.9091\n",
      "Epoch 113/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.9091\n",
      "Epoch 114/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.9091\n",
      "Epoch 115/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.9091\n",
      "Epoch 116/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.9091\n",
      "Epoch 117/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.9091\n",
      "Epoch 118/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4328 - accuracy: 0.9091\n",
      "Epoch 119/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.9091\n",
      "Epoch 120/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.9091\n",
      "Epoch 121/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.9091\n",
      "Epoch 122/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.9091\n",
      "Epoch 123/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.9091\n",
      "Epoch 124/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.9091\n",
      "Epoch 125/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.9091\n",
      "Epoch 126/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.9091\n",
      "Epoch 127/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.9091\n",
      "Epoch 128/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.9091\n",
      "Epoch 129/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4327 - accuracy: 0.9091\n",
      "Epoch 130/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4327 - accuracy: 0.9091\n",
      "Epoch 131/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.9091\n",
      "Epoch 132/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.9091\n",
      "Epoch 133/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.9091\n",
      "Epoch 134/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.9091\n",
      "Epoch 135/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.9091\n",
      "Epoch 136/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.9091\n",
      "Epoch 137/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.9091\n",
      "Epoch 138/10000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4326 - accuracy: 0.9091\n",
      "Epoch 139/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.9091\n",
      "Epoch 140/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.9091\n",
      "Epoch 141/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.9091\n",
      "Epoch 142/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.9091\n",
      "Epoch 143/10000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.9091\n",
      "Epoch 144/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.9091\n",
      "Epoch 145/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.9091\n",
      "Epoch 146/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.9091\n",
      "Epoch 147/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.9091\n",
      "Epoch 148/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.9091\n",
      "Epoch 149/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.9091\n",
      "Epoch 150/10000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.9091\n",
      "Epoch 151/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.9091\n",
      "Epoch 152/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.9091\n",
      "Epoch 153/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.9091\n",
      "Epoch 154/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.9091\n",
      "Epoch 155/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.9091\n",
      "Epoch 156/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.9091\n",
      "Epoch 157/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.9091\n",
      "Epoch 158/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.9091\n",
      "Epoch 159/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.9091\n",
      "Epoch 160/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.9091\n",
      "Epoch 161/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.9091\n",
      "Epoch 162/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.9091\n",
      "Epoch 163/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.9091\n",
      "Epoch 164/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.9091\n",
      "Epoch 165/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.9091\n",
      "Epoch 166/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.9091\n",
      "Epoch 167/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.9091\n",
      "Epoch 168/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.9091\n",
      "Epoch 169/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.9091\n",
      "Epoch 170/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.9091\n",
      "Epoch 171/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.9091\n",
      "Epoch 172/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.9091\n",
      "Epoch 173/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.9091\n",
      "Epoch 174/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.9091\n",
      "Epoch 175/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.9091\n",
      "Epoch 176/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.9091\n",
      "Epoch 177/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.9091\n",
      "Epoch 178/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.9091\n",
      "Epoch 179/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.9091\n",
      "Epoch 180/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.9091\n",
      "Epoch 181/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.9091\n",
      "Epoch 182/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.9091\n",
      "Epoch 183/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.9091\n",
      "Epoch 184/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.9091\n",
      "Epoch 185/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.9091\n",
      "Epoch 186/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.9091\n",
      "Epoch 187/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.9091\n",
      "Epoch 188/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.9091\n",
      "Epoch 189/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.9091\n",
      "Epoch 190/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.9091\n",
      "Epoch 191/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.9091\n",
      "Epoch 192/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.9091\n",
      "Epoch 193/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.9091\n",
      "Epoch 194/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.9091\n",
      "Epoch 195/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.9091\n",
      "Epoch 196/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.9091\n",
      "Epoch 197/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.9091\n",
      "Epoch 198/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.9091\n",
      "Epoch 199/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.9091\n",
      "Epoch 200/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.9091\n",
      "Epoch 201/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.9091\n",
      "Epoch 202/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.9091\n",
      "Epoch 203/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.9091\n",
      "Epoch 204/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.9091\n",
      "Epoch 205/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.9091\n",
      "Epoch 206/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.9091\n",
      "Epoch 207/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4317 - accuracy: 0.9091\n",
      "Epoch 208/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.9091\n",
      "Epoch 209/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.9091\n",
      "Epoch 210/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.9091\n",
      "Epoch 211/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.9091\n",
      "Epoch 212/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.9091\n",
      "Epoch 213/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.9091\n",
      "Epoch 214/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.9091\n",
      "Epoch 215/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.9091\n",
      "Epoch 216/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.9091\n",
      "Epoch 217/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.9091\n",
      "Epoch 218/10000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.9091\n",
      "Epoch 219/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.9091\n",
      "Epoch 220/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.9091\n",
      "Epoch 221/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.9091\n",
      "Epoch 222/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.9091\n",
      "Epoch 223/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.9091\n",
      "Epoch 224/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.9091\n",
      "Epoch 225/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.9091\n",
      "Epoch 226/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.9091\n",
      "Epoch 227/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.9091\n",
      "Epoch 228/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.9091\n",
      "Epoch 229/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.9091\n",
      "Epoch 230/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.9091\n",
      "Epoch 231/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.9091\n",
      "Epoch 232/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.9091\n",
      "Epoch 233/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.9091\n",
      "Epoch 234/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.9091\n",
      "Epoch 235/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.9091\n",
      "Epoch 236/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.9091\n",
      "Epoch 237/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.9091\n",
      "Epoch 238/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.9091\n",
      "Epoch 239/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.9091\n",
      "Epoch 240/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.9091\n",
      "Epoch 241/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.9091\n",
      "Epoch 242/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.9091\n",
      "Epoch 243/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.9091\n",
      "Epoch 244/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4313 - accuracy: 0.9091\n",
      "Epoch 245/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.9091\n",
      "Epoch 246/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4313 - accuracy: 0.9091\n",
      "Epoch 247/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4313 - accuracy: 0.9091\n",
      "Epoch 248/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.9091\n",
      "Epoch 249/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.9091\n",
      "Epoch 250/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.9091\n",
      "Epoch 251/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.9091\n",
      "Epoch 252/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.9091\n",
      "Epoch 253/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.9091\n",
      "Epoch 254/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.9091\n",
      "Epoch 255/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.9091\n",
      "Epoch 256/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.9091\n",
      "Epoch 257/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.9091\n",
      "Epoch 258/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.9091\n",
      "Epoch 259/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.9091\n",
      "Epoch 260/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4311 - accuracy: 0.9091\n",
      "Epoch 261/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.9091\n",
      "Epoch 262/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.9091\n",
      "Epoch 263/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.9091\n",
      "Epoch 264/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.9091\n",
      "Epoch 265/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.9091\n",
      "Epoch 266/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.9091\n",
      "Epoch 267/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.9091\n",
      "Epoch 268/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.9091\n",
      "Epoch 269/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.9091\n",
      "Epoch 270/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4310 - accuracy: 0.9091\n",
      "Epoch 271/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.9091\n",
      "Epoch 272/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.9091\n",
      "Epoch 273/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.9091\n",
      "Epoch 274/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.9091\n",
      "Epoch 275/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.9091\n",
      "Epoch 276/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.9091\n",
      "Epoch 277/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.9091\n",
      "Epoch 278/10000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.9091\n",
      "Epoch 279/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4309 - accuracy: 0.9091\n",
      "Epoch 280/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.9091\n",
      "Epoch 281/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.9091\n",
      "Epoch 282/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.9091\n",
      "Epoch 283/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.9091\n",
      "Epoch 284/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.9091\n",
      "Epoch 285/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.9091\n",
      "Epoch 286/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.9091\n",
      "Epoch 287/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4308 - accuracy: 0.9091\n",
      "Epoch 288/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.9091\n",
      "Epoch 289/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.9091\n",
      "Epoch 290/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.9091\n",
      "Epoch 291/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.9091\n",
      "Epoch 292/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.9091\n",
      "Epoch 293/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.9091\n",
      "Epoch 294/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4307 - accuracy: 0.9091\n",
      "Epoch 295/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.9091\n",
      "Epoch 296/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.9091\n",
      "Epoch 297/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.9091\n",
      "Epoch 298/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.9091\n",
      "Epoch 299/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.9091\n",
      "Epoch 300/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.9091\n",
      "Epoch 301/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.9091\n",
      "Epoch 302/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4306 - accuracy: 0.9091\n",
      "Epoch 303/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4306 - accuracy: 0.9091\n",
      "Epoch 304/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4306 - accuracy: 0.9091\n",
      "Epoch 305/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.9091\n",
      "Epoch 306/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.9091\n",
      "Epoch 307/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.9091\n",
      "Epoch 308/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.9091\n",
      "Epoch 309/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4306 - accuracy: 0.9091\n",
      "Epoch 310/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.9091\n",
      "Epoch 311/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4305 - accuracy: 0.9091\n",
      "Epoch 312/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4305 - accuracy: 0.9091\n",
      "Epoch 313/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4305 - accuracy: 0.9091\n",
      "Epoch 314/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.9091\n",
      "Epoch 315/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.9091\n",
      "Epoch 316/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.9091\n",
      "Epoch 317/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.9091\n",
      "Epoch 318/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.9091\n",
      "Epoch 319/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.9091\n",
      "Epoch 320/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.9091\n",
      "Epoch 321/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.9091\n",
      "Epoch 322/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.9091\n",
      "Epoch 323/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.9091\n",
      "Epoch 324/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.9091\n",
      "Epoch 325/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.9091\n",
      "Epoch 326/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.9091\n",
      "Epoch 327/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.9091\n",
      "Epoch 328/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4303 - accuracy: 0.9091\n",
      "Epoch 329/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.9091\n",
      "Epoch 330/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.9091\n",
      "Epoch 331/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.9091\n",
      "Epoch 332/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.9091\n",
      "Epoch 333/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.9091\n",
      "Epoch 334/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.9091\n",
      "Epoch 335/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.9091\n",
      "Epoch 336/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.9091\n",
      "Epoch 337/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4302 - accuracy: 0.9091\n",
      "Epoch 338/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4302 - accuracy: 0.9091\n",
      "Epoch 339/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4302 - accuracy: 0.9091\n",
      "Epoch 340/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4302 - accuracy: 0.9091\n",
      "Epoch 341/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4302 - accuracy: 0.9091\n",
      "Epoch 342/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4302 - accuracy: 0.9091\n",
      "Epoch 343/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4302 - accuracy: 0.9091\n",
      "Epoch 344/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4302 - accuracy: 0.9091\n",
      "Epoch 345/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.9091\n",
      "Epoch 346/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.9091\n",
      "Epoch 347/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.9091\n",
      "Epoch 348/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.9091\n",
      "Epoch 349/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.9091\n",
      "Epoch 350/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.9091\n",
      "Epoch 351/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.9091\n",
      "Epoch 352/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.9091\n",
      "Epoch 353/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.9091\n",
      "Epoch 354/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.9091\n",
      "Epoch 355/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.9091\n",
      "Epoch 356/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.9091\n",
      "Epoch 357/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.9091\n",
      "Epoch 358/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.9091\n",
      "Epoch 359/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.9091\n",
      "Epoch 360/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.9091\n",
      "Epoch 361/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.9091\n",
      "Epoch 362/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.9091\n",
      "Epoch 363/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.9091\n",
      "Epoch 364/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.9091\n",
      "Epoch 365/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.9091\n",
      "Epoch 366/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.9091\n",
      "Epoch 367/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.9091\n",
      "Epoch 368/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.9091\n",
      "Epoch 369/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.9091\n",
      "Epoch 370/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.9091\n",
      "Epoch 371/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.9091\n",
      "Epoch 372/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.9091\n",
      "Epoch 373/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.9091\n",
      "Epoch 374/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.9091\n",
      "Epoch 375/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.9091\n",
      "Epoch 376/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.9091\n",
      "Epoch 377/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.9091\n",
      "Epoch 378/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.9091\n",
      "Epoch 379/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.9091\n",
      "Epoch 380/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.9091\n",
      "Epoch 381/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.9091\n",
      "Epoch 382/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.9091\n",
      "Epoch 383/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4297 - accuracy: 0.9091\n",
      "Epoch 384/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4297 - accuracy: 0.9091\n",
      "Epoch 385/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.9091\n",
      "Epoch 386/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.9091\n",
      "Epoch 387/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.9091\n",
      "Epoch 388/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.9091\n",
      "Epoch 389/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.9091\n",
      "Epoch 390/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.9091\n",
      "Epoch 391/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.9091\n",
      "Epoch 392/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.9091\n",
      "Epoch 393/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.9091\n",
      "Epoch 394/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.9091\n",
      "Epoch 395/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.9091\n",
      "Epoch 396/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.9091\n",
      "Epoch 397/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.9091\n",
      "Epoch 398/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.9091\n",
      "Epoch 399/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.9091\n",
      "Epoch 400/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.9091\n",
      "Epoch 401/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.9091\n",
      "Epoch 402/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.9091\n",
      "Epoch 403/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.9091\n",
      "Epoch 404/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.9091\n",
      "Epoch 405/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.9091\n",
      "Epoch 406/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.9091\n",
      "Epoch 407/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.9091\n",
      "Epoch 408/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.9091\n",
      "Epoch 409/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.9091\n",
      "Epoch 410/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.9091\n",
      "Epoch 411/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4294 - accuracy: 0.9091\n",
      "Epoch 412/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4294 - accuracy: 0.9091\n",
      "Epoch 413/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4294 - accuracy: 0.9091\n",
      "Epoch 414/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.9091\n",
      "Epoch 415/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.9091\n",
      "Epoch 416/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.9091\n",
      "Epoch 417/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.9091\n",
      "Epoch 418/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.9091\n",
      "Epoch 419/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4294 - accuracy: 0.9091\n",
      "Epoch 420/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4294 - accuracy: 0.9091\n",
      "Epoch 421/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.9091\n",
      "Epoch 422/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.9091\n",
      "Epoch 423/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.9091\n",
      "Epoch 424/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.9091\n",
      "Epoch 425/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.9091\n",
      "Epoch 426/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.9091\n",
      "Epoch 427/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.9091\n",
      "Epoch 428/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.9091\n",
      "Epoch 429/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.9091\n",
      "Epoch 430/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.9091\n",
      "Epoch 431/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.9091\n",
      "Epoch 432/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.9091\n",
      "Epoch 433/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.9091\n",
      "Epoch 434/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.9091\n",
      "Epoch 435/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.9091\n",
      "Epoch 436/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.9091\n",
      "Epoch 437/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.9091\n",
      "Epoch 438/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.9091\n",
      "Epoch 439/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.9091\n",
      "Epoch 440/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4291 - accuracy: 0.9091\n",
      "Epoch 441/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.9091\n",
      "Epoch 442/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.9091\n",
      "Epoch 443/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.9091\n",
      "Epoch 444/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.9091\n",
      "Epoch 445/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.9091\n",
      "Epoch 446/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.9091\n",
      "Epoch 447/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4291 - accuracy: 0.9091\n",
      "Epoch 448/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4291 - accuracy: 0.9091\n",
      "Epoch 449/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.9091\n",
      "Epoch 450/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4290 - accuracy: 0.9091\n",
      "Epoch 451/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.9091\n",
      "Epoch 452/10000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.9091\n",
      "Epoch 453/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.9091\n",
      "Epoch 454/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.9091\n",
      "Epoch 455/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.9091\n",
      "Epoch 456/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.9091\n",
      "Epoch 457/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.9091\n",
      "Epoch 458/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.9091\n",
      "Epoch 459/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.9091\n",
      "Epoch 460/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.9091\n",
      "Epoch 461/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.9091\n",
      "Epoch 462/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.9091\n",
      "Epoch 463/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.9091\n",
      "Epoch 464/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.9091\n",
      "Epoch 465/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.9091\n",
      "Epoch 466/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.9091\n",
      "Epoch 467/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.9091\n",
      "Epoch 468/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.9091\n",
      "Epoch 469/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.9091\n",
      "Epoch 470/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.9091\n",
      "Epoch 471/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.9091\n",
      "Epoch 472/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.9091\n",
      "Epoch 473/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.9091\n",
      "Epoch 474/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.9091\n",
      "Epoch 475/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.9091\n",
      "Epoch 476/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.9091\n",
      "Epoch 477/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.9091\n",
      "Epoch 478/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.9091\n",
      "Epoch 479/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.9091\n",
      "Epoch 480/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.9091\n",
      "Epoch 481/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.9091\n",
      "Epoch 482/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.9091\n",
      "Epoch 483/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.9091\n",
      "Epoch 484/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.9091\n",
      "Epoch 485/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.9091\n",
      "Epoch 486/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.9091\n",
      "Epoch 487/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.9091\n",
      "Epoch 488/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.9091\n",
      "Epoch 489/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.9091\n",
      "Epoch 490/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.9091\n",
      "Epoch 491/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.9091\n",
      "Epoch 492/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.9091\n",
      "Epoch 493/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.9091\n",
      "Epoch 494/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.9091\n",
      "Epoch 495/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.9091\n",
      "Epoch 496/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.9091\n",
      "Epoch 497/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4286 - accuracy: 0.9091\n",
      "Epoch 498/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.9091\n",
      "Epoch 499/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.9091\n",
      "Epoch 500/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.9091\n",
      "Epoch 501/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.9091\n",
      "Epoch 502/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.9091\n",
      "Epoch 503/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.9091\n",
      "Epoch 504/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.9091\n",
      "Epoch 505/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.9091\n",
      "Epoch 506/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.9091\n",
      "Epoch 507/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.9091\n",
      "Epoch 508/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.9091\n",
      "Epoch 509/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.9091\n",
      "Epoch 510/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.9091\n",
      "Epoch 511/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.9091\n",
      "Epoch 512/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.9091\n",
      "Epoch 513/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.9091\n",
      "Epoch 514/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.9091\n",
      "Epoch 515/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.9091\n",
      "Epoch 516/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.9091\n",
      "Epoch 517/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.9091\n",
      "Epoch 518/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4283 - accuracy: 0.9091\n",
      "Epoch 519/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4283 - accuracy: 0.9091\n",
      "Epoch 520/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.9091\n",
      "Epoch 521/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.9091\n",
      "Epoch 522/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.9091\n",
      "Epoch 523/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.9091\n",
      "Epoch 524/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.9091\n",
      "Epoch 525/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.9091\n",
      "Epoch 526/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4283 - accuracy: 0.9091\n",
      "Epoch 527/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4283 - accuracy: 0.9091\n",
      "Epoch 528/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.9091\n",
      "Epoch 529/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.9091\n",
      "Epoch 530/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.9091\n",
      "Epoch 531/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.9091\n",
      "Epoch 532/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.9091\n",
      "Epoch 533/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.9091\n",
      "Epoch 534/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.9091\n",
      "Epoch 535/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.9091\n",
      "Epoch 536/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.9091\n",
      "Epoch 537/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.9091\n",
      "Epoch 538/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.9091\n",
      "Epoch 539/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.9091\n",
      "Epoch 540/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.9091\n",
      "Epoch 541/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.9091\n",
      "Epoch 542/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.9091\n",
      "Epoch 543/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.9091\n",
      "Epoch 544/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.9091\n",
      "Epoch 545/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.9091\n",
      "Epoch 546/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.9091\n",
      "Epoch 547/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.9091\n",
      "Epoch 548/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.9091\n",
      "Epoch 549/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.9091\n",
      "Epoch 550/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.9091\n",
      "Epoch 551/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.9091\n",
      "Epoch 552/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.9091\n",
      "Epoch 553/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.9091\n",
      "Epoch 554/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.9091\n",
      "Epoch 555/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4280 - accuracy: 0.9091\n",
      "Epoch 556/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.9091\n",
      "Epoch 557/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4280 - accuracy: 0.9091\n",
      "Epoch 558/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.9091\n",
      "Epoch 559/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.9091\n",
      "Epoch 560/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.9091\n",
      "Epoch 561/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.9091\n",
      "Epoch 562/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.9091\n",
      "Epoch 563/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.9091\n",
      "Epoch 564/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.9091\n",
      "Epoch 565/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.9091\n",
      "Epoch 566/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.9091\n",
      "Epoch 567/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.9091\n",
      "Epoch 568/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.9091\n",
      "Epoch 569/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.9091\n",
      "Epoch 570/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.9091\n",
      "Epoch 571/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.9091\n",
      "Epoch 572/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.9091\n",
      "Epoch 573/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.9091\n",
      "Epoch 574/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.9091\n",
      "Epoch 575/10000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4278 - accuracy: 0.9091\n",
      "Epoch 576/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.9091\n",
      "Epoch 577/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.9091\n",
      "Epoch 578/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.9091\n",
      "Epoch 579/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.9091\n",
      "Epoch 580/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.9091\n",
      "Epoch 581/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.9091\n",
      "Epoch 582/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4277 - accuracy: 0.9091\n",
      "Epoch 583/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.9091\n",
      "Epoch 584/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.9091\n",
      "Epoch 585/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.9091\n",
      "Epoch 586/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4277 - accuracy: 0.9091\n",
      "Epoch 587/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.9091\n",
      "Epoch 588/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.9091\n",
      "Epoch 589/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.9091\n",
      "Epoch 590/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.9091\n",
      "Epoch 591/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.9091\n",
      "Epoch 592/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.9091\n",
      "Epoch 593/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.9091\n",
      "Epoch 594/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.9091\n",
      "Epoch 595/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.9091\n",
      "Epoch 596/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.9091\n",
      "Epoch 597/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.9091\n",
      "Epoch 598/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.9091\n",
      "Epoch 599/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.9091\n",
      "Epoch 600/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.9091\n",
      "Epoch 601/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.9091\n",
      "Epoch 602/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.9091\n",
      "Epoch 603/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.9091\n",
      "Epoch 604/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.9091\n",
      "Epoch 605/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.9091\n",
      "Epoch 606/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.9091\n",
      "Epoch 607/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.9091\n",
      "Epoch 608/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.9091\n",
      "Epoch 609/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.9091\n",
      "Epoch 610/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.9091\n",
      "Epoch 611/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.9091\n",
      "Epoch 612/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.9091\n",
      "Epoch 613/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.9091\n",
      "Epoch 614/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.9091\n",
      "Epoch 615/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.9091\n",
      "Epoch 616/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.9091\n",
      "Epoch 617/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.9091\n",
      "Epoch 618/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.9091\n",
      "Epoch 619/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.9091\n",
      "Epoch 620/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.9091\n",
      "Epoch 621/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.9091\n",
      "Epoch 622/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.9091\n",
      "Epoch 623/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.9091\n",
      "Epoch 624/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.9091\n",
      "Epoch 625/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.9091\n",
      "Epoch 626/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.9091\n",
      "Epoch 627/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.9091\n",
      "Epoch 628/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.9091\n",
      "Epoch 629/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.9091\n",
      "Epoch 630/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4272 - accuracy: 0.9091\n",
      "Epoch 631/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4272 - accuracy: 0.9091\n",
      "Epoch 632/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4272 - accuracy: 0.9091\n",
      "Epoch 633/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.9091\n",
      "Epoch 634/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.9091\n",
      "Epoch 635/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4272 - accuracy: 0.9091\n",
      "Epoch 636/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.9091\n",
      "Epoch 637/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4272 - accuracy: 0.9091\n",
      "Epoch 638/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.9091\n",
      "Epoch 639/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.9091\n",
      "Epoch 640/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.9091\n",
      "Epoch 641/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.9091\n",
      "Epoch 642/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.9091\n",
      "Epoch 643/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.9091\n",
      "Epoch 644/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.9091\n",
      "Epoch 645/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.9091\n",
      "Epoch 646/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.9091\n",
      "Epoch 647/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.9091\n",
      "Epoch 648/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.9091\n",
      "Epoch 649/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.9091\n",
      "Epoch 650/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.9091\n",
      "Epoch 651/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.9091\n",
      "Epoch 652/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4270 - accuracy: 0.9091\n",
      "Epoch 653/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.9091\n",
      "Epoch 654/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.9091\n",
      "Epoch 655/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.9091\n",
      "Epoch 656/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.9091\n",
      "Epoch 657/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.9091\n",
      "Epoch 658/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.9091\n",
      "Epoch 659/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.9091\n",
      "Epoch 660/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.9091\n",
      "Epoch 661/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.9091\n",
      "Epoch 662/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.9091\n",
      "Epoch 663/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.9091\n",
      "Epoch 664/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.9091\n",
      "Epoch 665/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.9091\n",
      "Epoch 666/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.9091\n",
      "Epoch 667/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.9091\n",
      "Epoch 668/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.9091\n",
      "Epoch 669/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.9091\n",
      "Epoch 670/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.9091\n",
      "Epoch 671/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.9091\n",
      "Epoch 672/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.9091\n",
      "Epoch 673/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.9091\n",
      "Epoch 674/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.9091\n",
      "Epoch 675/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.9091\n",
      "Epoch 676/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.9091\n",
      "Epoch 677/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.9091\n",
      "Epoch 678/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.9091\n",
      "Epoch 679/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.9091\n",
      "Epoch 680/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.9091\n",
      "Epoch 681/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.9091\n",
      "Epoch 682/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.9091\n",
      "Epoch 683/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.9091\n",
      "Epoch 684/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.9091\n",
      "Epoch 685/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.9091\n",
      "Epoch 686/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.9091\n",
      "Epoch 687/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.9091\n",
      "Epoch 688/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.9091\n",
      "Epoch 689/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.9091\n",
      "Epoch 690/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.9091\n",
      "Epoch 691/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.9091\n",
      "Epoch 692/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.9091\n",
      "Epoch 693/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.9091\n",
      "Epoch 694/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.9091\n",
      "Epoch 695/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.9091\n",
      "Epoch 696/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.9091\n",
      "Epoch 697/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.9091\n",
      "Epoch 698/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.9091\n",
      "Epoch 699/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.9091\n",
      "Epoch 700/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.9091\n",
      "Epoch 701/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.9091\n",
      "Epoch 702/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.9091\n",
      "Epoch 703/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.9091\n",
      "Epoch 704/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.9091\n",
      "Epoch 705/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.9091\n",
      "Epoch 706/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.9091\n",
      "Epoch 707/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.9091\n",
      "Epoch 708/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.9091\n",
      "Epoch 709/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.9091\n",
      "Epoch 710/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.9091\n",
      "Epoch 711/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.9091\n",
      "Epoch 712/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.9091\n",
      "Epoch 713/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.9091\n",
      "Epoch 714/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.9091\n",
      "Epoch 715/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.9091\n",
      "Epoch 716/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.9091\n",
      "Epoch 717/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.9091\n",
      "Epoch 718/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.9091\n",
      "Epoch 719/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.9091\n",
      "Epoch 720/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4264 - accuracy: 0.9091\n",
      "Epoch 721/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.9091\n",
      "Epoch 722/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.9091\n",
      "Epoch 723/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.9091\n",
      "Epoch 724/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.9091\n",
      "Epoch 725/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.9091\n",
      "Epoch 726/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4263 - accuracy: 0.9091\n",
      "Epoch 727/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4263 - accuracy: 0.9091\n",
      "Epoch 728/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4263 - accuracy: 0.9091\n",
      "Epoch 729/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.9091\n",
      "Epoch 730/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.9091\n",
      "Epoch 731/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.9091\n",
      "Epoch 732/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.9091\n",
      "Epoch 733/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.9091\n",
      "Epoch 734/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.9091\n",
      "Epoch 735/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.9091\n",
      "Epoch 736/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4263 - accuracy: 0.9091\n",
      "Epoch 737/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4262 - accuracy: 0.9091\n",
      "Epoch 738/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4262 - accuracy: 0.9091\n",
      "Epoch 739/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.9091\n",
      "Epoch 740/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.9091\n",
      "Epoch 741/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.9091\n",
      "Epoch 742/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4262 - accuracy: 0.9091\n",
      "Epoch 743/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.9091\n",
      "Epoch 744/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4262 - accuracy: 0.9091\n",
      "Epoch 745/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.9091\n",
      "Epoch 746/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.9091\n",
      "Epoch 747/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4262 - accuracy: 0.9091\n",
      "Epoch 748/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4262 - accuracy: 0.9091\n",
      "Epoch 749/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4261 - accuracy: 0.9091\n",
      "Epoch 750/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4261 - accuracy: 0.9091\n",
      "Epoch 751/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4261 - accuracy: 0.9091\n",
      "Epoch 752/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.9091\n",
      "Epoch 753/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.9091\n",
      "Epoch 754/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.9091\n",
      "Epoch 755/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4261 - accuracy: 0.9091\n",
      "Epoch 756/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4261 - accuracy: 0.9091\n",
      "Epoch 757/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.9091\n",
      "Epoch 758/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4261 - accuracy: 0.9091\n",
      "Epoch 759/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4261 - accuracy: 0.9091\n",
      "Epoch 760/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4260 - accuracy: 0.9091\n",
      "Epoch 761/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.9091\n",
      "Epoch 762/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.9091\n",
      "Epoch 763/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.9091\n",
      "Epoch 764/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.9091\n",
      "Epoch 765/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.9091\n",
      "Epoch 766/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4260 - accuracy: 0.9091\n",
      "Epoch 767/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4260 - accuracy: 0.9091\n",
      "Epoch 768/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.9091\n",
      "Epoch 769/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4260 - accuracy: 0.9091\n",
      "Epoch 770/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.9091\n",
      "Epoch 771/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.9091\n",
      "Epoch 772/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.9091\n",
      "Epoch 773/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.9091\n",
      "Epoch 774/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.9091\n",
      "Epoch 775/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.9091\n",
      "Epoch 776/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.9091\n",
      "Epoch 777/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.9091\n",
      "Epoch 778/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4259 - accuracy: 0.9091\n",
      "Epoch 779/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4259 - accuracy: 0.9091\n",
      "Epoch 780/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4259 - accuracy: 0.9091\n",
      "Epoch 781/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.9091\n",
      "Epoch 782/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.9091\n",
      "Epoch 783/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4258 - accuracy: 0.9091\n",
      "Epoch 784/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4258 - accuracy: 0.9091\n",
      "Epoch 785/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4258 - accuracy: 0.9091\n",
      "Epoch 786/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.9091\n",
      "Epoch 787/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.9091\n",
      "Epoch 788/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.9091\n",
      "Epoch 789/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.9091\n",
      "Epoch 790/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.9091\n",
      "Epoch 791/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.9091\n",
      "Epoch 792/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.9091\n",
      "Epoch 793/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.9091\n",
      "Epoch 794/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.9091\n",
      "Epoch 795/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.9091\n",
      "Epoch 796/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.9091\n",
      "Epoch 797/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.9091\n",
      "Epoch 798/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.9091\n",
      "Epoch 799/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4257 - accuracy: 0.9091\n",
      "Epoch 800/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.9091\n",
      "Epoch 801/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.9091\n",
      "Epoch 802/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.9091\n",
      "Epoch 803/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.9091\n",
      "Epoch 804/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.9091\n",
      "Epoch 805/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4256 - accuracy: 0.9091\n",
      "Epoch 806/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.9091\n",
      "Epoch 807/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4256 - accuracy: 0.9091\n",
      "Epoch 808/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.9091\n",
      "Epoch 809/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4256 - accuracy: 0.9091\n",
      "Epoch 810/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4256 - accuracy: 0.9091\n",
      "Epoch 811/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.9091\n",
      "Epoch 812/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4256 - accuracy: 0.9091\n",
      "Epoch 813/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4256 - accuracy: 0.9091\n",
      "Epoch 814/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4256 - accuracy: 0.9091\n",
      "Epoch 815/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.9091\n",
      "Epoch 816/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.9091\n",
      "Epoch 817/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.9091\n",
      "Epoch 818/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4255 - accuracy: 0.9091\n",
      "Epoch 819/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.9091\n",
      "Epoch 820/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4255 - accuracy: 0.9091\n",
      "Epoch 821/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4255 - accuracy: 0.9091\n",
      "Epoch 822/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4255 - accuracy: 0.9091\n",
      "Epoch 823/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4255 - accuracy: 0.9091\n",
      "Epoch 824/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4255 - accuracy: 0.9091\n",
      "Epoch 825/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4255 - accuracy: 0.9091\n",
      "Epoch 826/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.9091\n",
      "Epoch 827/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4255 - accuracy: 0.9091\n",
      "Epoch 828/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.9091\n",
      "Epoch 829/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.9091\n",
      "Epoch 830/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.8636\n",
      "Epoch 831/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8636\n",
      "Epoch 832/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8636\n",
      "Epoch 833/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.8636\n",
      "Epoch 834/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8636\n",
      "Epoch 835/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8636\n",
      "Epoch 836/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8636\n",
      "Epoch 837/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.8636\n",
      "Epoch 838/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8636\n",
      "Epoch 839/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.8636\n",
      "Epoch 840/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.8636\n",
      "Epoch 841/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.8636\n",
      "Epoch 842/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4253 - accuracy: 0.8636\n",
      "Epoch 843/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4253 - accuracy: 0.8636\n",
      "Epoch 844/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4253 - accuracy: 0.8636\n",
      "Epoch 845/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.8636\n",
      "Epoch 846/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4253 - accuracy: 0.8636\n",
      "Epoch 847/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.8636\n",
      "Epoch 848/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4253 - accuracy: 0.8636\n",
      "Epoch 849/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4253 - accuracy: 0.8636\n",
      "Epoch 850/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4253 - accuracy: 0.8636\n",
      "Epoch 851/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4252 - accuracy: 0.8636\n",
      "Epoch 852/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4252 - accuracy: 0.8636\n",
      "Epoch 853/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4252 - accuracy: 0.8636\n",
      "Epoch 854/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8636\n",
      "Epoch 855/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8636\n",
      "Epoch 856/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8636\n",
      "Epoch 857/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8636\n",
      "Epoch 858/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8636\n",
      "Epoch 859/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4252 - accuracy: 0.8636\n",
      "Epoch 860/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4252 - accuracy: 0.8636\n",
      "Epoch 861/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8636\n",
      "Epoch 862/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.8636\n",
      "Epoch 863/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.8636\n",
      "Epoch 864/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.8636\n",
      "Epoch 865/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.8636\n",
      "Epoch 866/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8636\n",
      "Epoch 867/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8636\n",
      "Epoch 868/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.8636\n",
      "Epoch 869/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8636\n",
      "Epoch 870/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.8636\n",
      "Epoch 871/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.8636\n",
      "Epoch 872/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8636\n",
      "Epoch 873/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8636\n",
      "Epoch 874/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.8636\n",
      "Epoch 875/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.8636\n",
      "Epoch 876/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8636\n",
      "Epoch 877/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.8636\n",
      "Epoch 878/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8636\n",
      "Epoch 879/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8636\n",
      "Epoch 880/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4250 - accuracy: 0.8636\n",
      "Epoch 881/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8636\n",
      "Epoch 882/10000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4250 - accuracy: 0.8636\n",
      "Epoch 883/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8636\n",
      "Epoch 884/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.8636\n",
      "Epoch 885/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.8636\n",
      "Epoch 886/10000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8636\n",
      "Epoch 887/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.8636\n",
      "Epoch 888/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4249 - accuracy: 0.8636\n",
      "Epoch 889/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8636\n",
      "Epoch 890/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4249 - accuracy: 0.8636\n",
      "Epoch 891/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8636\n",
      "Epoch 892/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8636\n",
      "Epoch 893/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4249 - accuracy: 0.8636\n",
      "Epoch 894/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4249 - accuracy: 0.8636\n",
      "Epoch 895/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8636\n",
      "Epoch 896/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4249 - accuracy: 0.8636\n",
      "Epoch 897/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.8636\n",
      "Epoch 898/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8636\n",
      "Epoch 899/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.8636\n",
      "Epoch 900/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.8636\n",
      "Epoch 901/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.8636\n",
      "Epoch 902/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.8636\n",
      "Epoch 903/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.8636\n",
      "Epoch 904/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.8636\n",
      "Epoch 905/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.8636\n",
      "Epoch 906/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.8636\n",
      "Epoch 907/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.8636\n",
      "Epoch 908/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.8636\n",
      "Epoch 909/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.8636\n",
      "Epoch 910/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4247 - accuracy: 0.8636\n",
      "Epoch 911/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4247 - accuracy: 0.8636\n",
      "Epoch 912/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8636\n",
      "Epoch 913/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4247 - accuracy: 0.8636\n",
      "Epoch 914/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8636\n",
      "Epoch 915/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8636\n",
      "Epoch 916/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8636\n",
      "Epoch 917/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4247 - accuracy: 0.8636\n",
      "Epoch 918/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8636\n",
      "Epoch 919/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.8636\n",
      "Epoch 920/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.8636\n",
      "Epoch 921/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4247 - accuracy: 0.8636\n",
      "Epoch 922/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.8636\n",
      "Epoch 923/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.8636\n",
      "Epoch 924/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.8636\n",
      "Epoch 925/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4246 - accuracy: 0.8636\n",
      "Epoch 926/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.8636\n",
      "Epoch 927/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.8636\n",
      "Epoch 928/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.8636\n",
      "Epoch 929/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.8636\n",
      "Epoch 930/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8636\n",
      "Epoch 931/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.8636\n",
      "Epoch 932/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.8636\n",
      "Epoch 933/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.8636\n",
      "Epoch 934/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.8636\n",
      "Epoch 935/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4245 - accuracy: 0.8636\n",
      "Epoch 936/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8636\n",
      "Epoch 937/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4245 - accuracy: 0.8636\n",
      "Epoch 938/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.8636\n",
      "Epoch 939/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4245 - accuracy: 0.8636\n",
      "Epoch 940/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.8636\n",
      "Epoch 941/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.8636\n",
      "Epoch 942/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.8636\n",
      "Epoch 943/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4245 - accuracy: 0.8636\n",
      "Epoch 944/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.8636\n",
      "Epoch 945/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4245 - accuracy: 0.8636\n",
      "Epoch 946/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4244 - accuracy: 0.8636\n",
      "Epoch 947/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.8636\n",
      "Epoch 948/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.8636\n",
      "Epoch 949/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4244 - accuracy: 0.8636\n",
      "Epoch 950/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.8636\n",
      "Epoch 951/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.8636\n",
      "Epoch 952/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.8636\n",
      "Epoch 953/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.8636\n",
      "Epoch 954/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.8636\n",
      "Epoch 955/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.8636\n",
      "Epoch 956/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.8636\n",
      "Epoch 957/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.8636\n",
      "Epoch 958/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8636\n",
      "Epoch 959/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.8636\n",
      "Epoch 960/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.8636\n",
      "Epoch 961/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.8636\n",
      "Epoch 962/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.8636\n",
      "Epoch 963/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.8636\n",
      "Epoch 964/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.8636\n",
      "Epoch 965/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.8636\n",
      "Epoch 966/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.8636\n",
      "Epoch 967/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.8636\n",
      "Epoch 968/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.8636\n",
      "Epoch 969/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.8636\n",
      "Epoch 970/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.8636\n",
      "Epoch 971/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4242 - accuracy: 0.8636\n",
      "Epoch 972/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.8636\n",
      "Epoch 973/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.8636\n",
      "Epoch 974/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.8636\n",
      "Epoch 975/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.8636\n",
      "Epoch 976/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.8636\n",
      "Epoch 977/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.8636\n",
      "Epoch 978/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.8636\n",
      "Epoch 979/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4242 - accuracy: 0.8636\n",
      "Epoch 980/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.8636\n",
      "Epoch 981/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.8636\n",
      "Epoch 982/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8636\n",
      "Epoch 983/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.8636\n",
      "Epoch 984/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8636\n",
      "Epoch 985/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8636\n",
      "Epoch 986/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8636\n",
      "Epoch 987/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.8636\n",
      "Epoch 988/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4241 - accuracy: 0.8636\n",
      "Epoch 989/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.8636\n",
      "Epoch 990/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.8636\n",
      "Epoch 991/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.8636\n",
      "Epoch 992/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8636\n",
      "Epoch 993/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8636\n",
      "Epoch 994/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8636\n",
      "Epoch 995/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8636\n",
      "Epoch 996/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.8636\n",
      "Epoch 997/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8636\n",
      "Epoch 998/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.8636\n",
      "Epoch 999/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.8636\n",
      "Epoch 1000/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.8636\n",
      "Epoch 1001/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4240 - accuracy: 0.8636\n",
      "Epoch 1002/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4240 - accuracy: 0.8636\n",
      "Epoch 1003/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8636\n",
      "Epoch 1004/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8636\n",
      "Epoch 1005/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.8636\n",
      "Epoch 1006/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8636\n",
      "Epoch 1007/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8636\n",
      "Epoch 1008/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8636\n",
      "Epoch 1009/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8636\n",
      "Epoch 1010/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8636\n",
      "Epoch 1011/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8636\n",
      "Epoch 1012/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8636\n",
      "Epoch 1013/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8636\n",
      "Epoch 1014/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8636\n",
      "Epoch 1015/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8636\n",
      "Epoch 1016/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8636\n",
      "Epoch 1017/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8636\n",
      "Epoch 1018/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8636\n",
      "Epoch 1019/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.8636\n",
      "Epoch 1020/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8636\n",
      "Epoch 1021/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8636\n",
      "Epoch 1022/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8636\n",
      "Epoch 1023/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8636\n",
      "Epoch 1024/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8636\n",
      "Epoch 1025/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8636\n",
      "Epoch 1026/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8636\n",
      "Epoch 1027/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.8636\n",
      "Epoch 1028/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.8636\n",
      "Epoch 1029/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4238 - accuracy: 0.8636\n",
      "Epoch 1030/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.8636\n",
      "Epoch 1031/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.8636\n",
      "Epoch 1032/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.8636\n",
      "Epoch 1033/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.8636\n",
      "Epoch 1034/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.8636\n",
      "Epoch 1035/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.8636\n",
      "Epoch 1036/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.8636\n",
      "Epoch 1037/10000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4237 - accuracy: 0.8636\n",
      "Epoch 1038/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.8636\n",
      "Epoch 1039/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.8636\n",
      "Epoch 1040/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.8636\n",
      "Epoch 1041/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.8636\n",
      "Epoch 1042/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.8636\n",
      "Epoch 1043/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.8636\n",
      "Epoch 1044/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.8636\n",
      "Epoch 1045/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8636\n",
      "Epoch 1046/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8636\n",
      "Epoch 1047/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8636\n",
      "Epoch 1048/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8636\n",
      "Epoch 1049/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.8636\n",
      "Epoch 1050/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8636\n",
      "Epoch 1051/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8636\n",
      "Epoch 1052/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.8636\n",
      "Epoch 1053/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8636\n",
      "Epoch 1054/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8636\n",
      "Epoch 1055/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8636\n",
      "Epoch 1056/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.8636\n",
      "Epoch 1057/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.8636\n",
      "Epoch 1058/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.8636\n",
      "Epoch 1059/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.8636\n",
      "Epoch 1060/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.8636\n",
      "Epoch 1061/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.8636\n",
      "Epoch 1062/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.8636\n",
      "Epoch 1063/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.8636\n",
      "Epoch 1064/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.8636\n",
      "Epoch 1065/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8636\n",
      "Epoch 1066/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8636\n",
      "Epoch 1067/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.8636\n",
      "Epoch 1068/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.8636\n",
      "Epoch 1069/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.8636\n",
      "Epoch 1070/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.8636\n",
      "Epoch 1071/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8636\n",
      "Epoch 1072/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8636\n",
      "Epoch 1073/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8636\n",
      "Epoch 1074/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8636\n",
      "Epoch 1075/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8636\n",
      "Epoch 1076/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.8636\n",
      "Epoch 1077/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8636\n",
      "Epoch 1078/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.8636\n",
      "Epoch 1079/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8636\n",
      "Epoch 1080/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4234 - accuracy: 0.8636\n",
      "Epoch 1081/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4234 - accuracy: 0.8636\n",
      "Epoch 1082/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.8636\n",
      "Epoch 1083/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4234 - accuracy: 0.8636\n",
      "Epoch 1084/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.8636\n",
      "Epoch 1085/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.8636\n",
      "Epoch 1086/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4233 - accuracy: 0.8636\n",
      "Epoch 1087/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4233 - accuracy: 0.8636\n",
      "Epoch 1088/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4233 - accuracy: 0.8636\n",
      "Epoch 1089/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.8636\n",
      "Epoch 1090/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8636\n",
      "Epoch 1091/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8636\n",
      "Epoch 1092/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.8636\n",
      "Epoch 1093/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.8636\n",
      "Epoch 1094/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4233 - accuracy: 0.8636\n",
      "Epoch 1095/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.8636\n",
      "Epoch 1096/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4233 - accuracy: 0.8636\n",
      "Epoch 1097/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4232 - accuracy: 0.8636\n",
      "Epoch 1098/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4232 - accuracy: 0.8636\n",
      "Epoch 1099/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.8636\n",
      "Epoch 1100/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.8636\n",
      "Epoch 1101/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.8636\n",
      "Epoch 1102/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.8636\n",
      "Epoch 1103/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.8636\n",
      "Epoch 1104/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.8636\n",
      "Epoch 1105/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.8636\n",
      "Epoch 1106/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.8636\n",
      "Epoch 1107/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4232 - accuracy: 0.8636\n",
      "Epoch 1108/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.8636\n",
      "Epoch 1109/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4232 - accuracy: 0.8636\n",
      "Epoch 1110/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8636\n",
      "Epoch 1111/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8636\n",
      "Epoch 1112/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8636\n",
      "Epoch 1113/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8636\n",
      "Epoch 1114/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8636\n",
      "Epoch 1115/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.8636\n",
      "Epoch 1116/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8636\n",
      "Epoch 1117/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8636\n",
      "Epoch 1118/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.8636\n",
      "Epoch 1119/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.8636\n",
      "Epoch 1120/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8636\n",
      "Epoch 1121/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.8636\n",
      "Epoch 1122/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.8636\n",
      "Epoch 1123/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8636\n",
      "Epoch 1124/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8636\n",
      "Epoch 1125/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8636\n",
      "Epoch 1126/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8636\n",
      "Epoch 1127/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8636\n",
      "Epoch 1128/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8636\n",
      "Epoch 1129/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8636\n",
      "Epoch 1130/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4230 - accuracy: 0.8636\n",
      "Epoch 1131/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8636\n",
      "Epoch 1132/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8636\n",
      "Epoch 1133/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8636\n",
      "Epoch 1134/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8636\n",
      "Epoch 1135/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8636\n",
      "Epoch 1136/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.8636\n",
      "Epoch 1137/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8636\n",
      "Epoch 1138/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8636\n",
      "Epoch 1139/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.8636\n",
      "Epoch 1140/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8636\n",
      "Epoch 1141/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8636\n",
      "Epoch 1142/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.8636\n",
      "Epoch 1143/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.8636\n",
      "Epoch 1144/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.8636\n",
      "Epoch 1145/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.8636\n",
      "Epoch 1146/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.8636\n",
      "Epoch 1147/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8636\n",
      "Epoch 1148/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8636\n",
      "Epoch 1149/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8636\n",
      "Epoch 1150/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8636\n",
      "Epoch 1151/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8636\n",
      "Epoch 1152/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8636\n",
      "Epoch 1153/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8636\n",
      "Epoch 1154/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8636\n",
      "Epoch 1155/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8636\n",
      "Epoch 1156/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8636\n",
      "Epoch 1157/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8636\n",
      "Epoch 1158/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8636\n",
      "Epoch 1159/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8636\n",
      "Epoch 1160/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8636\n",
      "Epoch 1161/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.8636\n",
      "Epoch 1162/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.8636\n",
      "Epoch 1163/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8636\n",
      "Epoch 1164/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4227 - accuracy: 0.8636\n",
      "Epoch 1165/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4227 - accuracy: 0.8636\n",
      "Epoch 1166/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4227 - accuracy: 0.8636\n",
      "Epoch 1167/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4227 - accuracy: 0.8636\n",
      "Epoch 1168/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8636\n",
      "Epoch 1169/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8636\n",
      "Epoch 1170/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8636\n",
      "Epoch 1171/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8636\n",
      "Epoch 1172/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8636\n",
      "Epoch 1173/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4227 - accuracy: 0.8636\n",
      "Epoch 1174/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8636\n",
      "Epoch 1175/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8636\n",
      "Epoch 1176/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8636\n",
      "Epoch 1177/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8636\n",
      "Epoch 1178/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8636\n",
      "Epoch 1179/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8636\n",
      "Epoch 1180/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8636\n",
      "Epoch 1181/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8636\n",
      "Epoch 1182/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8636\n",
      "Epoch 1183/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8636\n",
      "Epoch 1184/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8636\n",
      "Epoch 1185/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8636\n",
      "Epoch 1186/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8636\n",
      "Epoch 1187/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4226 - accuracy: 0.8636\n",
      "Epoch 1188/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4226 - accuracy: 0.8636\n",
      "Epoch 1189/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4226 - accuracy: 0.8636\n",
      "Epoch 1190/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4225 - accuracy: 0.8636\n",
      "Epoch 1191/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.8636\n",
      "Epoch 1192/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.8636\n",
      "Epoch 1193/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.8636\n",
      "Epoch 1194/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.8636\n",
      "Epoch 1195/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.8636\n",
      "Epoch 1196/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8636\n",
      "Epoch 1197/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8636\n",
      "Epoch 1198/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4225 - accuracy: 0.8636\n",
      "Epoch 1199/10000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4225 - accuracy: 0.8636\n",
      "Epoch 1200/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4225 - accuracy: 0.8636\n",
      "Epoch 1201/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.8636\n",
      "Epoch 1202/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.8636\n",
      "Epoch 1203/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.8636\n",
      "Epoch 1204/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8636\n",
      "Epoch 1205/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8636\n",
      "Epoch 1206/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8636\n",
      "Epoch 1207/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8636\n",
      "Epoch 1208/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8636\n",
      "Epoch 1209/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.8636\n",
      "Epoch 1210/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8636\n",
      "Epoch 1211/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.8636\n",
      "Epoch 1212/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.8636\n",
      "Epoch 1213/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8636\n",
      "Epoch 1214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8636\n",
      "Epoch 1215/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8636\n",
      "Epoch 1216/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8636\n",
      "Epoch 1217/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.8636\n",
      "Epoch 1218/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8636\n",
      "Epoch 1219/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8636\n",
      "Epoch 1220/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4223 - accuracy: 0.8636\n",
      "Epoch 1221/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4223 - accuracy: 0.8636\n",
      "Epoch 1222/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4223 - accuracy: 0.8636\n",
      "Epoch 1223/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4223 - accuracy: 0.8636\n",
      "Epoch 1224/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8636\n",
      "Epoch 1225/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4223 - accuracy: 0.8636\n",
      "Epoch 1226/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4223 - accuracy: 0.8636\n",
      "Epoch 1227/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8636\n",
      "Epoch 1228/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8636\n",
      "Epoch 1229/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8636\n",
      "Epoch 1230/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8636\n",
      "Epoch 1231/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8636\n",
      "Epoch 1232/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.8636\n",
      "Epoch 1233/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.8636\n",
      "Epoch 1234/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.8636\n",
      "Epoch 1235/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.8636\n",
      "Epoch 1236/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.8636\n",
      "Epoch 1237/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.8636\n",
      "Epoch 1238/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.8636\n",
      "Epoch 1239/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.8636\n",
      "Epoch 1240/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8636\n",
      "Epoch 1241/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.8636\n",
      "Epoch 1242/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.8636\n",
      "Epoch 1243/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.8636\n",
      "Epoch 1244/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.8636\n",
      "Epoch 1245/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.8636\n",
      "Epoch 1246/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.8636\n",
      "Epoch 1247/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.8636\n",
      "Epoch 1248/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.8636\n",
      "Epoch 1249/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.8636\n",
      "Epoch 1250/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.8636\n",
      "Epoch 1251/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.8636\n",
      "Epoch 1252/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.8636\n",
      "Epoch 1253/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.8636\n",
      "Epoch 1254/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.8636\n",
      "Epoch 1255/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.8636\n",
      "Epoch 1256/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.8636\n",
      "Epoch 1257/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.8636\n",
      "Epoch 1258/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.8636\n",
      "Epoch 1259/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.8636\n",
      "Epoch 1260/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.8636\n",
      "Epoch 1261/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.8636\n",
      "Epoch 1262/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.8636\n",
      "Epoch 1263/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8636\n",
      "Epoch 1264/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8636\n",
      "Epoch 1265/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8636\n",
      "Epoch 1266/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8636\n",
      "Epoch 1267/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8636\n",
      "Epoch 1268/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8636\n",
      "Epoch 1269/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.8636\n",
      "Epoch 1270/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.8636\n",
      "Epoch 1271/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8636\n",
      "Epoch 1272/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4220 - accuracy: 0.8636\n",
      "Epoch 1273/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.8636\n",
      "Epoch 1274/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.8636\n",
      "Epoch 1275/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8636\n",
      "Epoch 1276/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4219 - accuracy: 0.8636\n",
      "Epoch 1277/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4219 - accuracy: 0.8636\n",
      "Epoch 1278/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.8636\n",
      "Epoch 1279/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8636\n",
      "Epoch 1280/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8636\n",
      "Epoch 1281/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8636\n",
      "Epoch 1282/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8636\n",
      "Epoch 1283/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8636\n",
      "Epoch 1284/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8636\n",
      "Epoch 1285/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8636\n",
      "Epoch 1286/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8636\n",
      "Epoch 1287/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8636\n",
      "Epoch 1288/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8636\n",
      "Epoch 1289/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8636\n",
      "Epoch 1290/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8636\n",
      "Epoch 1291/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8636\n",
      "Epoch 1292/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.8636\n",
      "Epoch 1293/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8636\n",
      "Epoch 1294/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8636\n",
      "Epoch 1295/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8636\n",
      "Epoch 1296/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.8636\n",
      "Epoch 1297/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8636\n",
      "Epoch 1298/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8636\n",
      "Epoch 1299/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8636\n",
      "Epoch 1300/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8636\n",
      "Epoch 1301/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8636\n",
      "Epoch 1302/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8636\n",
      "Epoch 1303/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8636\n",
      "Epoch 1304/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8636\n",
      "Epoch 1305/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8636\n",
      "Epoch 1306/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4217 - accuracy: 0.8636\n",
      "Epoch 1307/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8636\n",
      "Epoch 1308/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8636\n",
      "Epoch 1309/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8636\n",
      "Epoch 1310/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8636\n",
      "Epoch 1311/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8636\n",
      "Epoch 1312/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8636\n",
      "Epoch 1313/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8636\n",
      "Epoch 1314/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4217 - accuracy: 0.8636\n",
      "Epoch 1315/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8636\n",
      "Epoch 1316/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8636\n",
      "Epoch 1317/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.8636\n",
      "Epoch 1318/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.8636\n",
      "Epoch 1319/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.8636\n",
      "Epoch 1320/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8636\n",
      "Epoch 1321/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8636\n",
      "Epoch 1322/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8636\n",
      "Epoch 1323/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8636\n",
      "Epoch 1324/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8636\n",
      "Epoch 1325/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8636\n",
      "Epoch 1326/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.8636\n",
      "Epoch 1327/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.8636\n",
      "Epoch 1328/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.8636\n",
      "Epoch 1329/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.8636\n",
      "Epoch 1330/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.8636\n",
      "Epoch 1331/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.8636\n",
      "Epoch 1332/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8636\n",
      "Epoch 1333/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8636\n",
      "Epoch 1334/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.8636\n",
      "Epoch 1335/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8636\n",
      "Epoch 1336/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8636\n",
      "Epoch 1337/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8636\n",
      "Epoch 1338/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8636\n",
      "Epoch 1339/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8636\n",
      "Epoch 1340/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8636\n",
      "Epoch 1341/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8636\n",
      "Epoch 1342/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8636\n",
      "Epoch 1343/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.8636\n",
      "Epoch 1344/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8636\n",
      "Epoch 1345/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8636\n",
      "Epoch 1346/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8636\n",
      "Epoch 1347/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8636\n",
      "Epoch 1348/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8636\n",
      "Epoch 1349/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8636\n",
      "Epoch 1350/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8636\n",
      "Epoch 1351/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8636\n",
      "Epoch 1352/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8636\n",
      "Epoch 1353/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8636\n",
      "Epoch 1354/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8636\n",
      "Epoch 1355/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.8636\n",
      "Epoch 1356/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8636\n",
      "Epoch 1357/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8636\n",
      "Epoch 1358/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8636\n",
      "Epoch 1359/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4214 - accuracy: 0.8636\n",
      "Epoch 1360/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4213 - accuracy: 0.8636\n",
      "Epoch 1361/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8636\n",
      "Epoch 1362/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8636\n",
      "Epoch 1363/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8636\n",
      "Epoch 1364/10000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8636\n",
      "Epoch 1365/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8636\n",
      "Epoch 1366/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8636\n",
      "Epoch 1367/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8636\n",
      "Epoch 1368/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8636\n",
      "Epoch 1369/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8636\n",
      "Epoch 1370/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8636\n",
      "Epoch 1371/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8636\n",
      "Epoch 1372/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8636\n",
      "Epoch 1373/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8636\n",
      "Epoch 1374/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8636\n",
      "Epoch 1375/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.8636\n",
      "Epoch 1376/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.8636\n",
      "Epoch 1377/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.8636\n",
      "Epoch 1378/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.8636\n",
      "Epoch 1379/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.8636\n",
      "Epoch 1380/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.8636\n",
      "Epoch 1381/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.8636\n",
      "Epoch 1382/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.8636\n",
      "Epoch 1383/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.8636\n",
      "Epoch 1384/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4212 - accuracy: 0.8636\n",
      "Epoch 1385/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.8636\n",
      "Epoch 1386/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.8636\n",
      "Epoch 1387/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.8636\n",
      "Epoch 1388/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4212 - accuracy: 0.8636\n",
      "Epoch 1389/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.8636\n",
      "Epoch 1390/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8636\n",
      "Epoch 1391/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8636\n",
      "Epoch 1392/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8636\n",
      "Epoch 1393/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8636\n",
      "Epoch 1394/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.8636\n",
      "Epoch 1395/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8636\n",
      "Epoch 1396/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.8636\n",
      "Epoch 1397/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8636\n",
      "Epoch 1398/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8636\n",
      "Epoch 1399/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8636\n",
      "Epoch 1400/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8636\n",
      "Epoch 1401/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4211 - accuracy: 0.8636\n",
      "Epoch 1402/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8636\n",
      "Epoch 1403/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8636\n",
      "Epoch 1404/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8636\n",
      "Epoch 1405/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 1406/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 1407/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 1408/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 1409/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 1410/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 1411/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 1412/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 1413/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 1414/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 1415/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 1416/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 1417/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 1418/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 1419/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 1420/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1421/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1422/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1423/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1424/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1425/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1426/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1427/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1428/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1429/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1430/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1431/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1432/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1433/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1434/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1435/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.8636\n",
      "Epoch 1436/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8636\n",
      "Epoch 1437/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.8636\n",
      "Epoch 1438/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.8636\n",
      "Epoch 1439/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8636\n",
      "Epoch 1440/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8636\n",
      "Epoch 1441/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8636\n",
      "Epoch 1442/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.8636\n",
      "Epoch 1443/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8636\n",
      "Epoch 1444/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8636\n",
      "Epoch 1445/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8636\n",
      "Epoch 1446/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8636\n",
      "Epoch 1447/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.8636\n",
      "Epoch 1448/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8636\n",
      "Epoch 1449/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4208 - accuracy: 0.8636\n",
      "Epoch 1450/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8636\n",
      "Epoch 1451/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.8636\n",
      "Epoch 1452/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.8636\n",
      "Epoch 1453/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.8636\n",
      "Epoch 1454/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.8636\n",
      "Epoch 1455/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.8636\n",
      "Epoch 1456/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.8636\n",
      "Epoch 1457/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.8636\n",
      "Epoch 1458/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.8636\n",
      "Epoch 1459/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.8636\n",
      "Epoch 1460/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.8636\n",
      "Epoch 1461/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.8636\n",
      "Epoch 1462/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.8636\n",
      "Epoch 1463/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.8636\n",
      "Epoch 1464/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.8636\n",
      "Epoch 1465/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.8636\n",
      "Epoch 1466/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1467/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1468/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1469/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1470/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1471/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1472/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1473/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1474/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1475/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1476/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1477/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1478/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1479/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1480/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1481/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.8636\n",
      "Epoch 1482/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1483/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1484/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1485/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1486/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1487/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1488/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1489/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1490/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1491/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1492/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1493/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1494/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1495/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1496/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1497/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8636\n",
      "Epoch 1498/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1499/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1500/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1501/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1502/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1503/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1504/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1505/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1506/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1507/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1508/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1509/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1510/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1511/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1512/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1513/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8636\n",
      "Epoch 1514/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1515/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1516/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1517/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1518/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1519/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1520/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1521/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1522/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1523/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1524/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1525/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1526/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1527/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1528/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1529/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4203 - accuracy: 0.8636\n",
      "Epoch 1530/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1531/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1532/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1533/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1534/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1535/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1536/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1537/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1538/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1539/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1540/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1541/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1542/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1543/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1544/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1545/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8636\n",
      "Epoch 1546/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1547/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1548/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1549/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1550/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1551/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1552/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1553/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1554/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1555/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1556/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1557/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1558/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1559/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1560/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1561/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4201 - accuracy: 0.8636\n",
      "Epoch 1562/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1563/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1564/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1565/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1566/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1567/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1568/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1569/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1570/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1571/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1572/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1573/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1574/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1575/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1576/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1577/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.8636\n",
      "Epoch 1578/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1579/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1580/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1581/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1582/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1583/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1584/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1585/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1586/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1587/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1588/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1589/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1590/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1591/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1592/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1593/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1594/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.8636\n",
      "Epoch 1595/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1596/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1597/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1598/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1599/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1600/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1601/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1602/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1603/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1604/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1605/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1606/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1607/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1608/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1609/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1610/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.8636\n",
      "Epoch 1611/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1612/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1613/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1614/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1615/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1616/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1617/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1618/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1619/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1620/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1621/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1622/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1623/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1624/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1625/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1626/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1627/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.8636\n",
      "Epoch 1628/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1629/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1630/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1631/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1632/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1633/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1634/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1635/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1636/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1637/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1638/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1639/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1640/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1641/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1642/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1643/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1644/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8636\n",
      "Epoch 1645/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1646/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1647/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1648/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1649/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1650/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1651/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1652/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1653/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1654/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1655/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1656/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1657/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1658/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1659/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1660/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1661/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8636\n",
      "Epoch 1662/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1663/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1664/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1665/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1666/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1667/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1668/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1669/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1670/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1671/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1672/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1673/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1674/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1675/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1676/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1677/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1678/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.8636\n",
      "Epoch 1679/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1680/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1681/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1682/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1683/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1684/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1685/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1686/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1687/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1688/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1689/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1690/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1691/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1692/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1693/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1694/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1695/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8636\n",
      "Epoch 1696/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1697/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1698/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1699/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1700/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1701/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1702/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1703/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1704/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1705/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1706/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1707/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1708/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1709/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1710/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1711/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1712/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1713/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.8636\n",
      "Epoch 1714/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1715/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1716/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1717/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1718/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1719/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1720/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1721/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1722/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1723/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1724/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1725/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1726/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1727/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1728/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1729/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1730/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8636\n",
      "Epoch 1731/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1732/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1733/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1734/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1735/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1736/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1737/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1738/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1739/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1740/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1741/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1742/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1743/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1744/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1745/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1746/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1747/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1748/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.8636\n",
      "Epoch 1749/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1750/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1751/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1752/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1753/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1754/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1755/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1756/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1757/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1758/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1759/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1760/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1761/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1762/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1763/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1764/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1765/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1766/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.8636\n",
      "Epoch 1767/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1768/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1769/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1770/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1771/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1772/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1773/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1774/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1775/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1776/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1777/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1778/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1779/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1780/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1781/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1782/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1783/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1784/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.8636\n",
      "Epoch 1785/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1786/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1787/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1788/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1789/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1790/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1791/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1792/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1793/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1794/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1795/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1796/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1797/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1798/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1799/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1800/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1801/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1802/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8636\n",
      "Epoch 1803/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1804/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1805/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1806/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1807/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1808/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1809/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1810/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1811/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1812/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1813/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1814/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1815/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1816/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1817/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1818/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1819/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1820/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1821/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4186 - accuracy: 0.8636\n",
      "Epoch 1822/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1823/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1824/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1825/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1826/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1827/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1828/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1829/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1830/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1831/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1832/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1833/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1834/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1835/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1836/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1837/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1838/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1839/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8636\n",
      "Epoch 1840/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1841/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1842/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1843/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1844/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1845/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1846/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1847/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1848/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1849/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1850/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1851/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1852/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1853/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1854/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1855/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1856/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1857/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1858/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.8636\n",
      "Epoch 1859/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1860/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1861/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1862/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1863/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1864/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1865/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1866/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1867/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1868/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1869/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1870/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1871/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1872/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1873/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1874/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1875/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1876/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1877/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8636\n",
      "Epoch 1878/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1879/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1880/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1881/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1882/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1883/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1884/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1885/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1886/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1887/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1888/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1889/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1890/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1891/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1892/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1893/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1894/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1895/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1896/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8636\n",
      "Epoch 1897/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1898/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1899/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1900/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1901/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1902/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1903/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1904/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1905/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1906/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1907/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1908/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1909/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1910/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1911/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1912/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1913/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1914/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1915/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8636\n",
      "Epoch 1916/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1917/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1918/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1919/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1920/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1921/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1922/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1923/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1924/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1925/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1926/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1927/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1928/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1929/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1930/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1931/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1932/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1933/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1934/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.8636\n",
      "Epoch 1935/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1936/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1937/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1938/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1939/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1940/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1941/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1942/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1943/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1944/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1945/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1946/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1947/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1948/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1949/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1950/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1951/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1952/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1953/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1954/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.8636\n",
      "Epoch 1955/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1956/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1957/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1958/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1959/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1960/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1961/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1962/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1963/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1964/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1965/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1966/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1967/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1968/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1969/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1970/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1971/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1972/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1973/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1974/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8636\n",
      "Epoch 1975/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1976/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1977/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1978/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1979/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1980/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1981/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1982/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1983/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1984/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1985/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1986/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1987/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1988/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1989/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1990/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1991/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1992/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1993/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1994/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 1995/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 1996/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 1997/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 1998/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 1999/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2000/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2001/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2002/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2003/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2004/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2005/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2006/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2007/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2008/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2009/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2010/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2011/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2012/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2013/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2014/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.8636\n",
      "Epoch 2015/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2016/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2017/10000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2018/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2019/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2020/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2021/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2022/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2023/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2024/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2025/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2026/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2027/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2028/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2029/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2030/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2031/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2032/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2033/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2034/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2035/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.8636\n",
      "Epoch 2036/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2037/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2038/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2039/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2040/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2041/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2042/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2043/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2044/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2045/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2046/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2047/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2048/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2049/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2050/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2051/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2052/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2053/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2054/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2055/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8636\n",
      "Epoch 2056/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2057/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2058/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2059/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2060/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2061/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2062/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2063/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2064/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2065/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2066/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2067/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2068/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2069/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2070/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2071/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2072/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2073/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2074/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2075/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2076/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.8636\n",
      "Epoch 2077/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2078/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2079/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2080/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2081/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2082/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2083/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2084/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2085/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2086/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2087/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2088/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2089/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2090/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2091/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2092/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2093/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2094/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2095/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2096/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2097/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8636\n",
      "Epoch 2098/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2099/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2100/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2101/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2102/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2103/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2104/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2105/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2106/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2107/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2108/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2109/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2110/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2111/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2112/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2113/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2114/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2115/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2116/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2117/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2118/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.8636\n",
      "Epoch 2119/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2120/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2121/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2122/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2123/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2124/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2125/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2126/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2127/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2128/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2129/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2130/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2131/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2132/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2133/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2134/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2135/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2136/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2137/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2138/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2139/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2140/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.8636\n",
      "Epoch 2141/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2142/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2143/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2144/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2145/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2146/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2147/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2148/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2149/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2150/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2151/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2152/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2153/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2154/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2155/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2156/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2157/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2158/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2159/10000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2160/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2161/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2162/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8636\n",
      "Epoch 2163/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2164/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2165/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2166/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2167/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2168/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2169/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2170/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2171/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2172/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2173/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2174/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2175/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2176/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2177/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2178/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2179/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2180/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2181/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2182/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2183/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2184/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.8636\n",
      "Epoch 2185/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2186/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2187/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2188/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2189/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2190/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2191/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2192/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2193/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2194/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2195/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2196/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2197/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2198/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2199/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2200/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2201/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2202/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2203/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2204/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2205/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2206/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.8636\n",
      "Epoch 2207/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2208/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2209/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2210/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2211/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2212/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2213/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2214/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2215/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2216/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2217/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2218/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2219/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2220/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2221/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2222/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2223/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2224/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2225/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2226/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2227/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2228/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2229/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.8636\n",
      "Epoch 2230/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2231/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2232/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2233/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2234/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2235/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2236/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2237/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2238/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2239/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2240/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2241/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2242/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2243/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2244/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2245/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2246/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2247/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2248/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2249/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2250/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2251/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2252/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.8636\n",
      "Epoch 2253/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2254/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2255/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2256/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2257/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2258/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2259/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2260/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2261/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2262/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2263/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2264/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2265/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2266/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2267/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2268/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2269/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2270/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2271/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2272/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2273/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2274/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2275/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8636\n",
      "Epoch 2276/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2277/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2278/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2279/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2280/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2281/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2282/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2283/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2284/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2285/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2286/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2287/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2288/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2289/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2290/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2291/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2292/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2293/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2294/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2295/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2296/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2297/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2298/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4163 - accuracy: 0.8636\n",
      "Epoch 2299/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2300/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2301/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2302/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2303/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2304/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2305/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2306/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2307/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2308/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2309/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2310/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2311/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2312/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2313/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2314/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2315/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2316/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2317/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2318/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2319/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2320/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2321/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2322/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8636\n",
      "Epoch 2323/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2324/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2325/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2326/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2327/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2328/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2329/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2330/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2331/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2332/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2333/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2334/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2335/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2336/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2337/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2338/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2339/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2340/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2341/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2342/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2343/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2344/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2345/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2346/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.8636\n",
      "Epoch 2347/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2348/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2349/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2350/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2351/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2352/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2353/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2354/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2355/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2356/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2357/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2358/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2359/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2360/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2361/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2362/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2363/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2364/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2365/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2366/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2367/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2368/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2369/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2370/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8636\n",
      "Epoch 2371/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2372/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2373/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2374/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2375/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2376/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2377/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2378/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2379/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2380/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2381/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2382/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2383/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2384/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2385/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2386/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2387/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2388/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2389/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2390/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2391/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2392/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2393/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2394/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8636\n",
      "Epoch 2395/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2396/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2397/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2398/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2399/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2400/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2401/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2402/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2403/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2404/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2405/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2406/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2407/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2408/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2409/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2410/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2411/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2412/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2413/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2414/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2415/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2416/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2417/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2418/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2419/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8636\n",
      "Epoch 2420/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2421/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2422/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2423/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2424/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2425/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2426/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2427/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2428/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2429/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2430/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2431/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2432/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2433/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2434/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2435/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2436/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2437/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2438/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2439/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2440/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2441/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2442/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2443/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2444/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2445/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8636\n",
      "Epoch 2446/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2447/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2448/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2449/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2450/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2451/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2452/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2453/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2454/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2455/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2456/10000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2457/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2458/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2459/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2460/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2461/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2462/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2463/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2464/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2465/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2466/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2467/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2468/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2469/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2470/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.8636\n",
      "Epoch 2471/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2472/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2473/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2474/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2475/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2476/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2477/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2478/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2479/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2480/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2481/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2482/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2483/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2484/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2485/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2486/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2487/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2488/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2489/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2490/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2491/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2492/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2493/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2494/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2495/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2496/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8636\n",
      "Epoch 2497/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2498/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2499/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2500/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2501/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2502/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2503/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2504/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2505/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2506/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2507/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2508/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2509/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2510/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2511/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2512/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2513/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2514/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2515/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2516/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2517/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2518/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2519/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2520/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2521/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2522/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2523/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8636\n",
      "Epoch 2524/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2525/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2526/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2527/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2528/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2529/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2530/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2531/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2532/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2533/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2534/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2535/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2536/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2537/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2538/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2539/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2540/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2541/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2542/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2543/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2544/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2545/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2546/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2547/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2548/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2549/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8636\n",
      "Epoch 2550/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2551/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2552/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2553/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2554/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2555/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2556/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2557/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2558/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2559/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2560/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2561/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2562/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2563/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2564/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2565/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2566/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2567/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2568/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2569/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2570/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2571/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2572/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2573/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2574/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2575/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2576/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8636\n",
      "Epoch 2577/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2578/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2579/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2580/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2581/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2582/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2583/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2584/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2585/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2586/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2587/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2588/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2589/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2590/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2591/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2592/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2593/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2594/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2595/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2596/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2597/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2598/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2599/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2600/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2601/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2602/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2603/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2604/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4151 - accuracy: 0.8636\n",
      "Epoch 2605/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2606/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2607/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2608/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2609/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2610/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2611/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2612/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2613/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2614/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2615/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2616/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2617/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2618/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2619/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2620/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2621/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2622/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2623/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2624/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2625/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2626/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2627/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2628/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2629/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2630/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2631/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2632/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4150 - accuracy: 0.8636\n",
      "Epoch 2633/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2634/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2635/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2636/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2637/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2638/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2639/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2640/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2641/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2642/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2643/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2644/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2645/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2646/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2647/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2648/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2649/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2650/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2651/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2652/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2653/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2654/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2655/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2656/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2657/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2658/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2659/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2660/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8636\n",
      "Epoch 2661/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2662/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2663/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2664/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2665/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2666/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2667/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2668/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2669/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2670/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2671/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2672/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2673/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2674/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2675/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2676/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2677/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2678/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2679/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2680/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2681/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2682/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2683/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2684/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2685/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2686/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2687/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2688/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2689/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4148 - accuracy: 0.8636\n",
      "Epoch 2690/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2691/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2692/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2693/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2694/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2695/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2696/10000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2697/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2698/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2699/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2700/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2701/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2702/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2703/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2704/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2705/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2706/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2707/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2708/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2709/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2710/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2711/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2712/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2713/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2714/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2715/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2716/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2717/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2718/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8636\n",
      "Epoch 2719/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2720/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2721/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2722/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2723/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2724/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2725/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2726/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2727/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2728/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2729/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2730/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2731/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2732/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2733/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2734/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2735/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2736/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2737/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2738/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2739/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2740/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2741/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2742/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2743/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2744/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2745/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2746/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2747/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2748/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8636\n",
      "Epoch 2749/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2750/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2751/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2752/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2753/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2754/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2755/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2756/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2757/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2758/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2759/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2760/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2761/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2762/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2763/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2764/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2765/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2766/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2767/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2768/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2769/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2770/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2771/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2772/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2773/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2774/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2775/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2776/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2777/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2778/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4145 - accuracy: 0.8636\n",
      "Epoch 2779/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2780/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2781/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2782/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2783/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2784/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2785/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2786/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2787/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2788/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2789/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2790/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2791/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2792/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2793/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2794/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2795/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2796/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2797/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2798/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2799/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2800/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2801/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2802/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2803/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2804/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2805/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2806/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2807/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2808/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2809/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8636\n",
      "Epoch 2810/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2811/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2812/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2813/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2814/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2815/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2816/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2817/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2818/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2819/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2820/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2821/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2822/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2823/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2824/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2825/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2826/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2827/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2828/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2829/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2830/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2831/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2832/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2833/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2834/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2835/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2836/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2837/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2838/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2839/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2840/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2841/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8636\n",
      "Epoch 2842/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2843/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2844/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2845/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2846/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2847/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2848/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2849/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2850/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2851/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2852/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2853/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2854/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2855/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2856/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2857/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2858/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2859/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2860/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2861/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2862/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2863/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2864/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2865/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2866/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2867/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2868/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2869/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2870/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2871/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2872/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2873/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8636\n",
      "Epoch 2874/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2875/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2876/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2877/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2878/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2879/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2880/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2881/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2882/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2883/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2884/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2885/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2886/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2887/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2888/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2889/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2890/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2891/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2892/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2893/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2894/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2895/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2896/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2897/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2898/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2899/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2900/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2901/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2902/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2903/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2904/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2905/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8636\n",
      "Epoch 2906/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2907/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2908/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2909/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2910/10000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2911/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2912/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2913/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2914/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2915/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2916/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2917/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2918/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2919/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2920/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2921/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2922/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2923/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2924/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2925/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2926/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2927/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2928/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2929/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2930/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2931/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2932/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2933/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2934/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2935/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2936/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2937/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2938/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8636\n",
      "Epoch 2939/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2940/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2941/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2942/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2943/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2944/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2945/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2946/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2947/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2948/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2949/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2950/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2951/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2952/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2953/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2954/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2955/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2956/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2957/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2958/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2959/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2960/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2961/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2962/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2963/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2964/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2965/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2966/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2967/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2968/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2969/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2970/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2971/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2972/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8636\n",
      "Epoch 2973/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2974/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2975/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2976/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2977/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2978/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2979/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2980/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2981/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2982/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2983/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2984/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2985/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2986/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2987/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2988/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2989/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2990/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2991/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2992/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2993/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2994/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2995/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2996/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2997/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2998/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 2999/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 3000/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 3001/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 3002/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 3003/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 3004/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 3005/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 3006/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 3007/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.8636\n",
      "Epoch 3008/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3009/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3010/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3011/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3012/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3013/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3014/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3015/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3016/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3017/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3018/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3019/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3020/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3021/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3022/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3023/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3024/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3025/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3026/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3027/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3028/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3029/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3030/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3031/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3032/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3033/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3034/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3035/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3036/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3037/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3038/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3039/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3040/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3041/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3042/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8636\n",
      "Epoch 3043/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3044/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3045/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3046/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3047/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3048/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3049/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3050/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3051/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3052/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3053/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3054/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3055/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3056/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3057/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3058/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3059/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3060/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3061/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3062/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3063/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3064/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3065/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3066/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3067/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3068/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3069/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3070/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3071/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3072/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3073/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3074/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3075/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3076/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3077/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3078/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8636\n",
      "Epoch 3079/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3080/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3081/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3082/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3083/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3084/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3085/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3086/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3087/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3088/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3089/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3090/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3091/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3092/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3093/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3094/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3095/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3096/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3097/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3098/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3099/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3100/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3101/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3102/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3103/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3104/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3105/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3106/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3107/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3108/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3109/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3110/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3111/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3112/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3113/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3114/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3115/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4135 - accuracy: 0.8636\n",
      "Epoch 3116/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3117/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3118/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3119/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3120/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3121/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3122/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3123/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3124/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3125/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3126/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3127/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3128/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3129/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3130/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3131/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3132/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3133/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3134/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3135/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3136/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3137/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3138/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3139/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3140/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3141/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3142/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3143/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3144/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3145/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3146/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3147/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3148/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3149/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3150/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3151/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3152/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3153/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8636\n",
      "Epoch 3154/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3155/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3156/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3157/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3158/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3159/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3160/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3161/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3162/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3163/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3164/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3165/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3166/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3167/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3168/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3169/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3170/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3171/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3172/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3173/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3174/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3175/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3176/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3177/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3178/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3179/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3180/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3181/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3182/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3183/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3184/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3185/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3186/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3187/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3188/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3189/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3190/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3191/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8636\n",
      "Epoch 3192/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3193/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3194/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3195/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3196/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3197/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3198/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3199/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3200/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3201/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3202/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3203/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3204/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3205/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3206/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3207/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3208/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3209/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3210/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3211/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3212/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3213/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3215/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3216/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3217/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3218/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3219/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3220/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3221/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3222/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3223/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3224/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3225/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3226/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3227/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3228/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3229/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3230/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3231/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8636\n",
      "Epoch 3232/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3233/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3234/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3235/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3236/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3237/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3238/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3239/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3240/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3241/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3242/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3243/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3244/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3245/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3246/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3247/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3248/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3249/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3250/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3251/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3252/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3253/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3254/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3255/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3256/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3257/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3258/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3259/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3260/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3261/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3262/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3263/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3264/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3265/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3266/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3267/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3268/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3269/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3270/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3271/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3272/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8636\n",
      "Epoch 3273/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3274/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3275/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3276/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3277/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3278/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3279/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3280/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3281/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3282/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3283/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3284/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3285/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3286/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3287/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3288/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3289/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3290/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3291/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3292/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3293/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3294/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3295/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3296/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3297/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3298/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3299/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3300/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3301/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3302/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3303/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3304/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3305/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3306/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3307/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3308/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3309/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3310/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3311/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3312/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3313/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8636\n",
      "Epoch 3314/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3315/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3316/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3317/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3318/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3319/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3320/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3321/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3322/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3323/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3324/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3325/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3326/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3327/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3328/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3329/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3330/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3331/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3332/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3333/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3334/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3335/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3336/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3337/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3338/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3339/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3340/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3341/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3342/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3343/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3344/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3345/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3346/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3347/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3348/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3349/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3350/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3351/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3352/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3353/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3354/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3355/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3356/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8636\n",
      "Epoch 3357/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3358/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3359/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3360/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3361/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3362/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3363/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3364/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3365/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3366/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3367/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3368/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3369/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3370/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3371/10000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3372/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3373/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3374/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3375/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3376/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3377/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3378/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3379/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3380/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3381/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3382/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3383/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3384/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3385/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3386/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3387/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3388/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3389/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3390/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3391/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3392/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3393/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3394/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3395/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3396/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3397/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3398/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3399/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3400/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8636\n",
      "Epoch 3401/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3402/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3403/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3404/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3405/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3406/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3407/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3408/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3409/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3410/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3411/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3412/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3413/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3414/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3415/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3416/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3417/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3418/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3419/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3420/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3421/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3422/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3423/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3424/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3425/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3426/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3427/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3428/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3429/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3430/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3431/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3432/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3433/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3434/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3435/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3436/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3437/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3438/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3439/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3440/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3441/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3442/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3443/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3444/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3445/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3446/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8636\n",
      "Epoch 3447/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3448/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3449/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3450/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3451/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3452/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3453/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3454/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3455/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3456/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3457/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3458/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3459/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3460/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3461/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3462/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3463/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3464/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3465/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3466/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3467/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3468/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3469/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3470/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3471/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3472/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3473/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3474/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3475/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3476/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3477/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3478/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3479/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3480/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3481/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3482/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3483/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3484/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3485/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3486/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3487/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3488/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3489/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3490/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3491/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3492/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8636\n",
      "Epoch 3493/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3494/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3495/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3496/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3497/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3498/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3499/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3500/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3501/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3502/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3503/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3504/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3505/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3506/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3507/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3508/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3509/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3510/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3511/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3512/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3513/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3514/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3515/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3516/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3517/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3518/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3519/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3520/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3521/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3522/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3523/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3524/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3525/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3526/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3527/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3528/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3529/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3530/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3531/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3532/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3533/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3534/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3535/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3536/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3537/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3538/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3539/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3540/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3541/10000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4125 - accuracy: 0.8636\n",
      "Epoch 3542/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3543/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3544/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3545/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3546/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3547/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3548/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3549/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3550/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3551/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3552/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3553/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3554/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3555/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3556/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3557/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3558/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3559/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3560/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3561/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3562/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3563/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3564/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3565/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3566/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3567/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3568/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3569/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3570/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3571/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3572/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3573/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3574/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3575/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3576/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3577/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3578/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3579/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3580/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3581/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3582/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3583/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3584/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3585/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3586/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3587/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3588/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3589/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3590/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3591/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8636\n",
      "Epoch 3592/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3593/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3594/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3595/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3596/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3597/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3598/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3599/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3600/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3601/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3602/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3603/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3604/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3605/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3606/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3607/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3608/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3609/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3610/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3611/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3612/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3613/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3614/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3615/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3616/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3617/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3618/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3619/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3620/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3621/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3622/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3623/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3624/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3625/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3626/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3627/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3628/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3629/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3630/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3631/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3632/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3633/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3634/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3635/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3636/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3637/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3638/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3639/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3640/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3641/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3642/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3643/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8636\n",
      "Epoch 3644/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3645/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3646/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3647/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3648/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3649/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3650/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3651/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3652/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3653/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3654/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3655/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3656/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3657/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3658/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3659/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3660/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3661/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3662/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3663/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3664/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3665/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3666/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3667/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3668/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3669/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3670/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3671/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3672/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3673/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3674/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3675/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3676/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3677/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3678/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3679/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3680/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3681/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3682/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3683/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3684/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3685/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3686/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3687/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3688/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3689/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3690/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3691/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3692/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3693/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3694/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3695/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3696/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8636\n",
      "Epoch 3697/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3698/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3699/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3700/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3701/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3702/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3703/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3704/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3705/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3706/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3707/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3708/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3709/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3710/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3711/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3712/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3713/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3714/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3715/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3716/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3717/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3718/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3719/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3720/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3721/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3722/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3723/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3724/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3725/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3726/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3727/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3728/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3729/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3730/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3731/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3732/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3733/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3734/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3735/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3736/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3737/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3738/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3739/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3740/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3741/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3742/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3743/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3744/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3745/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3746/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3747/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3748/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3749/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3750/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3751/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3752/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8636\n",
      "Epoch 3753/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3754/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3755/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3756/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3757/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3758/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3759/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3760/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3761/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3762/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3763/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3764/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3765/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3766/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3767/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3768/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3769/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3770/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3771/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3772/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3773/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3774/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3775/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3776/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3777/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3778/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3779/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3780/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3781/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3782/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3783/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3784/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3785/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3786/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3787/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3788/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3789/10000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3790/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3791/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3792/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3793/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3794/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3795/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3796/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3797/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3798/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3799/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3800/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3801/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3802/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3803/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3804/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3805/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3806/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3807/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3808/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3809/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3810/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3811/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8636\n",
      "Epoch 3812/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3813/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3814/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3815/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3816/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3817/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3818/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3819/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3820/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3821/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3822/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3823/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3824/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3825/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3826/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3827/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3828/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3829/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3830/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3831/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3832/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3833/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3834/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3835/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3836/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3837/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3838/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3839/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3840/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3841/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3842/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3843/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3844/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3845/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3846/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3847/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3848/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3849/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3850/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3851/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3852/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3853/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3854/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3855/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3856/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3857/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3858/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3859/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3860/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3861/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3862/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3863/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3864/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3865/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3866/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3867/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3868/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3869/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3870/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3871/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8636\n",
      "Epoch 3872/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3873/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3874/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3875/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3876/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3877/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3878/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3879/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3880/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3881/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3882/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3883/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3884/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3885/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3886/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3887/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3888/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3889/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3890/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3891/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3892/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3893/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3894/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3895/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3896/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3897/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3898/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3899/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3900/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3901/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3902/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3903/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3904/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3905/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3906/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3907/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3908/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3909/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3910/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3911/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3912/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3913/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3914/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3915/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3916/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3917/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3918/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3919/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3920/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3921/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3922/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3923/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3924/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3925/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3926/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3927/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3928/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3929/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3930/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3931/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3932/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3933/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3934/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3935/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8636\n",
      "Epoch 3936/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3937/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3938/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3939/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3940/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3941/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3942/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3943/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3944/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3945/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3946/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3947/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3948/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3949/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3950/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3951/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3952/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3953/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3954/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3955/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3956/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3957/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3958/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3959/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3960/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3961/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3962/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3963/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3964/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3965/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3966/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3967/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3968/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3969/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3970/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3971/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3972/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3973/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3974/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3975/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3976/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3977/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3978/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3979/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3980/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3981/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3982/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3983/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3984/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3985/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3986/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3987/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3988/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3989/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3990/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3991/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3992/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3993/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3994/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3995/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3996/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3997/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3998/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 3999/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 4000/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 4001/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 4002/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 4003/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8636\n",
      "Epoch 4004/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4005/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4006/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4007/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4008/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4009/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4010/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4011/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4012/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4013/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4014/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4015/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4016/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4017/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4018/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4019/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4020/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4021/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4022/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4023/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4024/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4025/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4026/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4027/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4028/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4029/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4030/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4031/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4032/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4033/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4034/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4035/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4036/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4037/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4038/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4039/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4040/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4041/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4042/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4043/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4044/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4045/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4046/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4047/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4048/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4049/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4050/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4051/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4052/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4053/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4054/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4055/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4056/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4057/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4058/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4059/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4060/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4061/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4062/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4063/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4064/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4065/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4066/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4067/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4068/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4069/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4070/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4071/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4072/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4073/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8636\n",
      "Epoch 4074/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4075/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4076/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4077/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4078/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4079/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4080/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4081/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4082/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4083/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4084/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4085/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4086/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4087/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4088/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4089/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4090/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4091/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4092/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4093/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4094/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4095/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4096/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4097/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4098/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4099/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4100/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4101/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4102/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4103/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4104/10000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4105/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4106/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4107/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4108/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4109/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4110/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4111/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4112/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4113/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4114/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4115/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4116/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4117/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4118/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4119/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4120/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4121/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4122/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4123/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4124/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4125/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4126/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4127/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4128/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4129/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4130/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4131/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4132/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4133/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4134/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4135/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4136/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4137/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4138/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4139/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4140/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4141/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4142/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4143/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4144/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4145/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4146/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4147/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4148/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4149/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8636\n",
      "Epoch 4150/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4151/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4152/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4153/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4154/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4155/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4156/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4157/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4158/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4159/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4160/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4161/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4162/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4163/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4164/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4165/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4166/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4167/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4168/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4169/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4170/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4171/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4172/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4173/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4174/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4175/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4176/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4177/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4178/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4179/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4180/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4181/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4182/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4183/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4184/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4185/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4186/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4187/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4188/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4189/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4190/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4191/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4192/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4193/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4194/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4195/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4196/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4197/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4198/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4199/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4200/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4201/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4202/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4203/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4204/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4205/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4206/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4207/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4208/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4209/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4210/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4211/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4212/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4213/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4214/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4215/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4216/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4217/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4218/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4219/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4220/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4221/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4222/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4223/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4224/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4225/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4226/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4227/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4228/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4229/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8636\n",
      "Epoch 4230/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4231/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4232/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4233/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4234/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4235/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4236/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4237/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4238/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4239/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4240/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4241/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4242/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4243/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4244/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4245/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4246/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4247/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4248/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4249/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4250/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4251/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4252/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4253/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4254/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4255/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4256/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4257/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4258/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4259/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4260/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4261/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4262/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4263/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4264/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4265/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4266/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4267/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4268/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4269/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4270/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4271/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4272/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4273/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4274/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4275/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4276/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4277/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4278/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4279/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4280/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4281/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4282/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4283/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4284/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4285/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4286/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4287/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4288/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4289/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4290/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4291/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4292/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4293/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4294/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4295/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4296/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4297/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4298/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4299/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4300/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4301/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4302/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4303/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4304/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4305/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4306/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4307/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4308/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4309/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4310/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4311/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4312/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4313/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4314/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4315/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8636\n",
      "Epoch 4316/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4317/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4318/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4319/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4320/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4321/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4322/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4323/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4324/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4325/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4326/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4327/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4328/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4329/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4330/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4331/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4332/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4333/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4334/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4335/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4336/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4337/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4338/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4339/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4340/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4341/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4342/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4343/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4344/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4345/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4346/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4347/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4348/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4349/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4350/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4351/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4352/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4353/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4354/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4355/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4356/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4357/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4358/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4359/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4360/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4361/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4362/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4363/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4364/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4365/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4366/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4367/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4368/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4369/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4370/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4371/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4372/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4373/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4374/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4375/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4376/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4377/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4378/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4379/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4380/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4381/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4382/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4383/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4384/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4385/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4386/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4387/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4388/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4389/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4390/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4391/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4392/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4393/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4394/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4395/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4396/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4397/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4398/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4399/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4400/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4401/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4402/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4403/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4404/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4405/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4406/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4407/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4408/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8636\n",
      "Epoch 4409/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4410/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4411/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4412/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4413/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4414/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4415/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4416/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4417/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4418/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4419/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4420/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4421/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4422/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4423/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4424/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4425/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4426/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4427/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4428/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4429/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4430/10000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4431/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4432/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4433/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4434/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4435/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4436/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4437/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4438/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4439/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4440/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4441/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4442/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4443/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4444/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4445/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4446/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4447/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4448/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4449/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4450/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4451/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4452/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4453/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4454/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4455/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4456/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4457/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4458/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4459/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4460/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4461/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4462/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4463/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4464/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4465/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4466/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4467/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4468/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4469/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4470/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4471/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4472/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4473/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4474/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4475/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4476/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4477/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4478/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4479/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4480/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4481/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4482/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4483/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4484/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4485/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4486/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4487/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4488/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4489/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4490/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4491/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4492/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4493/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4494/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4495/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4496/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4497/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4498/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4499/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4500/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4501/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4502/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4503/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4504/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4505/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4506/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4507/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4508/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4509/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4510/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8636\n",
      "Epoch 4511/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4512/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4513/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4514/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4515/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4516/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4517/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4518/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4519/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4520/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4521/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4522/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4523/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4524/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4525/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4526/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4527/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4528/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4529/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4530/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4531/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4532/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4533/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4534/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4535/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4536/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4537/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4538/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4539/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4540/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4541/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4542/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4543/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4544/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4545/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4546/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4547/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4548/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4549/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4550/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4551/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4552/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4553/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4554/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4555/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4556/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4557/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4558/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4559/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4560/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4561/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4562/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4563/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4564/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4565/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4566/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4567/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4568/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4569/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4570/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4571/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4572/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4573/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4574/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4575/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4576/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4577/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4578/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4579/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4580/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4581/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4582/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4583/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4584/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4585/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4586/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4587/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4588/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4589/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4590/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4591/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4592/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4593/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4594/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4595/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4596/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4597/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4598/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4599/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4600/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4601/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4602/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4603/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4604/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4605/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4606/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4607/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4608/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4609/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4610/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4611/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4612/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4613/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4614/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4615/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4616/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4617/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4618/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4619/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4620/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4621/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4622/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4623/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8636\n",
      "Epoch 4624/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4625/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4626/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4627/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4628/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4629/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4630/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4631/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4632/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4633/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4634/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4635/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4636/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4637/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4638/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4639/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4640/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4641/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4642/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4643/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4644/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4645/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4646/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4647/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4648/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4649/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4650/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4651/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4652/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4653/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4654/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4655/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4656/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4657/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4658/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4659/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4660/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4661/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4662/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4663/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4664/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4665/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4666/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4667/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4668/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4669/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4670/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4671/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4672/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4673/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4674/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4675/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4676/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4677/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4678/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4679/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4680/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4681/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4682/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4683/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4684/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4685/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4686/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4687/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4688/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4689/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4690/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4691/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4692/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4693/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4694/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4695/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4696/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4697/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4698/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4699/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4700/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4701/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4702/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4703/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4704/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4705/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4706/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4707/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4708/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4709/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4710/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4711/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4712/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4713/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4714/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4715/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4716/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4717/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4718/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4719/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4720/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4721/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4722/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4723/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4724/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4725/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4726/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4727/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4728/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4729/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4730/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4731/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4732/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4733/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4734/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4735/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4736/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4737/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4738/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4739/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4740/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4741/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4742/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4743/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4744/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4745/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4746/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4747/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4748/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4749/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4750/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4109 - accuracy: 0.8636\n",
      "Epoch 4751/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4752/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4753/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4754/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4755/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4756/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4757/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4758/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4759/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4760/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4761/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4762/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4763/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4764/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4765/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4766/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4767/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4768/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4769/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4770/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4771/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4772/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4773/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4774/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4775/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4776/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4777/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4778/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4779/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4780/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4781/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4782/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4783/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4784/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4785/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4786/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4787/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4788/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4789/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4790/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4791/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4792/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4793/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4794/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4795/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4796/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4797/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4798/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4799/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4800/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4801/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4802/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4803/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4804/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4805/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4806/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4807/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4808/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4809/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4810/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4811/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4812/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4813/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4814/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4815/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4816/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4817/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4818/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4819/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4820/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4821/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4822/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4823/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4824/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4825/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4826/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4827/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4828/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4829/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4830/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4831/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4832/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4833/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4834/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4835/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4836/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4837/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4838/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4839/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4840/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4841/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4842/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4843/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4844/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4845/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4846/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4847/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4848/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4849/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4850/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4851/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4852/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4853/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4854/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4855/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4856/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4857/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4858/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4859/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4860/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4861/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4862/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4863/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4864/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4865/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4866/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4867/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4868/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4869/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4870/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4871/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4872/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4873/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4874/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4875/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4876/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4877/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4878/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4879/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4880/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4881/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4882/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4883/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4884/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4885/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4886/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4887/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4888/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4889/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4890/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4891/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4892/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4893/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4894/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4895/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4896/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8636\n",
      "Epoch 4897/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4898/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4899/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4900/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4901/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4902/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4903/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4904/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4905/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4906/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4907/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4908/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4909/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4910/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4911/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4912/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4913/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4914/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4915/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4916/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4917/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4918/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4919/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4920/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4921/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4922/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4923/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4924/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4925/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4926/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4927/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4928/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4929/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4930/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4931/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4932/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4933/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4934/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4935/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4936/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4937/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4938/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4939/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4940/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4941/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4942/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4943/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4944/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4945/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4946/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4947/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4948/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4949/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4950/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4951/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4952/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4953/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4954/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4955/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4956/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4957/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4958/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4959/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4960/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4961/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4962/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4963/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4964/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4965/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4966/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4967/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4968/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4969/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4970/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4971/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4972/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4973/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4974/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4975/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4976/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4977/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4978/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4979/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4980/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4981/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4982/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4983/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4984/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4985/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4986/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4987/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4988/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4989/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4990/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4991/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4992/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4993/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4994/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4995/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4996/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4997/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4998/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 4999/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5000/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5001/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5002/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5003/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5004/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5005/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5006/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5007/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5008/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5009/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5010/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5011/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5012/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5013/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5014/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5015/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5016/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5017/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5018/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5019/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5020/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5021/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5022/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5023/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5024/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5025/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5026/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5027/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5028/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5029/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5030/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5031/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5032/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5033/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5034/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5035/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5036/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5037/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5038/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5039/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5040/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5041/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5042/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5043/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5044/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5045/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5046/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5047/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5048/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5049/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5050/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5051/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5052/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5053/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5054/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5055/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5056/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5057/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5058/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5059/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5060/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5061/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5062/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5063/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5064/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5065/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5066/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5067/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5068/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5069/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5070/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8636\n",
      "Epoch 5071/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5072/10000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5073/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5074/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5075/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5076/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5077/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5078/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5079/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5080/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5081/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5082/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5083/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5084/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5085/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5086/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5087/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5088/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5089/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5090/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5091/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5092/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5093/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5094/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5095/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5096/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5097/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5098/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5099/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5100/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5101/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5102/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5103/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5104/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5105/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5106/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5107/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5108/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5109/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5110/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5111/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5112/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5113/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5114/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5115/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5116/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5117/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5118/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5119/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5120/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5121/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5122/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5123/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5124/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5125/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5126/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5127/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5128/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5129/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5130/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5131/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5132/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5133/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5134/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5135/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5136/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5137/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5138/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5139/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5140/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5141/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5142/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5143/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5144/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5145/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5146/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5147/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5148/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5149/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5150/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5151/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5152/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5153/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5154/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5155/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5156/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5157/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5158/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5159/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5160/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5161/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5162/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5163/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5164/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5165/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5166/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5167/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5168/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5169/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5170/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5171/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5172/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5173/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5174/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5175/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5176/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5177/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5178/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5179/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5180/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5181/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5182/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5183/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5184/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5185/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5186/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5187/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5188/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5189/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5190/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5191/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5192/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5193/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5194/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5195/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5196/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5197/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5198/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5199/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5200/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5201/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5202/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5203/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5204/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5205/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5206/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5207/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5208/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5209/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5210/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5211/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5212/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5213/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5215/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5216/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5217/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5218/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5219/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5220/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5221/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5222/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5223/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5224/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5225/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5226/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5227/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5228/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5229/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5230/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5231/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5232/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5233/10000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5234/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5235/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5236/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5237/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5238/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5239/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5240/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5241/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5242/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5243/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5244/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5245/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5246/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5247/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5248/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5249/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5250/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5251/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5252/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5253/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5254/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5255/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5256/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5257/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5258/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5259/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5260/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5261/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5262/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5263/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5264/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5265/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5266/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5267/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5268/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5269/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5270/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5271/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5272/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5273/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5274/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5275/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5276/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5277/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5278/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5279/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5280/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5281/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5282/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5283/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5284/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5285/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5286/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5287/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5288/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5289/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5290/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5291/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8636\n",
      "Epoch 5292/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5293/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5294/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5295/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5296/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5297/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5298/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5299/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5300/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5301/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5302/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5303/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5304/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5305/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5306/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5307/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5308/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5309/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5310/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5311/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5312/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5313/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5314/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5315/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5316/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5317/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5318/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5319/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5320/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5321/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5322/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5323/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5324/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5325/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5326/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5327/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5328/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5329/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5330/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5331/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5332/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5333/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5334/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5335/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5336/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5337/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5338/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5339/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5340/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5341/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5342/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5343/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5344/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5345/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5346/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5347/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5348/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5349/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5350/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5351/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5352/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5353/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5354/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5355/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5356/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5357/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5358/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5359/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5360/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5361/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5362/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5363/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5364/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5365/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5366/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5367/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5368/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5369/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5370/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5371/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5372/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5373/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5374/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5375/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5376/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5377/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5378/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5379/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5380/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5381/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5382/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5383/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5384/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5385/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5386/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5387/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5388/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5389/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5390/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5391/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5392/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5393/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5394/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5395/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5396/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5397/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5398/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5399/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5400/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5401/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5402/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5403/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5404/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5405/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5406/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5407/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5408/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5409/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5410/10000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5411/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5412/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5413/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5414/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5415/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5416/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5417/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5418/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5419/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5420/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5421/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5422/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5423/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5424/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5425/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5426/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5427/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5428/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5429/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5430/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5431/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5432/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5433/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5434/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5435/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5436/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5437/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5438/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5439/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5440/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5441/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5442/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5443/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5444/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5445/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5446/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5447/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5448/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5449/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5450/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5451/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5452/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5453/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5454/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5455/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5456/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5457/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5458/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5459/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5460/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5461/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5462/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5463/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5464/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5465/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5466/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5467/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5468/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5469/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5470/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5471/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5472/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5473/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5474/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5475/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5476/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5477/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5478/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5479/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5480/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5481/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5482/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5483/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5484/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5485/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5486/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5487/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5488/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5489/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5490/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5491/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5492/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5493/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5494/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5495/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5496/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5497/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5498/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5499/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5500/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5501/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5502/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5503/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5504/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5505/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5506/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5507/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5508/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5509/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5510/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5511/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5512/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5513/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5514/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5515/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5516/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5517/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5518/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5519/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5520/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5521/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5522/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5523/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5524/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5525/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5526/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5527/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5528/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5529/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5530/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5531/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5532/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5533/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5534/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5535/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5536/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5537/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5538/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5539/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5540/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5541/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5542/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5543/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5544/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5545/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5546/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5547/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5548/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5549/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5550/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5551/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5552/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5553/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5554/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5555/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5556/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5557/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5558/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5559/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5560/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5561/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5562/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5563/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5564/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5565/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5566/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5567/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5568/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5569/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5570/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5571/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5572/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5573/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5574/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5575/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5576/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5577/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5578/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5579/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5580/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5581/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5582/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5583/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5584/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5585/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5586/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5587/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5588/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5589/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5590/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5591/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5592/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5593/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5594/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5595/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5596/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5597/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5598/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5599/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5600/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5601/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5602/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5603/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5604/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5605/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5606/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8636\n",
      "Epoch 5607/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5608/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5609/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5610/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5611/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5612/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5613/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5614/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5615/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5616/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5617/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5618/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5619/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5620/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5621/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5622/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5623/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5624/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5625/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5626/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5627/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5628/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5629/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5630/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5631/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5632/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5633/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5634/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5635/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5636/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5637/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5638/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5639/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5640/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5641/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5642/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5643/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5644/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5645/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5646/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5647/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5648/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5649/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5650/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5651/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5652/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5653/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5654/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5655/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5656/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5657/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5658/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5659/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5660/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5661/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5662/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5663/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5664/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5665/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5666/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5667/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5668/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5669/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5670/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5671/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5672/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5673/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5674/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5675/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5676/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5677/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5678/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5679/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5680/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5681/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5682/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5683/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5684/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5685/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5686/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5687/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5688/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5689/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5690/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5691/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5692/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5693/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5694/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5695/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5696/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5697/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5698/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5699/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5700/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5701/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5702/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5703/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5704/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5705/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5706/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5707/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5708/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5709/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5710/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5711/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5712/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5713/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5714/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5715/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5716/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5717/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5718/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5719/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5720/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5721/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5722/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5723/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5724/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5725/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5726/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5727/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5728/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5729/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5730/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5731/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5732/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5733/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5734/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5735/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5736/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5737/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5738/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5739/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5740/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5741/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5742/10000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5743/10000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5744/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5745/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5746/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5747/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5748/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5749/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5750/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5751/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5752/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5753/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5754/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5755/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5756/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5757/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5758/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5759/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5760/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5761/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5762/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5763/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5764/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5765/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5766/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5767/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5768/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5769/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5770/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5771/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5772/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5773/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5774/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5775/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5776/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5777/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5778/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5779/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5780/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5781/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5782/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5783/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5784/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5785/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5786/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5787/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5788/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5789/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5790/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5791/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5792/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5793/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5794/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5795/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5796/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5797/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5798/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5799/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5800/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5801/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5802/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5803/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5804/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5805/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5806/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5807/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5808/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5809/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5810/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5811/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5812/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5813/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5814/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5815/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5816/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5817/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5818/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5819/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5820/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5821/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5822/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5823/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5824/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5825/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5826/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5827/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5828/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5829/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5830/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5831/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5832/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5833/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5834/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5835/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5836/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5837/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5838/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5839/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5840/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5841/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5842/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5843/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5844/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5845/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5846/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5847/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5848/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5849/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5850/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5851/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5852/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5853/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5854/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5855/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5856/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5857/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5858/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5859/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5860/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5861/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5862/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5863/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5864/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5865/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5866/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5867/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5868/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5869/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5870/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5871/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5872/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5873/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5874/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5875/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5876/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5877/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5878/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5879/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5880/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5881/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5882/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5883/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5884/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5885/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5886/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5887/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5888/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5889/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5890/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5891/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5892/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5893/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5894/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5895/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5896/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5897/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5898/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5899/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5900/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5901/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5902/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5903/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5904/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5905/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5906/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5907/10000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5908/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5909/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5910/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5911/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5912/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5913/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5914/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5915/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5916/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5917/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5918/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5919/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5920/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5921/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5922/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5923/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5924/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5925/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5926/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5927/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5928/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5929/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5930/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5931/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5932/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5933/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5934/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5935/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5936/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5937/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5938/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5939/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5940/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5941/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5942/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5943/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5944/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5945/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5946/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5947/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5948/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5949/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5950/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5951/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5952/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5953/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5954/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5955/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5956/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5957/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5958/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5959/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5960/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5961/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5962/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5963/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5964/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5965/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5966/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5967/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5968/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5969/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5970/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5971/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5972/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5973/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5974/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5975/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5976/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5977/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5978/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5979/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5980/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5981/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5982/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5983/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5984/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5985/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5986/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5987/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5988/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5989/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5990/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5991/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5992/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5993/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5994/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5995/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5996/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5997/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5998/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 5999/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6000/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6001/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6002/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6003/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6004/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6005/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6006/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6007/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6008/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6009/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6010/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6011/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6012/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6013/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6014/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6015/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6016/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6017/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6018/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6019/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6020/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6021/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6022/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6023/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6024/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6025/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6026/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6027/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6028/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6029/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6030/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6031/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6032/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6033/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6034/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6035/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6036/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6037/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6038/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6039/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6040/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6041/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6042/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6043/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6044/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6045/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6046/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6047/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6048/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6049/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6050/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6051/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6052/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6053/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6054/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6055/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6056/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6057/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6058/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6059/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6060/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6061/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6062/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6063/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6064/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6065/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6066/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6067/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6068/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6069/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6070/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6071/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6072/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6073/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6074/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6075/10000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6076/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6077/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6078/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6079/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6080/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6081/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6082/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6083/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6084/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6085/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6086/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6087/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6088/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6089/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6090/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6091/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6092/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6093/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6094/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6095/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6096/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6097/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6098/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6099/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6100/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6101/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6102/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6103/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6104/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6105/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6106/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6107/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6108/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6109/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6110/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6111/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6112/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6113/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6114/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6115/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6116/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6117/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6118/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6119/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6120/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6121/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6122/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6123/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6124/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6125/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6126/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6127/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6128/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6129/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6130/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6131/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6132/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6133/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6134/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6135/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6136/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6137/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6138/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6139/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6140/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6141/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6142/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6143/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6144/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6145/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6146/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6147/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6148/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6149/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6150/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6151/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6152/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6153/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6154/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6155/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6156/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6157/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6158/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6159/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6160/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6161/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6162/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6163/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6164/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6165/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6166/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6167/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6168/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6169/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6170/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6171/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6172/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6173/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6174/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6175/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6176/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6177/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6178/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6179/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6180/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6181/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6182/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6183/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6184/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6185/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6186/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6187/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6188/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6189/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6190/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6191/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6192/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6193/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6194/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6195/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6196/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6197/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6198/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6199/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6200/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6201/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6202/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6203/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6204/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6205/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6206/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6207/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6208/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6209/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6210/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6211/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6212/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6213/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6214/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6215/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6216/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6217/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6218/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6219/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6220/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6221/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6222/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6223/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6224/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6225/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6226/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6227/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6228/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6229/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6230/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6231/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6232/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6233/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6234/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6235/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6236/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6237/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6238/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6239/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6240/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6241/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6242/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6243/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6244/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6245/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6246/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6247/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6248/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6249/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6250/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6251/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6252/10000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6253/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6254/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6255/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6256/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6257/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6258/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6259/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6260/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6261/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6262/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6263/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6264/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6265/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6266/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6267/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6268/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6269/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6270/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6271/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6272/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6273/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6274/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6275/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6276/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6277/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8636\n",
      "Epoch 6278/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6279/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6280/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6281/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6282/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6283/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6284/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6285/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6286/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6287/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6288/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6289/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6290/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6291/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6292/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6293/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6294/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6295/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6296/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6297/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6298/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6299/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6300/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6301/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6302/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6303/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6304/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6305/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6306/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6307/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6308/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6309/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6310/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6311/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6312/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6313/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6314/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6315/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6316/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6317/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6318/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6319/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6320/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6321/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6322/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6323/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6324/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6325/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6326/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6327/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6328/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6329/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6330/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6331/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6332/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6333/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6334/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6335/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6336/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6337/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6338/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6339/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6340/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6341/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6342/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6343/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6344/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6345/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6346/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6347/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6348/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6349/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6350/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6351/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6352/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6353/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6354/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6355/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6356/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6357/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6358/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6359/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6360/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6361/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6362/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6363/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6364/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6365/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6366/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6367/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6368/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6369/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6370/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6371/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6372/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6373/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6374/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6375/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6376/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6377/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6378/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6379/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6380/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6381/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6382/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6383/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6384/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6385/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6386/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6387/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6388/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6389/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6390/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6391/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6392/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6393/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6394/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6395/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6396/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6397/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6398/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6399/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6400/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6401/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6402/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6403/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6404/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6405/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6406/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6407/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6408/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6409/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6410/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6411/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6412/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6413/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6414/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6415/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6416/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6417/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6418/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6419/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6420/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6421/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6422/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6423/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6424/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6425/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6426/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6427/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6428/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6429/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6430/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6431/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6432/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6433/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6434/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6435/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6436/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6437/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6438/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6439/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6440/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6441/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6442/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6443/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6444/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6445/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6446/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6447/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6448/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6449/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6450/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6451/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6452/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6453/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6454/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6455/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6456/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6457/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6458/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6459/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6460/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6461/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6462/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6463/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6464/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6465/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6466/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6467/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6468/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6469/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6470/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6471/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6472/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6473/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6474/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6475/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6476/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6477/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6478/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6479/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6480/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6481/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6482/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6483/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6484/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6485/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6486/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6487/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6488/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6489/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6490/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6491/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6492/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6493/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6494/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6495/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6496/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6497/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6498/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6499/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6500/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6501/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6502/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6503/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6504/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6505/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6506/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6507/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6508/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6509/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6510/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6511/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6512/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6513/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6514/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6515/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6516/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6517/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6518/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6519/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6520/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6521/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6522/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6523/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6524/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6525/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6526/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6527/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6528/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6529/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6530/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6531/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6532/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6533/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6534/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6535/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6536/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6537/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6538/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6539/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6540/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6541/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6542/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6543/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6544/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6545/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6546/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6547/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6548/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6549/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6550/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6551/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6552/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6553/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6554/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6555/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6556/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6557/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6558/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6559/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6560/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6561/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6562/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6563/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6564/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6565/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6566/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6567/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6568/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6569/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6570/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6571/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6572/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6573/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6574/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6575/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6576/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6577/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6578/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6579/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6580/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6581/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6582/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6583/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6584/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6585/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6586/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6587/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6588/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6589/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6590/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6591/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6592/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6593/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6594/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6595/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6596/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6597/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6598/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6599/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6600/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6601/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6602/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6603/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6604/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6605/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6606/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6607/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6608/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6609/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6610/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6611/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6612/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6613/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6614/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6615/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6616/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6617/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6618/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6619/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6620/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6621/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6622/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6623/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6624/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6625/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6626/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6627/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6628/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6629/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6630/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6631/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6632/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6633/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6634/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6635/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6636/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6637/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6638/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6639/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6640/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6641/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6642/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6643/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6644/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6645/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6646/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6647/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6648/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6649/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6650/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6651/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6652/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6653/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6654/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6655/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6656/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6657/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6658/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6659/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6660/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6661/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6662/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6663/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6664/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6665/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6666/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6667/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6668/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6669/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6670/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6671/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6672/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6673/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6674/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6675/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6676/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6677/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6678/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6679/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6680/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6681/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6682/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6683/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6684/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6685/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6686/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6687/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6688/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6689/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6690/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6691/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6692/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6693/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6694/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6695/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6696/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6697/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6698/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6699/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6700/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6701/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6702/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6703/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6704/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6705/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6706/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6707/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6708/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6709/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6710/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6711/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6712/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6713/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6714/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6715/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6716/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6717/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6718/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6719/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6720/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6721/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6722/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6723/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6724/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6725/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6726/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6727/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6728/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6729/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6730/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6731/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6732/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6733/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6734/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6735/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6736/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6737/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6738/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6739/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6740/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6741/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6742/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6743/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6744/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6745/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6746/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6747/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6748/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6749/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6750/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6751/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6752/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6753/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6754/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6755/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6756/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6757/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6758/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6759/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6760/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6761/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6762/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6763/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6764/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6765/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6766/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6767/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6768/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6769/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6770/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6771/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6772/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6773/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6774/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6775/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6776/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6777/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6778/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6779/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6780/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6781/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6782/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6783/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6784/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6785/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6786/10000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6787/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6788/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6789/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6790/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6791/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6792/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6793/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6794/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6795/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6796/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6797/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6798/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6799/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6800/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6801/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6802/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6803/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6804/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6805/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6806/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6807/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6808/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6809/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6810/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6811/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6812/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6813/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6814/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6815/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6816/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6817/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6818/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6819/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6820/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6821/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6822/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6823/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6824/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6825/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6826/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6827/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6828/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6829/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6830/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6831/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6832/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6833/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6834/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6835/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6836/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6837/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6838/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6839/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6840/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6841/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6842/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6843/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6844/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6845/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6846/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6847/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6848/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6849/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6850/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6851/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6852/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6853/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6854/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6855/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6856/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6857/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6858/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6859/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6860/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6861/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6862/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6863/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6864/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6865/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6866/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6867/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6868/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6869/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6870/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6871/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6872/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6873/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6874/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6875/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6876/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6877/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6878/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6879/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6880/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6881/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6882/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6883/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6884/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6885/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6886/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6887/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6888/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6889/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6890/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6891/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6892/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6893/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6894/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6895/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6896/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6897/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6898/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6899/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6900/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6901/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6902/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6903/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6904/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6905/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6906/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6907/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6908/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6909/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6910/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6911/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6912/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6913/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6914/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6915/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6916/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6917/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6918/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6919/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6920/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6921/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6922/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6923/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6924/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6925/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6926/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6927/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6928/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6929/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6930/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6931/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6932/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6933/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6934/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6935/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6936/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6937/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6938/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6939/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6940/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6941/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6942/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6943/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6944/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6945/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6946/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6947/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6948/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6949/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6950/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6951/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6952/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6953/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6954/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6955/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6956/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6957/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6958/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6959/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6960/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6961/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6962/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6963/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6964/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6965/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6966/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6967/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6968/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6969/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6970/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6971/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6972/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6973/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6974/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6975/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6976/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6977/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6978/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6979/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6980/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6981/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6982/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6983/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6984/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6985/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6986/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6987/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6988/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6989/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6990/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6991/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6992/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6993/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6994/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6995/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6996/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6997/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6998/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 6999/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7000/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7001/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7002/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7003/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7004/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7005/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7006/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7007/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7008/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7009/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7010/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7011/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7012/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7013/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7014/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7015/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7016/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7017/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7018/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7019/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7020/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7021/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7022/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7023/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7024/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7025/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7026/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7027/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7028/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7029/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7030/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7031/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7032/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7033/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7034/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7035/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7036/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7037/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7038/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7039/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7040/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7041/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7042/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7043/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7044/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7045/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7046/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7047/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7048/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7049/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7050/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7051/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7052/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7053/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7054/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7055/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7056/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7057/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7058/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7059/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7060/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7061/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7062/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7063/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7064/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7065/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7066/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7067/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7068/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7069/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7070/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7071/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7072/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7073/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7074/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7075/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7076/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7077/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7078/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7079/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7080/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7081/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7082/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7083/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7084/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7085/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7086/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7087/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7088/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7089/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7090/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7091/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7092/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7093/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7094/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7095/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7096/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7097/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7098/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7099/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7100/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7101/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7102/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7103/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7104/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7105/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7106/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7107/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7108/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7109/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7110/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7111/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7112/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7113/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7114/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7115/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7116/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7117/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7118/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7119/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7120/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7121/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7122/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7123/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7124/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7125/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7126/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7127/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7128/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7129/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7130/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7131/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7132/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7133/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7134/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7135/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7136/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7137/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7138/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7139/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7140/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7141/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7142/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7143/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7144/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7145/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7146/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7147/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7148/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7149/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7150/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7151/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7152/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7153/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7154/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7155/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7156/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7157/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7158/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7159/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7160/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7161/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7162/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7163/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7164/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7165/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7166/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7167/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7168/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7169/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7170/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7171/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7172/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7173/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7174/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7175/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7176/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7177/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7178/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7179/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7180/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7181/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7182/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7183/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7184/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7185/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7186/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7187/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7188/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7189/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7190/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7191/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7192/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7193/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7194/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7195/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7196/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7197/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7198/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7199/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7200/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7201/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7202/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7203/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7204/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7205/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7206/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7207/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7208/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7209/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7210/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7211/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7212/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7213/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7215/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7216/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7217/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7218/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7219/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7220/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7221/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7222/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7223/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7224/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7225/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7226/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7227/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7228/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7229/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7230/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7231/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7232/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7233/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7234/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7235/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7236/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7237/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7238/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7239/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7240/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7241/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7242/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7243/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7244/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7245/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7246/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7247/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7248/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7249/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7250/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7251/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7252/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7253/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7254/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7255/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7256/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7257/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7258/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7259/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7260/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7261/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7262/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7263/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7264/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7265/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7266/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7267/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7268/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7269/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7270/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7271/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7272/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7273/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7274/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7275/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7276/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7277/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7278/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7279/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7280/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7281/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7282/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7283/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7284/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7285/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7286/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7287/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7288/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7289/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7290/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7291/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7292/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7293/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7294/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7295/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7296/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7297/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7298/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7299/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7300/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7301/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7302/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7303/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7304/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7305/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7306/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7307/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7308/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7309/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7310/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7311/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7312/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7313/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7314/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7315/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7316/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7317/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7318/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7319/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7320/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7321/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7322/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7323/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7324/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7325/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7326/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7327/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7328/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7329/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7330/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7331/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7332/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7333/10000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7334/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7335/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7336/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7337/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7338/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7339/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7340/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7341/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7342/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7343/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7344/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7345/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7346/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7347/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7348/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7349/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7350/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7351/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7352/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7353/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7354/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7355/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7356/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7357/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7358/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7359/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7360/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7361/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7362/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7363/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7364/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7365/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7366/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7367/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7368/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7369/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7370/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7371/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7372/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7373/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7374/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7375/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7376/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7377/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7378/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7379/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7380/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7381/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7382/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7383/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7384/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7385/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7386/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7387/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7388/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7389/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7390/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7391/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7392/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7393/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7394/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7395/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7396/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7397/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7398/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7399/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7400/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7401/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7402/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7403/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7404/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7405/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7406/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7407/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7408/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7409/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7410/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7411/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7412/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7413/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7414/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7415/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7416/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7417/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7418/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7419/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7420/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7421/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7422/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7423/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7424/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7425/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7426/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7427/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7428/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7429/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7430/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7431/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7432/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7433/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7434/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7435/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7436/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7437/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7438/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7439/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7440/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7441/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7442/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7443/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7444/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7445/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7446/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7447/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7448/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7449/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7450/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7451/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7452/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7453/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7454/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7455/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7456/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7457/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7458/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7459/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7460/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7461/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7462/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7463/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7464/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7465/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7466/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7467/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7468/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7469/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7470/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7471/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7472/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7473/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7474/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7475/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7476/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7477/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7478/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7479/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7480/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7481/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7482/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7483/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7484/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7485/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7486/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7487/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7488/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7489/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7490/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7491/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7492/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7493/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7494/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7495/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7496/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7497/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7498/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7499/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7500/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7501/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7502/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7503/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7504/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7505/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7506/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7507/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7508/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7509/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7510/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7511/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7512/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7513/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7514/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7515/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7516/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7517/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7518/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7519/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7520/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7521/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7522/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7523/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7524/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7525/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7526/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7527/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7528/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7529/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7530/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7531/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7532/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7533/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7534/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7535/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7536/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7537/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7538/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7539/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7540/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7541/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7542/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7543/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7544/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7545/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7546/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7547/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7548/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7549/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7550/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7551/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7552/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7553/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7554/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7555/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7556/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7557/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7558/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7559/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7560/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7561/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7562/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7563/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7564/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7565/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7566/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7567/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7568/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7569/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7570/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7571/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7572/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7573/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7574/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7575/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7576/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7577/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7578/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7579/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7580/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7581/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7582/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7583/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7584/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7585/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7586/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7587/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7588/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7589/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7590/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7591/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7592/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7593/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7594/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7595/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7596/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7597/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7598/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7599/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7600/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7601/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7602/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7603/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7604/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7605/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7606/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7607/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7608/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7609/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7610/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7611/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7612/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7613/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7614/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7615/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7616/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7617/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7618/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7619/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7620/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7621/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7622/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7623/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7624/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7625/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7626/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7627/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7628/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7629/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7630/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7631/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7632/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7633/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7634/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7635/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7636/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7637/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7638/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7639/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7640/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7641/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7642/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7643/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7644/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7645/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7646/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7647/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7648/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7649/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7650/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7651/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7652/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7653/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7654/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7655/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7656/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7657/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7658/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7659/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7660/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7661/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7662/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7663/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7664/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7665/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7666/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7667/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7668/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7669/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7670/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7671/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7672/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7673/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7674/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7675/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7676/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7677/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7678/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7679/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7680/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7681/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7682/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7683/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7684/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7685/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7686/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7687/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7688/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7689/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7690/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7691/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7692/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7693/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7694/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7695/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7696/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7697/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7698/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7699/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7700/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7701/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7702/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7703/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7704/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7705/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7706/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7707/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7708/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7709/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7710/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7711/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7712/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7713/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7714/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7715/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7716/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7717/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7718/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7719/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7720/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7721/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7722/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7723/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7724/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7725/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7726/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7727/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7728/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7729/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7730/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7731/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7732/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7733/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7734/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7735/10000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7736/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7737/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7738/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7739/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7740/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7741/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7742/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7743/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7744/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7745/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7746/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7747/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7748/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7749/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7750/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7751/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7752/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7753/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7754/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7755/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7756/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7757/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7758/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7759/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7760/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7761/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7762/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7763/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7764/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7765/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7766/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7767/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7768/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7769/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7770/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7771/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7772/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7773/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7774/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7775/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7776/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7777/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7778/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7779/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7780/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7781/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7782/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7783/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7784/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7785/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7786/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7787/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7788/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7789/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7790/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7791/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7792/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7793/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7794/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7795/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7796/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7797/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7798/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7799/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7800/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7801/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7802/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7803/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7804/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7805/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7806/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7807/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7808/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7809/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7810/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7811/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7812/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7813/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7814/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7815/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7816/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7817/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7818/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7819/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7820/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7821/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7822/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7823/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7824/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7825/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7826/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7827/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7828/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7829/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7830/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7831/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7832/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7833/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7834/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7835/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7836/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7837/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7838/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7839/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7840/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7841/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7842/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7843/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7844/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7845/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7846/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7847/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7848/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7849/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7850/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7851/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7852/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7853/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7854/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7855/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7856/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7857/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7858/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7859/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7860/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7861/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7862/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7863/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7864/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7865/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7866/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7867/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7868/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7869/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7870/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7871/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7872/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7873/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7874/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7875/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7876/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7877/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7878/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7879/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7880/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7881/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7882/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7883/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7884/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7885/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7886/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7887/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7888/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7889/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7890/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7891/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7892/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7893/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7894/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7895/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7896/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7897/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7898/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7899/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7900/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7901/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7902/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7903/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7904/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7905/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7906/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7907/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7908/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7909/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7910/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7911/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7912/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7913/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7914/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7915/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7916/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7917/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7918/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7919/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7920/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7921/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7922/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7923/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7924/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7925/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7926/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7927/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7928/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7929/10000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7930/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7931/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7932/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7933/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7934/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7935/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7936/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7937/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7938/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7939/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7940/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7941/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7942/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7943/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7944/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7945/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7946/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7947/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7948/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7949/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7950/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7951/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7952/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7953/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7954/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7955/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7956/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7957/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7958/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7959/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7960/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7961/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7962/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7963/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7964/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7965/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7966/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7967/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7968/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7969/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7970/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7971/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7972/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7973/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7974/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7975/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7976/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7977/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7978/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7979/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7980/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7981/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7982/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7983/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7984/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7985/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7986/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7987/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7988/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7989/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7990/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7991/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7992/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7993/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7994/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7995/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7996/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7997/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7998/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 7999/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8000/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8001/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8002/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8003/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8004/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8005/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8006/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8007/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8008/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8009/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8010/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8011/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8012/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8013/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8014/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8015/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8016/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8017/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8018/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8019/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8020/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8021/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8022/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8023/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8024/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8025/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8026/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8027/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8028/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8029/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8030/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8031/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8032/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8033/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8034/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8035/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8036/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8037/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8038/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8039/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8040/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8041/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8042/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8043/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8044/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8045/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8046/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8047/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8048/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8049/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8050/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8051/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8052/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8053/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8054/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8055/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8056/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8057/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8058/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8059/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8060/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8061/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8062/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8063/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8064/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8065/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8066/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8067/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8068/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8069/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8070/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8071/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8072/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8073/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8074/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8075/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8076/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8077/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8078/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8079/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8080/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8081/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8082/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8083/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8084/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8085/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8086/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8087/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8088/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8089/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8090/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8091/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8092/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8093/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8094/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8095/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8096/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8097/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8098/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8099/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8100/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8101/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8102/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8103/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8104/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8105/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8106/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8107/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8108/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8109/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8110/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8111/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8112/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8113/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8114/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8115/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8116/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8117/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8118/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8119/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8120/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8121/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8122/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8123/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8124/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8125/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8126/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8127/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8128/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8129/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8130/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8131/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8132/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8133/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8134/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8135/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8136/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8137/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8138/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8139/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8140/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8141/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8142/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8143/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8144/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8145/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8146/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8147/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8148/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8149/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8150/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8151/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8152/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8153/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8154/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8155/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8156/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8157/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8158/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8159/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8160/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8161/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8162/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8163/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8164/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8165/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8166/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8167/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8168/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8169/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8170/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8171/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8172/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8173/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8174/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8175/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8176/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8177/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8178/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8179/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8180/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8181/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8182/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8183/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8184/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8185/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8186/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8187/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8188/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8189/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8190/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8191/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8192/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8193/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8194/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8195/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8196/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8197/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8198/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8199/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8200/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8201/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8202/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8203/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8204/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8205/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8206/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8207/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8208/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8209/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8210/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8211/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8212/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8213/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8214/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8215/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8216/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8217/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8218/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8219/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8220/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8221/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8222/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8223/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8224/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8225/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8226/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8227/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8228/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8229/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8230/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8231/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8232/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8233/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8234/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8235/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8236/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8237/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8238/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8239/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8240/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8241/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8242/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8243/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8244/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8245/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8246/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8247/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8248/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8249/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8250/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8251/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8252/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8253/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8254/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8255/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8256/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8257/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8258/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8259/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8260/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8261/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8262/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8263/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8264/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8265/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8266/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8267/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8268/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8269/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8270/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8271/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8272/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8273/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8274/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8275/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8276/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8277/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8278/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8279/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8280/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8281/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8282/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8283/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8284/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8285/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8286/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8287/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8288/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8289/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8290/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8291/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8292/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8293/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8294/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8295/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8296/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8297/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8298/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8299/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8300/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8301/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8302/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8303/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8304/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8305/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8306/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8307/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8308/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8309/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8310/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8311/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8312/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8313/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8314/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8315/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8316/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8317/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8318/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8319/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8320/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8321/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8322/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8323/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8324/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8325/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8326/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8327/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8328/10000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8329/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8330/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8331/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8332/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8333/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8334/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8335/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8336/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8337/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8338/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8339/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8340/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8341/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8342/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8343/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8344/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8345/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8346/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8347/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8348/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8349/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8350/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8351/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8352/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8353/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8354/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8355/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8356/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8357/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8358/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8359/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8360/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8361/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8362/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8363/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8364/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8365/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8366/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8367/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8368/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8369/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8370/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8371/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8372/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8373/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8374/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8375/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8376/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8377/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8378/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8379/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8380/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8381/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8382/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8383/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8384/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8385/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8386/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8387/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8388/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8389/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8390/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8391/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8392/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8393/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8394/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8395/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8396/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8397/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8398/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8399/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8400/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8401/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8402/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8403/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8404/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8405/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8406/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8407/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8408/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8409/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8410/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8411/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8412/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8413/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8414/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8415/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8416/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8417/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8418/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8419/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8420/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8421/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8422/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8423/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8424/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8425/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8426/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8427/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8428/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8429/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8430/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8431/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8432/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8433/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8434/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8435/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8436/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8437/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8438/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8439/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8440/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8441/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8442/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8443/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8444/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8445/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8446/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8447/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8448/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8449/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8450/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8451/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8452/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8453/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8454/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8455/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8456/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8457/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8458/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8459/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8460/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8461/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8462/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8463/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8464/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8465/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8466/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8467/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8468/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8469/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8470/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8471/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8472/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8473/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8474/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8475/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8476/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8477/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8478/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8479/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8480/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8481/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8482/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8483/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8484/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8485/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8486/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8487/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8488/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8489/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8490/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8491/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8492/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8493/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8494/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8495/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8496/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8497/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8498/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8499/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8500/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8501/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8502/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8503/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8504/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8505/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8506/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8507/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8508/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8509/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8510/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8511/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8512/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8513/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8514/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8515/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8516/10000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8517/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8518/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8519/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8520/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8521/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8522/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8523/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8524/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8525/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8526/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8527/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8528/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8529/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8530/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8531/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8532/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8533/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8534/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8535/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8536/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8537/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8538/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8539/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8540/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8541/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8542/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8543/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8544/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8545/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8546/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8547/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8548/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8549/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8550/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8551/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8552/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8553/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8554/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8555/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8556/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8557/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8558/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8559/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8560/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8561/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8562/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8563/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8564/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8565/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8566/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8567/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8568/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8569/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8570/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8571/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8572/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8573/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8574/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8575/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8576/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8577/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8578/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8579/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8580/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8581/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8582/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8583/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8584/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8585/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8586/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8587/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8588/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8589/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8590/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8591/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8592/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8593/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8594/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8595/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8596/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8597/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8598/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8599/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8600/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8601/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8602/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8603/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8604/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8605/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8606/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8607/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8608/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8609/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8610/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8611/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8612/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8613/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8614/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8615/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8616/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8617/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8618/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8619/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8620/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8621/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8622/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8623/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8624/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8625/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8626/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8627/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8628/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8629/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8630/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8631/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8632/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8633/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8634/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8635/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8636/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8637/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8638/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8639/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8640/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8641/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8642/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8643/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8644/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8645/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8646/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8647/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8648/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8649/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8650/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8651/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8652/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8653/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8654/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8655/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8656/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8657/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8658/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8659/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8660/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8661/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8662/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8663/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8664/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8665/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8666/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8667/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8668/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8669/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8670/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8671/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8672/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8673/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8674/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8675/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8676/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8677/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8678/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8679/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8680/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8681/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8682/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8683/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8684/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8685/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8686/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8687/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8688/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8689/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8690/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8691/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8692/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8693/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8694/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8695/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8696/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8697/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8698/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8699/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8700/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8701/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8702/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8703/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8704/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8705/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8706/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8707/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8708/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8709/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8710/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8711/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8712/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8713/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8714/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8715/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8716/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8717/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8718/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8719/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8720/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8721/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8722/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8723/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8724/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8725/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8726/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8727/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8728/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8729/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8730/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8731/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8732/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8733/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8734/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8735/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8736/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8737/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8738/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8739/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8740/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8741/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8742/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8743/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8744/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8745/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8746/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8747/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8748/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8749/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8750/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8751/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8752/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8753/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8754/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8755/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8756/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8757/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8758/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8759/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8760/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8761/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8762/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8763/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8764/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8765/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8766/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8767/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8768/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8769/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8770/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8771/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8772/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8773/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8774/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8775/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8776/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8777/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8778/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8779/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8780/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8781/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8782/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8783/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8784/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8785/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8786/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8787/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8788/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8789/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8790/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8791/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8792/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8793/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8794/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8795/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8796/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8797/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8798/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8799/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8800/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8801/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8802/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8803/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8804/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8805/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8806/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8807/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8808/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8809/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8810/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8811/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8812/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8813/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8814/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8815/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8816/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8817/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8818/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8819/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8820/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8821/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8822/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8823/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8824/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8825/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8826/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8827/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8828/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8829/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8830/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8831/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8832/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8833/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8834/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8835/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8836/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8837/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8838/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8839/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8840/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8841/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8842/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8843/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8844/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8845/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8846/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8847/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8848/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8849/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8850/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8851/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8852/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8853/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8854/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8855/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8856/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8857/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8858/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8859/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8860/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8861/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8862/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8863/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8864/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8865/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8866/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8867/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8868/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8869/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8870/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8871/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8872/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8873/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8874/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8875/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8876/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8877/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8878/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8879/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8880/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8881/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8882/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8883/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8884/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8885/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8886/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8887/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8888/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8889/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8890/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8891/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8892/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8893/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8894/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8895/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8896/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8897/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8898/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8899/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8900/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8901/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8902/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8903/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8904/10000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8905/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8906/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8907/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8908/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8909/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8910/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8911/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8912/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8913/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8914/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8915/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8916/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8917/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8918/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8919/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8920/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8921/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8922/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8923/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8924/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8925/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8926/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8927/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8928/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8929/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8930/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8931/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8932/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8933/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8934/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8935/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8936/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8937/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8938/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8939/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8940/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8941/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8942/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8943/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8944/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8945/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8946/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8947/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8948/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8949/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8950/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8951/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8952/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8953/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8954/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8955/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8956/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8957/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8958/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8959/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8960/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8961/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8962/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8963/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8964/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8965/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8966/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8967/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8968/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8969/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8970/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8971/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8972/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8973/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8974/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8975/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8976/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8977/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8978/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8979/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8980/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8981/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8982/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8983/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8984/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8985/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8986/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8987/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8988/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8989/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8990/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8991/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8992/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8993/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8994/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8995/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8996/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8997/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8998/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 8999/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9000/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9001/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9002/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9003/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9004/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9005/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9006/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9007/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9008/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9009/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9010/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9011/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9012/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9013/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9014/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9015/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9016/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9017/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9018/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9019/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9020/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9021/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9022/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9023/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9024/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9025/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9026/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9027/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9028/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9029/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9030/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9031/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9032/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9033/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9034/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9035/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9036/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9037/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9038/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9039/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9040/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9041/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9042/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9043/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9044/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9045/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9046/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9047/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9048/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9049/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9050/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9051/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9052/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9053/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9054/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9055/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9056/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9057/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9058/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9059/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9060/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9061/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9062/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9063/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9064/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9065/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9066/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9067/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9068/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9069/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9070/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9071/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9072/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9073/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9074/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9075/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9076/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9077/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9078/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9079/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9080/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9081/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9082/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9083/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9084/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9085/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9086/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9087/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9088/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9089/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9090/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9091/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9092/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9093/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9094/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9095/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9096/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9097/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9098/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9099/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9100/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9101/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9102/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9103/10000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9104/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9105/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9106/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9107/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9108/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9109/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9110/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9111/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9112/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9113/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9114/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9115/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9116/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9117/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9118/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9119/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9120/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9121/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9122/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9123/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9124/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9125/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9126/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9127/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9128/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9129/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9130/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9131/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9132/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9133/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9134/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9135/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9136/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9137/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9138/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9139/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9140/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9141/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9142/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9143/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9144/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9145/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9146/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9147/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9148/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9149/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9150/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9151/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9152/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9153/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9154/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9155/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9156/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9157/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9158/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9159/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9160/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9161/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9162/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9163/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9164/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9165/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9166/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9167/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9168/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9169/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9170/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9171/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9172/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9173/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9174/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9175/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9176/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9177/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9178/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9179/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9180/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9181/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9182/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9183/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9184/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9185/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9186/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9187/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9188/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9189/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9190/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9191/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9192/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9193/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9194/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9195/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9196/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9197/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9198/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9199/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9200/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9201/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9202/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9203/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9204/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9205/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9206/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9207/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9208/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9209/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9210/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9211/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9212/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9213/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9215/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9216/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9217/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9218/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9219/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9220/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9221/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9222/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9223/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9224/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9225/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9226/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9227/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9228/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9229/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9230/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9231/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9232/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9233/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9234/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9235/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9236/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9237/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9238/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9239/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9240/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9241/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9242/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9243/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9244/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9245/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9246/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9247/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9248/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9249/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9250/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9251/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9252/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9253/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9254/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9255/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9256/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9257/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9258/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9259/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9260/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9261/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9262/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9263/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9264/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9265/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9266/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9267/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9268/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9269/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9270/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9271/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9272/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9273/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9274/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9275/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9276/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9277/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9278/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9279/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9280/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9281/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9282/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9283/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9284/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9285/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9286/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9287/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9288/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9289/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9290/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9291/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9292/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9293/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9294/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9295/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9296/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9297/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9298/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9299/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9300/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9301/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9302/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9303/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9304/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9305/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9306/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9307/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9308/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9309/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9310/10000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9311/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9312/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9313/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9314/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9315/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9316/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9317/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9318/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9319/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9320/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9321/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9322/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9323/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9324/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9325/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9326/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9327/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9328/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9329/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9330/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9331/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9332/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9333/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9334/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9335/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9336/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9337/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9338/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9339/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9340/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9341/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9342/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9343/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9344/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9345/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9346/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9347/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9348/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9349/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9350/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9351/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9352/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9353/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9354/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9355/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9356/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9357/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9358/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9359/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9360/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9361/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9362/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9363/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9364/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9365/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9366/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9367/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9368/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9369/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9370/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9371/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9372/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9373/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9374/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9375/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9376/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9377/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9378/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9379/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9380/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9381/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9382/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9383/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9384/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9385/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9386/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9387/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9388/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9389/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9390/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9391/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9392/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9393/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9394/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9395/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9396/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9397/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9398/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9399/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9400/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9401/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9402/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9403/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9404/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9405/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9406/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9407/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9408/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9409/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9410/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9411/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9412/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9413/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9414/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9415/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9416/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9417/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9418/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9419/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9420/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9421/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9422/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9423/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9424/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9425/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9426/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9427/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9428/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9429/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9430/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9431/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9432/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9433/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9434/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9435/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9436/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9437/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9438/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9439/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9440/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9441/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9442/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9443/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9444/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9445/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9446/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9447/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9448/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9449/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9450/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9451/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9452/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9453/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9454/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9455/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9456/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9457/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9458/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9459/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9460/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9461/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9462/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9463/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9464/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9465/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9466/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9467/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9468/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9469/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9470/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9471/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9472/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9473/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9474/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9475/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9476/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9477/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9478/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9479/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9480/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9481/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9482/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9483/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9484/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9485/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9486/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9487/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9488/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9489/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9490/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9491/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9492/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9493/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9494/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9495/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9496/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9497/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9498/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9499/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9500/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9501/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9502/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9503/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9504/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9505/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9506/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9507/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9508/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9509/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9510/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9511/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9512/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9513/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9514/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9515/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9516/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9517/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9518/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9519/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9520/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9521/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9522/10000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9523/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9524/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9525/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9526/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9527/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9528/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9529/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9530/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9531/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9532/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9533/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9534/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9535/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9536/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9537/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9538/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9539/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9540/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9541/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9542/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9543/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9544/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9545/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9546/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9547/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9548/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9549/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9550/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9551/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9552/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9553/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9554/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9555/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9556/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9557/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9558/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9559/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9560/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9561/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9562/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9563/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9564/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9565/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9566/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9567/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9568/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9569/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9570/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9571/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9572/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9573/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9574/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9575/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9576/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9577/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9578/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9579/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9580/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9581/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9582/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9583/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9584/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9585/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9586/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9587/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9588/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9589/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9590/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9591/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9592/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9593/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9594/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9595/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9596/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9597/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9598/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9599/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9600/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9601/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9602/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9603/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9604/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9605/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9606/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9607/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9608/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9609/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9610/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9611/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9612/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9613/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9614/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9615/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9616/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9617/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9618/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9619/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9620/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9621/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9622/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9623/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9624/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9625/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9626/10000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9627/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9628/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9629/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9630/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9631/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9632/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9633/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9634/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9635/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9636/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9637/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9638/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9639/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9640/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9641/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9642/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9643/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9644/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9645/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9646/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9647/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9648/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9649/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9650/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9651/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9652/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9653/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9654/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9655/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9656/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9657/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9658/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9659/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9660/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9661/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9662/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9663/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9664/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9665/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9666/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9667/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9668/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9669/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9670/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9671/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9672/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9673/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9674/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9675/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9676/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9677/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9678/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9679/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9680/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9681/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9682/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9683/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9684/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9685/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9686/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9687/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9688/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9689/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9690/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9691/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9692/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9693/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9694/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9695/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9696/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9697/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9698/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9699/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9700/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9701/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9702/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9703/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9704/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9705/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9706/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9707/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9708/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9709/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9710/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9711/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9712/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9713/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9714/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9715/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9716/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9717/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9718/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9719/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9720/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9721/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9722/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9723/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9724/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9725/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9726/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9727/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9728/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9729/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9730/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9731/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9732/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9733/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9734/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9735/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9736/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9737/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9738/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9739/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9740/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9741/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9742/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9743/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9744/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9745/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9746/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9747/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9748/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9749/10000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9750/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9751/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9752/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9753/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9754/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9755/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9756/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9757/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9758/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9759/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9760/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9761/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9762/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9763/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9764/10000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9765/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9766/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9767/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9768/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9769/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9770/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9771/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9772/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9773/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9774/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9775/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9776/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9777/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9778/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9779/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9780/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9781/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9782/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9783/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9784/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9785/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9786/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9787/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9788/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9789/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9790/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9791/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9792/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9793/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9794/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9795/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9796/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9797/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9798/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9799/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9800/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9801/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9802/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9803/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9804/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9805/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9806/10000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9807/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9808/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9809/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9810/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9811/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9812/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9813/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9814/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9815/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9816/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9817/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9818/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9819/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9820/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9821/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9822/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9823/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9824/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9825/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9826/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9827/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9828/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9829/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9830/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9831/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9832/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9833/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9834/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9835/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9836/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9837/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9838/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9839/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9840/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9841/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9842/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9843/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9844/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9845/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9846/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9847/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9848/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9849/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9850/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9851/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9852/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9853/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9854/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9855/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9856/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9857/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9858/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9859/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9860/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9861/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9862/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9863/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9864/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9865/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9866/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9867/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9868/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9869/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9870/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9871/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9872/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9873/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9874/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9875/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9876/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9877/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9878/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9879/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9880/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9881/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9882/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9883/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9884/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9885/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9886/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9887/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9888/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9889/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9890/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9891/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9892/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9893/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9894/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9895/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9896/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9897/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9898/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9899/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9900/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9901/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9902/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9903/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9904/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9905/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9906/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9907/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9908/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9909/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9910/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9911/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9912/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9913/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9914/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9915/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9916/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9917/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9918/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9919/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9920/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9921/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9922/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9923/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9924/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9925/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9926/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9927/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9928/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9929/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9930/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9931/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9932/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9933/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9934/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9935/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9936/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9937/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9938/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9939/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9940/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9941/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9942/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9943/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9944/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9945/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9946/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9947/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9948/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9949/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9950/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9951/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9952/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9953/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9954/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9955/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9956/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9957/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9958/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9959/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9960/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9961/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9962/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9963/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9964/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9965/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9966/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9967/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9968/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9969/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9970/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9971/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9972/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9973/10000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9974/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9975/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9976/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9977/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9978/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9979/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9980/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9981/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9982/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9983/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9984/10000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9985/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9986/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9987/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9988/10000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9989/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9990/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9991/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9992/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9993/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9994/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9995/10000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9996/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9997/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9998/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 9999/10000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8636\n",
      "Epoch 10000/10000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21d10b76800>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d9c5fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[10.990772 ],\n",
       "        [ 1.8886737]], dtype=float32),\n",
       " array([-5.764316], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8123ce5",
   "metadata": {},
   "source": [
    "#### This means we get w1 = 10.990772, w2 = 1.8886737, bias = -5.764316 from tensorflow implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dcdb1b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.981535973278524, 1.8876850545628159, -5.75962085462742)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cofficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44145350",
   "metadata": {},
   "source": [
    "#### And we get w1 = 10.981535973278524, w2 = 1.8876850545628159, bias = -5.75962085462742 from our code implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80fc36e",
   "metadata": {},
   "source": [
    "## Hence from both we get the values which are very very very close to eachother"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
